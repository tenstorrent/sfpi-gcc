// { dg-options "-fpreprocessed -mcpu=tt-wh-tensix -O2 -fno-exceptions -fno-rtti" }




       

       






namespace std
{
  typedef unsigned int size_t;
  typedef int ptrdiff_t;


  typedef decltype(nullptr) nullptr_t;


#pragma GCC visibility push(default)


  extern "C++" __attribute__ ((__noreturn__, __always_inline__))
  inline void __terminate() noexcept
  {
    void terminate() noexcept __attribute__ ((__noreturn__));
    terminate();
  }
#pragma GCC visibility pop
}
namespace std
{
  inline namespace __cxx11 __attribute__((__abi_tag__ ("cxx11"))) { }
}
namespace __gnu_cxx
{
  inline namespace __cxx11 __attribute__((__abi_tag__ ("cxx11"))) { }
}
namespace std
{
#pragma GCC visibility push(default)




  constexpr inline bool
  __is_constant_evaluated() noexcept
  {





    return __builtin_is_constant_evaluated();



  }
#pragma GCC visibility pop
}











extern "C" {


}
extern "C" {



typedef signed char __int8_t;

typedef unsigned char __uint8_t;
typedef short int __int16_t;

typedef short unsigned int __uint16_t;
typedef long int __int32_t;

typedef long unsigned int __uint32_t;
typedef long long int __int64_t;

typedef long long unsigned int __uint64_t;
typedef signed char __int_least8_t;

typedef unsigned char __uint_least8_t;
typedef short int __int_least16_t;

typedef short unsigned int __uint_least16_t;
typedef long int __int_least32_t;

typedef long unsigned int __uint_least32_t;
typedef long long int __int_least64_t;

typedef long long unsigned int __uint_least64_t;
typedef long long int __intmax_t;







typedef long long unsigned int __uintmax_t;







typedef int __intptr_t;

typedef unsigned int __uintptr_t;
}
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
       
extern "C" {




typedef __int8_t int8_t ;



typedef __uint8_t uint8_t ;







typedef __int16_t int16_t ;



typedef __uint16_t uint16_t ;







typedef __int32_t int32_t ;



typedef __uint32_t uint32_t ;







typedef __int64_t int64_t ;



typedef __uint64_t uint64_t ;






typedef __intmax_t intmax_t;




typedef __uintmax_t uintmax_t;




typedef __intptr_t intptr_t;




typedef __uintptr_t uintptr_t;




}


extern "C" {



typedef __int_least8_t int_least8_t;
typedef __uint_least8_t uint_least8_t;




typedef __int_least16_t int_least16_t;
typedef __uint_least16_t uint_least16_t;




typedef __int_least32_t int_least32_t;
typedef __uint_least32_t uint_least32_t;




typedef __int_least64_t int_least64_t;
typedef __uint_least64_t uint_least64_t;
  typedef int int_fast8_t;
  typedef unsigned int uint_fast8_t;
  typedef int int_fast16_t;
  typedef unsigned int uint_fast16_t;
  typedef int int_fast32_t;
  typedef unsigned int uint_fast32_t;
  typedef long long int int_fast64_t;
  typedef long long unsigned int uint_fast64_t;
}


namespace std
{

  using ::int8_t;
  using ::int16_t;
  using ::int32_t;
  using ::int64_t;

  using ::int_fast8_t;
  using ::int_fast16_t;
  using ::int_fast32_t;
  using ::int_fast64_t;

  using ::int_least8_t;
  using ::int_least16_t;
  using ::int_least32_t;
  using ::int_least64_t;

  using ::intmax_t;
  using ::intptr_t;

  using ::uint8_t;
  using ::uint16_t;
  using ::uint32_t;
  using ::uint64_t;

  using ::uint_fast8_t;
  using ::uint_fast16_t;
  using ::uint_fast32_t;
  using ::uint_fast64_t;

  using ::uint_least8_t;
  using ::uint_least16_t;
  using ::uint_least32_t;
  using ::uint_least64_t;

  using ::uintmax_t;
  using ::uintptr_t;





}




       




enum ProgrammableCoreType {
    TENSIX = 0,
    ACTIVE_ETH = 1,
    IDLE_ETH = 2,
    COUNT = 3,
};

enum class TensixProcessorTypes : uint8_t { DM0 = 0, DM1 = 1, MATH0 = 2, MATH1 = 3, MATH2 = 4, COUNT = 5 };

enum class EthProcessorTypes : uint8_t { DM0 = 0, COUNT = 1 };

constexpr uint8_t MaxProcessorsPerCoreType = 5;
constexpr uint8_t MaxDMProcessorsPerCoreType = 2;
constexpr uint8_t NumTensixDispatchClasses = 3;
constexpr uint8_t NumEthDispatchClasses = 1;
constexpr uint8_t noc_size_x = 10;
constexpr uint8_t noc_size_y = 12;
constexpr uint8_t tensix_harvest_axis = 0x1;




       







       

namespace ckernel
{


struct semaphore
{
    constexpr static uint32_t MATH_PACK = 1;
    constexpr static uint32_t UNPACK_TO_DEST = 2;
    constexpr static uint32_t UNPACK_OPERAND_SYNC = 3;
    constexpr static uint32_t PACK_DONE = 4;
    constexpr static uint32_t UNPACK_SYNC = 5;


    constexpr static uint32_t UNPACK_MATH_DONE = 6;
    constexpr static uint32_t MATH_DONE = 7;

    constexpr static uint16_t t6_sem(const uint8_t sem_index)
    {
        return (1 << sem_index);
    }
};

struct mutex
{
    constexpr static uint32_t REG_RMW = 0;
};

constexpr uint8_t PC_BUF_SEMAPHORE_BASE = 8;
constexpr uint8_t MATH_HALF_DEST_SIZE = 32;
constexpr uint8_t MAX_CONFIG_STATES = 2;


enum firmware_msg_e
{
    FLIP_STATE_ID = 1,
    RUN_INSTRUCTIONS = 2,
    RESET_DEST_OFFSET_ID = 3,
    SET_PERF_SCRATCH = 4
};

}
union tt_uint64_t {
    uint64_t v;
    struct {
        uint32_t hi;
        uint32_t lo;
    };
};




inline __attribute__((always_inline)) uint64_t tt_l1_load(tt_uint64_t __attribute__((rvtt_l1_ptr))* p) {
    tt_uint64_t v;

    v.hi = p->hi;
    v.lo = p->lo;
    return v.v;
}

inline __attribute__((always_inline)) uint64_t tt_l1_load(volatile tt_uint64_t* __attribute__((rvtt_l1_ptr)) p) {
    tt_uint64_t v;

    v.hi = p->hi;
    v.lo = p->lo;
    return v.v;
}

extern uint32_t cfg_state_id;
extern uint32_t unp_cfg_context;

extern uint32_t volatile __attribute__((rvtt_l1_ptr)) l1_buffer[16];

extern uint32_t pack_sync_tile_dst_ptr;
extern uint32_t math_sync_tile_dst_index;

extern uint32_t __local_mem_rodata_start_addr[];
extern uint32_t __local_mem_rodata_end_addr[];
extern uint32_t __firmware_start[];




       








       

namespace std __attribute__ ((__visibility__ ("default")))
{







  enum float_round_style
  {
    round_indeterminate = -1,
    round_toward_zero = 0,
    round_to_nearest = 1,
    round_toward_infinity = 2,
    round_toward_neg_infinity = 3
  };







  enum float_denorm_style
  {

    denorm_indeterminate = -1,

    denorm_absent = 0,

    denorm_present = 1
  };
  struct __numeric_limits_base
  {


    static constexpr bool is_specialized = false;




    static constexpr int digits = 0;


    static constexpr int digits10 = 0;




    static constexpr int max_digits10 = 0;



    static constexpr bool is_signed = false;


    static constexpr bool is_integer = false;




    static constexpr bool is_exact = false;



    static constexpr int radix = 0;



    static constexpr int min_exponent = 0;



    static constexpr int min_exponent10 = 0;




    static constexpr int max_exponent = 0;



    static constexpr int max_exponent10 = 0;


    static constexpr bool has_infinity = false;



    static constexpr bool has_quiet_NaN = false;



    static constexpr bool has_signaling_NaN = false;


    static constexpr float_denorm_style has_denorm = denorm_absent;



    static constexpr bool has_denorm_loss = false;



    static constexpr bool is_iec559 = false;




    static constexpr bool is_bounded = false;
    static constexpr bool is_modulo = false;


    static constexpr bool traps = false;


    static constexpr bool tinyness_before = false;




    static constexpr float_round_style round_style =
          round_toward_zero;
  };
  template<typename _Tp>
    struct numeric_limits : public __numeric_limits_base
    {


      static constexpr _Tp
      min() noexcept { return _Tp(); }


      static constexpr _Tp
      max() noexcept { return _Tp(); }




      static constexpr _Tp
      lowest() noexcept { return _Tp(); }




      static constexpr _Tp
      epsilon() noexcept { return _Tp(); }


      static constexpr _Tp
      round_error() noexcept { return _Tp(); }


      static constexpr _Tp
      infinity() noexcept { return _Tp(); }



      static constexpr _Tp
      quiet_NaN() noexcept { return _Tp(); }



      static constexpr _Tp
      signaling_NaN() noexcept { return _Tp(); }




      static constexpr _Tp
      denorm_min() noexcept { return _Tp(); }
    };




  template<typename _Tp>
    struct numeric_limits<const _Tp>
    : public numeric_limits<_Tp> { };

  template<typename _Tp>
    struct numeric_limits<volatile _Tp>
    : public numeric_limits<_Tp> { };

  template<typename _Tp>
    struct numeric_limits<const volatile _Tp>
    : public numeric_limits<_Tp> { };
  template<>
    struct numeric_limits<bool>
    {
      static constexpr bool is_specialized = true;

      static constexpr bool
      min() noexcept { return false; }

      static constexpr bool
      max() noexcept { return true; }


      static constexpr bool
      lowest() noexcept { return min(); }

      static constexpr int digits = 1;
      static constexpr int digits10 = 0;

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr bool
      epsilon() noexcept { return false; }

      static constexpr bool
      round_error() noexcept { return false; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr bool
      infinity() noexcept { return false; }

      static constexpr bool
      quiet_NaN() noexcept { return false; }

      static constexpr bool
      signaling_NaN() noexcept { return false; }

      static constexpr bool
      denorm_min() noexcept { return false; }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;




      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<char>
    {
      static constexpr bool is_specialized = true;

      static constexpr char
      min() noexcept { return (((char)(-1) < 0) ? -(((char)(-1) < 0) ? (((((char)1 << ((sizeof(char) * 8 - ((char)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char)0) - 1 : (char)0); }

      static constexpr char
      max() noexcept { return (((char)(-1) < 0) ? (((((char)1 << ((sizeof(char) * 8 - ((char)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char)0); }


      static constexpr char
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(char) * 8 - ((char)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char) * 8 - ((char)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = ((char)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char
      epsilon() noexcept { return 0; }

      static constexpr char
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr
      char infinity() noexcept { return char(); }

      static constexpr char
      quiet_NaN() noexcept { return char(); }

      static constexpr char
      signaling_NaN() noexcept { return char(); }

      static constexpr char
      denorm_min() noexcept { return static_cast<char>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<signed char>
    {
      static constexpr bool is_specialized = true;

      static constexpr signed char
      min() noexcept { return -0x7f - 1; }

      static constexpr signed char
      max() noexcept { return 0x7f; }


      static constexpr signed char
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(signed char) * 8 - ((signed char)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(signed char) * 8 - ((signed char)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr signed char
      epsilon() noexcept { return 0; }

      static constexpr signed char
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr signed char
      infinity() noexcept { return static_cast<signed char>(0); }

      static constexpr signed char
      quiet_NaN() noexcept { return static_cast<signed char>(0); }

      static constexpr signed char
      signaling_NaN() noexcept
      { return static_cast<signed char>(0); }

      static constexpr signed char
      denorm_min() noexcept
      { return static_cast<signed char>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned char>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned char
      min() noexcept { return 0; }

      static constexpr unsigned char
      max() noexcept { return 0x7f * 2U + 1; }


      static constexpr unsigned char
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned char) * 8 - ((unsigned char)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned char) * 8 - ((unsigned char)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned char
      epsilon() noexcept { return 0; }

      static constexpr unsigned char
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned char
      infinity() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr unsigned char
      quiet_NaN() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr unsigned char
      signaling_NaN() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr unsigned char
      denorm_min() noexcept
      { return static_cast<unsigned char>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<wchar_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr wchar_t
      min() noexcept { return (((wchar_t)(-1) < 0) ? -(((wchar_t)(-1) < 0) ? (((((wchar_t)1 << ((sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(wchar_t)0) - 1 : (wchar_t)0); }

      static constexpr wchar_t
      max() noexcept { return (((wchar_t)(-1) < 0) ? (((((wchar_t)1 << ((sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(wchar_t)0); }


      static constexpr wchar_t
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(wchar_t) * 8 - ((wchar_t)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = ((wchar_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr wchar_t
      epsilon() noexcept { return 0; }

      static constexpr wchar_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr wchar_t
      infinity() noexcept { return wchar_t(); }

      static constexpr wchar_t
      quiet_NaN() noexcept { return wchar_t(); }

      static constexpr wchar_t
      signaling_NaN() noexcept { return wchar_t(); }

      static constexpr wchar_t
      denorm_min() noexcept { return wchar_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };
  template<>
    struct numeric_limits<char16_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr char16_t
      min() noexcept { return (((char16_t)(-1) < 0) ? -(((char16_t)(-1) < 0) ? (((((char16_t)1 << ((sizeof(char16_t) * 8 - ((char16_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char16_t)0) - 1 : (char16_t)0); }

      static constexpr char16_t
      max() noexcept { return (((char16_t)(-1) < 0) ? (((((char16_t)1 << ((sizeof(char16_t) * 8 - ((char16_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char16_t)0); }

      static constexpr char16_t
      lowest() noexcept { return min(); }

      static constexpr int digits = (sizeof(char16_t) * 8 - ((char16_t)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char16_t) * 8 - ((char16_t)(-1) < 0)) * 643L / 2136);
      static constexpr int max_digits10 = 0;
      static constexpr bool is_signed = ((char16_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char16_t
      epsilon() noexcept { return 0; }

      static constexpr char16_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr char16_t
      infinity() noexcept { return char16_t(); }

      static constexpr char16_t
      quiet_NaN() noexcept { return char16_t(); }

      static constexpr char16_t
      signaling_NaN() noexcept { return char16_t(); }

      static constexpr char16_t
      denorm_min() noexcept { return char16_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style = round_toward_zero;
    };


  template<>
    struct numeric_limits<char32_t>
    {
      static constexpr bool is_specialized = true;

      static constexpr char32_t
      min() noexcept { return (((char32_t)(-1) < 0) ? -(((char32_t)(-1) < 0) ? (((((char32_t)1 << ((sizeof(char32_t) * 8 - ((char32_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char32_t)0) - 1 : (char32_t)0); }

      static constexpr char32_t
      max() noexcept { return (((char32_t)(-1) < 0) ? (((((char32_t)1 << ((sizeof(char32_t) * 8 - ((char32_t)(-1) < 0)) - 1)) - 1) << 1) + 1) : ~(char32_t)0); }

      static constexpr char32_t
      lowest() noexcept { return min(); }

      static constexpr int digits = (sizeof(char32_t) * 8 - ((char32_t)(-1) < 0));
      static constexpr int digits10 = ((sizeof(char32_t) * 8 - ((char32_t)(-1) < 0)) * 643L / 2136);
      static constexpr int max_digits10 = 0;
      static constexpr bool is_signed = ((char32_t)(-1) < 0);
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr char32_t
      epsilon() noexcept { return 0; }

      static constexpr char32_t
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr char32_t
      infinity() noexcept { return char32_t(); }

      static constexpr char32_t
      quiet_NaN() noexcept { return char32_t(); }

      static constexpr char32_t
      signaling_NaN() noexcept { return char32_t(); }

      static constexpr char32_t
      denorm_min() noexcept { return char32_t(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = !is_signed;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style = round_toward_zero;
    };



  template<>
    struct numeric_limits<short>
    {
      static constexpr bool is_specialized = true;

      static constexpr short
      min() noexcept { return -0x7fff - 1; }

      static constexpr short
      max() noexcept { return 0x7fff; }


      static constexpr short
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(short) * 8 - ((short)(-1) < 0));
      static constexpr int digits10 = ((sizeof(short) * 8 - ((short)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr short
      epsilon() noexcept { return 0; }

      static constexpr short
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr short
      infinity() noexcept { return short(); }

      static constexpr short
      quiet_NaN() noexcept { return short(); }

      static constexpr short
      signaling_NaN() noexcept { return short(); }

      static constexpr short
      denorm_min() noexcept { return short(); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned short>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned short
      min() noexcept { return 0; }

      static constexpr unsigned short
      max() noexcept { return 0x7fff * 2U + 1; }


      static constexpr unsigned short
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned short) * 8 - ((unsigned short)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned short) * 8 - ((unsigned short)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned short
      epsilon() noexcept { return 0; }

      static constexpr unsigned short
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned short
      infinity() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr unsigned short
      quiet_NaN() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr unsigned short
      signaling_NaN() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr unsigned short
      denorm_min() noexcept
      { return static_cast<unsigned short>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<int>
    {
      static constexpr bool is_specialized = true;

      static constexpr int
      min() noexcept { return -0x7fffffff - 1; }

      static constexpr int
      max() noexcept { return 0x7fffffff; }


      static constexpr int
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(int) * 8 - ((int)(-1) < 0));
      static constexpr int digits10 = ((sizeof(int) * 8 - ((int)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr int
      epsilon() noexcept { return 0; }

      static constexpr int
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr int
      infinity() noexcept { return static_cast<int>(0); }

      static constexpr int
      quiet_NaN() noexcept { return static_cast<int>(0); }

      static constexpr int
      signaling_NaN() noexcept { return static_cast<int>(0); }

      static constexpr int
      denorm_min() noexcept { return static_cast<int>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned int>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned int
      min() noexcept { return 0; }

      static constexpr unsigned int
      max() noexcept { return 0x7fffffff * 2U + 1; }


      static constexpr unsigned int
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned int) * 8 - ((unsigned int)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned int) * 8 - ((unsigned int)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned int
      epsilon() noexcept { return 0; }

      static constexpr unsigned int
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned int
      infinity() noexcept { return static_cast<unsigned int>(0); }

      static constexpr unsigned int
      quiet_NaN() noexcept
      { return static_cast<unsigned int>(0); }

      static constexpr unsigned int
      signaling_NaN() noexcept
      { return static_cast<unsigned int>(0); }

      static constexpr unsigned int
      denorm_min() noexcept
      { return static_cast<unsigned int>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<long>
    {
      static constexpr bool is_specialized = true;

      static constexpr long
      min() noexcept { return -0x7fffffffL - 1; }

      static constexpr long
      max() noexcept { return 0x7fffffffL; }


      static constexpr long
      lowest() noexcept { return min(); }


      static constexpr int digits = (sizeof(long) * 8 - ((long)(-1) < 0));
      static constexpr int digits10 = ((sizeof(long) * 8 - ((long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr long
      epsilon() noexcept { return 0; }

      static constexpr long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr long
      infinity() noexcept { return static_cast<long>(0); }

      static constexpr long
      quiet_NaN() noexcept { return static_cast<long>(0); }

      static constexpr long
      signaling_NaN() noexcept { return static_cast<long>(0); }

      static constexpr long
      denorm_min() noexcept { return static_cast<long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned long>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned long
      min() noexcept { return 0; }

      static constexpr unsigned long
      max() noexcept { return 0x7fffffffL * 2UL + 1; }


      static constexpr unsigned long
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned long) * 8 - ((unsigned long)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned long) * 8 - ((unsigned long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned long
      epsilon() noexcept { return 0; }

      static constexpr unsigned long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned long
      infinity() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr unsigned long
      quiet_NaN() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr unsigned long
      signaling_NaN() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr unsigned long
      denorm_min() noexcept
      { return static_cast<unsigned long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<long long>
    {
      static constexpr bool is_specialized = true;

      static constexpr long long
      min() noexcept { return -0x7fffffffffffffffLL - 1; }

      static constexpr long long
      max() noexcept { return 0x7fffffffffffffffLL; }


      static constexpr long long
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(long long) * 8 - ((long long)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(long long) * 8 - ((long long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr long long
      epsilon() noexcept { return 0; }

      static constexpr long long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr long long
      infinity() noexcept { return static_cast<long long>(0); }

      static constexpr long long
      quiet_NaN() noexcept { return static_cast<long long>(0); }

      static constexpr long long
      signaling_NaN() noexcept
      { return static_cast<long long>(0); }

      static constexpr long long
      denorm_min() noexcept { return static_cast<long long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };


  template<>
    struct numeric_limits<unsigned long long>
    {
      static constexpr bool is_specialized = true;

      static constexpr unsigned long long
      min() noexcept { return 0; }

      static constexpr unsigned long long
      max() noexcept { return 0x7fffffffffffffffLL * 2ULL + 1; }


      static constexpr unsigned long long
      lowest() noexcept { return min(); }


      static constexpr int digits
       = (sizeof(unsigned long long) * 8 - ((unsigned long long)(-1) < 0));
      static constexpr int digits10
       = ((sizeof(unsigned long long) * 8 - ((unsigned long long)(-1) < 0)) * 643L / 2136);

      static constexpr int max_digits10 = 0;

      static constexpr bool is_signed = false;
      static constexpr bool is_integer = true;
      static constexpr bool is_exact = true;
      static constexpr int radix = 2;

      static constexpr unsigned long long
      epsilon() noexcept { return 0; }

      static constexpr unsigned long long
      round_error() noexcept { return 0; }

      static constexpr int min_exponent = 0;
      static constexpr int min_exponent10 = 0;
      static constexpr int max_exponent = 0;
      static constexpr int max_exponent10 = 0;

      static constexpr bool has_infinity = false;
      static constexpr bool has_quiet_NaN = false;
      static constexpr bool has_signaling_NaN = false;
      static constexpr float_denorm_style has_denorm
       = denorm_absent;
      static constexpr bool has_denorm_loss = false;

      static constexpr unsigned long long
      infinity() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr unsigned long long
      quiet_NaN() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr unsigned long long
      signaling_NaN() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr unsigned long long
      denorm_min() noexcept
      { return static_cast<unsigned long long>(0); }

      static constexpr bool is_iec559 = false;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = true;

      static constexpr bool traps = true;
      static constexpr bool tinyness_before = false;
      static constexpr float_round_style round_style
       = round_toward_zero;
    };
  template<>
    struct numeric_limits<float>
    {
      static constexpr bool is_specialized = true;

      static constexpr float
      min() noexcept { return 1.17549435082228750796873653722224568e-38F; }

      static constexpr float
      max() noexcept { return 3.40282346638528859811704183484516925e+38F; }


      static constexpr float
      lowest() noexcept { return -3.40282346638528859811704183484516925e+38F; }


      static constexpr int digits = 24;
      static constexpr int digits10 = 6;

      static constexpr int max_digits10
  = (2 + (24) * 643L / 2136);

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr float
      epsilon() noexcept { return 1.19209289550781250000000000000000000e-7F; }

      static constexpr float
      round_error() noexcept { return 0.5F; }

      static constexpr int min_exponent = (-125);
      static constexpr int min_exponent10 = (-37);
      static constexpr int max_exponent = 128;
      static constexpr int max_exponent10 = 38;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;
      static constexpr bool has_signaling_NaN = has_quiet_NaN;
      static constexpr float_denorm_style has_denorm
 = bool(1) ? denorm_present : denorm_absent;
      static constexpr bool has_denorm_loss
       = false;

      static constexpr float
      infinity() noexcept { return __builtin_huge_valf(); }

      static constexpr float
      quiet_NaN() noexcept { return __builtin_nanf(""); }

      static constexpr float
      signaling_NaN() noexcept { return __builtin_nansf(""); }

      static constexpr float
      denorm_min() noexcept { return 1.40129846432481707092372958328991613e-45F; }

      static constexpr bool is_iec559
 = has_infinity && has_quiet_NaN && has_denorm == denorm_present;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before
       = false;
      static constexpr float_round_style round_style
       = round_to_nearest;
    };






  template<>
    struct numeric_limits<double>
    {
      static constexpr bool is_specialized = true;

      static constexpr double
      min() noexcept { return double(2.22507385850720138309023271733240406e-308L); }

      static constexpr double
      max() noexcept { return double(1.79769313486231570814527423731704357e+308L); }


      static constexpr double
      lowest() noexcept { return -double(1.79769313486231570814527423731704357e+308L); }


      static constexpr int digits = 53;
      static constexpr int digits10 = 15;

      static constexpr int max_digits10
  = (2 + (53) * 643L / 2136);

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr double
      epsilon() noexcept { return double(2.22044604925031308084726333618164062e-16L); }

      static constexpr double
      round_error() noexcept { return 0.5; }

      static constexpr int min_exponent = (-1021);
      static constexpr int min_exponent10 = (-307);
      static constexpr int max_exponent = 1024;
      static constexpr int max_exponent10 = 308;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;
      static constexpr bool has_signaling_NaN = has_quiet_NaN;
      static constexpr float_denorm_style has_denorm
 = bool(1) ? denorm_present : denorm_absent;
      static constexpr bool has_denorm_loss
        = false;

      static constexpr double
      infinity() noexcept { return __builtin_huge_val(); }

      static constexpr double
      quiet_NaN() noexcept { return __builtin_nan(""); }

      static constexpr double
      signaling_NaN() noexcept { return __builtin_nans(""); }

      static constexpr double
      denorm_min() noexcept { return double(4.94065645841246544176568792868221372e-324L); }

      static constexpr bool is_iec559
 = has_infinity && has_quiet_NaN && has_denorm == denorm_present;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before
       = false;
      static constexpr float_round_style round_style
       = round_to_nearest;
    };






  template<>
    struct numeric_limits<long double>
    {
      static constexpr bool is_specialized = true;

      static constexpr long double
      min() noexcept { return 3.36210314311209350626267781732175260e-4932L; }

      static constexpr long double
      max() noexcept { return 1.18973149535723176508575932662800702e+4932L; }


      static constexpr long double
      lowest() noexcept { return -1.18973149535723176508575932662800702e+4932L; }


      static constexpr int digits = 113;
      static constexpr int digits10 = 33;

      static constexpr int max_digits10
  = (2 + (113) * 643L / 2136);

      static constexpr bool is_signed = true;
      static constexpr bool is_integer = false;
      static constexpr bool is_exact = false;
      static constexpr int radix = 2;

      static constexpr long double
      epsilon() noexcept { return 1.92592994438723585305597794258492732e-34L; }

      static constexpr long double
      round_error() noexcept { return 0.5L; }

      static constexpr int min_exponent = (-16381);
      static constexpr int min_exponent10 = (-4931);
      static constexpr int max_exponent = 16384;
      static constexpr int max_exponent10 = 4932;

      static constexpr bool has_infinity = 1;
      static constexpr bool has_quiet_NaN = 1;
      static constexpr bool has_signaling_NaN = has_quiet_NaN;
      static constexpr float_denorm_style has_denorm
 = bool(1) ? denorm_present : denorm_absent;
      static constexpr bool has_denorm_loss
 = false;

      static constexpr long double
      infinity() noexcept { return __builtin_huge_vall(); }

      static constexpr long double
      quiet_NaN() noexcept { return __builtin_nanl(""); }

      static constexpr long double
      signaling_NaN() noexcept { return __builtin_nansl(""); }

      static constexpr long double
      denorm_min() noexcept { return 6.47517511943802511092443895822764655e-4966L; }

      static constexpr bool is_iec559
 = has_infinity && has_quiet_NaN && has_denorm == denorm_present;
      static constexpr bool is_bounded = true;
      static constexpr bool is_modulo = false;

      static constexpr bool traps = false;
      static constexpr bool tinyness_before =
      false;
      static constexpr float_round_style round_style =
            round_to_nearest;
    };






}
       







namespace std __attribute__ ((__visibility__ ("default")))
{


  template<typename _Tp>
    class reference_wrapper;
  template<typename _Tp, _Tp __v>
    struct integral_constant
    {
      static constexpr _Tp value = __v;
      typedef _Tp value_type;
      typedef integral_constant<_Tp, __v> type;
      constexpr operator value_type() const noexcept { return value; }




      constexpr value_type operator()() const noexcept { return value; }

    };







  using true_type = integral_constant<bool, true>;


  using false_type = integral_constant<bool, false>;



  template<bool __v>
    using __bool_constant = integral_constant<bool, __v>;






  template<bool __v>
    using bool_constant = integral_constant<bool, __v>;




  template<bool>
    struct __conditional
    {
      template<typename _Tp, typename>
 using type = _Tp;
    };

  template<>
    struct __conditional<false>
    {
      template<typename, typename _Up>
 using type = _Up;
    };


  template<bool _Cond, typename _If, typename _Else>
    using __conditional_t
      = typename __conditional<_Cond>::template type<_If, _Else>;


  template <typename _Type>
    struct __type_identity
    { using type = _Type; };

  template<typename _Tp>
    using __type_identity_t = typename __type_identity<_Tp>::type;

  template<typename...>
    struct __or_;

  template<>
    struct __or_<>
    : public false_type
    { };

  template<typename _B1>
    struct __or_<_B1>
    : public _B1
    { };

  template<typename _B1, typename _B2>
    struct __or_<_B1, _B2>
    : public __conditional_t<_B1::value, _B1, _B2>
    { };

  template<typename _B1, typename _B2, typename _B3, typename... _Bn>
    struct __or_<_B1, _B2, _B3, _Bn...>
    : public __conditional_t<_B1::value, _B1, __or_<_B2, _B3, _Bn...>>
    { };

  template<typename...>
    struct __and_;

  template<>
    struct __and_<>
    : public true_type
    { };

  template<typename _B1>
    struct __and_<_B1>
    : public _B1
    { };

  template<typename _B1, typename _B2>
    struct __and_<_B1, _B2>
    : public __conditional_t<_B1::value, _B2, _B1>
    { };

  template<typename _B1, typename _B2, typename _B3, typename... _Bn>
    struct __and_<_B1, _B2, _B3, _Bn...>
    : public __conditional_t<_B1::value, __and_<_B2, _B3, _Bn...>, _B1>
    { };

  template<typename _Pp>
    struct __not_
    : public __bool_constant<!bool(_Pp::value)>
    { };





  template<typename... _Bn>
    inline constexpr bool __or_v = __or_<_Bn...>::value;
  template<typename... _Bn>
    inline constexpr bool __and_v = __and_<_Bn...>::value;




  template<typename... _Bn>
    struct conjunction
    : __and_<_Bn...>
    { };

  template<typename... _Bn>
    struct disjunction
    : __or_<_Bn...>
    { };

  template<typename _Pp>
    struct negation
    : __not_<_Pp>
    { };




  template<typename... _Bn>
    inline constexpr bool conjunction_v = conjunction<_Bn...>::value;

  template<typename... _Bn>
    inline constexpr bool disjunction_v = disjunction<_Bn...>::value;

  template<typename _Pp>
    inline constexpr bool negation_v = negation<_Pp>::value;





  template<typename>
    struct is_reference;
  template<typename>
    struct is_function;
  template<typename>
    struct is_void;
  template<typename>
    struct remove_cv;
  template<typename>
    struct is_const;


  template<typename>
    struct __is_array_unknown_bounds;




  template <typename _Tp, size_t = sizeof(_Tp)>
    constexpr true_type __is_complete_or_unbounded(__type_identity<_Tp>)
    { return {}; }

  template <typename _TypeIdentity,
      typename _NestedType = typename _TypeIdentity::type>
    constexpr typename __or_<
      is_reference<_NestedType>,
      is_function<_NestedType>,
      is_void<_NestedType>,
      __is_array_unknown_bounds<_NestedType>
    >::type __is_complete_or_unbounded(_TypeIdentity)
    { return {}; }






  template<typename _Tp>
    struct __success_type
    { typedef _Tp type; };

  struct __failure_type
  { };


  template<typename _Tp>
    using __remove_cv_t = typename remove_cv<_Tp>::type;



  template<typename>
    struct __is_void_helper
    : public false_type { };

  template<>
    struct __is_void_helper<void>
    : public true_type { };



  template<typename _Tp>
    struct is_void
    : public __is_void_helper<__remove_cv_t<_Tp>>::type
    { };


  template<typename>
    struct __is_integral_helper
    : public false_type { };

  template<>
    struct __is_integral_helper<bool>
    : public true_type { };

  template<>
    struct __is_integral_helper<char>
    : public true_type { };

  template<>
    struct __is_integral_helper<signed char>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned char>
    : public true_type { };




  template<>
    struct __is_integral_helper<wchar_t>
    : public true_type { };







  template<>
    struct __is_integral_helper<char16_t>
    : public true_type { };

  template<>
    struct __is_integral_helper<char32_t>
    : public true_type { };

  template<>
    struct __is_integral_helper<short>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned short>
    : public true_type { };

  template<>
    struct __is_integral_helper<int>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned int>
    : public true_type { };

  template<>
    struct __is_integral_helper<long>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned long>
    : public true_type { };

  template<>
    struct __is_integral_helper<long long>
    : public true_type { };

  template<>
    struct __is_integral_helper<unsigned long long>
    : public true_type { };
  template<typename _Tp>
    struct is_integral
    : public __is_integral_helper<__remove_cv_t<_Tp>>::type
    { };


  template<typename>
    struct __is_floating_point_helper
    : public false_type { };

  template<>
    struct __is_floating_point_helper<float>
    : public true_type { };

  template<>
    struct __is_floating_point_helper<double>
    : public true_type { };

  template<>
    struct __is_floating_point_helper<long double>
    : public true_type { };
  template<typename _Tp>
    struct is_floating_point
    : public __is_floating_point_helper<__remove_cv_t<_Tp>>::type
    { };


  template<typename>
    struct is_array
    : public false_type { };

  template<typename _Tp, std::size_t _Size>
    struct is_array<_Tp[_Size]>
    : public true_type { };

  template<typename _Tp>
    struct is_array<_Tp[]>
    : public true_type { };

  template<typename>
    struct __is_pointer_helper
    : public false_type { };

  template<typename _Tp>
    struct __is_pointer_helper<_Tp*>
    : public true_type { };


  template<typename _Tp>
    struct is_pointer
    : public __is_pointer_helper<__remove_cv_t<_Tp>>::type
    { };


  template<typename>
    struct is_lvalue_reference
    : public false_type { };

  template<typename _Tp>
    struct is_lvalue_reference<_Tp&>
    : public true_type { };


  template<typename>
    struct is_rvalue_reference
    : public false_type { };

  template<typename _Tp>
    struct is_rvalue_reference<_Tp&&>
    : public true_type { };

  template<typename>
    struct __is_member_object_pointer_helper
    : public false_type { };

  template<typename _Tp, typename _Cp>
    struct __is_member_object_pointer_helper<_Tp _Cp::*>
    : public __not_<is_function<_Tp>>::type { };


  template<typename _Tp>
    struct is_member_object_pointer
    : public __is_member_object_pointer_helper<__remove_cv_t<_Tp>>::type
    { };

  template<typename>
    struct __is_member_function_pointer_helper
    : public false_type { };

  template<typename _Tp, typename _Cp>
    struct __is_member_function_pointer_helper<_Tp _Cp::*>
    : public is_function<_Tp>::type { };


  template<typename _Tp>
    struct is_member_function_pointer
    : public __is_member_function_pointer_helper<__remove_cv_t<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_enum
    : public integral_constant<bool, __is_enum(_Tp)>
    { };


  template<typename _Tp>
    struct is_union
    : public integral_constant<bool, __is_union(_Tp)>
    { };


  template<typename _Tp>
    struct is_class
    : public integral_constant<bool, __is_class(_Tp)>
    { };


  template<typename _Tp>
    struct is_function
    : public __bool_constant<!is_const<const _Tp>::value> { };

  template<typename _Tp>
    struct is_function<_Tp&>
    : public false_type { };

  template<typename _Tp>
    struct is_function<_Tp&&>
    : public false_type { };



  template<typename>
    struct __is_null_pointer_helper
    : public false_type { };

  template<>
    struct __is_null_pointer_helper<std::nullptr_t>
    : public true_type { };


  template<typename _Tp>
    struct is_null_pointer
    : public __is_null_pointer_helper<__remove_cv_t<_Tp>>::type
    { };



  template<typename _Tp>
    struct __is_nullptr_t
    : public is_null_pointer<_Tp>
    { } __attribute__ ((__deprecated__ ("use '" "std::is_null_pointer" "' instead")));




  template<typename _Tp>
    struct is_reference
    : public __or_<is_lvalue_reference<_Tp>,
                   is_rvalue_reference<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_arithmetic
    : public __or_<is_integral<_Tp>, is_floating_point<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_fundamental
    : public __or_<is_arithmetic<_Tp>, is_void<_Tp>,
     is_null_pointer<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_object
    : public __not_<__or_<is_function<_Tp>, is_reference<_Tp>,
                          is_void<_Tp>>>::type
    { };

  template<typename>
    struct is_member_pointer;


  template<typename _Tp>
    struct is_scalar
    : public __or_<is_arithmetic<_Tp>, is_enum<_Tp>, is_pointer<_Tp>,
                   is_member_pointer<_Tp>, is_null_pointer<_Tp>>::type
    { };


  template<typename _Tp>
    struct is_compound
    : public __not_<is_fundamental<_Tp>>::type { };


  template<typename _Tp>
    struct __is_member_pointer_helper
    : public false_type { };

  template<typename _Tp, typename _Cp>
    struct __is_member_pointer_helper<_Tp _Cp::*>
    : public true_type { };



  template<typename _Tp>
    struct is_member_pointer
    : public __is_member_pointer_helper<__remove_cv_t<_Tp>>::type
    { };

  template<typename, typename>
    struct is_same;


  template<typename _Tp, typename... _Types>
    using __is_one_of = __or_<is_same<_Tp, _Types>...>;


  __extension__
  template<typename _Tp>
    using __is_signed_integer = __is_one_of<__remove_cv_t<_Tp>,
   signed char, signed short, signed int, signed long,
   signed long long
   >;


  __extension__
  template<typename _Tp>
    using __is_unsigned_integer = __is_one_of<__remove_cv_t<_Tp>,
   unsigned char, unsigned short, unsigned int, unsigned long,
   unsigned long long
   >;


  template<typename _Tp>
    using __is_standard_integer
      = __or_<__is_signed_integer<_Tp>, __is_unsigned_integer<_Tp>>;


  template<typename...> using __void_t = void;



  template<typename _Tp, typename = void>
    struct __is_referenceable
    : public false_type
    { };

  template<typename _Tp>
    struct __is_referenceable<_Tp, __void_t<_Tp&>>
    : public true_type
    { };





  template<typename>
    struct is_const
    : public false_type { };

  template<typename _Tp>
    struct is_const<_Tp const>
    : public true_type { };


  template<typename>
    struct is_volatile
    : public false_type { };

  template<typename _Tp>
    struct is_volatile<_Tp volatile>
    : public true_type { };


  template<typename _Tp>
    struct is_trivial
    : public integral_constant<bool, __is_trivial(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_copyable
    : public integral_constant<bool, __is_trivially_copyable(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_standard_layout
    : public integral_constant<bool, __is_standard_layout(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };






  template<typename _Tp>
    struct
   
    is_pod
    : public integral_constant<bool, __is_pod(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };





  template<typename _Tp>
    struct
    [[__deprecated__]]
    is_literal_type
    : public integral_constant<bool, __is_literal_type(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_empty
    : public integral_constant<bool, __is_empty(_Tp)>
    { };


  template<typename _Tp>
    struct is_polymorphic
    : public integral_constant<bool, __is_polymorphic(_Tp)>
    { };





  template<typename _Tp>
    struct is_final
    : public integral_constant<bool, __is_final(_Tp)>
    { };



  template<typename _Tp>
    struct is_abstract
    : public integral_constant<bool, __is_abstract(_Tp)>
    { };


  template<typename _Tp,
    bool = is_arithmetic<_Tp>::value>
    struct __is_signed_helper
    : public false_type { };

  template<typename _Tp>
    struct __is_signed_helper<_Tp, true>
    : public integral_constant<bool, _Tp(-1) < _Tp(0)>
    { };



  template<typename _Tp>
    struct is_signed
    : public __is_signed_helper<_Tp>::type
    { };


  template<typename _Tp>
    struct is_unsigned
    : public __and_<is_arithmetic<_Tp>, __not_<is_signed<_Tp>>>
    { };


  template<typename _Tp, typename _Up = _Tp&&>
    _Up
    __declval(int);

  template<typename _Tp>
    _Tp
    __declval(long);


  template<typename _Tp>
    auto declval() noexcept -> decltype(__declval<_Tp>(0));

  template<typename, unsigned = 0>
    struct extent;

  template<typename>
    struct remove_all_extents;


  template<typename _Tp>
    struct __is_array_known_bounds
    : public integral_constant<bool, (extent<_Tp>::value > 0)>
    { };

  template<typename _Tp>
    struct __is_array_unknown_bounds
    : public __and_<is_array<_Tp>, __not_<extent<_Tp>>>
    { };
  struct __do_is_destructible_impl
  {
    template<typename _Tp, typename = decltype(declval<_Tp&>().~_Tp())>
      static true_type __test(int);

    template<typename>
      static false_type __test(...);
  };

  template<typename _Tp>
    struct __is_destructible_impl
    : public __do_is_destructible_impl
    {
      typedef decltype(__test<_Tp>(0)) type;
    };

  template<typename _Tp,
           bool = __or_<is_void<_Tp>,
                        __is_array_unknown_bounds<_Tp>,
                        is_function<_Tp>>::value,
           bool = __or_<is_reference<_Tp>, is_scalar<_Tp>>::value>
    struct __is_destructible_safe;

  template<typename _Tp>
    struct __is_destructible_safe<_Tp, false, false>
    : public __is_destructible_impl<typename
               remove_all_extents<_Tp>::type>::type
    { };

  template<typename _Tp>
    struct __is_destructible_safe<_Tp, true, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_destructible_safe<_Tp, false, true>
    : public true_type { };



  template<typename _Tp>
    struct is_destructible
    : public __is_destructible_safe<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };







  struct __do_is_nt_destructible_impl
  {
    template<typename _Tp>
      static __bool_constant<noexcept(declval<_Tp&>().~_Tp())>
      __test(int);

    template<typename>
      static false_type __test(...);
  };

  template<typename _Tp>
    struct __is_nt_destructible_impl
    : public __do_is_nt_destructible_impl
    {
      typedef decltype(__test<_Tp>(0)) type;
    };

  template<typename _Tp,
           bool = __or_<is_void<_Tp>,
                        __is_array_unknown_bounds<_Tp>,
                        is_function<_Tp>>::value,
           bool = __or_<is_reference<_Tp>, is_scalar<_Tp>>::value>
    struct __is_nt_destructible_safe;

  template<typename _Tp>
    struct __is_nt_destructible_safe<_Tp, false, false>
    : public __is_nt_destructible_impl<typename
               remove_all_extents<_Tp>::type>::type
    { };

  template<typename _Tp>
    struct __is_nt_destructible_safe<_Tp, true, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_nt_destructible_safe<_Tp, false, true>
    : public true_type { };



  template<typename _Tp>
    struct is_nothrow_destructible
    : public __is_nt_destructible_safe<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename... _Args>
    struct __is_constructible_impl
    : public __bool_constant<__is_constructible(_Tp, _Args...)>
    { };



  template<typename _Tp, typename... _Args>
    struct is_constructible
      : public __is_constructible_impl<_Tp, _Args...>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_default_constructible
    : public __is_constructible_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_copy_constructible_impl;

  template<typename _Tp>
    struct __is_copy_constructible_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_copy_constructible_impl<_Tp, true>
    : public __is_constructible_impl<_Tp, const _Tp&>
    { };



  template<typename _Tp>
    struct is_copy_constructible
    : public __is_copy_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_move_constructible_impl;

  template<typename _Tp>
    struct __is_move_constructible_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_move_constructible_impl<_Tp, true>
    : public __is_constructible_impl<_Tp, _Tp&&>
    { };



  template<typename _Tp>
    struct is_move_constructible
    : public __is_move_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename... _Args>
    using __is_nothrow_constructible_impl
      = __bool_constant<__is_nothrow_constructible(_Tp, _Args...)>;



  template<typename _Tp, typename... _Args>
    struct is_nothrow_constructible
    : public __is_nothrow_constructible_impl<_Tp, _Args...>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_default_constructible
    : public __bool_constant<__is_nothrow_constructible(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_nothrow_copy_constructible_impl;

  template<typename _Tp>
    struct __is_nothrow_copy_constructible_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_nothrow_copy_constructible_impl<_Tp, true>
    : public __is_nothrow_constructible_impl<_Tp, const _Tp&>
    { };



  template<typename _Tp>
    struct is_nothrow_copy_constructible
    : public __is_nothrow_copy_constructible_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_nothrow_move_constructible_impl;

  template<typename _Tp>
    struct __is_nothrow_move_constructible_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_nothrow_move_constructible_impl<_Tp, true>
    : public __is_nothrow_constructible_impl<_Tp, _Tp&&>
    { };



  template<typename _Tp>
    struct is_nothrow_move_constructible
    : public __is_nothrow_move_constructible_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    struct is_assignable
    : public __bool_constant<__is_assignable(_Tp, _Up)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_copy_assignable_impl;

  template<typename _Tp>
    struct __is_copy_assignable_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_copy_assignable_impl<_Tp, true>
    : public __bool_constant<__is_assignable(_Tp&, const _Tp&)>
    { };


  template<typename _Tp>
    struct is_copy_assignable
    : public __is_copy_assignable_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_move_assignable_impl;

  template<typename _Tp>
    struct __is_move_assignable_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_move_assignable_impl<_Tp, true>
    : public __bool_constant<__is_assignable(_Tp&, _Tp&&)>
    { };


  template<typename _Tp>
    struct is_move_assignable
    : public __is_move_assignable_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, typename _Up>
    using __is_nothrow_assignable_impl
      = __bool_constant<__is_nothrow_assignable(_Tp, _Up)>;


  template<typename _Tp, typename _Up>
    struct is_nothrow_assignable
    : public __is_nothrow_assignable_impl<_Tp, _Up>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_nt_copy_assignable_impl;

  template<typename _Tp>
    struct __is_nt_copy_assignable_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_nt_copy_assignable_impl<_Tp, true>
    : public __is_nothrow_assignable_impl<_Tp&, const _Tp&>
    { };


  template<typename _Tp>
    struct is_nothrow_copy_assignable
    : public __is_nt_copy_assignable_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_nt_move_assignable_impl;

  template<typename _Tp>
    struct __is_nt_move_assignable_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_nt_move_assignable_impl<_Tp, true>
    : public __is_nothrow_assignable_impl<_Tp&, _Tp&&>
    { };


  template<typename _Tp>
    struct is_nothrow_move_assignable
    : public __is_nt_move_assignable_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename... _Args>
    struct is_trivially_constructible
    : public __bool_constant<__is_trivially_constructible(_Tp, _Args...)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_default_constructible
    : public __bool_constant<__is_trivially_constructible(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  struct __do_is_implicitly_default_constructible_impl
  {
    template <typename _Tp>
    static void __helper(const _Tp&);

    template <typename _Tp>
    static true_type __test(const _Tp&,
                            decltype(__helper<const _Tp&>({}))* = 0);

    static false_type __test(...);
  };

  template<typename _Tp>
    struct __is_implicitly_default_constructible_impl
    : public __do_is_implicitly_default_constructible_impl
    {
      typedef decltype(__test(declval<_Tp>())) type;
    };

  template<typename _Tp>
    struct __is_implicitly_default_constructible_safe
    : public __is_implicitly_default_constructible_impl<_Tp>::type
    { };

  template <typename _Tp>
    struct __is_implicitly_default_constructible
    : public __and_<__is_constructible_impl<_Tp>,
      __is_implicitly_default_constructible_safe<_Tp>>
    { };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_trivially_copy_constructible_impl;

  template<typename _Tp>
    struct __is_trivially_copy_constructible_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_trivially_copy_constructible_impl<_Tp, true>
    : public __and_<__is_copy_constructible_impl<_Tp>,
      integral_constant<bool,
   __is_trivially_constructible(_Tp, const _Tp&)>>
    { };


  template<typename _Tp>
    struct is_trivially_copy_constructible
    : public __is_trivially_copy_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_trivially_move_constructible_impl;

  template<typename _Tp>
    struct __is_trivially_move_constructible_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_trivially_move_constructible_impl<_Tp, true>
    : public __and_<__is_move_constructible_impl<_Tp>,
      integral_constant<bool,
   __is_trivially_constructible(_Tp, _Tp&&)>>
    { };


  template<typename _Tp>
    struct is_trivially_move_constructible
    : public __is_trivially_move_constructible_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    struct is_trivially_assignable
    : public __bool_constant<__is_trivially_assignable(_Tp, _Up)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_trivially_copy_assignable_impl;

  template<typename _Tp>
    struct __is_trivially_copy_assignable_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_trivially_copy_assignable_impl<_Tp, true>
    : public __bool_constant<__is_trivially_assignable(_Tp&, const _Tp&)>
    { };


  template<typename _Tp>
    struct is_trivially_copy_assignable
    : public __is_trivially_copy_assignable_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __is_trivially_move_assignable_impl;

  template<typename _Tp>
    struct __is_trivially_move_assignable_impl<_Tp, false>
    : public false_type { };

  template<typename _Tp>
    struct __is_trivially_move_assignable_impl<_Tp, true>
    : public __bool_constant<__is_trivially_assignable(_Tp&, _Tp&&)>
    { };


  template<typename _Tp>
    struct is_trivially_move_assignable
    : public __is_trivially_move_assignable_impl<_Tp>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_trivially_destructible
    : public __and_<__is_destructible_safe<_Tp>,
      __bool_constant<__has_trivial_destructor(_Tp)>>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    struct has_virtual_destructor
    : public integral_constant<bool, __has_virtual_destructor(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };





  template<typename _Tp>
    struct alignment_of
    : public integral_constant<std::size_t, alignof(_Tp)>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename>
    struct rank
    : public integral_constant<std::size_t, 0> { };

  template<typename _Tp, std::size_t _Size>
    struct rank<_Tp[_Size]>
    : public integral_constant<std::size_t, 1 + rank<_Tp>::value> { };

  template<typename _Tp>
    struct rank<_Tp[]>
    : public integral_constant<std::size_t, 1 + rank<_Tp>::value> { };


  template<typename, unsigned _Uint>
    struct extent
    : public integral_constant<std::size_t, 0> { };

  template<typename _Tp, unsigned _Uint, std::size_t _Size>
    struct extent<_Tp[_Size], _Uint>
    : public integral_constant<std::size_t,
          _Uint == 0 ? _Size : extent<_Tp,
          _Uint - 1>::value>
    { };

  template<typename _Tp, unsigned _Uint>
    struct extent<_Tp[], _Uint>
    : public integral_constant<std::size_t,
          _Uint == 0 ? 0 : extent<_Tp,
             _Uint - 1>::value>
    { };





  template<typename _Tp, typename _Up>
    struct is_same

    : public integral_constant<bool, __is_same(_Tp, _Up)>



    { };
  template<typename _Base, typename _Derived>
    struct is_base_of
    : public integral_constant<bool, __is_base_of(_Base, _Derived)>
    { };

  template<typename _From, typename _To,
           bool = __or_<is_void<_From>, is_function<_To>,
                        is_array<_To>>::value>
    struct __is_convertible_helper
    {
      typedef typename is_void<_To>::type type;
    };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wctor-dtor-privacy"
  template<typename _From, typename _To>
    class __is_convertible_helper<_From, _To, false>
    {
      template<typename _To1>
 static void __test_aux(_To1) noexcept;

      template<typename _From1, typename _To1,
        typename = decltype(__test_aux<_To1>(std::declval<_From1>()))>
 static true_type
 __test(int);

      template<typename, typename>
 static false_type
 __test(...);

    public:
      typedef decltype(__test<_From, _To>(0)) type;
    };
#pragma GCC diagnostic pop


  template<typename _From, typename _To>
    struct is_convertible
    : public __is_convertible_helper<_From, _To>::type
    { };


  template<typename _ToElementType, typename _FromElementType>
    using __is_array_convertible
      = is_convertible<_FromElementType(*)[], _ToElementType(*)[]>;

  template<typename _From, typename _To,
           bool = __or_<is_void<_From>, is_function<_To>,
                        is_array<_To>>::value>
    struct __is_nt_convertible_helper
    : is_void<_To>
    { };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wctor-dtor-privacy"
  template<typename _From, typename _To>
    class __is_nt_convertible_helper<_From, _To, false>
    {
      template<typename _To1>
 static void __test_aux(_To1) noexcept;

      template<typename _From1, typename _To1>
 static
 __bool_constant<noexcept(__test_aux<_To1>(std::declval<_From1>()))>
 __test(int);

      template<typename, typename>
 static false_type
 __test(...);

    public:
      using type = decltype(__test<_From, _To>(0));
    };
#pragma GCC diagnostic pop
  template<typename _Tp>
    struct remove_const
    { typedef _Tp type; };

  template<typename _Tp>
    struct remove_const<_Tp const>
    { typedef _Tp type; };


  template<typename _Tp>
    struct remove_volatile
    { typedef _Tp type; };

  template<typename _Tp>
    struct remove_volatile<_Tp volatile>
    { typedef _Tp type; };


  template<typename _Tp>
    struct remove_cv
    { using type = _Tp; };

  template<typename _Tp>
    struct remove_cv<const _Tp>
    { using type = _Tp; };

  template<typename _Tp>
    struct remove_cv<volatile _Tp>
    { using type = _Tp; };

  template<typename _Tp>
    struct remove_cv<const volatile _Tp>
    { using type = _Tp; };


  template<typename _Tp>
    struct add_const
    { typedef _Tp const type; };


  template<typename _Tp>
    struct add_volatile
    { typedef _Tp volatile type; };


  template<typename _Tp>
    struct add_cv
    {
      typedef typename
      add_const<typename add_volatile<_Tp>::type>::type type;
    };






  template<typename _Tp>
    using remove_const_t = typename remove_const<_Tp>::type;


  template<typename _Tp>
    using remove_volatile_t = typename remove_volatile<_Tp>::type;


  template<typename _Tp>
    using remove_cv_t = typename remove_cv<_Tp>::type;


  template<typename _Tp>
    using add_const_t = typename add_const<_Tp>::type;


  template<typename _Tp>
    using add_volatile_t = typename add_volatile<_Tp>::type;


  template<typename _Tp>
    using add_cv_t = typename add_cv<_Tp>::type;





  template<typename _Tp>
    struct remove_reference
    { typedef _Tp type; };

  template<typename _Tp>
    struct remove_reference<_Tp&>
    { typedef _Tp type; };

  template<typename _Tp>
    struct remove_reference<_Tp&&>
    { typedef _Tp type; };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __add_lvalue_reference_helper
    { typedef _Tp type; };

  template<typename _Tp>
    struct __add_lvalue_reference_helper<_Tp, true>
    { typedef _Tp& type; };


  template<typename _Tp>
    struct add_lvalue_reference
    : public __add_lvalue_reference_helper<_Tp>
    { };

  template<typename _Tp, bool = __is_referenceable<_Tp>::value>
    struct __add_rvalue_reference_helper
    { typedef _Tp type; };

  template<typename _Tp>
    struct __add_rvalue_reference_helper<_Tp, true>
    { typedef _Tp&& type; };


  template<typename _Tp>
    struct add_rvalue_reference
    : public __add_rvalue_reference_helper<_Tp>
    { };



  template<typename _Tp>
    using remove_reference_t = typename remove_reference<_Tp>::type;


  template<typename _Tp>
    using add_lvalue_reference_t = typename add_lvalue_reference<_Tp>::type;


  template<typename _Tp>
    using add_rvalue_reference_t = typename add_rvalue_reference<_Tp>::type;







  template<typename _Unqualified, bool _IsConst, bool _IsVol>
    struct __cv_selector;

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, false, false>
    { typedef _Unqualified __type; };

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, false, true>
    { typedef volatile _Unqualified __type; };

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, true, false>
    { typedef const _Unqualified __type; };

  template<typename _Unqualified>
    struct __cv_selector<_Unqualified, true, true>
    { typedef const volatile _Unqualified __type; };

  template<typename _Qualified, typename _Unqualified,
    bool _IsConst = is_const<_Qualified>::value,
    bool _IsVol = is_volatile<_Qualified>::value>
    class __match_cv_qualifiers
    {
      typedef __cv_selector<_Unqualified, _IsConst, _IsVol> __match;

    public:
      typedef typename __match::__type __type;
    };


  template<typename _Tp>
    struct __make_unsigned
    { typedef _Tp __type; };

  template<>
    struct __make_unsigned<char>
    { typedef unsigned char __type; };

  template<>
    struct __make_unsigned<signed char>
    { typedef unsigned char __type; };

  template<>
    struct __make_unsigned<short>
    { typedef unsigned short __type; };

  template<>
    struct __make_unsigned<int>
    { typedef unsigned int __type; };

  template<>
    struct __make_unsigned<long>
    { typedef unsigned long __type; };

  template<>
    struct __make_unsigned<long long>
    { typedef unsigned long long __type; };
  template<typename _Tp,
    bool _IsInt = is_integral<_Tp>::value,
    bool _IsEnum = is_enum<_Tp>::value>
    class __make_unsigned_selector;

  template<typename _Tp>
    class __make_unsigned_selector<_Tp, true, false>
    {
      using __unsigned_type
 = typename __make_unsigned<__remove_cv_t<_Tp>>::__type;

    public:
      using __type
 = typename __match_cv_qualifiers<_Tp, __unsigned_type>::__type;
    };

  class __make_unsigned_selector_base
  {
  protected:
    template<typename...> struct _List { };

    template<typename _Tp, typename... _Up>
      struct _List<_Tp, _Up...> : _List<_Up...>
      { static constexpr size_t __size = sizeof(_Tp); };

    template<size_t _Sz, typename _Tp, bool = (_Sz <= _Tp::__size)>
      struct __select;

    template<size_t _Sz, typename _Uint, typename... _UInts>
      struct __select<_Sz, _List<_Uint, _UInts...>, true>
      { using __type = _Uint; };

    template<size_t _Sz, typename _Uint, typename... _UInts>
      struct __select<_Sz, _List<_Uint, _UInts...>, false>
      : __select<_Sz, _List<_UInts...>>
      { };
  };


  template<typename _Tp>
    class __make_unsigned_selector<_Tp, false, true>
    : __make_unsigned_selector_base
    {

      using _UInts = _List<unsigned char, unsigned short, unsigned int,
      unsigned long, unsigned long long>;

      using __unsigned_type = typename __select<sizeof(_Tp), _UInts>::__type;

    public:
      using __type
 = typename __match_cv_qualifiers<_Tp, __unsigned_type>::__type;
    };





  template<>
    struct __make_unsigned<wchar_t>
    {
      using __type
 = typename __make_unsigned_selector<wchar_t, false, true>::__type;
    };
  template<>
    struct __make_unsigned<char16_t>
    {
      using __type
 = typename __make_unsigned_selector<char16_t, false, true>::__type;
    };

  template<>
    struct __make_unsigned<char32_t>
    {
      using __type
 = typename __make_unsigned_selector<char32_t, false, true>::__type;
    };






  template<typename _Tp>
    struct make_unsigned
    { typedef typename __make_unsigned_selector<_Tp>::__type type; };


  template<>
    struct make_unsigned<bool>;




  template<typename _Tp>
    struct __make_signed
    { typedef _Tp __type; };

  template<>
    struct __make_signed<char>
    { typedef signed char __type; };

  template<>
    struct __make_signed<unsigned char>
    { typedef signed char __type; };

  template<>
    struct __make_signed<unsigned short>
    { typedef signed short __type; };

  template<>
    struct __make_signed<unsigned int>
    { typedef signed int __type; };

  template<>
    struct __make_signed<unsigned long>
    { typedef signed long __type; };

  template<>
    struct __make_signed<unsigned long long>
    { typedef signed long long __type; };
  template<typename _Tp,
    bool _IsInt = is_integral<_Tp>::value,
    bool _IsEnum = is_enum<_Tp>::value>
    class __make_signed_selector;

  template<typename _Tp>
    class __make_signed_selector<_Tp, true, false>
    {
      using __signed_type
 = typename __make_signed<__remove_cv_t<_Tp>>::__type;

    public:
      using __type
 = typename __match_cv_qualifiers<_Tp, __signed_type>::__type;
    };


  template<typename _Tp>
    class __make_signed_selector<_Tp, false, true>
    {
      typedef typename __make_unsigned_selector<_Tp>::__type __unsigned_type;

    public:
      typedef typename __make_signed_selector<__unsigned_type>::__type __type;
    };





  template<>
    struct __make_signed<wchar_t>
    {
      using __type
 = typename __make_signed_selector<wchar_t, false, true>::__type;
    };
  template<>
    struct __make_signed<char16_t>
    {
      using __type
 = typename __make_signed_selector<char16_t, false, true>::__type;
    };

  template<>
    struct __make_signed<char32_t>
    {
      using __type
 = typename __make_signed_selector<char32_t, false, true>::__type;
    };






  template<typename _Tp>
    struct make_signed
    { typedef typename __make_signed_selector<_Tp>::__type type; };


  template<>
    struct make_signed<bool>;



  template<typename _Tp>
    using make_signed_t = typename make_signed<_Tp>::type;


  template<typename _Tp>
    using make_unsigned_t = typename make_unsigned<_Tp>::type;





  template<typename _Tp>
    struct remove_extent
    { typedef _Tp type; };

  template<typename _Tp, std::size_t _Size>
    struct remove_extent<_Tp[_Size]>
    { typedef _Tp type; };

  template<typename _Tp>
    struct remove_extent<_Tp[]>
    { typedef _Tp type; };


  template<typename _Tp>
    struct remove_all_extents
    { typedef _Tp type; };

  template<typename _Tp, std::size_t _Size>
    struct remove_all_extents<_Tp[_Size]>
    { typedef typename remove_all_extents<_Tp>::type type; };

  template<typename _Tp>
    struct remove_all_extents<_Tp[]>
    { typedef typename remove_all_extents<_Tp>::type type; };



  template<typename _Tp>
    using remove_extent_t = typename remove_extent<_Tp>::type;


  template<typename _Tp>
    using remove_all_extents_t = typename remove_all_extents<_Tp>::type;




  template<typename _Tp, typename>
    struct __remove_pointer_helper
    { typedef _Tp type; };

  template<typename _Tp, typename _Up>
    struct __remove_pointer_helper<_Tp, _Up*>
    { typedef _Up type; };


  template<typename _Tp>
    struct remove_pointer
    : public __remove_pointer_helper<_Tp, __remove_cv_t<_Tp>>
    { };

  template<typename _Tp, bool = __or_<__is_referenceable<_Tp>,
          is_void<_Tp>>::value>
    struct __add_pointer_helper
    { typedef _Tp type; };

  template<typename _Tp>
    struct __add_pointer_helper<_Tp, true>
    { typedef typename remove_reference<_Tp>::type* type; };


  template<typename _Tp>
    struct add_pointer
    : public __add_pointer_helper<_Tp>
    { };



  template<typename _Tp>
    using remove_pointer_t = typename remove_pointer<_Tp>::type;


  template<typename _Tp>
    using add_pointer_t = typename add_pointer<_Tp>::type;


  template<std::size_t _Len>
    struct __aligned_storage_msa
    {
      union __type
      {
 unsigned char __data[_Len];
 struct __attribute__((__aligned__)) { } __align;
      };
    };
  template<std::size_t _Len, std::size_t _Align =
    __alignof__(typename __aligned_storage_msa<_Len>::__type)>
    struct aligned_storage
    {
      union type
      {
 unsigned char __data[_Len];
 struct __attribute__((__aligned__((_Align)))) { } __align;
      };
    };

  template <typename... _Types>
    struct __strictest_alignment
    {
      static const size_t _S_alignment = 0;
      static const size_t _S_size = 0;
    };

  template <typename _Tp, typename... _Types>
    struct __strictest_alignment<_Tp, _Types...>
    {
      static const size_t _S_alignment =
        alignof(_Tp) > __strictest_alignment<_Types...>::_S_alignment
 ? alignof(_Tp) : __strictest_alignment<_Types...>::_S_alignment;
      static const size_t _S_size =
        sizeof(_Tp) > __strictest_alignment<_Types...>::_S_size
 ? sizeof(_Tp) : __strictest_alignment<_Types...>::_S_size;
    };
  template <size_t _Len, typename... _Types>
    struct aligned_union
    {
    private:
      static_assert(sizeof...(_Types) != 0, "At least one type is required");

      using __strictest = __strictest_alignment<_Types...>;
      static const size_t _S_len = _Len > __strictest::_S_size
 ? _Len : __strictest::_S_size;
    public:

      static const size_t alignment_value = __strictest::_S_alignment;

      typedef typename aligned_storage<_S_len, alignment_value>::type type;
    };

  template <size_t _Len, typename... _Types>
    const size_t aligned_union<_Len, _Types...>::alignment_value;





  template<typename _Up,
    bool _IsArray = is_array<_Up>::value,
    bool _IsFunction = is_function<_Up>::value>
    struct __decay_selector;


  template<typename _Up>
    struct __decay_selector<_Up, false, false>
    { typedef __remove_cv_t<_Up> __type; };

  template<typename _Up>
    struct __decay_selector<_Up, true, false>
    { typedef typename remove_extent<_Up>::type* __type; };

  template<typename _Up>
    struct __decay_selector<_Up, false, true>
    { typedef typename add_pointer<_Up>::type __type; };



  template<typename _Tp>
    class decay
    {
      typedef typename remove_reference<_Tp>::type __remove_type;

    public:
      typedef typename __decay_selector<__remove_type>::__type type;
    };




  template<typename _Tp>
    struct __strip_reference_wrapper
    {
      typedef _Tp __type;
    };

  template<typename _Tp>
    struct __strip_reference_wrapper<reference_wrapper<_Tp> >
    {
      typedef _Tp& __type;
    };


  template<typename _Tp>
    using __decay_t = typename decay<_Tp>::type;

  template<typename _Tp>
    using __decay_and_strip = __strip_reference_wrapper<__decay_t<_Tp>>;




  template<bool, typename _Tp = void>
    struct enable_if
    { };


  template<typename _Tp>
    struct enable_if<true, _Tp>
    { typedef _Tp type; };




  template<bool _Cond, typename _Tp = void>
    using __enable_if_t = typename enable_if<_Cond, _Tp>::type;


  template<typename... _Cond>
    using _Require = __enable_if_t<__and_<_Cond...>::value>;


  template<typename _Tp>
    using __remove_cvref_t
     = typename remove_cv<typename remove_reference<_Tp>::type>::type;




  template<bool _Cond, typename _Iftrue, typename _Iffalse>
    struct conditional
    { typedef _Iftrue type; };


  template<typename _Iftrue, typename _Iffalse>
    struct conditional<false, _Iftrue, _Iffalse>
    { typedef _Iffalse type; };


  template<typename... _Tp>
    struct common_type;




  struct __do_common_type_impl
  {
    template<typename _Tp, typename _Up>
      using __cond_t
 = decltype(true ? std::declval<_Tp>() : std::declval<_Up>());



    template<typename _Tp, typename _Up>
      static __success_type<__decay_t<__cond_t<_Tp, _Up>>>
      _S_test(int);
    template<typename, typename>
      static __failure_type
      _S_test_2(...);

    template<typename _Tp, typename _Up>
      static decltype(_S_test_2<_Tp, _Up>(0))
      _S_test(...);
  };


  template<>
    struct common_type<>
    { };


  template<typename _Tp0>
    struct common_type<_Tp0>
    : public common_type<_Tp0, _Tp0>
    { };


  template<typename _Tp1, typename _Tp2,
    typename _Dp1 = __decay_t<_Tp1>, typename _Dp2 = __decay_t<_Tp2>>
    struct __common_type_impl
    {


      using type = common_type<_Dp1, _Dp2>;
    };

  template<typename _Tp1, typename _Tp2>
    struct __common_type_impl<_Tp1, _Tp2, _Tp1, _Tp2>
    : private __do_common_type_impl
    {


      using type = decltype(_S_test<_Tp1, _Tp2>(0));
    };


  template<typename _Tp1, typename _Tp2>
    struct common_type<_Tp1, _Tp2>
    : public __common_type_impl<_Tp1, _Tp2>::type
    { };

  template<typename...>
    struct __common_type_pack
    { };

  template<typename, typename, typename = void>
    struct __common_type_fold;


  template<typename _Tp1, typename _Tp2, typename... _Rp>
    struct common_type<_Tp1, _Tp2, _Rp...>
    : public __common_type_fold<common_type<_Tp1, _Tp2>,
    __common_type_pack<_Rp...>>
    { };




  template<typename _CTp, typename... _Rp>
    struct __common_type_fold<_CTp, __common_type_pack<_Rp...>,
         __void_t<typename _CTp::type>>
    : public common_type<typename _CTp::type, _Rp...>
    { };


  template<typename _CTp, typename _Rp>
    struct __common_type_fold<_CTp, _Rp, void>
    { };

  template<typename _Tp, bool = is_enum<_Tp>::value>
    struct __underlying_type_impl
    {
      using type = __underlying_type(_Tp);
    };

  template<typename _Tp>
    struct __underlying_type_impl<_Tp, false>
    { };



  template<typename _Tp>
    struct underlying_type
    : public __underlying_type_impl<_Tp>
    { };


  template<typename _Tp>
    struct __declval_protector
    {
      static const bool __stop = false;
    };






  template<typename _Tp>
    auto declval() noexcept -> decltype(__declval<_Tp>(0))
    {
      static_assert(__declval_protector<_Tp>::__stop,
      "declval() must not be used!");
      return __declval<_Tp>(0);
    }


  template<typename _Signature>
    struct result_of;






  struct __invoke_memfun_ref { };
  struct __invoke_memfun_deref { };
  struct __invoke_memobj_ref { };
  struct __invoke_memobj_deref { };
  struct __invoke_other { };


  template<typename _Tp, typename _Tag>
    struct __result_of_success : __success_type<_Tp>
    { using __invoke_type = _Tag; };


  struct __result_of_memfun_ref_impl
  {
    template<typename _Fp, typename _Tp1, typename... _Args>
      static __result_of_success<decltype(
      (std::declval<_Tp1>().*std::declval<_Fp>())(std::declval<_Args>()...)
      ), __invoke_memfun_ref> _S_test(int);

    template<typename...>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_memfun_ref
    : private __result_of_memfun_ref_impl
    {
      typedef decltype(_S_test<_MemPtr, _Arg, _Args...>(0)) type;
    };


  struct __result_of_memfun_deref_impl
  {
    template<typename _Fp, typename _Tp1, typename... _Args>
      static __result_of_success<decltype(
      ((*std::declval<_Tp1>()).*std::declval<_Fp>())(std::declval<_Args>()...)
      ), __invoke_memfun_deref> _S_test(int);

    template<typename...>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_memfun_deref
    : private __result_of_memfun_deref_impl
    {
      typedef decltype(_S_test<_MemPtr, _Arg, _Args...>(0)) type;
    };


  struct __result_of_memobj_ref_impl
  {
    template<typename _Fp, typename _Tp1>
      static __result_of_success<decltype(
      std::declval<_Tp1>().*std::declval<_Fp>()
      ), __invoke_memobj_ref> _S_test(int);

    template<typename, typename>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_memobj_ref
    : private __result_of_memobj_ref_impl
    {
      typedef decltype(_S_test<_MemPtr, _Arg>(0)) type;
    };


  struct __result_of_memobj_deref_impl
  {
    template<typename _Fp, typename _Tp1>
      static __result_of_success<decltype(
      (*std::declval<_Tp1>()).*std::declval<_Fp>()
      ), __invoke_memobj_deref> _S_test(int);

    template<typename, typename>
      static __failure_type _S_test(...);
  };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_memobj_deref
    : private __result_of_memobj_deref_impl
    {
      typedef decltype(_S_test<_MemPtr, _Arg>(0)) type;
    };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_memobj;

  template<typename _Res, typename _Class, typename _Arg>
    struct __result_of_memobj<_Res _Class::*, _Arg>
    {
      typedef __remove_cvref_t<_Arg> _Argval;
      typedef _Res _Class::* _MemPtr;
      typedef typename __conditional_t<__or_<is_same<_Argval, _Class>,
        is_base_of<_Class, _Argval>>::value,
        __result_of_memobj_ref<_MemPtr, _Arg>,
        __result_of_memobj_deref<_MemPtr, _Arg>
      >::type type;
    };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_memfun;

  template<typename _Res, typename _Class, typename _Arg, typename... _Args>
    struct __result_of_memfun<_Res _Class::*, _Arg, _Args...>
    {
      typedef typename remove_reference<_Arg>::type _Argval;
      typedef _Res _Class::* _MemPtr;
      typedef typename __conditional_t<is_base_of<_Class, _Argval>::value,
        __result_of_memfun_ref<_MemPtr, _Arg, _Args...>,
        __result_of_memfun_deref<_MemPtr, _Arg, _Args...>
      >::type type;
    };






  template<typename _Tp, typename _Up = __remove_cvref_t<_Tp>>
    struct __inv_unwrap
    {
      using type = _Tp;
    };

  template<typename _Tp, typename _Up>
    struct __inv_unwrap<_Tp, reference_wrapper<_Up>>
    {
      using type = _Up&;
    };

  template<bool, bool, typename _Functor, typename... _ArgTypes>
    struct __result_of_impl
    {
      typedef __failure_type type;
    };

  template<typename _MemPtr, typename _Arg>
    struct __result_of_impl<true, false, _MemPtr, _Arg>
    : public __result_of_memobj<__decay_t<_MemPtr>,
    typename __inv_unwrap<_Arg>::type>
    { };

  template<typename _MemPtr, typename _Arg, typename... _Args>
    struct __result_of_impl<false, true, _MemPtr, _Arg, _Args...>
    : public __result_of_memfun<__decay_t<_MemPtr>,
    typename __inv_unwrap<_Arg>::type, _Args...>
    { };


  struct __result_of_other_impl
  {
    template<typename _Fn, typename... _Args>
      static __result_of_success<decltype(
      std::declval<_Fn>()(std::declval<_Args>()...)
      ), __invoke_other> _S_test(int);

    template<typename...>
      static __failure_type _S_test(...);
  };

  template<typename _Functor, typename... _ArgTypes>
    struct __result_of_impl<false, false, _Functor, _ArgTypes...>
    : private __result_of_other_impl
    {
      typedef decltype(_S_test<_Functor, _ArgTypes...>(0)) type;
    };


  template<typename _Functor, typename... _ArgTypes>
    struct __invoke_result
    : public __result_of_impl<
        is_member_object_pointer<
          typename remove_reference<_Functor>::type
        >::value,
        is_member_function_pointer<
          typename remove_reference<_Functor>::type
        >::value,
 _Functor, _ArgTypes...
      >::type
    { };


  template<typename _Functor, typename... _ArgTypes>
    struct result_of<_Functor(_ArgTypes...)>
    : public __invoke_result<_Functor, _ArgTypes...>
    { } __attribute__ ((__deprecated__ ("use '" "std::invoke_result" "' instead")));



  template<size_t _Len, size_t _Align =
     __alignof__(typename __aligned_storage_msa<_Len>::__type)>
    using aligned_storage_t = typename aligned_storage<_Len, _Align>::type;

  template <size_t _Len, typename... _Types>
    using aligned_union_t = typename aligned_union<_Len, _Types...>::type;


  template<typename _Tp>
    using decay_t = typename decay<_Tp>::type;


  template<bool _Cond, typename _Tp = void>
    using enable_if_t = typename enable_if<_Cond, _Tp>::type;


  template<bool _Cond, typename _Iftrue, typename _Iffalse>
    using conditional_t = typename conditional<_Cond, _Iftrue, _Iffalse>::type;


  template<typename... _Tp>
    using common_type_t = typename common_type<_Tp...>::type;


  template<typename _Tp>
    using underlying_type_t = typename underlying_type<_Tp>::type;


  template<typename _Tp>
    using result_of_t = typename result_of<_Tp>::type;





  template<typename...> using void_t = void;
  template<typename _Default, typename _AlwaysVoid,
    template<typename...> class _Op, typename... _Args>
    struct __detector
    {
      using type = _Default;
      using __is_detected = false_type;
    };


  template<typename _Default, template<typename...> class _Op,
     typename... _Args>
    struct __detector<_Default, __void_t<_Op<_Args...>>, _Op, _Args...>
    {
      using type = _Op<_Args...>;
      using __is_detected = true_type;
    };

  template<typename _Default, template<typename...> class _Op,
    typename... _Args>
    using __detected_or = __detector<_Default, void, _Op, _Args...>;



  template<typename _Default, template<typename...> class _Op,
    typename... _Args>
    using __detected_or_t
      = typename __detected_or<_Default, _Op, _Args...>::type;
  template <typename _Tp>
    struct __is_swappable;

  template <typename _Tp>
    struct __is_nothrow_swappable;

  template<typename>
    struct __is_tuple_like_impl : false_type
    { };


  template<typename _Tp>
    struct __is_tuple_like
    : public __is_tuple_like_impl<__remove_cvref_t<_Tp>>::type
    { };


  template<typename _Tp>
   
    inline
    _Require<__not_<__is_tuple_like<_Tp>>,
      is_move_constructible<_Tp>,
      is_move_assignable<_Tp>>
    swap(_Tp&, _Tp&)
    noexcept(__and_<is_nothrow_move_constructible<_Tp>,
             is_nothrow_move_assignable<_Tp>>::value);

  template<typename _Tp, size_t _Nm>
   
    inline
    __enable_if_t<__is_swappable<_Tp>::value>
    swap(_Tp (&__a)[_Nm], _Tp (&__b)[_Nm])
    noexcept(__is_nothrow_swappable<_Tp>::value);


  namespace __swappable_details {
    using std::swap;

    struct __do_is_swappable_impl
    {
      template<typename _Tp, typename
               = decltype(swap(std::declval<_Tp&>(), std::declval<_Tp&>()))>
        static true_type __test(int);

      template<typename>
        static false_type __test(...);
    };

    struct __do_is_nothrow_swappable_impl
    {
      template<typename _Tp>
        static __bool_constant<
          noexcept(swap(std::declval<_Tp&>(), std::declval<_Tp&>()))
        > __test(int);

      template<typename>
        static false_type __test(...);
    };

  }

  template<typename _Tp>
    struct __is_swappable_impl
    : public __swappable_details::__do_is_swappable_impl
    {
      typedef decltype(__test<_Tp>(0)) type;
    };

  template<typename _Tp>
    struct __is_nothrow_swappable_impl
    : public __swappable_details::__do_is_nothrow_swappable_impl
    {
      typedef decltype(__test<_Tp>(0)) type;
    };

  template<typename _Tp>
    struct __is_swappable
    : public __is_swappable_impl<_Tp>::type
    { };

  template<typename _Tp>
    struct __is_nothrow_swappable
    : public __is_nothrow_swappable_impl<_Tp>::type
    { };







  template<typename _Tp>
    struct is_swappable
    : public __is_swappable_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    struct is_nothrow_swappable
    : public __is_nothrow_swappable_impl<_Tp>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp>
    inline constexpr bool is_swappable_v =
      is_swappable<_Tp>::value;


  template<typename _Tp>
    inline constexpr bool is_nothrow_swappable_v =
      is_nothrow_swappable<_Tp>::value;



  namespace __swappable_with_details {
    using std::swap;

    struct __do_is_swappable_with_impl
    {
      template<typename _Tp, typename _Up, typename
               = decltype(swap(std::declval<_Tp>(), std::declval<_Up>())),
               typename
               = decltype(swap(std::declval<_Up>(), std::declval<_Tp>()))>
        static true_type __test(int);

      template<typename, typename>
        static false_type __test(...);
    };

    struct __do_is_nothrow_swappable_with_impl
    {
      template<typename _Tp, typename _Up>
        static __bool_constant<
          noexcept(swap(std::declval<_Tp>(), std::declval<_Up>()))
          &&
          noexcept(swap(std::declval<_Up>(), std::declval<_Tp>()))
        > __test(int);

      template<typename, typename>
        static false_type __test(...);
    };

  }

  template<typename _Tp, typename _Up>
    struct __is_swappable_with_impl
    : public __swappable_with_details::__do_is_swappable_with_impl
    {
      typedef decltype(__test<_Tp, _Up>(0)) type;
    };


  template<typename _Tp>
    struct __is_swappable_with_impl<_Tp&, _Tp&>
    : public __swappable_details::__do_is_swappable_impl
    {
      typedef decltype(__test<_Tp&>(0)) type;
    };

  template<typename _Tp, typename _Up>
    struct __is_nothrow_swappable_with_impl
    : public __swappable_with_details::__do_is_nothrow_swappable_with_impl
    {
      typedef decltype(__test<_Tp, _Up>(0)) type;
    };


  template<typename _Tp>
    struct __is_nothrow_swappable_with_impl<_Tp&, _Tp&>
    : public __swappable_details::__do_is_nothrow_swappable_impl
    {
      typedef decltype(__test<_Tp&>(0)) type;
    };



  template<typename _Tp, typename _Up>
    struct is_swappable_with
    : public __is_swappable_with_impl<_Tp, _Up>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "first template argument must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Up>{}),
 "second template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp, typename _Up>
    struct is_nothrow_swappable_with
    : public __is_nothrow_swappable_with_impl<_Tp, _Up>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "first template argument must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Up>{}),
 "second template argument must be a complete class or an unbounded array");
    };



  template<typename _Tp, typename _Up>
    inline constexpr bool is_swappable_with_v =
      is_swappable_with<_Tp, _Up>::value;


  template<typename _Tp, typename _Up>
    inline constexpr bool is_nothrow_swappable_with_v =
      is_nothrow_swappable_with<_Tp, _Up>::value;
  template<typename _Result, typename _Ret,
    bool = is_void<_Ret>::value, typename = void>
    struct __is_invocable_impl
    : false_type
    {
      using __nothrow_type = false_type;
    };


  template<typename _Result, typename _Ret>
    struct __is_invocable_impl<_Result, _Ret,
                                true,
          __void_t<typename _Result::type>>
    : true_type
    {
      using __nothrow_type = true_type;
    };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wctor-dtor-privacy"

  template<typename _Result, typename _Ret>
    struct __is_invocable_impl<_Result, _Ret,
                                false,
          __void_t<typename _Result::type>>
    {
    private:



      static typename _Result::type _S_get() noexcept;

      template<typename _Tp>
 static void _S_conv(_Tp) noexcept;


      template<typename _Tp, bool _Check_Noex = false,
        typename = decltype(_S_conv<_Tp>(_S_get())),
        bool _Noex = noexcept(_S_conv<_Tp>(_S_get()))>
 static __bool_constant<_Check_Noex ? _Noex : true>
 _S_test(int);

      template<typename _Tp, bool = false>
 static false_type
 _S_test(...);

    public:

      using type = decltype(_S_test<_Ret>(1));


      using __nothrow_type = decltype(_S_test<_Ret, true>(1));
    };
#pragma GCC diagnostic pop

  template<typename _Fn, typename... _ArgTypes>
    struct __is_invocable
    : __is_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, void>::type
    { };

  template<typename _Fn, typename _Tp, typename... _Args>
    constexpr bool __call_is_nt(__invoke_memfun_ref)
    {
      using _Up = typename __inv_unwrap<_Tp>::type;
      return noexcept((std::declval<_Up>().*std::declval<_Fn>())(
     std::declval<_Args>()...));
    }

  template<typename _Fn, typename _Tp, typename... _Args>
    constexpr bool __call_is_nt(__invoke_memfun_deref)
    {
      return noexcept(((*std::declval<_Tp>()).*std::declval<_Fn>())(
     std::declval<_Args>()...));
    }

  template<typename _Fn, typename _Tp>
    constexpr bool __call_is_nt(__invoke_memobj_ref)
    {
      using _Up = typename __inv_unwrap<_Tp>::type;
      return noexcept(std::declval<_Up>().*std::declval<_Fn>());
    }

  template<typename _Fn, typename _Tp>
    constexpr bool __call_is_nt(__invoke_memobj_deref)
    {
      return noexcept((*std::declval<_Tp>()).*std::declval<_Fn>());
    }

  template<typename _Fn, typename... _Args>
    constexpr bool __call_is_nt(__invoke_other)
    {
      return noexcept(std::declval<_Fn>()(std::declval<_Args>()...));
    }

  template<typename _Result, typename _Fn, typename... _Args>
    struct __call_is_nothrow
    : __bool_constant<
 std::__call_is_nt<_Fn, _Args...>(typename _Result::__invoke_type{})
      >
    { };

  template<typename _Fn, typename... _Args>
    using __call_is_nothrow_
      = __call_is_nothrow<__invoke_result<_Fn, _Args...>, _Fn, _Args...>;


  template<typename _Fn, typename... _Args>
    struct __is_nothrow_invocable
    : __and_<__is_invocable<_Fn, _Args...>,
             __call_is_nothrow_<_Fn, _Args...>>::type
    { };

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wctor-dtor-privacy"
  struct __nonesuchbase {};
  struct __nonesuch : private __nonesuchbase {
    ~__nonesuch() = delete;
    __nonesuch(__nonesuch const&) = delete;
    void operator=(__nonesuch const&) = delete;
  };
#pragma GCC diagnostic pop






  template<typename _Functor, typename... _ArgTypes>
    struct invoke_result
    : public __invoke_result<_Functor, _ArgTypes...>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Functor>{}),
 "_Functor must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
    };


  template<typename _Fn, typename... _Args>
    using invoke_result_t = typename invoke_result<_Fn, _Args...>::type;


  template<typename _Fn, typename... _ArgTypes>
    struct is_invocable
    : __is_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, void>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
    };


  template<typename _Ret, typename _Fn, typename... _ArgTypes>
    struct is_invocable_r
    : __is_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, _Ret>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Ret>{}),
 "_Ret must be a complete class or an unbounded array");
    };


  template<typename _Fn, typename... _ArgTypes>
    struct is_nothrow_invocable
    : __and_<__is_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, void>,
      __call_is_nothrow_<_Fn, _ArgTypes...>>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
    };


  template<typename _Result, typename _Ret>
    using __is_nt_invocable_impl
      = typename __is_invocable_impl<_Result, _Ret>::__nothrow_type;



  template<typename _Ret, typename _Fn, typename... _ArgTypes>
    struct is_nothrow_invocable_r
    : __and_<__is_nt_invocable_impl<__invoke_result<_Fn, _ArgTypes...>, _Ret>,
             __call_is_nothrow_<_Fn, _ArgTypes...>>::type
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Fn>{}),
 "_Fn must be a complete class or an unbounded array");
      static_assert((std::__is_complete_or_unbounded(
 __type_identity<_ArgTypes>{}) && ...),
 "each argument type must be a complete class or an unbounded array");
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Ret>{}),
 "_Ret must be a complete class or an unbounded array");
    };
template <typename _Tp>
  inline constexpr bool is_void_v = is_void<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_null_pointer_v = is_null_pointer<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_integral_v = is_integral<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_floating_point_v = is_floating_point<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_array_v = is_array<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_pointer_v = is_pointer<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_lvalue_reference_v =
    is_lvalue_reference<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_rvalue_reference_v =
    is_rvalue_reference<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_member_object_pointer_v =
    is_member_object_pointer<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_member_function_pointer_v =
    is_member_function_pointer<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_enum_v = is_enum<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_union_v = is_union<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_class_v = is_class<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_function_v = is_function<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_reference_v = is_reference<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_arithmetic_v = is_arithmetic<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_fundamental_v = is_fundamental<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_object_v = is_object<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_scalar_v = is_scalar<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_compound_v = is_compound<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_member_pointer_v = is_member_pointer<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_const_v = is_const<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_volatile_v = is_volatile<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_trivial_v = is_trivial<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_copyable_v =
    is_trivially_copyable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_standard_layout_v = is_standard_layout<_Tp>::value;
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
template <typename _Tp>
 
  inline constexpr bool is_pod_v = is_pod<_Tp>::value;
template <typename _Tp>
  [[__deprecated__]]
  inline constexpr bool is_literal_type_v = is_literal_type<_Tp>::value;
#pragma GCC diagnostic pop
 template <typename _Tp>
  inline constexpr bool is_empty_v = is_empty<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_polymorphic_v = is_polymorphic<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_abstract_v = is_abstract<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_final_v = is_final<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_signed_v = is_signed<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_unsigned_v = is_unsigned<_Tp>::value;
template <typename _Tp, typename... _Args>
  inline constexpr bool is_constructible_v =
    is_constructible<_Tp, _Args...>::value;
template <typename _Tp>
  inline constexpr bool is_default_constructible_v =
    is_default_constructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_copy_constructible_v =
    is_copy_constructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_move_constructible_v =
    is_move_constructible<_Tp>::value;
template <typename _Tp, typename _Up>
  inline constexpr bool is_assignable_v = is_assignable<_Tp, _Up>::value;
template <typename _Tp>
  inline constexpr bool is_copy_assignable_v = is_copy_assignable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_move_assignable_v = is_move_assignable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_destructible_v = is_destructible<_Tp>::value;
template <typename _Tp, typename... _Args>
  inline constexpr bool is_trivially_constructible_v =
    is_trivially_constructible<_Tp, _Args...>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_default_constructible_v =
    is_trivially_default_constructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_copy_constructible_v =
    is_trivially_copy_constructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_move_constructible_v =
    is_trivially_move_constructible<_Tp>::value;
template <typename _Tp, typename _Up>
  inline constexpr bool is_trivially_assignable_v =
    is_trivially_assignable<_Tp, _Up>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_copy_assignable_v =
    is_trivially_copy_assignable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_move_assignable_v =
    is_trivially_move_assignable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_trivially_destructible_v =
    is_trivially_destructible<_Tp>::value;
template <typename _Tp, typename... _Args>
  inline constexpr bool is_nothrow_constructible_v =
    is_nothrow_constructible<_Tp, _Args...>::value;
template <typename _Tp>
  inline constexpr bool is_nothrow_default_constructible_v =
    is_nothrow_default_constructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_nothrow_copy_constructible_v =
    is_nothrow_copy_constructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_nothrow_move_constructible_v =
    is_nothrow_move_constructible<_Tp>::value;
template <typename _Tp, typename _Up>
  inline constexpr bool is_nothrow_assignable_v =
    is_nothrow_assignable<_Tp, _Up>::value;
template <typename _Tp>
  inline constexpr bool is_nothrow_copy_assignable_v =
    is_nothrow_copy_assignable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_nothrow_move_assignable_v =
    is_nothrow_move_assignable<_Tp>::value;
template <typename _Tp>
  inline constexpr bool is_nothrow_destructible_v =
    is_nothrow_destructible<_Tp>::value;
template <typename _Tp>
  inline constexpr bool has_virtual_destructor_v =
    has_virtual_destructor<_Tp>::value;
template <typename _Tp>
  inline constexpr size_t alignment_of_v = alignment_of<_Tp>::value;
template <typename _Tp>
  inline constexpr size_t rank_v = rank<_Tp>::value;
template <typename _Tp, unsigned _Idx = 0>
  inline constexpr size_t extent_v = extent<_Tp, _Idx>::value;

template <typename _Tp, typename _Up>
  inline constexpr bool is_same_v = __is_same(_Tp, _Up);




template <typename _Base, typename _Derived>
  inline constexpr bool is_base_of_v = is_base_of<_Base, _Derived>::value;
template <typename _From, typename _To>
  inline constexpr bool is_convertible_v = is_convertible<_From, _To>::value;
template<typename _Fn, typename... _Args>
  inline constexpr bool is_invocable_v = is_invocable<_Fn, _Args...>::value;
template<typename _Fn, typename... _Args>
  inline constexpr bool is_nothrow_invocable_v
    = is_nothrow_invocable<_Fn, _Args...>::value;
template<typename _Ret, typename _Fn, typename... _Args>
  inline constexpr bool is_invocable_r_v
    = is_invocable_r<_Ret, _Fn, _Args...>::value;
template<typename _Ret, typename _Fn, typename... _Args>
  inline constexpr bool is_nothrow_invocable_r_v
    = is_nothrow_invocable_r<_Ret, _Fn, _Args...>::value;






  template<typename _Tp>
    struct has_unique_object_representations
    : bool_constant<__has_unique_object_representations(
      remove_cv_t<remove_all_extents_t<_Tp>>
      )>
    {
      static_assert(std::__is_complete_or_unbounded(__type_identity<_Tp>{}),
 "template argument must be a complete class or an unbounded array");
    };


  template<typename _Tp>
    inline constexpr bool has_unique_object_representations_v
      = has_unique_object_representations<_Tp>::value;






  template<typename _Tp>
    struct is_aggregate
    : bool_constant<__is_aggregate(remove_cv_t<_Tp>)>
    { };


  template<typename _Tp>
    inline constexpr bool is_aggregate_v = is_aggregate<_Tp>::value;

}


enum xmov_direction_t {
    XMOV_L0_TO_L1 = 0,
    XMOV_L1_TO_L0 = 1,
    XMOV_L0_TO_L0 = 2,
    XMOV_L1_TO_L1 = 3,
};

enum tdma_mover_id_t { TDMA_MOVER0 = 0, TDMA_MOVER1 = 1 };

enum math_fidelity_t { MATH_HF = 1, MATH_AUTO = 2, MATH_LF = 4 };

enum relu_mode_t { RELU_NONE = 0, RELU_PLAIN = 1, RELU_THRESH = 2, RELU_MAX = 3 };

enum stochastic_round_settings_t { STOCH_RND_NONE = 0, STOCH_RND_FPU = 1, STOCH_RND_GASKET = 2, STOCH_RND_PACKER = 4 };




struct packer_config_t {
    uint32_t row_section_size : 16;
    uint32_t exp_section_size : 16;
    uint32_t tile_dst_addr : 32;
    uint32_t uncompressed : 1;
    uint32_t reserved_0 : 3;
    uint32_t out_data_format : 2;
    uint32_t reserved_1 : 2;
    uint32_t in_data_format : 2;
    uint32_t reserved_2 : 22;
    uint32_t reserved_3 : 32;
};

struct fifo_ctl_t {
    uint32_t rd_ptr;
    uint32_t wr_ptr;
    uint32_t rsvd0;
    uint32_t rsvd1;





};

struct packer_config_u {
    uint32_t val[4];
    packer_config_t f;
};

struct mover_config_t {
    uint32_t src_addr : 32;
    uint32_t dst_addr : 32;
    uint32_t xfer_size : 32;
    uint32_t xfer_dir : 2;
    uint32_t reserved_0 : 30;
};

struct mover_config_u {
    uint32_t val[4];
    mover_config_t f;
};






struct tile_descriptor_t {
    uint32_t data_format : 4;
    uint32_t uncompressed : 1;
    uint32_t reserved_0 : 3;
    uint32_t blobs_per_xy_plane : 4;
    uint32_t reserved_1 : 4;
    uint32_t x_dim : 16;
    uint32_t y_dim : 16;
    uint32_t z_dim : 16;
    uint32_t w_dim : 16;
    uint32_t blobs_y_start : 32;
    uint32_t digest_type : 8;
    uint32_t digest_size : 8;
};

union tile_descriptor_u {
    uint32_t val[4];
    tile_descriptor_t f;
};

struct TileHeader {

    std::uint16_t tile_size_16B = 0;
    std::uint16_t reserved_0_mbz : 1;
    std::uint16_t tile_id : 15;

    std::uint8_t metadata_size_16B = 0;
    std::uint8_t reserved_1 = 0;
    std::uint16_t format = 0x10;

    std::uint32_t zero_mask = 0;
    std::uint32_t reserved_3 = 0;

    TileHeader() : reserved_0_mbz(0), tile_id(0) {}

    bool IsCompressed() const { return ((format & 0x10) == 0); }
};

union TileHeader_u {
    uint32_t val[4];
    TileHeader header;
    TileHeader_u() {};
};

static_assert(sizeof(TileHeader) == 16, "TileHeader must be 16B");

struct SectionHeader {

    std::uint16_t section_id;
    std::uint16_t section_size;
    std::uint16_t tile_count;


    std::uint16_t reserved[5];







};


static_assert(sizeof(SectionHeader) == 16, "struct section_header must be 16 bytes");

static constexpr std::uint32_t TEST_MSG_EN_TENSIX_PM = 0;
static constexpr std::uint32_t TEST_MSG_DBG_DISABLE = 1;
static constexpr std::uint32_t TEST_MSG_SET_MAX_EXP_THRESH = 2;
static constexpr std::uint32_t TEST_MSG_RISC_BP_DISABLE = 3;
static constexpr std::uint32_t TEST_MSG_SET_RELU_PARAMS = 4;
static constexpr std::uint32_t TEST_MSG_SET_PRNG_SEED = 5;
static constexpr std::uint32_t TEST_MSG_RISC_PREFETCHER_CTRL = 6;
static constexpr std::uint32_t TEST_MSG_SYNTH_CKERNEL = 10;

static constexpr std::uint32_t COMMAND_QUEUE_SIZE_BYTES_LOG2 = 16;
static constexpr std::uint32_t COMMAND_QUEUE_SIZE_BYTES = 1 << COMMAND_QUEUE_SIZE_BYTES_LOG2;
static constexpr std::uint32_t COMMAND_SIZE_BYTES_LOG2 = 5;
static constexpr std::uint32_t COMMAND_SIZE_BYTES = 1 << COMMAND_SIZE_BYTES_LOG2;

static constexpr std::uint32_t DEST_FACE_WIDTH = 16;
static constexpr std::uint32_t DEST_FACE_WIDTH_LOG2 = 4;
static constexpr std::uint32_t DEST_FACE_HEIGHT = 16;
static constexpr std::uint32_t DEST_FACE_HEIGHT_LOG2 = 4;
static constexpr std::uint32_t DEST_REGISTER_FULL_SIZE = 64 * DEST_FACE_HEIGHT;
static constexpr std::uint32_t DEST_REGISTER_FULL_SIZE_LOG2 = 12;
static constexpr std::uint32_t DEST_REGISTER_HALF_SIZE = DEST_REGISTER_FULL_SIZE / 2;
static constexpr std::uint32_t BIT32_DEST_REGISTER_HALF_SIZE = DEST_REGISTER_HALF_SIZE / 2;

static constexpr std::uint32_t DEST_REGISTER_FULL_SIZE_BYTES = DEST_REGISTER_FULL_SIZE * 2 * 16;
static constexpr std::uint32_t DEST_REGISTER_HALF_SIZE_BYTES = DEST_REGISTER_FULL_SIZE_BYTES / 2;

static constexpr std::uint32_t SIM_L1_SIZE = 0x16E000;

static constexpr std::uint32_t L1_SIZE = 0x16E000;
static constexpr std::uint32_t FIFO_BASE_ADDRESS_ALIGN_BITS = 9;
static constexpr std::uint32_t FIFO_BASE_ADDRESS_ALIGN = 1 << FIFO_BASE_ADDRESS_ALIGN_BITS;

enum class DataFormat : std::uint8_t {
    Float32 = 0,
    Float16 = 1,
    Bfp8 = 2,
    Bfp4 = 3,
    Bfp2 = 11,
    Float16_b = 5,
    Bfp8_b = 6,
    Bfp4_b = 7,
    Bfp2_b = 15,
    Lf8 = 10,
    Int8 = 14,
    UInt8 = 30,
    UInt16 = 9,
    Int32 = 8,
    UInt32 = 24,
    Tf32 = 4,
    testMan7 = 0x82,
    testMan2 = 0x8A,
    Invalid = 0xff
};

struct io_queue_pointers_t {
    static constexpr std::uint32_t INVALID_IO_QUEUE_POINTER = 0xfeedface;
    static constexpr std::uint32_t WRAP_MASK = 0x80000000;
    static constexpr std::uint32_t MAX_IO_QUEUES = 256;
    static constexpr std::uint32_t INPUT_IO_QUEUES = 64;

    std::uint32_t rdptr;
    std::uint32_t wrptr;
    std::uint32_t base_addr;
    std::uint32_t data_size_16B;
    std::uint32_t buffer_size_16B;

    inline void init_input_queue(
        std::uint32_t buffer_start, std::uint32_t buffer_end, std::uint32_t data_size) volatile {
        base_addr = buffer_start;
        rdptr = buffer_start;
        data_size_16B = data_size >> 4;
        buffer_size_16B = (buffer_end - buffer_start) >> 4;
    }

    inline void init_output_queue(
        std::uint32_t buffer_start, std::uint32_t buffer_end, std::uint32_t data_size) volatile {
        base_addr = buffer_start;
        wrptr = buffer_start;
        data_size_16B = data_size >> 4;
        buffer_size_16B = (buffer_end - buffer_start) >> 4;
    }

    inline void reset() volatile {
        rdptr = INVALID_IO_QUEUE_POINTER;
        wrptr = INVALID_IO_QUEUE_POINTER;
    }

    inline bool valid() volatile { return (rdptr != INVALID_IO_QUEUE_POINTER); }

    inline std::uint32_t get_buffer_end() const volatile { return base_addr + (buffer_size_16B << 4); }

    inline void increment_rd_pointer() volatile {
        if (!valid()) {
            return;
        }
        std::uint32_t new_rdptr = rdptr + (data_size_16B << 4);
        if ((new_rdptr & ~WRAP_MASK) >= get_buffer_end()) {
            if (wrap_bit(new_rdptr)) {
                new_rdptr = base_addr;
            } else {
                new_rdptr = WRAP_MASK | base_addr;
            }
        }
        rdptr = new_rdptr;
    }

    inline bool wrap_bit(std::uint32_t ptr) volatile { return (ptr & WRAP_MASK) != 0; }

    inline void increment_wr_pointer() volatile {
        if (wrptr == INVALID_IO_QUEUE_POINTER) {
            return;
        }
        std::uint32_t new_wrptr = wrptr + (data_size_16B << 4);
        if ((new_wrptr & ~WRAP_MASK) >= get_buffer_end()) {
            if (wrap_bit(new_wrptr)) {
                new_wrptr = base_addr;
            } else {
                new_wrptr = WRAP_MASK | base_addr;
            }
        }
        wrptr = new_wrptr;
    }

    inline void set_wr_pointer(std::uint32_t value) volatile { wrptr = value; }

    inline void set_rd_pointer(std::uint32_t value) volatile { rdptr = value; }

    inline bool empty() volatile { return rdptr == wrptr; }

    inline bool full() volatile {
        auto wrapped_rdptr = rdptr ^ WRAP_MASK;
        return wrapped_rdptr == wrptr;
    }

    inline bool has_data() volatile {
        return (rdptr != INVALID_IO_QUEUE_POINTER) and (wrptr != INVALID_IO_QUEUE_POINTER) and (not empty());
    }

    inline std::uint32_t unwrap_ptr(std::uint32_t value) const volatile {
        if (value == INVALID_IO_QUEUE_POINTER) {
            return value;
        }
        return value & ~WRAP_MASK;
    }
};
       




       


using uint = std::uint32_t;
using byte = std::uint8_t;
struct riscv_debug_reg_dbg_dbus_cntl_t {
    uint dbg_sig_sel : 16;
    uint dbg_daisy_sel : 8;
    uint dbg_rd_sel : 4;
    uint dbg_reg_ovrd_en : 1;
    uint dbg_daisy_en : 1;
    uint dbg_reserved : 2;
};

union riscv_debug_reg_dbg_dbus_cntl_u {
    uint val;
    riscv_debug_reg_dbg_dbus_cntl_t f;
};

struct riscv_debug_reg_dbg_l1_mem_reg2_t {
    uint mem_dump_mode : 4;
    uint skip_cycles : 8;
    uint mem_write : 1;
    uint mem_read : 1;
    uint reserved : 18;
};

union riscv_debug_reg_dbg_l1_mem_reg2_u {
    uint val;
    riscv_debug_reg_dbg_l1_mem_reg2_t f;
};
static constexpr unsigned int R0 = 0;
static constexpr unsigned int R1 = 1;
static constexpr unsigned int R2 = 2;
static constexpr unsigned int R3 = 3;
static constexpr unsigned int R4 = 4;
static constexpr unsigned int R5 = 5;
static constexpr unsigned int R6 = 6;
static constexpr unsigned int R7 = 7;
static constexpr unsigned int R8 = 8;
static constexpr unsigned int R9 = 9;
static constexpr unsigned int R10 = 10;
static constexpr unsigned int R11 = 11;
static constexpr unsigned int R12 = 12;
static constexpr unsigned int R13 = 13;
static constexpr unsigned int R14 = 14;
static constexpr unsigned int R15 = 15;
static constexpr unsigned int R16 = 16;
static constexpr unsigned int R17 = 17;
static constexpr unsigned int R18 = 18;
static constexpr unsigned int R19 = 19;
static constexpr unsigned int R20 = 20;
static constexpr unsigned int R21 = 21;
static constexpr unsigned int R22 = 22;
static constexpr unsigned int R23 = 23;
static constexpr unsigned int R24 = 24;
static constexpr unsigned int R25 = 25;
static constexpr unsigned int R26 = 26;
static constexpr unsigned int R27 = 27;
static constexpr unsigned int R28 = 28;
static constexpr unsigned int R29 = 29;
static constexpr unsigned int R30 = 30;
static constexpr unsigned int R31 = 31;
static constexpr unsigned int R32 = 32;
static constexpr unsigned int R33 = 33;
static constexpr unsigned int R34 = 34;
static constexpr unsigned int R35 = 35;
static constexpr unsigned int R36 = 36;
static constexpr unsigned int R37 = 37;
static constexpr unsigned int R38 = 38;
static constexpr unsigned int R39 = 39;
static constexpr unsigned int R40 = 40;
static constexpr unsigned int R41 = 41;
static constexpr unsigned int R42 = 42;
static constexpr unsigned int R43 = 43;
static constexpr unsigned int R44 = 44;
static constexpr unsigned int R45 = 45;
static constexpr unsigned int R46 = 46;
static constexpr unsigned int R47 = 47;
static constexpr unsigned int R48 = 48;
static constexpr unsigned int R49 = 49;
static constexpr unsigned int R50 = 50;
static constexpr unsigned int R51 = 51;
static constexpr unsigned int R52 = 52;
static constexpr unsigned int R53 = 53;
static constexpr unsigned int R54 = 54;
static constexpr unsigned int R55 = 55;
static constexpr unsigned int R56 = 56;
static constexpr unsigned int R57 = 57;
static constexpr unsigned int R58 = 58;
static constexpr unsigned int R59 = 59;
static constexpr unsigned int R60 = 60;
static constexpr unsigned int R61 = 61;
static constexpr unsigned int R62 = 62;
static constexpr unsigned int R63 = 63;
enum cnt_id_t { UNP0 = 1, UNP1 = 2, PCK0 = 4 };
template <class T>
inline T bitmask(unsigned int bits) {
    static_assert(!std::numeric_limits<T>::is_signed, "bitmask type must be unsigned");



    static_assert(std::numeric_limits<T>::radix == 2, "bitmask type must be radix 2");

    return (bits == std::numeric_limits<T>::digits) ? std::numeric_limits<T>::max() : (T(1) << bits) - 1;
}

template <class T>
inline typename std::make_unsigned<T>::type pack_field(T x, unsigned int to_shift) {
    using u_T = typename std::make_unsigned<T>::type;
    u_T u_x(x);




    return u_x << to_shift;
}

template <class T>
inline typename std::make_unsigned<T>::type pack_field(T x, unsigned int bits, unsigned int to_shift) {
    typename std::make_unsigned<T>::type u_x(x);




    return u_x << to_shift;
}

template <class T>
inline typename std::make_unsigned<T>::type pack_field(
    T x, unsigned int bits, unsigned int from_shift, unsigned int to_shift) {
    typename std::make_unsigned<T>::type u_x(x);




    return ((u_x >> from_shift) & bitmask<T>(bits)) << to_shift;
}





       
using vptr_uint = volatile uint32_t*;
using vptr_pc_buf = vptr_uint;
using vptr_mailbox = vptr_uint;



typedef __builtin_va_list __gnuc_va_list;
typedef __gnuc_va_list va_list;







inline void clobber_all_memory(void) { asm volatile("" ::: "memory"); }
inline void ex_push_insn(vptr_uint instrn_buffer, uint instrn) { instrn_buffer[0] = instrn; }






inline void ex_push_insn(vptr_uint instrn_buffer, uint instrn1, uint instrn2) {
    instrn_buffer[0] = instrn1;
    instrn_buffer[0] = instrn2;
}

inline void ex_pacr(uint addr_mode, uint zero_write, uint flush, uint last, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (addr_mode << 15) | (zero_write << 12) | (flush << 8) | (last);
    ex_push_insn(instrn_buf, (0x41000000 | (instrn)));
}

inline void ex_upacr(uint block_sel, uint addr_mode, uint zero_write, uint last, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (block_sel << 23) | (addr_mode << 15) | (zero_write << 4) | (last);
    ex_push_insn(instrn_buf, (0x42000000 | (instrn)));
}

inline void ex_xsearch(uint block_sel, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (block_sel << 23);
    ex_push_insn(instrn_buf, (0x43000000 | (instrn)));
}

inline void ex_nop(vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0;
    ex_push_insn(instrn_buf, (0x02000000 | (instrn)));
}

inline void ex_flush(vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0;
    ex_push_insn(instrn_buf, (0x81000000 | (instrn)));
}





inline void ex_zerosrc(uint src, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | src;
    ex_push_insn(instrn_buf, (0x1b000000 | (instrn)));
}

inline void ex_mova2d(uint addr_mode, uint srca_transp, uint dest_index, uint srca_index, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (addr_mode << 15) | (srca_transp << 12) | (dest_index << 4) | (srca_index);
    ex_push_insn(instrn_buf, (0x1a000000 | (instrn)));
}

inline void ex_stallwait(uint wait_res, uint stall_res, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (stall_res << 12) | (wait_res);
    ex_push_insn(instrn_buf, (0xa2000000 | (instrn)));
}

inline void ex_setc16(uint addr, uint val, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (addr << 16) | (val & 0xFFFF);
    ex_push_insn(instrn_buf, (0xb2000000 | (instrn)));
}

inline void ex_instrn_wrcfg(uint gpr, uint cfg_addr, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (gpr << 16) | (cfg_addr);
    ex_push_insn(instrn_buf, (0xb0000000 | (instrn)));
}

inline void ex_instrn_rdcfg(uint gpr, uint cfg_addr, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (gpr << 16) | (cfg_addr);
    ex_push_insn(instrn_buf, (0xb1000000 | (instrn)));
}

inline uint32_t rmw_cfg_value(uint cfg_shamt, uint32_t cfg_mask, uint32_t wrdata, uint32_t l_cfg_data) {
    uint32_t cfg_data = l_cfg_data;


    wrdata <<= cfg_shamt;
    wrdata &= cfg_mask;


    cfg_data &= ~cfg_mask;


    cfg_data |= wrdata;

    return cfg_data;
}

inline void ex_rmw_cfg(uint cfg_addr32, uint cfg_shamt, uint32_t cfg_mask, uint wr_val, vptr_uint cfg_regs) {
    uint addr = cfg_addr32;
    uint32_t cfg_data = cfg_regs[addr];
    cfg_regs[addr] = rmw_cfg_value(cfg_shamt, cfg_mask, wr_val, cfg_data);
}

inline void ex_rmw_cfg_gpr(
    uint cfg_addr32, uint cfg_shamt, uint32_t cfg_mask, uint gpr_index, vptr_uint regfile, vptr_uint cfg_regs) {
    uint32_t wrdata = regfile[gpr_index];
    ex_rmw_cfg(cfg_addr32, cfg_shamt, cfg_mask, wrdata, cfg_regs);
}




inline void ex_setadc(cnt_id_t cnt_ind, uint chan_ind, uint dim_ind, uint val, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (cnt_ind << 21) | (chan_ind << 20) | (dim_ind << 18) | (val & 0xFFFF);
    ex_push_insn(instrn_buf, (0x50000000 | (instrn)));
}

inline void ex_zeroacc(vptr_uint instrn_buf, uint clear_mode = 3, uint dest_register = 0, uint addressing_mode = 0) {
    uint instrn;
    instrn = 0x0 | (clear_mode << 19) | (addressing_mode << 15) | (dest_register << 0);
    ex_push_insn(instrn_buf, (0x10000000 | (instrn)));
}

inline void ex_encc(vptr_uint instrn_buf) {
    uint instrn;
    instrn = (3 << 12) | (10 << 0);
    ex_push_insn(instrn_buf, (0x8a000000 | (instrn)));
    ex_push_insn(instrn_buf, (0x02000000 | (0)));
}
inline void ex_setadcxy(cnt_id_t cntset_ind, uint srcb_y, uint srcb_x, uint srca_y, uint srca_x, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (cntset_ind << 21) | (srcb_y << 15) | (srcb_x << 12) | (srca_y << 9) | (srca_x << 6) | 0x0f;
    ex_push_insn(instrn_buf, (0x51000000 | (instrn)));
}

inline void ex_setadczw(cnt_id_t cntset_ind, uint srcb_w, uint srcb_z, uint srca_w, uint srca_z, vptr_uint instrn_buf) {
    uint instrn;
    instrn = 0x0 | (cntset_ind << 21) | (srcb_w << 15) | (srcb_z << 12) | (srca_w << 9) | (srca_z << 6) | 0x3f;
    ex_push_insn(instrn_buf, (0x54000000 | (instrn)));
}
inline void ex_setpkedgof(uint edge_mask, vptr_uint instrn_buf) {
    ex_push_insn(instrn_buf, (0x1d000000 | (edge_mask)));
}

inline void execute_kernel_loop(uint kernel_count, uint loop_count, vptr_pc_buf pc_buf) {


    clobber_all_memory();
    uint32_t val = ((kernel_count - 1) << 16) | (loop_count - 1);
    pc_buf[0] = (0x00000000 | (val));
}

inline void execute_kernel_sync(vptr_pc_buf pc_buf, vptr_mailbox mailbox) {

    volatile uint foo = 0xdeadbeef;
    volatile uint* fooptr = &foo;
    clobber_all_memory();
    pc_buf[1] = foo;

    *fooptr = pc_buf[1];


    clobber_all_memory();
}

inline void unhalt_tensix() {
    clobber_all_memory();
    volatile uint* pc_buf = reinterpret_cast<volatile uint*>(0xFFE80000);
    pc_buf[0] = 0x40000000;
}

inline void memory_write(uint addr, uint value) {

    volatile uint* buf = reinterpret_cast<volatile uint*>(addr);
    buf[0] = value;

}

inline uint memory_read(uint addr) {

    volatile uint* buf = reinterpret_cast<volatile uint*>(addr);
    return buf[0];




}

inline void execute_instruction(vptr_uint instrn_buffer, unsigned int instruction) {
    ex_push_insn(instrn_buffer, instruction);
}

inline void thcon_flush_dma(vptr_uint instrn_buffer, uint arg) {
    execute_instruction(instrn_buffer, (0x46000000 | (arg)));
}



inline void thcon_load_ind(
    vptr_uint instrn_buffer, uint base_addr_index, uint dst_data_index, uint offset_index, uint autoinc, uint size) {
    uint instrn_arg;

    instrn_arg =
        0x0 | (base_addr_index) | (dst_data_index << 6) | (autoinc << 12) | (offset_index << 14) | (size << 22);
    execute_instruction(instrn_buffer, (0x49000000 | (instrn_arg)));
}

inline void thcon_store_ind(
    vptr_uint instrn_buffer,
    uint base_index,
    uint src_data_index,
    uint offset_index,
    uint autoinc,
    uint mode_32b_16B,
    bool l0_l1_sel,
    uint tile_mode) {
    uint instrn_arg;
    uint sel = l0_l1_sel;

    instrn_arg = 0x0 | (base_index) | (src_data_index << 6) | (autoinc << 12) | (offset_index << 14) |
                 (tile_mode << 21) | (mode_32b_16B << 22) | (sel << 23);
    execute_instruction(instrn_buffer, (0x66000000 | (instrn_arg)));
}

inline void thcon_incr_get_ptr(
    vptr_uint instrn_buffer,
    uint mem_addr_index,
    uint data_reg_index,
    uint incr_val,
    uint wrap_val,
    bool rd_wr,
    bool l0_l1_sel) {
    uint instrn_arg;
    uint sel = l0_l1_sel;
    uint rd_wr_sel = (uint)rd_wr;



    instrn_arg = 0x0 | (mem_addr_index) | (data_reg_index << 6) | (wrap_val << 14) | (rd_wr_sel << 12) |
                 (incr_val << 18) | (sel << 23);
    execute_instruction(instrn_buffer, (0x62000000 | (instrn_arg)));
}

inline void thcon_incr_get_ptr_noinc(
    vptr_uint instrn_buffer,
    uint mem_addr_index,
    uint data_reg_index,
    uint incr_val,
    uint wrap_val,
    bool rd_wr,
    bool l0_l1_sel) {
    uint instrn_arg;
    uint sel = l0_l1_sel;
    uint rd_wr_sel = (uint)rd_wr;

    instrn_arg = 0x0 | (mem_addr_index) | (data_reg_index << 6) | (wrap_val << 14) | (rd_wr_sel << 12) |
                 (incr_val << 18) | (1 << 22) | (sel << 23);
    execute_instruction(instrn_buffer, (0x62000000 | (instrn_arg)));
}

inline void thcon_reg_to_flops(
    vptr_uint instrn_buffer,
    uint mode_32b_16B,
    uint reg_index,
    uint flop_index,
    uint target_select = 0,
    uint byte_offset = 0) {
    int instrn_arg;
    instrn_arg =
        0x0 | reg_index | (flop_index << 6) | (byte_offset << 18) | (target_select << 20) | (mode_32b_16B << 22);
    execute_instruction(instrn_buffer, (0x48000000 | (instrn_arg)));
}

inline void ex_clear_dvalid(uint clear_ab, uint reset, vptr_uint instrn_buffer) {
    int instrn_arg;
    instrn_arg = 0x0 | (reset & 0x1) | (clear_ab << 22);
    execute_instruction(instrn_buffer, (0x37000000 | (instrn_arg)));
}

inline void ex_sem_init(uint semaphore, uint max_value, uint init_value, vptr_uint instrn_buffer) {
    int instrn_arg;
    instrn_arg = 0x0 | (0x1 << (semaphore + 2)) | (init_value << 16) | (max_value << 20);
    execute_instruction(instrn_buffer, (0xa3000000 | (instrn_arg)));
}
inline void thcon_cas(
    vptr_uint instrn_buffer,
    uint8_t address_register_index,
    uint8_t data_register_index,
    uint8_t word_select,
    uint8_t compare_value,
    uint8_t swap_value,
    bool mem_heirarchy_select) {
    const uint32_t instrn_arg = ((uint32_t)address_register_index << 0) | ((uint32_t)data_register_index << 6) |
                                ((uint32_t)word_select << 12) | ((uint32_t)compare_value << 14) |
                                ((uint32_t)swap_value << 18) | ((uint32_t)mem_heirarchy_select << 23);

    execute_instruction(instrn_buffer, (0x64000000 | (instrn_arg)));
}

inline void thcon_at_swap(
    vptr_uint instrn_buffer, uint mem_addr_index, uint src_data_index, uint mask_16b, bool l0_l1_sel) {
    uint instrn_arg;
    uint sel = l0_l1_sel;


    instrn_arg = 0x0 | (mem_addr_index) | (src_data_index << 8) | (mask_16b << 14) | (sel << 23);
    execute_instruction(instrn_buffer, (0x63000000 | (instrn_arg)));
}



inline void thcon_write_16b_reg(
    vptr_uint instrn_buffer, uint addr , uint val, bool set_signals_mode = false) {
    uint setdma_payload;
    uint instrn_arg;

    setdma_payload = val;
    instrn_arg = 0x0 | addr | (setdma_payload << 8);
    if (set_signals_mode) {
        instrn_arg |= (1 << 7);
    }
    execute_instruction(instrn_buffer, (0x45000000 | (instrn_arg)));
}



inline void thcon_sigwrite_16b_reg(vptr_uint instrn_buffer, uint addr , uint sig_addr) {
    uint instrn_arg;

    instrn_arg = 0x0 | addr | (1 << 7) | (sig_addr << 8);
    execute_instruction(instrn_buffer, (0x45000000 | (instrn_arg)));
}



inline void thcon_write_32b_reg(uint addr , uint val) {
    volatile uint* regfile = reinterpret_cast<uint*>(0xFFE00000);
    regfile[addr] = val;
}



inline void thcon_write_16B_reg(uint addr, const uint* val) {
    uint addr_bot;
    addr_bot = addr << 2;
    int i;

    for (i = 0; i < 4; ++i) {
        thcon_write_32b_reg(addr_bot + i, val[i]);
    }
}

inline void thcon_set_packer_section_conf(vptr_uint instrn_buf, uint rowstart_size, uint exp_size) {


    uint reg_index = 9;
    uint flop_index = 4;
    uint reg;
    reg = 0x0 | rowstart_size | (exp_size << 16);
    thcon_write_32b_reg(reg_index, reg);
    thcon_reg_to_flops(instrn_buf, 1, reg_index, flop_index);
}

inline void thcon_write_tile_addr(vptr_uint instrn_buf, uint reg_index, uint unpacker_id) {





    thcon_reg_to_flops(instrn_buf, 1, reg_index, 3 + (4 * 2) + ((unpacker_id) * 32));

}

inline void thcon_set_packer_l1_dest_addr(vptr_uint instrn_buf, uint l1_dest_addr) {

    uint reg_index = 9;
    uint flop_index = 1 + (4 * 1);
    uint reg;
    reg = l1_dest_addr;
    thcon_write_32b_reg(reg_index, reg);
    thcon_reg_to_flops(instrn_buf, 1, reg_index, flop_index);
}

inline void thcon_set_packer_misc_conf(
    vptr_uint instrn_buf, uint disable_zcomp, uint in_data_format, uint out_data_format, uint dest_digest_offset) {


    uint reg_index = 9;
    uint flop_index = 2 + (4 * 1);
    uint reg;
    reg = 0x0 | disable_zcomp | (in_data_format << 8) | (out_data_format << 4) | (dest_digest_offset << 12);
    thcon_write_32b_reg(reg_index, reg);
    thcon_reg_to_flops(instrn_buf, 1, reg_index, flop_index);
}

inline void thcon_set_unpacker_misc_conf(vptr_uint instrn_buf, uint out_data_format, uint unpacker_id) {

    uint reg_index = 0;
    uint flop_index = 3 + (4 * 1) + ((unpacker_id) * 32);
    uint reg;
    reg = 0x0 | out_data_format;
    thcon_write_32b_reg(reg_index, reg);
    thcon_reg_to_flops(instrn_buf, 1, reg_index, flop_index);
}



inline void thcon_set_descriptor(vptr_uint instrn_buf, uint reg_index, uint unpacker_id) {
    uint reg_index_fixed;
    reg_index_fixed = reg_index << 2;
    thcon_reg_to_flops(instrn_buf, 0, reg_index_fixed, 0 + ((unpacker_id) * 32));
}

inline tile_descriptor_u thcon_build_descriptor(
    uint tile_id, uint tile_type, uint x_dim, uint y_dim, uint z_dim, uint w_dim, uint digest_type, uint digest_size) {
    tile_descriptor_u td;

    tile_id &= bitmask<uint>(
        16);

    td.val[0] = pack_field(tile_id, 16, 8) | pack_field(tile_type, 8, 0) | pack_field(x_dim, 8, 0, 24);
    td.val[1] = pack_field(x_dim, 8, 8, 0) | pack_field(y_dim, 16, 0, 8) | pack_field(z_dim, 8, 0, 24);
    td.val[2] = pack_field(z_dim, 8, 8, 0) | pack_field(w_dim, 16, 0, 8);
    td.val[3] = pack_field(digest_type, 8, 24) | pack_field(digest_size, 8, 16);

    return td;
}



inline void thcon_write_descriptor_to_reg(
    uint reg_index,
    uint tile_id,
    uint tile_type,
    uint x_dim,
    uint y_dim,
    uint z_dim,
    uint w_dim,
    uint digest_type,
    uint digest_size) {
    tile_descriptor_u td =
        thcon_build_descriptor(tile_id, tile_type, x_dim, y_dim, z_dim, w_dim, digest_type, digest_size);

    thcon_write_16B_reg(reg_index, td.val);
}


inline void thcon_write_descriptor_to_l1(
    uint addr,
    uint tile_id,
    uint tile_type,
    uint x_dim,
    uint y_dim,
    uint z_dim,
    uint w_dim,
    uint digest_type,
    uint digest_size) {
    volatile uint* ptr = reinterpret_cast<volatile uint*>(addr);

    tile_descriptor_u td =
        thcon_build_descriptor(tile_id, tile_type, x_dim, y_dim, z_dim, w_dim, digest_type, digest_size);

    ptr[0] = td.val[0];
    ptr[1] = td.val[1];
    ptr[2] = td.val[2];
    ptr[3] = td.val[3];
}
inline void breakpoint_set(uint thread, uint bkpt_index, bool pc_valid, uint pc = 0) {
    memory_write(
        (0xFFB12000 | 0x1C0), ((thread << 31) | (0x1 << 28) | (bkpt_index << 26) | (pc_valid << 21 | pc)));
}

inline void breakpoint_clear(uint thread, uint bkpt_index) {
    memory_write((0xFFB12000 | 0x1C0), ((thread << 31) | (0x2 << 28) | (bkpt_index << 26) | 0));
}


inline void breakpoint_set_data(uint thread, uint bkpt_index, uint data_index) {
    memory_write(
        (0xFFB12000 | 0x1C0), ((thread << 31) | (0x3 << 28) | (bkpt_index << 26) | data_index));
}

inline void breakpoint_set_condition_op(uint thread, uint bkpt_index, uint opcode, uint opcode_mask = 0xFF) {
    memory_write(
        (0xFFB12000 | 0x1C0),
        ((thread << 31) | (0x4 << 28) | (bkpt_index << 26) | (opcode_mask << 8 | opcode)));
}

inline void breakpoint_clear_condition_op(uint thread, uint bkpt_index) {
    memory_write((0xFFB12000 | 0x1C0), ((thread << 31) | (0x5 << 28) | (bkpt_index << 26) | 0));
}

inline void breakpoint_set_condition_loop(uint thread, uint bkpt_index, uint loop) {
    memory_write(
        (0xFFB12000 | 0x1C0),
        ((thread << 31) | (0x4 << 28) | (bkpt_index << 26) | (0x1 << 16) | loop));
}

inline void breakpoint_clear_condition_loop(uint thread, uint bkpt_index) {
    memory_write(
        (0xFFB12000 | 0x1C0), ((thread << 31) | (0x5 << 28) | (bkpt_index << 26) | 0x1 << 16));
}

inline void breakpoint_set_condition_other_thread(uint thread, uint bkpt_index) {
    memory_write(
        (0xFFB12000 | 0x1C0), ((thread << 31) | (0x4 << 28) | (bkpt_index << 26) | (0x2 << 16)));
}

inline void breakpoint_clear_condition_other_thread(uint thread, uint bkpt_index) {
    memory_write(
        (0xFFB12000 | 0x1C0), ((thread << 31) | (0x5 << 28) | (bkpt_index << 26) | 0x2 << 16));
}

inline void breakpoint_resume_execution(uint thread) {
    memory_write((0xFFB12000 | 0x1C0), ((thread << 31) | (0x0 << 28) | 0));
}


inline uint breakpoint_status(uint thread, uint bkpt_index) {
    uint status = memory_read((0xFFB12000 | 0x1C4));
    return (status >> ((bkpt_index + thread * 4) * 4)) & 0xF;
}


inline uint breakpoint_status() {
    uint status = memory_read((0xFFB12000 | 0x1C4));
    return status;
}

inline uint breakpoint_data() {
    volatile uint* ptr = reinterpret_cast<volatile uint*>((0xFFB12000 | 0x1C8));
    *ptr = 0;
    return *ptr;
}
inline void dbg_dump_array_enable() { memory_write((0xFFB12000 | 0x060), 1); }

inline void dbg_dump_array_disable() {

    memory_write((0xFFB12000 | 0x064), ((0 << 19) | (0xF << 16) | 0));
    memory_write((0xFFB12000 | 0x060), 0);
}

inline void dbg_dump_array_rd_cmd(uint thread, uint array_id, uint addr) {
    memory_write((0xFFB12000 | 0x064), ((thread << 19) | (array_id << 16) | addr));
    volatile uint dummy_wait;
    volatile uint* dummy_wait_ptr = &dummy_wait;
    *dummy_wait_ptr = memory_read((0xFFB12000 | 0x064));
}

inline void dbg_dump_array_to_l1(uint thread, uint addr) {

}

inline void dbg_instrn_buf_wait_for_ready() {
    while (1) {
        volatile uint status = memory_read((0xFFB12000 | 0x0A8));
        if (status == 0x77) {
            break;
        }
    }
}

inline void dbg_instrn_buf_set_override_en() {

    memory_write((0xFFB12000 | 0x0A0), 0x7);
}

inline void dbg_instrn_buf_push_instrn(uint instrn) {

    memory_write((0xFFB12000 | 0x0A4), instrn);

    memory_write((0xFFB12000 | 0x0A0), 0x17);

    memory_write((0xFFB12000 | 0x0A0), 0x07);
}

inline void dbg_instrn_buf_clear_override_en() {

    memory_write((0xFFB12000 | 0x0A0), 0x0);
}

extern "C" void wzerorange(uint32_t* start, uint32_t* end);
inline void wzeromem(uint32_t start, uint32_t len) { wzerorange((uint32_t*)start, (uint32_t*)(start + len)); }




       

       





       
       





#pragma GCC visibility push(default)




namespace std
{

  template<class _E>
    class initializer_list
    {
    public:
      typedef _E value_type;
      typedef const _E& reference;
      typedef const _E& const_reference;
      typedef size_t size_type;
      typedef const _E* iterator;
      typedef const _E* const_iterator;

    private:
      iterator _M_array;
      size_type _M_len;


      constexpr initializer_list(const_iterator __a, size_type __l)
      : _M_array(__a), _M_len(__l) { }

    public:
      constexpr initializer_list() noexcept
      : _M_array(0), _M_len(0) { }


      constexpr size_type
      size() const noexcept { return _M_len; }


      constexpr const_iterator
      begin() const noexcept { return _M_array; }


      constexpr const_iterator
      end() const noexcept { return begin() + size(); }
    };







  template<class _Tp>
    constexpr const _Tp*
    begin(initializer_list<_Tp> __ils) noexcept
    { return __ils.begin(); }







  template<class _Tp>
    constexpr const _Tp*
    end(initializer_list<_Tp> __ils) noexcept
    { return __ils.end(); }
}

#pragma GCC visibility pop



namespace std __attribute__ ((__visibility__ ("default")))
{



  void
  __throw_bad_exception(void) __attribute__((__noreturn__));


  void
  __throw_bad_alloc(void) __attribute__((__noreturn__));

  void
  __throw_bad_array_new_length(void) __attribute__((__noreturn__));


  void
  __throw_bad_cast(void) __attribute__((__noreturn__));

  void
  __throw_bad_typeid(void) __attribute__((__noreturn__));


  void
  __throw_logic_error(const char*) __attribute__((__noreturn__));

  void
  __throw_domain_error(const char*) __attribute__((__noreturn__));

  void
  __throw_invalid_argument(const char*) __attribute__((__noreturn__));

  void
  __throw_length_error(const char*) __attribute__((__noreturn__));

  void
  __throw_out_of_range(const char*) __attribute__((__noreturn__));

  void
  __throw_out_of_range_fmt(const char*, ...) __attribute__((__noreturn__))
    __attribute__((__format__(__gnu_printf__, 1, 2)));

  void
  __throw_runtime_error(const char*) __attribute__((__noreturn__));

  void
  __throw_range_error(const char*) __attribute__((__noreturn__));

  void
  __throw_overflow_error(const char*) __attribute__((__noreturn__));

  void
  __throw_underflow_error(const char*) __attribute__((__noreturn__));


  void
  __throw_ios_failure(const char*) __attribute__((__noreturn__));

  void
  __throw_ios_failure(const char*, int) __attribute__((__noreturn__));


  void
  __throw_system_error(int) __attribute__((__noreturn__));


  void
  __throw_future_error(int) __attribute__((__noreturn__));


  void
  __throw_bad_function_call() __attribute__((__noreturn__));


}
       
extern "C++" {

namespace std __attribute__ ((__visibility__ ("default")))
{


  struct __true_type { };
  struct __false_type { };

  template<bool>
    struct __truth_type
    { typedef __false_type __type; };

  template<>
    struct __truth_type<true>
    { typedef __true_type __type; };



  template<class _Sp, class _Tp>
    struct __traitor
    {
      enum { __value = bool(_Sp::__value) || bool(_Tp::__value) };
      typedef typename __truth_type<__value>::__type __type;
    };


  template<typename, typename>
    struct __are_same
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<typename _Tp>
    struct __are_same<_Tp, _Tp>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<typename _Tp>
    struct __is_void
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<>
    struct __is_void<void>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };




  template<typename _Tp>
    struct __is_integer
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };





  template<>
    struct __is_integer<bool>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<signed char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<>
    struct __is_integer<wchar_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };
  template<>
    struct __is_integer<char16_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<char32_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<>
    struct __is_integer<short>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned short>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<int>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned int>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<long long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_integer<unsigned long long>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };
  template<typename _Tp>
    struct __is_floating
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };


  template<>
    struct __is_floating<float>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_floating<double>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_floating<long double>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };




  template<typename _Tp>
    struct __is_pointer
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<typename _Tp>
    struct __is_pointer<_Tp*>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };




  template<typename _Tp>
    struct __is_arithmetic
    : public __traitor<__is_integer<_Tp>, __is_floating<_Tp> >
    { };




  template<typename _Tp>
    struct __is_scalar
    : public __traitor<__is_arithmetic<_Tp>, __is_pointer<_Tp> >
    { };




  template<typename _Tp>
    struct __is_char
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<>
    struct __is_char<char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<>
    struct __is_char<wchar_t>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  template<typename _Tp>
    struct __is_byte
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };

  template<>
    struct __is_byte<char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_byte<signed char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<>
    struct __is_byte<unsigned char>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };


  enum class byte : unsigned char;

  template<>
    struct __is_byte<byte>
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };
  template<typename> struct iterator_traits;


  template<typename _Tp>
    struct __is_nonvolatile_trivially_copyable
    {
      enum { __value = __is_trivially_copyable(_Tp) };
    };




  template<typename _Tp>
    struct __is_nonvolatile_trivially_copyable<volatile _Tp>
    {
      enum { __value = 0 };
    };


  template<typename _OutputIter, typename _InputIter>
    struct __memcpyable
    {
      enum { __value = 0 };
    };

  template<typename _Tp>
    struct __memcpyable<_Tp*, _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };

  template<typename _Tp>
    struct __memcpyable<_Tp*, const _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };






  template<typename _Iter1, typename _Iter2>
    struct __memcmpable
    {
      enum { __value = 0 };
    };


  template<typename _Tp>
    struct __memcmpable<_Tp*, _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };

  template<typename _Tp>
    struct __memcmpable<const _Tp*, _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };

  template<typename _Tp>
    struct __memcmpable<_Tp*, const _Tp*>
    : __is_nonvolatile_trivially_copyable<_Tp>
    { };







  template<typename _Tp, bool _TreatAsBytes =



 __is_byte<_Tp>::__value

    >
    struct __is_memcmp_ordered
    {
      static const bool __value = _Tp(-1) > _Tp(1);
    };

  template<typename _Tp>
    struct __is_memcmp_ordered<_Tp, false>
    {
      static const bool __value = false;
    };


  template<typename _Tp, typename _Up, bool = sizeof(_Tp) == sizeof(_Up)>
    struct __is_memcmp_ordered_with
    {
      static const bool __value = __is_memcmp_ordered<_Tp>::__value
 && __is_memcmp_ordered<_Up>::__value;
    };

  template<typename _Tp, typename _Up>
    struct __is_memcmp_ordered_with<_Tp, _Up, false>
    {
      static const bool __value = false;
    };
  template<>
    struct __is_memcmp_ordered_with<std::byte, std::byte, true>
    { static constexpr bool __value = true; };

  template<typename _Tp, bool _SameSize>
    struct __is_memcmp_ordered_with<_Tp, std::byte, _SameSize>
    { static constexpr bool __value = false; };

  template<typename _Up, bool _SameSize>
    struct __is_memcmp_ordered_with<std::byte, _Up, _SameSize>
    { static constexpr bool __value = false; };





  template<typename _Tp>
    struct __is_move_iterator
    {
      enum { __value = 0 };
      typedef __false_type __type;
    };



  template<typename _Iterator>
   
    inline _Iterator
    __miter_base(_Iterator __it)
    { return __it; }


}
}
       




extern "C++" {

namespace __gnu_cxx __attribute__ ((__visibility__ ("default")))
{



  template<bool, typename>
    struct __enable_if
    { };

  template<typename _Tp>
    struct __enable_if<true, _Tp>
    { typedef _Tp __type; };



  template<bool _Cond, typename _Iftrue, typename _Iffalse>
    struct __conditional_type
    { typedef _Iftrue __type; };

  template<typename _Iftrue, typename _Iffalse>
    struct __conditional_type<false, _Iftrue, _Iffalse>
    { typedef _Iffalse __type; };



  template<typename _Tp>
    struct __add_unsigned
    {
    private:
      typedef __enable_if<std::__is_integer<_Tp>::__value, _Tp> __if_type;

    public:
      typedef typename __if_type::__type __type;
    };

  template<>
    struct __add_unsigned<char>
    { typedef unsigned char __type; };

  template<>
    struct __add_unsigned<signed char>
    { typedef unsigned char __type; };

  template<>
    struct __add_unsigned<short>
    { typedef unsigned short __type; };

  template<>
    struct __add_unsigned<int>
    { typedef unsigned int __type; };

  template<>
    struct __add_unsigned<long>
    { typedef unsigned long __type; };

  template<>
    struct __add_unsigned<long long>
    { typedef unsigned long long __type; };


  template<>
    struct __add_unsigned<bool>;

  template<>
    struct __add_unsigned<wchar_t>;



  template<typename _Tp>
    struct __remove_unsigned
    {
    private:
      typedef __enable_if<std::__is_integer<_Tp>::__value, _Tp> __if_type;

    public:
      typedef typename __if_type::__type __type;
    };

  template<>
    struct __remove_unsigned<char>
    { typedef signed char __type; };

  template<>
    struct __remove_unsigned<unsigned char>
    { typedef signed char __type; };

  template<>
    struct __remove_unsigned<unsigned short>
    { typedef short __type; };

  template<>
    struct __remove_unsigned<unsigned int>
    { typedef int __type; };

  template<>
    struct __remove_unsigned<unsigned long>
    { typedef long __type; };

  template<>
    struct __remove_unsigned<unsigned long long>
    { typedef long long __type; };


  template<>
    struct __remove_unsigned<bool>;

  template<>
    struct __remove_unsigned<wchar_t>;



  template<typename _Type>
    constexpr
    inline bool
    __is_null_pointer(_Type* __ptr)
    { return __ptr == 0; }

  template<typename _Type>
    constexpr
    inline bool
    __is_null_pointer(_Type)
    { return false; }


  constexpr bool
  __is_null_pointer(std::nullptr_t)
  { return true; }




  template<typename _Tp, bool = std::__is_integer<_Tp>::__value>
    struct __promote
    { typedef double __type; };




  template<typename _Tp>
    struct __promote<_Tp, false>
    { };

  template<>
    struct __promote<long double>
    { typedef long double __type; };

  template<>
    struct __promote<double>
    { typedef double __type; };

  template<>
    struct __promote<float>
    { typedef float __type; };



  template<typename... _Tp>
    using __promoted_t = decltype((typename __promote<_Tp>::__type(0) + ...));



  template<typename _Tp, typename _Up>
    using __promote_2 = __promote<__promoted_t<_Tp, _Up>>;

  template<typename _Tp, typename _Up, typename _Vp>
    using __promote_3 = __promote<__promoted_t<_Tp, _Up, _Vp>>;

  template<typename _Tp, typename _Up, typename _Vp, typename _Wp>
    using __promote_4 = __promote<__promoted_t<_Tp, _Up, _Vp, _Wp>>;

}
}
       




namespace __gnu_cxx __attribute__ ((__visibility__ ("default")))
{

  template<typename _Tp>
    struct __is_integer_nonstrict
    : public std::__is_integer<_Tp>
    {
      using std::__is_integer<_Tp>::__value;


      enum { __width = __value ? sizeof(_Tp) * 8 : 0 };
    };

  template<typename _Value>
    struct __numeric_traits_integer
    {

      static_assert(__is_integer_nonstrict<_Value>::__value,
      "invalid specialization");




      static const bool __is_signed = (_Value)(-1) < 0;
      static const int __digits
 = __is_integer_nonstrict<_Value>::__width - __is_signed;


      static const _Value __max = __is_signed
 ? (((((_Value)1 << (__digits - 1)) - 1) << 1) + 1)
 : ~(_Value)0;
      static const _Value __min = __is_signed ? -__max - 1 : (_Value)0;
    };

  template<typename _Value>
    const _Value __numeric_traits_integer<_Value>::__min;

  template<typename _Value>
    const _Value __numeric_traits_integer<_Value>::__max;

  template<typename _Value>
    const bool __numeric_traits_integer<_Value>::__is_signed;

  template<typename _Value>
    const int __numeric_traits_integer<_Value>::__digits;
  template<typename _Tp>
    using __int_traits = __numeric_traits_integer<_Tp>;
  template<typename _Value>
    struct __numeric_traits_floating
    {

      static const int __max_digits10 = (2 + (std::__are_same<_Value, float>::__value ? 24 : std::__are_same<_Value, double>::__value ? 53 : 113) * 643L / 2136);


      static const bool __is_signed = true;
      static const int __digits10 = (std::__are_same<_Value, float>::__value ? 6 : std::__are_same<_Value, double>::__value ? 15 : 33);
      static const int __max_exponent10 = (std::__are_same<_Value, float>::__value ? 38 : std::__are_same<_Value, double>::__value ? 308 : 4932);
    };

  template<typename _Value>
    const int __numeric_traits_floating<_Value>::__max_digits10;

  template<typename _Value>
    const bool __numeric_traits_floating<_Value>::__is_signed;

  template<typename _Value>
    const int __numeric_traits_floating<_Value>::__digits10;

  template<typename _Value>
    const int __numeric_traits_floating<_Value>::__max_exponent10;






  template<typename _Value>
    struct __numeric_traits
    : public __numeric_traits_integer<_Value>
    { };

  template<>
    struct __numeric_traits<float>
    : public __numeric_traits_floating<float>
    { };

  template<>
    struct __numeric_traits<double>
    : public __numeric_traits_floating<double>
    { };

  template<>
    struct __numeric_traits<long double>
    : public __numeric_traits_floating<long double>
    { };

}
namespace std __attribute__ ((__visibility__ ("default")))
{







  template<typename _Tp>
    inline constexpr _Tp*
    __addressof(_Tp& __r) noexcept
    { return __builtin_addressof(__r); }




}



namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Tp>
    [[__nodiscard__]]
    constexpr _Tp&&
    forward(typename std::remove_reference<_Tp>::type& __t) noexcept
    { return static_cast<_Tp&&>(__t); }







  template<typename _Tp>
    [[__nodiscard__]]
    constexpr _Tp&&
    forward(typename std::remove_reference<_Tp>::type&& __t) noexcept
    {
      static_assert(!std::is_lvalue_reference<_Tp>::value,
   "std::forward must not be used to convert an rvalue to an lvalue");
      return static_cast<_Tp&&>(__t);
    }






  template<typename _Tp>
    [[__nodiscard__]]
    constexpr typename std::remove_reference<_Tp>::type&&
    move(_Tp&& __t) noexcept
    { return static_cast<typename std::remove_reference<_Tp>::type&&>(__t); }


  template<typename _Tp>
    struct __move_if_noexcept_cond
    : public __and_<__not_<is_nothrow_move_constructible<_Tp>>,
                    is_copy_constructible<_Tp>>::type { };
  template<typename _Tp>
    [[__nodiscard__]]
    constexpr
    __conditional_t<__move_if_noexcept_cond<_Tp>::value, const _Tp&, _Tp&&>
    move_if_noexcept(_Tp& __x) noexcept
    { return std::move(__x); }
  template<typename _Tp>
    [[__nodiscard__]]
    inline constexpr _Tp*
    addressof(_Tp& __r) noexcept
    { return std::__addressof(__r); }



  template<typename _Tp>
    const _Tp* addressof(const _Tp&&) = delete;


  template <typename _Tp, typename _Up = _Tp>
   
    inline _Tp
    __exchange(_Tp& __obj, _Up&& __new_val)
    {
      _Tp __old_val = std::move(__obj);
      __obj = std::forward<_Up>(__new_val);
      return __old_val;
    }
  template<typename _Tp>
   
    inline

    typename enable_if<__and_<__not_<__is_tuple_like<_Tp>>,
         is_move_constructible<_Tp>,
         is_move_assignable<_Tp>>::value>::type



    swap(_Tp& __a, _Tp& __b)
    noexcept(__and_<is_nothrow_move_constructible<_Tp>, is_nothrow_move_assignable<_Tp>>::value)

    {




      _Tp __tmp = std::move(__a);
      __a = std::move(__b);
      __b = std::move(__tmp);
    }




  template<typename _Tp, size_t _Nm>
   
    inline

    typename enable_if<__is_swappable<_Tp>::value>::type



    swap(_Tp (&__a)[_Nm], _Tp (&__b)[_Nm])
    noexcept(__is_nothrow_swappable<_Tp>::value)
    {
      for (size_t __n = 0; __n < _Nm; ++__n)
 swap(__a[__n], __b[__n]);
    }



}
       






namespace std __attribute__ ((__visibility__ ("default")))
{



  template<typename _Tp>
    struct tuple_size;





  template<typename _Tp,
    typename _Up = typename remove_cv<_Tp>::type,
    typename = typename enable_if<is_same<_Tp, _Up>::value>::type,
    size_t = tuple_size<_Tp>::value>
    using __enable_if_has_tuple_size = _Tp;

  template<typename _Tp>
    struct tuple_size<const __enable_if_has_tuple_size<_Tp>>
    : public tuple_size<_Tp> { };

  template<typename _Tp>
    struct tuple_size<volatile __enable_if_has_tuple_size<_Tp>>
    : public tuple_size<_Tp> { };

  template<typename _Tp>
    struct tuple_size<const volatile __enable_if_has_tuple_size<_Tp>>
    : public tuple_size<_Tp> { };


  template<typename _Tp>
    inline constexpr size_t tuple_size_v = tuple_size<_Tp>::value;



  template<size_t __i, typename _Tp>
    struct tuple_element;


  template<size_t __i, typename _Tp>
    using __tuple_element_t = typename tuple_element<__i, _Tp>::type;

  template<size_t __i, typename _Tp>
    struct tuple_element<__i, const _Tp>
    {
      typedef typename add_const<__tuple_element_t<__i, _Tp>>::type type;
    };

  template<size_t __i, typename _Tp>
    struct tuple_element<__i, volatile _Tp>
    {
      typedef typename add_volatile<__tuple_element_t<__i, _Tp>>::type type;
    };

  template<size_t __i, typename _Tp>
    struct tuple_element<__i, const volatile _Tp>
    {
      typedef typename add_cv<__tuple_element_t<__i, _Tp>>::type type;
    };





  template<typename _Tp, typename... _Types>
    constexpr size_t
    __find_uniq_type_in_pack()
    {
      constexpr size_t __sz = sizeof...(_Types);
      constexpr bool __found[__sz] = { __is_same(_Tp, _Types) ... };
      size_t __n = __sz;
      for (size_t __i = 0; __i < __sz; ++__i)
 {
   if (__found[__i])
     {
       if (__n < __sz)
  return __sz;
       __n = __i;
     }
 }
      return __n;
    }
  template<size_t __i, typename _Tp>
    using tuple_element_t = typename tuple_element<__i, _Tp>::type;




  template<size_t... _Indexes> struct _Index_tuple { };


  template<size_t _Num>
    struct _Build_index_tuple
    {
      using __type = _Index_tuple<__integer_pack(_Num)...>;

    };






  template<typename _Tp, _Tp... _Idx>
    struct integer_sequence
    {



      typedef _Tp value_type;
      static constexpr size_t size() noexcept { return sizeof...(_Idx); }
    };


  template<typename _Tp, _Tp _Num>
    using make_integer_sequence



      = integer_sequence<_Tp, __integer_pack(_Tp(_Num))...>;



  template<size_t... _Idx>
    using index_sequence = integer_sequence<size_t, _Idx...>;


  template<size_t _Num>
    using make_index_sequence = make_integer_sequence<size_t, _Num>;


  template<typename... _Types>
    using index_sequence_for = make_index_sequence<sizeof...(_Types)>;



  struct in_place_t {
    explicit in_place_t() = default;
  };

  inline constexpr in_place_t in_place{};

  template<typename _Tp> struct in_place_type_t
  {
    explicit in_place_type_t() = default;
  };

  template<typename _Tp>
    inline constexpr in_place_type_t<_Tp> in_place_type{};

  template<size_t _Idx> struct in_place_index_t
  {
    explicit in_place_index_t() = default;
  };

  template<size_t _Idx>
    inline constexpr in_place_index_t<_Idx> in_place_index{};

  template<typename>
    inline constexpr bool __is_in_place_type_v = false;

  template<typename _Tp>
    inline constexpr bool __is_in_place_type_v<in_place_type_t<_Tp>> = true;

  template<typename _Tp>
    using __is_in_place_type = bool_constant<__is_in_place_type_v<_Tp>>;




  template<size_t _Np, typename... _Types>
    struct _Nth_type
    { };

  template<typename _Tp0, typename... _Rest>
    struct _Nth_type<0, _Tp0, _Rest...>
    { using type = _Tp0; };

  template<typename _Tp0, typename _Tp1, typename... _Rest>
    struct _Nth_type<1, _Tp0, _Tp1, _Rest...>
    { using type = _Tp1; };

  template<typename _Tp0, typename _Tp1, typename _Tp2, typename... _Rest>
    struct _Nth_type<2, _Tp0, _Tp1, _Tp2, _Rest...>
    { using type = _Tp2; };

  template<size_t _Np, typename _Tp0, typename _Tp1, typename _Tp2,
    typename... _Rest>



    struct _Nth_type<_Np, _Tp0, _Tp1, _Tp2, _Rest...>
    : _Nth_type<_Np - 3, _Rest...>
    { };


  template<typename _Tp0, typename _Tp1, typename... _Rest>
    struct _Nth_type<0, _Tp0, _Tp1, _Rest...>
    { using type = _Tp0; };

  template<typename _Tp0, typename _Tp1, typename _Tp2, typename... _Rest>
    struct _Nth_type<0, _Tp0, _Tp1, _Tp2, _Rest...>
    { using type = _Tp0; };

  template<typename _Tp0, typename _Tp1, typename _Tp2, typename... _Rest>
    struct _Nth_type<1, _Tp0, _Tp1, _Tp2, _Rest...>
    { using type = _Tp1; };



}






namespace std __attribute__ ((__visibility__ ("default")))
{

  struct piecewise_construct_t { explicit piecewise_construct_t() = default; };


  inline constexpr piecewise_construct_t piecewise_construct =
    piecewise_construct_t();




  template<typename...>
    class tuple;

  template<size_t...>
    struct _Index_tuple;







  template <bool, typename _T1, typename _T2>
    struct _PCC
    {
      template <typename _U1, typename _U2>
      static constexpr bool _ConstructiblePair()
      {
 return __and_<is_constructible<_T1, const _U1&>,
        is_constructible<_T2, const _U2&>>::value;
      }

      template <typename _U1, typename _U2>
      static constexpr bool _ImplicitlyConvertiblePair()
      {
 return __and_<is_convertible<const _U1&, _T1>,
        is_convertible<const _U2&, _T2>>::value;
      }

      template <typename _U1, typename _U2>
      static constexpr bool _MoveConstructiblePair()
      {
 return __and_<is_constructible<_T1, _U1&&>,
        is_constructible<_T2, _U2&&>>::value;
      }

      template <typename _U1, typename _U2>
      static constexpr bool _ImplicitlyMoveConvertiblePair()
      {
 return __and_<is_convertible<_U1&&, _T1>,
        is_convertible<_U2&&, _T2>>::value;
      }
    };

  template <typename _T1, typename _T2>
    struct _PCC<false, _T1, _T2>
    {
      template <typename _U1, typename _U2>
      static constexpr bool _ConstructiblePair()
      {
 return false;
      }

      template <typename _U1, typename _U2>
      static constexpr bool _ImplicitlyConvertiblePair()
      {
 return false;
      }

      template <typename _U1, typename _U2>
      static constexpr bool _MoveConstructiblePair()
      {
 return false;
      }

      template <typename _U1, typename _U2>
      static constexpr bool _ImplicitlyMoveConvertiblePair()
      {
 return false;
      }
    };



  template<typename _U1, typename _U2> class __pair_base
  {

    template<typename _T1, typename _T2> friend struct pair;
    __pair_base() = default;
    ~__pair_base() = default;
    __pair_base(const __pair_base&) = default;
    __pair_base& operator=(const __pair_base&) = delete;

  };
  template<typename _T1, typename _T2>
    struct pair
    : public __pair_base<_T1, _T2>
    {
      typedef _T1 first_type;
      typedef _T2 second_type;

      _T1 first;
      _T2 second;


      constexpr pair(const pair&) = default;
      constexpr pair(pair&&) = default;

      template<typename... _Args1, typename... _Args2>

 pair(piecewise_construct_t, tuple<_Args1...>, tuple<_Args2...>);


      void
      swap(pair& __p)
      noexcept(__and_<__is_nothrow_swappable<_T1>,
        __is_nothrow_swappable<_T2>>::value)
      {
 using std::swap;
 swap(first, __p.first);
 swap(second, __p.second);
      }

    private:
      template<typename... _Args1, size_t... _Indexes1,
        typename... _Args2, size_t... _Indexes2>

 pair(tuple<_Args1...>&, tuple<_Args2...>&,
      _Index_tuple<_Indexes1...>, _Index_tuple<_Indexes2...>);
    public:
      template <typename _U1 = _T1,
                typename _U2 = _T2,
                typename enable_if<__and_<
                                     __is_implicitly_default_constructible<_U1>,
                                     __is_implicitly_default_constructible<_U2>>
                                   ::value, bool>::type = true>
      constexpr pair()
      : first(), second() { }

      template <typename _U1 = _T1,
                typename _U2 = _T2,
                typename enable_if<__and_<
                       is_default_constructible<_U1>,
                       is_default_constructible<_U2>,
                       __not_<
                         __and_<__is_implicitly_default_constructible<_U1>,
                                __is_implicitly_default_constructible<_U2>>>>
                                   ::value, bool>::type = false>
      explicit constexpr pair()
      : first(), second() { }



      using _PCCP = _PCC<true, _T1, _T2>;



      template<typename _U1 = _T1, typename _U2=_T2, typename
        enable_if<_PCCP::template
      _ConstructiblePair<_U1, _U2>()
                  && _PCCP::template
      _ImplicitlyConvertiblePair<_U1, _U2>(),
                         bool>::type=true>
      constexpr pair(const _T1& __a, const _T2& __b)
      : first(__a), second(__b) { }


       template<typename _U1 = _T1, typename _U2=_T2, typename
  enable_if<_PCCP::template
       _ConstructiblePair<_U1, _U2>()
                   && !_PCCP::template
       _ImplicitlyConvertiblePair<_U1, _U2>(),
                         bool>::type=false>
      explicit constexpr pair(const _T1& __a, const _T2& __b)
      : first(__a), second(__b) { }



      template <typename _U1, typename _U2>
        using _PCCFP = _PCC<!is_same<_T1, _U1>::value
       || !is_same<_T2, _U2>::value,
       _T1, _T2>;


      template<typename _U1, typename _U2, typename
        enable_if<_PCCFP<_U1, _U2>::template
      _ConstructiblePair<_U1, _U2>()
                  && _PCCFP<_U1, _U2>::template
      _ImplicitlyConvertiblePair<_U1, _U2>(),
     bool>::type=true>
        constexpr pair(const pair<_U1, _U2>& __p)
        : first(__p.first), second(__p.second) { }

      template<typename _U1, typename _U2, typename
        enable_if<_PCCFP<_U1, _U2>::template
      _ConstructiblePair<_U1, _U2>()
    && !_PCCFP<_U1, _U2>::template
      _ImplicitlyConvertiblePair<_U1, _U2>(),
                         bool>::type=false>
 explicit constexpr pair(const pair<_U1, _U2>& __p)
 : first(__p.first), second(__p.second) { }
    private:



      struct __zero_as_null_pointer_constant
      {
 __zero_as_null_pointer_constant(int __zero_as_null_pointer_constant::*)
 { }
 template<typename _Tp,
   typename = __enable_if_t<is_null_pointer<_Tp>::value>>
 __zero_as_null_pointer_constant(_Tp) = delete;
      };

    public:




      template<typename _U1,
        __enable_if_t<__and_<__not_<is_reference<_U1>>,
        is_pointer<_T2>,
        is_constructible<_T1, _U1>,
        __not_<is_constructible<_T1, const _U1&>>,
        is_convertible<_U1, _T1>>::value,
        bool> = true>
 __attribute__ ((__deprecated__ ("use 'nullptr' instead of '0' to " "initialize std::pair of move-only " "type and pointer")))
 constexpr
 pair(_U1&& __x, __zero_as_null_pointer_constant, ...)
 : first(std::forward<_U1>(__x)), second(nullptr) { }

      template<typename _U1,
        __enable_if_t<__and_<__not_<is_reference<_U1>>,
        is_pointer<_T2>,
        is_constructible<_T1, _U1>,
        __not_<is_constructible<_T1, const _U1&>>,
        __not_<is_convertible<_U1, _T1>>>::value,
        bool> = false>
 __attribute__ ((__deprecated__ ("use 'nullptr' instead of '0' to " "initialize std::pair of move-only " "type and pointer")))
 explicit constexpr
 pair(_U1&& __x, __zero_as_null_pointer_constant, ...)
 : first(std::forward<_U1>(__x)), second(nullptr) { }

      template<typename _U2,
        __enable_if_t<__and_<is_pointer<_T1>,
        __not_<is_reference<_U2>>,
        is_constructible<_T2, _U2>,
        __not_<is_constructible<_T2, const _U2&>>,
        is_convertible<_U2, _T2>>::value,
        bool> = true>
 __attribute__ ((__deprecated__ ("use 'nullptr' instead of '0' to " "initialize std::pair of move-only " "type and pointer")))
 constexpr
 pair(__zero_as_null_pointer_constant, _U2&& __y, ...)
 : first(nullptr), second(std::forward<_U2>(__y)) { }

      template<typename _U2,
        __enable_if_t<__and_<is_pointer<_T1>,
        __not_<is_reference<_U2>>,
        is_constructible<_T2, _U2>,
        __not_<is_constructible<_T2, const _U2&>>,
        __not_<is_convertible<_U2, _T2>>>::value,
        bool> = false>
 __attribute__ ((__deprecated__ ("use 'nullptr' instead of '0' to " "initialize std::pair of move-only " "type and pointer")))
 explicit constexpr
 pair(__zero_as_null_pointer_constant, _U2&& __y, ...)
 : first(nullptr), second(std::forward<_U2>(__y)) { }



      template<typename _U1, typename _U2, typename
        enable_if<_PCCP::template
      _MoveConstructiblePair<_U1, _U2>()
     && _PCCP::template
      _ImplicitlyMoveConvertiblePair<_U1, _U2>(),
                         bool>::type=true>
 constexpr pair(_U1&& __x, _U2&& __y)
 : first(std::forward<_U1>(__x)), second(std::forward<_U2>(__y)) { }

      template<typename _U1, typename _U2, typename
        enable_if<_PCCP::template
      _MoveConstructiblePair<_U1, _U2>()
     && !_PCCP::template
      _ImplicitlyMoveConvertiblePair<_U1, _U2>(),
                         bool>::type=false>
 explicit constexpr pair(_U1&& __x, _U2&& __y)
 : first(std::forward<_U1>(__x)), second(std::forward<_U2>(__y)) { }


      template<typename _U1, typename _U2, typename
        enable_if<_PCCFP<_U1, _U2>::template
      _MoveConstructiblePair<_U1, _U2>()
     && _PCCFP<_U1, _U2>::template
      _ImplicitlyMoveConvertiblePair<_U1, _U2>(),
                         bool>::type=true>
 constexpr pair(pair<_U1, _U2>&& __p)
 : first(std::forward<_U1>(__p.first)),
   second(std::forward<_U2>(__p.second)) { }

      template<typename _U1, typename _U2, typename
        enable_if<_PCCFP<_U1, _U2>::template
      _MoveConstructiblePair<_U1, _U2>()
     && !_PCCFP<_U1, _U2>::template
      _ImplicitlyMoveConvertiblePair<_U1, _U2>(),
                         bool>::type=false>
 explicit constexpr pair(pair<_U1, _U2>&& __p)
 : first(std::forward<_U1>(__p.first)),
   second(std::forward<_U2>(__p.second)) { }

      pair&
      operator=(__conditional_t<__and_<is_copy_assignable<_T1>,
           is_copy_assignable<_T2>>::value,
    const pair&, const __nonesuch&> __p)
      {
 first = __p.first;
 second = __p.second;
 return *this;
      }

      pair&
      operator=(__conditional_t<__and_<is_move_assignable<_T1>,
           is_move_assignable<_T2>>::value,
    pair&&, __nonesuch&&> __p)
      noexcept(__and_<is_nothrow_move_assignable<_T1>,
        is_nothrow_move_assignable<_T2>>::value)
      {
 first = std::forward<first_type>(__p.first);
 second = std::forward<second_type>(__p.second);
 return *this;
      }

      template<typename _U1, typename _U2>
 typename enable_if<__and_<is_assignable<_T1&, const _U1&>,
      is_assignable<_T2&, const _U2&>>::value,
      pair&>::type
 operator=(const pair<_U1, _U2>& __p)
 {
   first = __p.first;
   second = __p.second;
   return *this;
 }

      template<typename _U1, typename _U2>
 typename enable_if<__and_<is_assignable<_T1&, _U1&&>,
      is_assignable<_T2&, _U2&&>>::value,
      pair&>::type
 operator=(pair<_U1, _U2>&& __p)
 {
   first = std::forward<_U1>(__p.first);
   second = std::forward<_U2>(__p.second);
   return *this;
 }
    };




  template<typename _T1, typename _T2> pair(_T1, _T2) -> pair<_T1, _T2>;



  template<typename _T1, typename _T2>
    inline constexpr bool
    operator==(const pair<_T1, _T2>& __x, const pair<_T1, _T2>& __y)
    { return __x.first == __y.first && __x.second == __y.second; }
  template<typename _T1, typename _T2>
    inline constexpr bool
    operator<(const pair<_T1, _T2>& __x, const pair<_T1, _T2>& __y)
    { return __x.first < __y.first
      || (!(__y.first < __x.first) && __x.second < __y.second); }


  template<typename _T1, typename _T2>
    inline constexpr bool
    operator!=(const pair<_T1, _T2>& __x, const pair<_T1, _T2>& __y)
    { return !(__x == __y); }


  template<typename _T1, typename _T2>
    inline constexpr bool
    operator>(const pair<_T1, _T2>& __x, const pair<_T1, _T2>& __y)
    { return __y < __x; }


  template<typename _T1, typename _T2>
    inline constexpr bool
    operator<=(const pair<_T1, _T2>& __x, const pair<_T1, _T2>& __y)
    { return !(__y < __x); }


  template<typename _T1, typename _T2>
    inline constexpr bool
    operator>=(const pair<_T1, _T2>& __x, const pair<_T1, _T2>& __y)
    { return !(__x < __y); }
  template<typename _T1, typename _T2>
    inline


    typename enable_if<__and_<__is_swappable<_T1>,
                              __is_swappable<_T2>>::value>::type



    swap(pair<_T1, _T2>& __x, pair<_T1, _T2>& __y)
    noexcept(noexcept(__x.swap(__y)))
    { __x.swap(__y); }


  template<typename _T1, typename _T2>
    typename enable_if<!__and_<__is_swappable<_T1>,
          __is_swappable<_T2>>::value>::type
    swap(pair<_T1, _T2>&, pair<_T1, _T2>&) = delete;
  template<typename _T1, typename _T2>
    constexpr pair<typename __decay_and_strip<_T1>::__type,
                   typename __decay_and_strip<_T2>::__type>
    make_pair(_T1&& __x, _T2&& __y)
    {
      typedef typename __decay_and_strip<_T1>::__type __ds_type1;
      typedef typename __decay_and_strip<_T2>::__type __ds_type2;
      typedef pair<__ds_type1, __ds_type2> __pair_type;
      return __pair_type(std::forward<_T1>(__x), std::forward<_T2>(__y));
    }
  template<typename _T1, typename _T2>
    struct __is_tuple_like_impl<pair<_T1, _T2>> : true_type
    { };



  template<class _Tp1, class _Tp2>
    struct tuple_size<pair<_Tp1, _Tp2>>
    : public integral_constant<size_t, 2> { };


  template<class _Tp1, class _Tp2>
    struct tuple_element<0, pair<_Tp1, _Tp2>>
    { typedef _Tp1 type; };


  template<class _Tp1, class _Tp2>
    struct tuple_element<1, pair<_Tp1, _Tp2>>
    { typedef _Tp2 type; };


  template<typename _Tp1, typename _Tp2>
    inline constexpr size_t tuple_size_v<pair<_Tp1, _Tp2>> = 2;

  template<typename _Tp1, typename _Tp2>
    inline constexpr size_t tuple_size_v<const pair<_Tp1, _Tp2>> = 2;

  template<typename _Tp>
    inline constexpr bool __is_pair = false;

  template<typename _Tp, typename _Up>
    inline constexpr bool __is_pair<pair<_Tp, _Up>> = true;

  template<typename _Tp, typename _Up>
    inline constexpr bool __is_pair<const pair<_Tp, _Up>> = true;



  template<size_t _Int>
    struct __pair_get;

  template<>
    struct __pair_get<0>
    {
      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp1&
 __get(pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.first; }

      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp1&&
 __move_get(pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<_Tp1>(__pair.first); }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp1&
 __const_get(const pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.first; }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp1&&
 __const_move_get(const pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<const _Tp1>(__pair.first); }
    };

  template<>
    struct __pair_get<1>
    {
      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp2&
 __get(pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.second; }

      template<typename _Tp1, typename _Tp2>
 static constexpr _Tp2&&
 __move_get(pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<_Tp2>(__pair.second); }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp2&
 __const_get(const pair<_Tp1, _Tp2>& __pair) noexcept
 { return __pair.second; }

      template<typename _Tp1, typename _Tp2>
 static constexpr const _Tp2&&
 __const_move_get(const pair<_Tp1, _Tp2>&& __pair) noexcept
 { return std::forward<const _Tp2>(__pair.second); }
    };






  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&
    get(pair<_Tp1, _Tp2>& __in) noexcept
    { return __pair_get<_Int>::__get(__in); }

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&&
    get(pair<_Tp1, _Tp2>&& __in) noexcept
    { return __pair_get<_Int>::__move_get(std::move(__in)); }

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr const typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&
    get(const pair<_Tp1, _Tp2>& __in) noexcept
    { return __pair_get<_Int>::__const_get(__in); }

  template<size_t _Int, class _Tp1, class _Tp2>
    constexpr const typename tuple_element<_Int, pair<_Tp1, _Tp2>>::type&&
    get(const pair<_Tp1, _Tp2>&& __in) noexcept
    { return __pair_get<_Int>::__const_move_get(std::move(__in)); }





  template <typename _Tp, typename _Up>
    constexpr _Tp&
    get(pair<_Tp, _Up>& __p) noexcept
    { return __p.first; }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&
    get(const pair<_Tp, _Up>& __p) noexcept
    { return __p.first; }

  template <typename _Tp, typename _Up>
    constexpr _Tp&&
    get(pair<_Tp, _Up>&& __p) noexcept
    { return std::move(__p.first); }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&&
    get(const pair<_Tp, _Up>&& __p) noexcept
    { return std::move(__p.first); }

  template <typename _Tp, typename _Up>
    constexpr _Tp&
    get(pair<_Up, _Tp>& __p) noexcept
    { return __p.second; }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&
    get(const pair<_Up, _Tp>& __p) noexcept
    { return __p.second; }

  template <typename _Tp, typename _Up>
    constexpr _Tp&&
    get(pair<_Up, _Tp>&& __p) noexcept
    { return std::move(__p.second); }

  template <typename _Tp, typename _Up>
    constexpr const _Tp&&
    get(const pair<_Up, _Tp>&& __p) noexcept
    { return std::move(__p.second); }






}
       
namespace std __attribute__ ((__visibility__ ("default")))
{

  struct input_iterator_tag { };


  struct output_iterator_tag { };


  struct forward_iterator_tag : public input_iterator_tag { };



  struct bidirectional_iterator_tag : public forward_iterator_tag { };



  struct random_access_iterator_tag : public bidirectional_iterator_tag { };
  template<typename _Category, typename _Tp, typename _Distance = ptrdiff_t,
           typename _Pointer = _Tp*, typename _Reference = _Tp&>
    struct [[__deprecated__]] iterator
    {

      typedef _Category iterator_category;

      typedef _Tp value_type;

      typedef _Distance difference_type;

      typedef _Pointer pointer;

      typedef _Reference reference;
    };
  template<typename _Iterator>
    struct iterator_traits;




  template<typename _Iterator, typename = __void_t<>>
    struct __iterator_traits { };



  template<typename _Iterator>
    struct __iterator_traits<_Iterator,
        __void_t<typename _Iterator::iterator_category,
          typename _Iterator::value_type,
          typename _Iterator::difference_type,
          typename _Iterator::pointer,
          typename _Iterator::reference>>
    {
      typedef typename _Iterator::iterator_category iterator_category;
      typedef typename _Iterator::value_type value_type;
      typedef typename _Iterator::difference_type difference_type;
      typedef typename _Iterator::pointer pointer;
      typedef typename _Iterator::reference reference;
    };


  template<typename _Iterator>
    struct iterator_traits
    : public __iterator_traits<_Iterator> { };
  template<typename _Tp>
    struct iterator_traits<_Tp*>
    {
      typedef random_access_iterator_tag iterator_category;
      typedef _Tp value_type;
      typedef ptrdiff_t difference_type;
      typedef _Tp* pointer;
      typedef _Tp& reference;
    };


  template<typename _Tp>
    struct iterator_traits<const _Tp*>
    {
      typedef random_access_iterator_tag iterator_category;
      typedef _Tp value_type;
      typedef ptrdiff_t difference_type;
      typedef const _Tp* pointer;
      typedef const _Tp& reference;
    };






  template<typename _Iter>
    inline constexpr
    typename iterator_traits<_Iter>::iterator_category
    __iterator_category(const _Iter&)
    { return typename iterator_traits<_Iter>::iterator_category(); }




  template<typename _Iter>
    using __iterator_category_t
      = typename iterator_traits<_Iter>::iterator_category;

  template<typename _InIter>
    using _RequireInputIter =
      __enable_if_t<is_convertible<__iterator_category_t<_InIter>,
       input_iterator_tag>::value>;

  template<typename _It,
    typename _Cat = __iterator_category_t<_It>>
    struct __is_random_access_iter
      : is_base_of<random_access_iterator_tag, _Cat>
    {
      typedef is_base_of<random_access_iterator_tag, _Cat> _Base;
      enum { __value = _Base::value };
    };








}
       

       


namespace std __attribute__ ((__visibility__ ("default")))
{




  template <typename> struct _List_iterator;
  template <typename> struct _List_const_iterator;


  template<typename _InputIterator>
    inline constexpr
    typename iterator_traits<_InputIterator>::difference_type
    __distance(_InputIterator __first, _InputIterator __last,
               input_iterator_tag)
    {

     

      typename iterator_traits<_InputIterator>::difference_type __n = 0;
      while (__first != __last)
 {
   ++__first;
   ++__n;
 }
      return __n;
    }

  template<typename _RandomAccessIterator>
    inline constexpr
    typename iterator_traits<_RandomAccessIterator>::difference_type
    __distance(_RandomAccessIterator __first, _RandomAccessIterator __last,
               random_access_iterator_tag)
    {

     

      return __last - __first;
    }



  template<typename _Tp>
    ptrdiff_t
    __distance(std::_List_iterator<_Tp>,
        std::_List_iterator<_Tp>,
        input_iterator_tag);

  template<typename _Tp>
    ptrdiff_t
    __distance(std::_List_const_iterator<_Tp>,
        std::_List_const_iterator<_Tp>,
        input_iterator_tag);




  template<typename _OutputIterator>
    void
    __distance(_OutputIterator, _OutputIterator, output_iterator_tag) = delete;
  template<typename _InputIterator>
    [[__nodiscard__]]
    inline constexpr
    typename iterator_traits<_InputIterator>::difference_type
    distance(_InputIterator __first, _InputIterator __last)
    {

      return std::__distance(__first, __last,
        std::__iterator_category(__first));
    }

  template<typename _InputIterator, typename _Distance>
    inline constexpr void
    __advance(_InputIterator& __i, _Distance __n, input_iterator_tag)
    {

     
      do { if (std::__is_constant_evaluated() && !bool(__n >= 0)) __builtin_unreachable(); } while (false);
      while (__n--)
 ++__i;
    }

  template<typename _BidirectionalIterator, typename _Distance>
    inline constexpr void
    __advance(_BidirectionalIterator& __i, _Distance __n,
       bidirectional_iterator_tag)
    {

     

      if (__n > 0)
        while (__n--)
   ++__i;
      else
        while (__n++)
   --__i;
    }

  template<typename _RandomAccessIterator, typename _Distance>
    inline constexpr void
    __advance(_RandomAccessIterator& __i, _Distance __n,
              random_access_iterator_tag)
    {

     

      if (__builtin_constant_p(__n) && __n == 1)
 ++__i;
      else if (__builtin_constant_p(__n) && __n == -1)
 --__i;
      else
 __i += __n;
    }



  template<typename _OutputIterator, typename _Distance>
    void
    __advance(_OutputIterator&, _Distance, output_iterator_tag) = delete;
  template<typename _InputIterator, typename _Distance>
    inline constexpr void
    advance(_InputIterator& __i, _Distance __n)
    {

      typename iterator_traits<_InputIterator>::difference_type __d = __n;
      std::__advance(__i, __d, std::__iterator_category(__i));
    }



  template<typename _InputIterator>
    [[__nodiscard__]]
    inline constexpr _InputIterator
    next(_InputIterator __x, typename
  iterator_traits<_InputIterator>::difference_type __n = 1)
    {

     
      std::advance(__x, __n);
      return __x;
    }

  template<typename _BidirectionalIterator>
    [[__nodiscard__]]
    inline constexpr _BidirectionalIterator
    prev(_BidirectionalIterator __x, typename
  iterator_traits<_BidirectionalIterator>::difference_type __n = 1)
    {

     

      std::advance(__x, -__n);
      return __x;
    }




}
namespace std __attribute__ ((__visibility__ ("default")))
{




  class __undefined;



  template<typename _Tp>
    struct __get_first_arg
    { using type = __undefined; };

  template<template<typename, typename...> class _SomeTemplate, typename _Tp,
           typename... _Types>
    struct __get_first_arg<_SomeTemplate<_Tp, _Types...>>
    { using type = _Tp; };



  template<typename _Tp, typename _Up>
    struct __replace_first_arg
    { };

  template<template<typename, typename...> class _SomeTemplate, typename _Up,
           typename _Tp, typename... _Types>
    struct __replace_first_arg<_SomeTemplate<_Tp, _Types...>, _Up>
    { using type = _SomeTemplate<_Up, _Types...>; };


  template<typename _Ptr, typename = void>
    struct __ptr_traits_elem : __get_first_arg<_Ptr>
    { };







  template<typename _Ptr>
    struct __ptr_traits_elem<_Ptr, __void_t<typename _Ptr::element_type>>
    { using type = typename _Ptr::element_type; };


  template<typename _Ptr>
    using __ptr_traits_elem_t = typename __ptr_traits_elem<_Ptr>::type;




  template<typename _Ptr, typename _Elt, bool = is_void<_Elt>::value>
    struct __ptr_traits_ptr_to
    {
      using pointer = _Ptr;
      using element_type = _Elt;







      static pointer
      pointer_to(element_type& __r)





      { return pointer::pointer_to(__r); }
    };


  template<typename _Ptr, typename _Elt>
    struct __ptr_traits_ptr_to<_Ptr, _Elt, true>
    { };


  template<typename _Tp>
    struct __ptr_traits_ptr_to<_Tp*, _Tp, false>
    {
      using pointer = _Tp*;
      using element_type = _Tp;






      static pointer
      pointer_to(element_type& __r) noexcept
      { return std::addressof(__r); }
    };

  template<typename _Ptr, typename _Elt>
    struct __ptr_traits_impl : __ptr_traits_ptr_to<_Ptr, _Elt>
    {
    private:
      template<typename _Tp>
 using __diff_t = typename _Tp::difference_type;

      template<typename _Tp, typename _Up>
 using __rebind = __type_identity<typename _Tp::template rebind<_Up>>;

    public:

      using pointer = _Ptr;


      using element_type = _Elt;


      using difference_type = __detected_or_t<ptrdiff_t, __diff_t, _Ptr>;


      template<typename _Up>
 using rebind = typename __detected_or_t<__replace_first_arg<_Ptr, _Up>,
      __rebind, _Ptr, _Up>::type;
    };



  template<typename _Ptr>
    struct __ptr_traits_impl<_Ptr, __undefined>
    { };







  template<typename _Ptr>
    struct pointer_traits : __ptr_traits_impl<_Ptr, __ptr_traits_elem_t<_Ptr>>
    { };







  template<typename _Tp>
    struct pointer_traits<_Tp*> : __ptr_traits_ptr_to<_Tp*, _Tp>
    {

      typedef _Tp* pointer;

      typedef _Tp element_type;

      typedef ptrdiff_t difference_type;

      template<typename _Up> using rebind = _Up*;
    };


  template<typename _Ptr, typename _Tp>
    using __ptr_rebind = typename pointer_traits<_Ptr>::template rebind<_Tp>;

  template<typename _Tp>
    constexpr _Tp*
    __to_address(_Tp* __ptr) noexcept
    {
      static_assert(!std::is_function<_Tp>::value, "not a function pointer");
      return __ptr;
    }


  template<typename _Ptr>
    constexpr typename std::pointer_traits<_Ptr>::element_type*
    __to_address(const _Ptr& __ptr)
    { return std::__to_address(__ptr.operator->()); }

}
namespace std __attribute__ ((__visibility__ ("default")))
{

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
  template<typename _Iterator>
    class reverse_iterator
    : public iterator<typename iterator_traits<_Iterator>::iterator_category,
        typename iterator_traits<_Iterator>::value_type,
        typename iterator_traits<_Iterator>::difference_type,
        typename iterator_traits<_Iterator>::pointer,
                      typename iterator_traits<_Iterator>::reference>
    {
      template<typename _Iter>
 friend class reverse_iterator;
    protected:
      _Iterator current;

      typedef iterator_traits<_Iterator> __traits_type;

    public:
      typedef _Iterator iterator_type;
      typedef typename __traits_type::pointer pointer;

      typedef typename __traits_type::difference_type difference_type;
      typedef typename __traits_type::reference reference;
      constexpr
      reverse_iterator()
      noexcept(noexcept(_Iterator()))
      : current()
      { }




      explicit constexpr
      reverse_iterator(iterator_type __x)
      noexcept(noexcept(_Iterator(__x)))
      : current(__x)
      { }




      constexpr
      reverse_iterator(const reverse_iterator& __x)
      noexcept(noexcept(_Iterator(__x.current)))
      : current(__x.current)
      { }


      reverse_iterator& operator=(const reverse_iterator&) = default;






      template<typename _Iter>



 constexpr
        reverse_iterator(const reverse_iterator<_Iter>& __x)
 noexcept(noexcept(_Iterator(__x.current)))
 : current(__x.current)
 { }


      template<typename _Iter>




 constexpr
 reverse_iterator&
 operator=(const reverse_iterator<_Iter>& __x)
 noexcept(noexcept(current = __x.current))
 {
   current = __x.current;
   return *this;
 }





      [[__nodiscard__]]
      constexpr iterator_type
      base() const
      noexcept(noexcept(_Iterator(current)))
      { return current; }
      [[__nodiscard__]]
      constexpr reference
      operator*() const
      {
 _Iterator __tmp = current;
 return *--__tmp;
      }






      [[__nodiscard__]]
      constexpr pointer
      operator->() const




      {


 _Iterator __tmp = current;
 --__tmp;
 return _S_to_pointer(__tmp);
      }






      constexpr reverse_iterator&
      operator++()
      {
 --current;
 return *this;
      }






      constexpr reverse_iterator
      operator++(int)
      {
 reverse_iterator __tmp = *this;
 --current;
 return __tmp;
      }






      constexpr reverse_iterator&
      operator--()
      {
 ++current;
 return *this;
      }






      constexpr reverse_iterator
      operator--(int)
      {
 reverse_iterator __tmp = *this;
 ++current;
 return __tmp;
      }






      [[__nodiscard__]]
      constexpr reverse_iterator
      operator+(difference_type __n) const
      { return reverse_iterator(current - __n); }







      constexpr reverse_iterator&
      operator+=(difference_type __n)
      {
 current -= __n;
 return *this;
      }






      [[__nodiscard__]]
      constexpr reverse_iterator
      operator-(difference_type __n) const
      { return reverse_iterator(current + __n); }







      constexpr reverse_iterator&
      operator-=(difference_type __n)
      {
 current += __n;
 return *this;
      }






      [[__nodiscard__]]
      constexpr reference
      operator[](difference_type __n) const
      { return *(*this + __n); }
    private:
      template<typename _Tp>
 static constexpr _Tp*
 _S_to_pointer(_Tp* __p)
        { return __p; }

      template<typename _Tp>
 static constexpr pointer
 _S_to_pointer(_Tp __t)
        { return __t.operator->(); }
    };
  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator==(const reverse_iterator<_Iterator>& __x,
        const reverse_iterator<_Iterator>& __y)
    { return __x.base() == __y.base(); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator<(const reverse_iterator<_Iterator>& __x,
       const reverse_iterator<_Iterator>& __y)
    { return __y.base() < __x.base(); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator!=(const reverse_iterator<_Iterator>& __x,
        const reverse_iterator<_Iterator>& __y)
    { return !(__x == __y); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator>(const reverse_iterator<_Iterator>& __x,
       const reverse_iterator<_Iterator>& __y)
    { return __y < __x; }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator<=(const reverse_iterator<_Iterator>& __x,
        const reverse_iterator<_Iterator>& __y)
    { return !(__y < __x); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator>=(const reverse_iterator<_Iterator>& __x,
        const reverse_iterator<_Iterator>& __y)
    { return !(__x < __y); }




  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator==(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    { return __x.base() == __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator<(const reverse_iterator<_IteratorL>& __x,
       const reverse_iterator<_IteratorR>& __y)
    { return __x.base() > __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator!=(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    { return __x.base() != __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator>(const reverse_iterator<_IteratorL>& __x,
       const reverse_iterator<_IteratorR>& __y)
    { return __x.base() < __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    inline constexpr bool
    operator<=(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    { return __x.base() >= __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator>=(const reverse_iterator<_IteratorL>& __x,
        const reverse_iterator<_IteratorR>& __y)
    { return __x.base() <= __y.base(); }
  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr auto
    operator-(const reverse_iterator<_IteratorL>& __x,
       const reverse_iterator<_IteratorR>& __y)
    -> decltype(__y.base() - __x.base())
    { return __y.base() - __x.base(); }


  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<_Iterator>
    operator+(typename reverse_iterator<_Iterator>::difference_type __n,
       const reverse_iterator<_Iterator>& __x)
    { return reverse_iterator<_Iterator>(__x.base() - __n); }



  template<typename _Iterator>
    inline constexpr reverse_iterator<_Iterator>
    __make_reverse_iterator(_Iterator __i)
    { return reverse_iterator<_Iterator>(__i); }







  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<_Iterator>
    make_reverse_iterator(_Iterator __i)
    { return reverse_iterator<_Iterator>(__i); }
  template<typename _Iterator>
   
    auto
    __niter_base(reverse_iterator<_Iterator> __it)
    -> decltype(__make_reverse_iterator(__niter_base(__it.base())))
    { return __make_reverse_iterator(__niter_base(__it.base())); }

  template<typename _Iterator>
    struct __is_move_iterator<reverse_iterator<_Iterator> >
      : __is_move_iterator<_Iterator>
    { };

  template<typename _Iterator>
   
    auto
    __miter_base(reverse_iterator<_Iterator> __it)
    -> decltype(__make_reverse_iterator(__miter_base(__it.base())))
    { return __make_reverse_iterator(__miter_base(__it.base())); }
  template<typename _Container>
    class back_insert_iterator
    : public iterator<output_iterator_tag, void, void, void, void>
    {
    protected:
      _Container* container;

    public:

      typedef _Container container_type;





      explicit
      back_insert_iterator(_Container& __x)
      : container(std::__addressof(__x)) { }
     
      back_insert_iterator&
      operator=(const typename _Container::value_type& __value)
      {
 container->push_back(__value);
 return *this;
      }

     
      back_insert_iterator&
      operator=(typename _Container::value_type&& __value)
      {
 container->push_back(std::move(__value));
 return *this;
      }



      [[__nodiscard__]]
      back_insert_iterator&
      operator*()
      { return *this; }


     
      back_insert_iterator&
      operator++()
      { return *this; }


     
      back_insert_iterator
      operator++(int)
      { return *this; }
    };
  template<typename _Container>
    [[__nodiscard__]]
    inline back_insert_iterator<_Container>
    back_inserter(_Container& __x)
    { return back_insert_iterator<_Container>(__x); }
  template<typename _Container>
    class front_insert_iterator
    : public iterator<output_iterator_tag, void, void, void, void>
    {
    protected:
      _Container* container;

    public:

      typedef _Container container_type;





      explicit
      front_insert_iterator(_Container& __x)
      : container(std::__addressof(__x)) { }
     
      front_insert_iterator&
      operator=(const typename _Container::value_type& __value)
      {
 container->push_front(__value);
 return *this;
      }

     
      front_insert_iterator&
      operator=(typename _Container::value_type&& __value)
      {
 container->push_front(std::move(__value));
 return *this;
      }



      [[__nodiscard__]]
      front_insert_iterator&
      operator*()
      { return *this; }


     
      front_insert_iterator&
      operator++()
      { return *this; }


     
      front_insert_iterator
      operator++(int)
      { return *this; }
    };
  template<typename _Container>
    [[__nodiscard__]]
    inline front_insert_iterator<_Container>
    front_inserter(_Container& __x)
    { return front_insert_iterator<_Container>(__x); }
  template<typename _Container>
    class insert_iterator
    : public iterator<output_iterator_tag, void, void, void, void>
    {



      typedef typename _Container::iterator _Iter;

    protected:
      _Container* container;
      _Iter iter;

    public:

      typedef _Container container_type;
     
      insert_iterator(_Container& __x, _Iter __i)
      : container(std::__addressof(__x)), iter(__i) {}
     
      insert_iterator&
      operator=(const typename _Container::value_type& __value)
      {
 iter = container->insert(iter, __value);
 ++iter;
 return *this;
      }

     
      insert_iterator&
      operator=(typename _Container::value_type&& __value)
      {
 iter = container->insert(iter, std::move(__value));
 ++iter;
 return *this;
      }



      [[__nodiscard__]]
      insert_iterator&
      operator*()
      { return *this; }


     
      insert_iterator&
      operator++()
      { return *this; }


     
      insert_iterator&
      operator++(int)
      { return *this; }
    };

#pragma GCC diagnostic pop
  template<typename _Container>
    [[__nodiscard__]]
    inline insert_iterator<_Container>
    inserter(_Container& __x, typename _Container::iterator __i)
    { return insert_iterator<_Container>(__x, __i); }





}

namespace __gnu_cxx __attribute__ ((__visibility__ ("default")))
{

  template<typename _Iterator, typename _Container>
    class __normal_iterator
    {
    protected:
      _Iterator _M_current;

      typedef std::iterator_traits<_Iterator> __traits_type;


      template<typename _Iter>
 using __convertible_from
   = std::__enable_if_t<std::is_convertible<_Iter, _Iterator>::value>;


    public:
      typedef _Iterator iterator_type;
      typedef typename __traits_type::iterator_category iterator_category;
      typedef typename __traits_type::value_type value_type;
      typedef typename __traits_type::difference_type difference_type;
      typedef typename __traits_type::reference reference;
      typedef typename __traits_type::pointer pointer;





      constexpr __normal_iterator() noexcept
      : _M_current(_Iterator()) { }

      explicit
      __normal_iterator(const _Iterator& __i) noexcept
      : _M_current(__i) { }



      template<typename _Iter, typename = __convertible_from<_Iter>>

 __normal_iterator(const __normal_iterator<_Iter, _Container>& __i)
 noexcept
        : _M_current(__i.base()) { }


     
      reference
      operator*() const noexcept
      { return *_M_current; }

     
      pointer
      operator->() const noexcept
      { return _M_current; }

     
      __normal_iterator&
      operator++() noexcept
      {
 ++_M_current;
 return *this;
      }

     
      __normal_iterator
      operator++(int) noexcept
      { return __normal_iterator(_M_current++); }


     
      __normal_iterator&
      operator--() noexcept
      {
 --_M_current;
 return *this;
      }

     
      __normal_iterator
      operator--(int) noexcept
      { return __normal_iterator(_M_current--); }


     
      reference
      operator[](difference_type __n) const noexcept
      { return _M_current[__n]; }

     
      __normal_iterator&
      operator+=(difference_type __n) noexcept
      { _M_current += __n; return *this; }

     
      __normal_iterator
      operator+(difference_type __n) const noexcept
      { return __normal_iterator(_M_current + __n); }

     
      __normal_iterator&
      operator-=(difference_type __n) noexcept
      { _M_current -= __n; return *this; }

     
      __normal_iterator
      operator-(difference_type __n) const noexcept
      { return __normal_iterator(_M_current - __n); }

     
      const _Iterator&
      base() const noexcept
      { return _M_current; }
    };
  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator==(const __normal_iterator<_IteratorL, _Container>& __lhs,
        const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept
    { return __lhs.base() == __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator==(const __normal_iterator<_Iterator, _Container>& __lhs,
        const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() == __rhs.base(); }

  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator!=(const __normal_iterator<_IteratorL, _Container>& __lhs,
        const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept
    { return __lhs.base() != __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator!=(const __normal_iterator<_Iterator, _Container>& __lhs,
        const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() != __rhs.base(); }


  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator<(const __normal_iterator<_IteratorL, _Container>& __lhs,
       const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept
    { return __lhs.base() < __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator<(const __normal_iterator<_Iterator, _Container>& __lhs,
       const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() < __rhs.base(); }

  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator>(const __normal_iterator<_IteratorL, _Container>& __lhs,
       const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept
    { return __lhs.base() > __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator>(const __normal_iterator<_Iterator, _Container>& __lhs,
       const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() > __rhs.base(); }

  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator<=(const __normal_iterator<_IteratorL, _Container>& __lhs,
        const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept
    { return __lhs.base() <= __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator<=(const __normal_iterator<_Iterator, _Container>& __lhs,
        const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() <= __rhs.base(); }

  template<typename _IteratorL, typename _IteratorR, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator>=(const __normal_iterator<_IteratorL, _Container>& __lhs,
        const __normal_iterator<_IteratorR, _Container>& __rhs)
    noexcept
    { return __lhs.base() >= __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline bool
    operator>=(const __normal_iterator<_Iterator, _Container>& __lhs,
        const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() >= __rhs.base(); }






  template<typename _IteratorL, typename _IteratorR, typename _Container>


    [[__nodiscard__]]
    inline auto
    operator-(const __normal_iterator<_IteratorL, _Container>& __lhs,
       const __normal_iterator<_IteratorR, _Container>& __rhs) noexcept
    -> decltype(__lhs.base() - __rhs.base())





    { return __lhs.base() - __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline typename __normal_iterator<_Iterator, _Container>::difference_type
    operator-(const __normal_iterator<_Iterator, _Container>& __lhs,
       const __normal_iterator<_Iterator, _Container>& __rhs)
    noexcept
    { return __lhs.base() - __rhs.base(); }

  template<typename _Iterator, typename _Container>
    [[__nodiscard__]]
    inline __normal_iterator<_Iterator, _Container>
    operator+(typename __normal_iterator<_Iterator, _Container>::difference_type
       __n, const __normal_iterator<_Iterator, _Container>& __i)
    noexcept
    { return __normal_iterator<_Iterator, _Container>(__i.base() + __n); }


}

namespace std __attribute__ ((__visibility__ ("default")))
{


  template<typename _Iterator, typename _Container>
   
    _Iterator
    __niter_base(__gnu_cxx::__normal_iterator<_Iterator, _Container> __it)
    noexcept(std::is_nothrow_copy_constructible<_Iterator>::value)
    { return __it.base(); }






  template<typename _Iterator, typename _Container>
    constexpr auto
    __to_address(const __gnu_cxx::__normal_iterator<_Iterator,
          _Container>& __it) noexcept
    -> decltype(std::__to_address(__it.base()))
    { return std::__to_address(__it.base()); }
  namespace __detail
  {
  }
  template<typename _Iterator>
    class move_iterator



    {
      _Iterator _M_current;

      using __traits_type = iterator_traits<_Iterator>;

      using __base_ref = typename __traits_type::reference;


      template<typename _Iter2>
 friend class move_iterator;
    public:
      using iterator_type = _Iterator;
      typedef typename __traits_type::iterator_category iterator_category;
      typedef typename __traits_type::value_type value_type;
      typedef typename __traits_type::difference_type difference_type;

      typedef _Iterator pointer;


      using reference
 = __conditional_t<is_reference<__base_ref>::value,
     typename remove_reference<__base_ref>::type&&,
     __base_ref>;


      constexpr
      move_iterator()
      : _M_current() { }

      explicit constexpr
      move_iterator(iterator_type __i)
      : _M_current(std::move(__i)) { }

      template<typename _Iter>



 constexpr
 move_iterator(const move_iterator<_Iter>& __i)
 : _M_current(__i._M_current) { }

      template<typename _Iter>




 constexpr
 move_iterator& operator=(const move_iterator<_Iter>& __i)
 {
   _M_current = __i._M_current;
   return *this;
 }


      [[__nodiscard__]]
      constexpr iterator_type
      base() const
      { return _M_current; }
      [[__nodiscard__]]
      constexpr reference
      operator*() const



      { return static_cast<reference>(*_M_current); }


      [[__nodiscard__]]
      constexpr pointer
      operator->() const
      { return _M_current; }

      constexpr move_iterator&
      operator++()
      {
 ++_M_current;
 return *this;
      }

      constexpr move_iterator
      operator++(int)
      {
 move_iterator __tmp = *this;
 ++_M_current;
 return __tmp;
      }







      constexpr move_iterator&
      operator--()
      {
 --_M_current;
 return *this;
      }

      constexpr move_iterator
      operator--(int)
      {
 move_iterator __tmp = *this;
 --_M_current;
 return __tmp;
      }

      [[__nodiscard__]]
      constexpr move_iterator
      operator+(difference_type __n) const
      { return move_iterator(_M_current + __n); }

      constexpr move_iterator&
      operator+=(difference_type __n)
      {
 _M_current += __n;
 return *this;
      }

      [[__nodiscard__]]
      constexpr move_iterator
      operator-(difference_type __n) const
      { return move_iterator(_M_current - __n); }

      constexpr move_iterator&
      operator-=(difference_type __n)
      {
 _M_current -= __n;
 return *this;
      }

      [[__nodiscard__]]
      constexpr reference
      operator[](difference_type __n) const



      { return std::move(_M_current[__n]); }
    };

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator==(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)



    { return __x.base() == __y.base(); }
  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator!=(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)
    { return !(__x == __y); }


  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator<(const move_iterator<_IteratorL>& __x,
       const move_iterator<_IteratorR>& __y)



    { return __x.base() < __y.base(); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator<=(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)



    { return !(__y < __x); }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator>(const move_iterator<_IteratorL>& __x,
       const move_iterator<_IteratorR>& __y)



    { return __y < __x; }

  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr bool
    operator>=(const move_iterator<_IteratorL>& __x,
        const move_iterator<_IteratorR>& __y)



    { return !(__x < __y); }




  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator==(const move_iterator<_Iterator>& __x,
        const move_iterator<_Iterator>& __y)
    { return __x.base() == __y.base(); }
  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator!=(const move_iterator<_Iterator>& __x,
        const move_iterator<_Iterator>& __y)
    { return !(__x == __y); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator<(const move_iterator<_Iterator>& __x,
       const move_iterator<_Iterator>& __y)
    { return __x.base() < __y.base(); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator<=(const move_iterator<_Iterator>& __x,
        const move_iterator<_Iterator>& __y)
    { return !(__y < __x); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator>(const move_iterator<_Iterator>& __x,
       const move_iterator<_Iterator>& __y)
    { return __y < __x; }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr bool
    operator>=(const move_iterator<_Iterator>& __x,
        const move_iterator<_Iterator>& __y)
    { return !(__x < __y); }



  template<typename _IteratorL, typename _IteratorR>
    [[__nodiscard__]]
    inline constexpr auto
    operator-(const move_iterator<_IteratorL>& __x,
       const move_iterator<_IteratorR>& __y)
    -> decltype(__x.base() - __y.base())
    { return __x.base() - __y.base(); }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr move_iterator<_Iterator>
    operator+(typename move_iterator<_Iterator>::difference_type __n,
       const move_iterator<_Iterator>& __x)
    { return __x + __n; }

  template<typename _Iterator>
    [[__nodiscard__]]
    inline constexpr move_iterator<_Iterator>
    make_move_iterator(_Iterator __i)
    { return move_iterator<_Iterator>(std::move(__i)); }

  template<typename _Iterator, typename _ReturnType
    = __conditional_t<__move_if_noexcept_cond
      <typename iterator_traits<_Iterator>::value_type>::value,
  _Iterator, move_iterator<_Iterator>>>
    inline constexpr _ReturnType
    __make_move_if_noexcept_iterator(_Iterator __i)
    { return _ReturnType(__i); }



  template<typename _Tp, typename _ReturnType
    = __conditional_t<__move_if_noexcept_cond<_Tp>::value,
        const _Tp*, move_iterator<_Tp*>>>
    inline constexpr _ReturnType
    __make_move_if_noexcept_iterator(_Tp* __i)
    { return _ReturnType(__i); }
  template<typename _Iterator>
   
    auto
    __niter_base(move_iterator<_Iterator> __it)
    -> decltype(make_move_iterator(__niter_base(__it.base())))
    { return make_move_iterator(__niter_base(__it.base())); }

  template<typename _Iterator>
    struct __is_move_iterator<move_iterator<_Iterator> >
    {
      enum { __value = 1 };
      typedef __true_type __type;
    };

  template<typename _Iterator>
   
    auto
    __miter_base(move_iterator<_Iterator> __it)
    -> decltype(__miter_base(__it.base()))
    { return __miter_base(__it.base()); }
  template<typename _InputIterator>
    using __iter_key_t = remove_const_t<
    typename iterator_traits<_InputIterator>::value_type::first_type>;

  template<typename _InputIterator>
    using __iter_val_t =
    typename iterator_traits<_InputIterator>::value_type::second_type;

  template<typename _T1, typename _T2>
    struct pair;

  template<typename _InputIterator>
    using __iter_to_alloc_t =
    pair<add_const_t<__iter_key_t<_InputIterator>>,
  __iter_val_t<_InputIterator>>;



}

namespace std
{
  namespace __debug { }
}




namespace __gnu_debug
{
  using namespace std::__debug;

  template<typename _Ite, typename _Seq, typename _Cat>
    struct _Safe_iterator;
}

namespace __gnu_cxx
{
namespace __ops
{
  struct _Iter_less_iter
  {
    template<typename _Iterator1, typename _Iterator2>
      constexpr
      bool
      operator()(_Iterator1 __it1, _Iterator2 __it2) const
      { return *__it1 < *__it2; }
  };

  constexpr
  inline _Iter_less_iter
  __iter_less_iter()
  { return _Iter_less_iter(); }

  struct _Iter_less_val
  {

    constexpr _Iter_less_val() = default;




   
    explicit
    _Iter_less_val(_Iter_less_iter) { }

    template<typename _Iterator, typename _Value>
     
      bool
      operator()(_Iterator __it, _Value& __val) const
      { return *__it < __val; }
  };

 
  inline _Iter_less_val
  __iter_less_val()
  { return _Iter_less_val(); }

 
  inline _Iter_less_val
  __iter_comp_val(_Iter_less_iter)
  { return _Iter_less_val(); }

  struct _Val_less_iter
  {

    constexpr _Val_less_iter() = default;




   
    explicit
    _Val_less_iter(_Iter_less_iter) { }

    template<typename _Value, typename _Iterator>
     
      bool
      operator()(_Value& __val, _Iterator __it) const
      { return __val < *__it; }
  };

 
  inline _Val_less_iter
  __val_less_iter()
  { return _Val_less_iter(); }

 
  inline _Val_less_iter
  __val_comp_iter(_Iter_less_iter)
  { return _Val_less_iter(); }

  struct _Iter_equal_to_iter
  {
    template<typename _Iterator1, typename _Iterator2>
     
      bool
      operator()(_Iterator1 __it1, _Iterator2 __it2) const
      { return *__it1 == *__it2; }
  };

 
  inline _Iter_equal_to_iter
  __iter_equal_to_iter()
  { return _Iter_equal_to_iter(); }

  struct _Iter_equal_to_val
  {
    template<typename _Iterator, typename _Value>
     
      bool
      operator()(_Iterator __it, _Value& __val) const
      { return *__it == __val; }
  };

 
  inline _Iter_equal_to_val
  __iter_equal_to_val()
  { return _Iter_equal_to_val(); }

 
  inline _Iter_equal_to_val
  __iter_comp_val(_Iter_equal_to_iter)
  { return _Iter_equal_to_val(); }

  template<typename _Compare>
    struct _Iter_comp_iter
    {
      _Compare _M_comp;

      explicit constexpr
      _Iter_comp_iter(_Compare __comp)
 : _M_comp(std::move(__comp))
      { }

      template<typename _Iterator1, typename _Iterator2>
        constexpr
        bool
        operator()(_Iterator1 __it1, _Iterator2 __it2)
        { return bool(_M_comp(*__it1, *__it2)); }
    };

  template<typename _Compare>
    constexpr
    inline _Iter_comp_iter<_Compare>
    __iter_comp_iter(_Compare __comp)
    { return _Iter_comp_iter<_Compare>(std::move(__comp)); }

  template<typename _Compare>
    struct _Iter_comp_val
    {
      _Compare _M_comp;

     
      explicit
      _Iter_comp_val(_Compare __comp)
 : _M_comp(std::move(__comp))
      { }

     
      explicit
      _Iter_comp_val(const _Iter_comp_iter<_Compare>& __comp)
 : _M_comp(__comp._M_comp)
      { }


     
      explicit
      _Iter_comp_val(_Iter_comp_iter<_Compare>&& __comp)
 : _M_comp(std::move(__comp._M_comp))
      { }


      template<typename _Iterator, typename _Value>

 bool
 operator()(_Iterator __it, _Value& __val)
 { return bool(_M_comp(*__it, __val)); }
    };

  template<typename _Compare>
   
    inline _Iter_comp_val<_Compare>
    __iter_comp_val(_Compare __comp)
    { return _Iter_comp_val<_Compare>(std::move(__comp)); }

  template<typename _Compare>
   
    inline _Iter_comp_val<_Compare>
    __iter_comp_val(_Iter_comp_iter<_Compare> __comp)
    { return _Iter_comp_val<_Compare>(std::move(__comp)); }

  template<typename _Compare>
    struct _Val_comp_iter
    {
      _Compare _M_comp;

     
      explicit
      _Val_comp_iter(_Compare __comp)
 : _M_comp(std::move(__comp))
      { }

     
      explicit
      _Val_comp_iter(const _Iter_comp_iter<_Compare>& __comp)
 : _M_comp(__comp._M_comp)
      { }


     
      explicit
      _Val_comp_iter(_Iter_comp_iter<_Compare>&& __comp)
 : _M_comp(std::move(__comp._M_comp))
      { }


      template<typename _Value, typename _Iterator>

 bool
 operator()(_Value& __val, _Iterator __it)
 { return bool(_M_comp(__val, *__it)); }
    };

  template<typename _Compare>
   
    inline _Val_comp_iter<_Compare>
    __val_comp_iter(_Compare __comp)
    { return _Val_comp_iter<_Compare>(std::move(__comp)); }

  template<typename _Compare>
   
    inline _Val_comp_iter<_Compare>
    __val_comp_iter(_Iter_comp_iter<_Compare> __comp)
    { return _Val_comp_iter<_Compare>(std::move(__comp)); }

  template<typename _Value>
    struct _Iter_equals_val
    {
      _Value& _M_value;

     
      explicit
      _Iter_equals_val(_Value& __value)
 : _M_value(__value)
      { }

      template<typename _Iterator>

 bool
 operator()(_Iterator __it)
 { return *__it == _M_value; }
    };

  template<typename _Value>
   
    inline _Iter_equals_val<_Value>
    __iter_equals_val(_Value& __val)
    { return _Iter_equals_val<_Value>(__val); }

  template<typename _Iterator1>
    struct _Iter_equals_iter
    {
      _Iterator1 _M_it1;

     
      explicit
      _Iter_equals_iter(_Iterator1 __it1)
 : _M_it1(__it1)
      { }

      template<typename _Iterator2>

 bool
 operator()(_Iterator2 __it2)
 { return *__it2 == *_M_it1; }
    };

  template<typename _Iterator>
   
    inline _Iter_equals_iter<_Iterator>
    __iter_comp_iter(_Iter_equal_to_iter, _Iterator __it)
    { return _Iter_equals_iter<_Iterator>(__it); }

  template<typename _Predicate>
    struct _Iter_pred
    {
      _Predicate _M_pred;

     
      explicit
      _Iter_pred(_Predicate __pred)
 : _M_pred(std::move(__pred))
      { }

      template<typename _Iterator>

 bool
 operator()(_Iterator __it)
 { return bool(_M_pred(*__it)); }
    };

  template<typename _Predicate>
   
    inline _Iter_pred<_Predicate>
    __pred_iter(_Predicate __pred)
    { return _Iter_pred<_Predicate>(std::move(__pred)); }

  template<typename _Compare, typename _Value>
    struct _Iter_comp_to_val
    {
      _Compare _M_comp;
      _Value& _M_value;

     
      _Iter_comp_to_val(_Compare __comp, _Value& __value)
 : _M_comp(std::move(__comp)), _M_value(__value)
      { }

      template<typename _Iterator>

 bool
 operator()(_Iterator __it)
 { return bool(_M_comp(*__it, _M_value)); }
    };

  template<typename _Compare, typename _Value>
    _Iter_comp_to_val<_Compare, _Value>
   
    __iter_comp_val(_Compare __comp, _Value &__val)
    {
      return _Iter_comp_to_val<_Compare, _Value>(std::move(__comp), __val);
    }

  template<typename _Compare, typename _Iterator1>
    struct _Iter_comp_to_iter
    {
      _Compare _M_comp;
      _Iterator1 _M_it1;

     
      _Iter_comp_to_iter(_Compare __comp, _Iterator1 __it1)
 : _M_comp(std::move(__comp)), _M_it1(__it1)
      { }

      template<typename _Iterator2>

 bool
 operator()(_Iterator2 __it2)
 { return bool(_M_comp(*__it2, *_M_it1)); }
    };

  template<typename _Compare, typename _Iterator>
   
    inline _Iter_comp_to_iter<_Compare, _Iterator>
    __iter_comp_iter(_Iter_comp_iter<_Compare> __comp, _Iterator __it)
    {
      return _Iter_comp_to_iter<_Compare, _Iterator>(
   std::move(__comp._M_comp), __it);
    }

  template<typename _Predicate>
    struct _Iter_negate
    {
      _Predicate _M_pred;

     
      explicit
      _Iter_negate(_Predicate __pred)
 : _M_pred(std::move(__pred))
      { }

      template<typename _Iterator>

 bool
 operator()(_Iterator __it)
 { return !bool(_M_pred(*__it)); }
    };

  template<typename _Predicate>
   
    inline _Iter_negate<_Predicate>
    __negate(_Iter_pred<_Predicate> __pred)
    { return _Iter_negate<_Predicate>(std::move(__pred._M_pred)); }

}
}







namespace std __attribute__ ((__visibility__ ("default")))
{






  template<typename _Tp, typename _Up>
    constexpr
    inline int
    __memcmp(const _Tp* __first1, const _Up* __first2, size_t __num)
    {

      static_assert(sizeof(_Tp) == sizeof(_Up), "can be compared with memcmp");
 return __builtin_memcmp(__first1, __first2, sizeof(_Tp) * __num);
    }
  template<typename _ForwardIterator1, typename _ForwardIterator2>
   
    inline void
    iter_swap(_ForwardIterator1 __a, _ForwardIterator2 __b)
    {

     

     
      swap(*__a, *__b);

    }
  template<typename _ForwardIterator1, typename _ForwardIterator2>
   
    _ForwardIterator2
    swap_ranges(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
  _ForwardIterator2 __first2)
    {

     

     

      ;

      for (; __first1 != __last1; ++__first1, (void)++__first2)
 std::iter_swap(__first1, __first2);
      return __first2;
    }
  template<typename _Tp>
    constexpr
    inline const _Tp&
    min(const _Tp& __a, const _Tp& __b)
    {

     

      if (__b < __a)
 return __b;
      return __a;
    }
  template<typename _Tp>
    constexpr
    inline const _Tp&
    max(const _Tp& __a, const _Tp& __b)
    {

     

      if (__a < __b)
 return __b;
      return __a;
    }
  template<typename _Tp, typename _Compare>
    constexpr
    inline const _Tp&
    min(const _Tp& __a, const _Tp& __b, _Compare __comp)
    {

      if (__comp(__b, __a))
 return __b;
      return __a;
    }
  template<typename _Tp, typename _Compare>
    constexpr
    inline const _Tp&
    max(const _Tp& __a, const _Tp& __b, _Compare __comp)
    {

      if (__comp(__a, __b))
 return __b;
      return __a;
    }



  template<typename _Iterator>
   
    inline _Iterator
    __niter_base(_Iterator __it)
    noexcept(std::is_nothrow_copy_constructible<_Iterator>::value)
    { return __it; }

  template<typename _Ite, typename _Seq>
    _Ite
    __niter_base(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq,
   std::random_access_iterator_tag>&);




  template<typename _From, typename _To>
   
    inline _From
    __niter_wrap(_From __from, _To __res)
    { return __from + (__res - std::__niter_base(__from)); }


  template<typename _Iterator>
   
    inline _Iterator
    __niter_wrap(const _Iterator&, _Iterator __res)
    { return __res; }







  template<bool _IsMove, bool _IsSimple, typename _Category>
    struct __copy_move
    {
      template<typename _II, typename _OI>

 static _OI
 __copy_m(_II __first, _II __last, _OI __result)
 {
   for (; __first != __last; ++__result, (void)++__first)
     *__result = *__first;
   return __result;
 }
    };


  template<typename _Category>
    struct __copy_move<true, false, _Category>
    {
      template<typename _II, typename _OI>

 static _OI
 __copy_m(_II __first, _II __last, _OI __result)
 {
   for (; __first != __last; ++__result, (void)++__first)
     *__result = std::move(*__first);
   return __result;
 }
    };


  template<>
    struct __copy_move<false, false, random_access_iterator_tag>
    {
      template<typename _II, typename _OI>

 static _OI
 __copy_m(_II __first, _II __last, _OI __result)
 {
   typedef typename iterator_traits<_II>::difference_type _Distance;
   for(_Distance __n = __last - __first; __n > 0; --__n)
     {
       *__result = *__first;
       ++__first;
       ++__result;
     }
   return __result;
 }

      template<typename _Tp, typename _Up>
 static void
 __assign_one(_Tp* __to, _Up* __from)
 { *__to = *__from; }
    };


  template<>
    struct __copy_move<true, false, random_access_iterator_tag>
    {
      template<typename _II, typename _OI>

 static _OI
 __copy_m(_II __first, _II __last, _OI __result)
 {
   typedef typename iterator_traits<_II>::difference_type _Distance;
   for(_Distance __n = __last - __first; __n > 0; --__n)
     {
       *__result = std::move(*__first);
       ++__first;
       ++__result;
     }
   return __result;
 }

      template<typename _Tp, typename _Up>
 static void
 __assign_one(_Tp* __to, _Up* __from)
 { *__to = std::move(*__from); }
    };


  template<bool _IsMove>
    struct __copy_move<_IsMove, true, random_access_iterator_tag>
    {
      template<typename _Tp, typename _Up>

 static _Up*
 __copy_m(_Tp* __first, _Tp* __last, _Up* __result)
 {
   const ptrdiff_t _Num = __last - __first;
   if (__builtin_expect(_Num > 1, true))
     __builtin_memmove(__result, __first, sizeof(_Tp) * _Num);
   else if (_Num == 1)
     std::__copy_move<_IsMove, false, random_access_iterator_tag>::
       __assign_one(__result, __first);
   return __result + _Num;
 }
    };



  template<typename _Tp, typename _Ref, typename _Ptr>
    struct _Deque_iterator;

  struct _Bit_iterator;





  template<typename _CharT>
    struct char_traits;

  template<typename _CharT, typename _Traits>
    class istreambuf_iterator;

  template<typename _CharT, typename _Traits>
    class ostreambuf_iterator;

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<__is_char<_CharT>::__value,
      ostreambuf_iterator<_CharT, char_traits<_CharT> > >::__type
    __copy_move_a2(_CharT*, _CharT*,
     ostreambuf_iterator<_CharT, char_traits<_CharT> >);

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<__is_char<_CharT>::__value,
      ostreambuf_iterator<_CharT, char_traits<_CharT> > >::__type
    __copy_move_a2(const _CharT*, const _CharT*,
     ostreambuf_iterator<_CharT, char_traits<_CharT> >);

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<__is_char<_CharT>::__value,
        _CharT*>::__type
    __copy_move_a2(istreambuf_iterator<_CharT, char_traits<_CharT> >,
     istreambuf_iterator<_CharT, char_traits<_CharT> >, _CharT*);

  template<bool _IsMove, typename _CharT>
    typename __gnu_cxx::__enable_if<
      __is_char<_CharT>::__value,
      std::_Deque_iterator<_CharT, _CharT&, _CharT*> >::__type
    __copy_move_a2(
 istreambuf_iterator<_CharT, char_traits<_CharT> >,
 istreambuf_iterator<_CharT, char_traits<_CharT> >,
 std::_Deque_iterator<_CharT, _CharT&, _CharT*>);

  template<bool _IsMove, typename _II, typename _OI>
   
    inline _OI
    __copy_move_a2(_II __first, _II __last, _OI __result)
    {
      typedef typename iterator_traits<_II>::iterator_category _Category;





      return std::__copy_move<_IsMove, __memcpyable<_OI, _II>::__value,
         _Category>::__copy_m(__first, __last, __result);
    }

  template<bool _IsMove,
    typename _Tp, typename _Ref, typename _Ptr, typename _OI>
    _OI
    __copy_move_a1(std::_Deque_iterator<_Tp, _Ref, _Ptr>,
     std::_Deque_iterator<_Tp, _Ref, _Ptr>,
     _OI);

  template<bool _IsMove,
    typename _ITp, typename _IRef, typename _IPtr, typename _OTp>
    std::_Deque_iterator<_OTp, _OTp&, _OTp*>
    __copy_move_a1(std::_Deque_iterator<_ITp, _IRef, _IPtr>,
     std::_Deque_iterator<_ITp, _IRef, _IPtr>,
     std::_Deque_iterator<_OTp, _OTp&, _OTp*>);

  template<bool _IsMove, typename _II, typename _Tp>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value,
      std::_Deque_iterator<_Tp, _Tp&, _Tp*> >::__type
    __copy_move_a1(_II, _II, std::_Deque_iterator<_Tp, _Tp&, _Tp*>);

  template<bool _IsMove, typename _II, typename _OI>
   
    inline _OI
    __copy_move_a1(_II __first, _II __last, _OI __result)
    { return std::__copy_move_a2<_IsMove>(__first, __last, __result); }

  template<bool _IsMove, typename _II, typename _OI>
   
    inline _OI
    __copy_move_a(_II __first, _II __last, _OI __result)
    {
      return std::__niter_wrap(__result,
  std::__copy_move_a1<_IsMove>(std::__niter_base(__first),
          std::__niter_base(__last),
          std::__niter_base(__result)));
    }

  template<bool _IsMove,
    typename _Ite, typename _Seq, typename _Cat, typename _OI>
    _OI
    __copy_move_a(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
    const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
    _OI);

  template<bool _IsMove,
    typename _II, typename _Ite, typename _Seq, typename _Cat>
    __gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>
    __copy_move_a(_II, _II,
    const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&);

  template<bool _IsMove,
    typename _IIte, typename _ISeq, typename _ICat,
    typename _OIte, typename _OSeq, typename _OCat>
    ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>
    __copy_move_a(const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
    const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
    const ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>&);

  template<typename _InputIterator, typename _Size, typename _OutputIterator>
   
    _OutputIterator
    __copy_n_a(_InputIterator __first, _Size __n, _OutputIterator __result,
        bool)
    {
      if (__n > 0)
 {
   while (true)
     {
       *__result = *__first;
       ++__result;
       if (--__n > 0)
  ++__first;
       else
  break;
     }
 }
      return __result;
    }

  template<typename _CharT, typename _Size>
    typename __gnu_cxx::__enable_if<
      __is_char<_CharT>::__value, _CharT*>::__type
    __copy_n_a(istreambuf_iterator<_CharT, char_traits<_CharT> >,
        _Size, _CharT*, bool);

  template<typename _CharT, typename _Size>
    typename __gnu_cxx::__enable_if<
      __is_char<_CharT>::__value,
      std::_Deque_iterator<_CharT, _CharT&, _CharT*> >::__type
    __copy_n_a(istreambuf_iterator<_CharT, char_traits<_CharT> >, _Size,
        std::_Deque_iterator<_CharT, _CharT&, _CharT*>,
        bool);
  template<typename _II, typename _OI>
   
    inline _OI
    copy(_II __first, _II __last, _OI __result)
    {

     
     

      ;

      return std::__copy_move_a<__is_move_iterator<_II>::__value>
      (std::__miter_base(__first), std::__miter_base(__last), __result);
    }
  template<typename _II, typename _OI>
   
    inline _OI
    move(_II __first, _II __last, _OI __result)
    {

     
     

      ;

      return std::__copy_move_a<true>(std::__miter_base(__first),
          std::__miter_base(__last), __result);
    }






  template<bool _IsMove, bool _IsSimple, typename _Category>
    struct __copy_move_backward
    {
      template<typename _BI1, typename _BI2>

 static _BI2
 __copy_move_b(_BI1 __first, _BI1 __last, _BI2 __result)
 {
   while (__first != __last)
     *--__result = *--__last;
   return __result;
 }
    };


  template<typename _Category>
    struct __copy_move_backward<true, false, _Category>
    {
      template<typename _BI1, typename _BI2>

 static _BI2
 __copy_move_b(_BI1 __first, _BI1 __last, _BI2 __result)
 {
   while (__first != __last)
     *--__result = std::move(*--__last);
   return __result;
 }
    };


  template<>
    struct __copy_move_backward<false, false, random_access_iterator_tag>
    {
      template<typename _BI1, typename _BI2>

 static _BI2
 __copy_move_b(_BI1 __first, _BI1 __last, _BI2 __result)
 {
   typename iterator_traits<_BI1>::difference_type
     __n = __last - __first;
   for (; __n > 0; --__n)
     *--__result = *--__last;
   return __result;
 }
    };


  template<>
    struct __copy_move_backward<true, false, random_access_iterator_tag>
    {
      template<typename _BI1, typename _BI2>

 static _BI2
 __copy_move_b(_BI1 __first, _BI1 __last, _BI2 __result)
 {
   typename iterator_traits<_BI1>::difference_type
     __n = __last - __first;
   for (; __n > 0; --__n)
     *--__result = std::move(*--__last);
   return __result;
 }
    };


  template<bool _IsMove>
    struct __copy_move_backward<_IsMove, true, random_access_iterator_tag>
    {
      template<typename _Tp, typename _Up>

 static _Up*
 __copy_move_b(_Tp* __first, _Tp* __last, _Up* __result)
 {
   const ptrdiff_t _Num = __last - __first;
   if (__builtin_expect(_Num > 1, true))
     __builtin_memmove(__result - _Num, __first, sizeof(_Tp) * _Num);
   else if (_Num == 1)
     std::__copy_move<_IsMove, false, random_access_iterator_tag>::
       __assign_one(__result - 1, __first);
   return __result - _Num;
 }
    };

  template<bool _IsMove, typename _BI1, typename _BI2>
   
    inline _BI2
    __copy_move_backward_a2(_BI1 __first, _BI1 __last, _BI2 __result)
    {
      typedef typename iterator_traits<_BI1>::iterator_category _Category;





      return std::__copy_move_backward<_IsMove,
           __memcpyable<_BI2, _BI1>::__value,
           _Category>::__copy_move_b(__first,
         __last,
         __result);
    }

  template<bool _IsMove, typename _BI1, typename _BI2>
   
    inline _BI2
    __copy_move_backward_a1(_BI1 __first, _BI1 __last, _BI2 __result)
    { return std::__copy_move_backward_a2<_IsMove>(__first, __last, __result); }

  template<bool _IsMove,
    typename _Tp, typename _Ref, typename _Ptr, typename _OI>
    _OI
    __copy_move_backward_a1(std::_Deque_iterator<_Tp, _Ref, _Ptr>,
       std::_Deque_iterator<_Tp, _Ref, _Ptr>,
       _OI);

  template<bool _IsMove,
    typename _ITp, typename _IRef, typename _IPtr, typename _OTp>
    std::_Deque_iterator<_OTp, _OTp&, _OTp*>
    __copy_move_backward_a1(
   std::_Deque_iterator<_ITp, _IRef, _IPtr>,
   std::_Deque_iterator<_ITp, _IRef, _IPtr>,
   std::_Deque_iterator<_OTp, _OTp&, _OTp*>);

  template<bool _IsMove, typename _II, typename _Tp>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value,
      std::_Deque_iterator<_Tp, _Tp&, _Tp*> >::__type
    __copy_move_backward_a1(_II, _II,
       std::_Deque_iterator<_Tp, _Tp&, _Tp*>);

  template<bool _IsMove, typename _II, typename _OI>
   
    inline _OI
    __copy_move_backward_a(_II __first, _II __last, _OI __result)
    {
      return std::__niter_wrap(__result,
  std::__copy_move_backward_a1<_IsMove>
    (std::__niter_base(__first), std::__niter_base(__last),
     std::__niter_base(__result)));
    }

  template<bool _IsMove,
    typename _Ite, typename _Seq, typename _Cat, typename _OI>
    _OI
    __copy_move_backward_a(
  const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
  const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
  _OI);

  template<bool _IsMove,
    typename _II, typename _Ite, typename _Seq, typename _Cat>
    __gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>
    __copy_move_backward_a(_II, _II,
  const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&);

  template<bool _IsMove,
    typename _IIte, typename _ISeq, typename _ICat,
    typename _OIte, typename _OSeq, typename _OCat>
    ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>
    __copy_move_backward_a(
  const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
  const ::__gnu_debug::_Safe_iterator<_IIte, _ISeq, _ICat>&,
  const ::__gnu_debug::_Safe_iterator<_OIte, _OSeq, _OCat>&);
  template<typename _BI1, typename _BI2>
   
    inline _BI2
    copy_backward(_BI1 __first, _BI1 __last, _BI2 __result)
    {

     
     
     

      ;

      return std::__copy_move_backward_a<__is_move_iterator<_BI1>::__value>
      (std::__miter_base(__first), std::__miter_base(__last), __result);
    }
  template<typename _BI1, typename _BI2>
   
    inline _BI2
    move_backward(_BI1 __first, _BI1 __last, _BI2 __result)
    {

     
     
     

      ;

      return std::__copy_move_backward_a<true>(std::__miter_base(__first),
            std::__miter_base(__last),
            __result);
    }






  template<typename _ForwardIterator, typename _Tp>
   
    inline typename
    __gnu_cxx::__enable_if<!__is_scalar<_Tp>::__value, void>::__type
    __fill_a1(_ForwardIterator __first, _ForwardIterator __last,
       const _Tp& __value)
    {
      for (; __first != __last; ++__first)
 *__first = __value;
    }

  template<typename _ForwardIterator, typename _Tp>
   
    inline typename
    __gnu_cxx::__enable_if<__is_scalar<_Tp>::__value, void>::__type
    __fill_a1(_ForwardIterator __first, _ForwardIterator __last,
       const _Tp& __value)
    {
      const _Tp __tmp = __value;
      for (; __first != __last; ++__first)
 *__first = __tmp;
    }


  template<typename _Tp>
   
    inline typename
    __gnu_cxx::__enable_if<__is_byte<_Tp>::__value, void>::__type
    __fill_a1(_Tp* __first, _Tp* __last, const _Tp& __c)
    {
      const _Tp __tmp = __c;
      if (const size_t __len = __last - __first)
 __builtin_memset(__first, static_cast<unsigned char>(__tmp), __len);
    }

  template<typename _Ite, typename _Cont, typename _Tp>
   
    inline void
    __fill_a1(::__gnu_cxx::__normal_iterator<_Ite, _Cont> __first,
       ::__gnu_cxx::__normal_iterator<_Ite, _Cont> __last,
       const _Tp& __value)
    { std::__fill_a1(__first.base(), __last.base(), __value); }

  template<typename _Tp, typename _VTp>
    void
    __fill_a1(const std::_Deque_iterator<_Tp, _Tp&, _Tp*>&,
       const std::_Deque_iterator<_Tp, _Tp&, _Tp*>&,
       const _VTp&);

 
  void
  __fill_a1(std::_Bit_iterator, std::_Bit_iterator,
     const bool&);

  template<typename _FIte, typename _Tp>
   
    inline void
    __fill_a(_FIte __first, _FIte __last, const _Tp& __value)
    { std::__fill_a1(__first, __last, __value); }

  template<typename _Ite, typename _Seq, typename _Cat, typename _Tp>
    void
    __fill_a(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
      const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>&,
      const _Tp&);
  template<typename _ForwardIterator, typename _Tp>
   
    inline void
    fill(_ForwardIterator __first, _ForwardIterator __last, const _Tp& __value)
    {

     

      ;

      std::__fill_a(__first, __last, __value);
    }


  inline constexpr int
  __size_to_integer(int __n) { return __n; }
  inline constexpr unsigned
  __size_to_integer(unsigned __n) { return __n; }
  inline constexpr long
  __size_to_integer(long __n) { return __n; }
  inline constexpr unsigned long
  __size_to_integer(unsigned long __n) { return __n; }
  inline constexpr long long
  __size_to_integer(long long __n) { return __n; }
  inline constexpr unsigned long long
  __size_to_integer(unsigned long long __n) { return __n; }
  inline constexpr long long
  __size_to_integer(float __n) { return (long long)__n; }
  inline constexpr long long
  __size_to_integer(double __n) { return (long long)__n; }
  inline constexpr long long
  __size_to_integer(long double __n) { return (long long)__n; }





  template<typename _OutputIterator, typename _Size, typename _Tp>
   
    inline typename
    __gnu_cxx::__enable_if<!__is_scalar<_Tp>::__value, _OutputIterator>::__type
    __fill_n_a1(_OutputIterator __first, _Size __n, const _Tp& __value)
    {
      for (; __n > 0; --__n, (void) ++__first)
 *__first = __value;
      return __first;
    }

  template<typename _OutputIterator, typename _Size, typename _Tp>
   
    inline typename
    __gnu_cxx::__enable_if<__is_scalar<_Tp>::__value, _OutputIterator>::__type
    __fill_n_a1(_OutputIterator __first, _Size __n, const _Tp& __value)
    {
      const _Tp __tmp = __value;
      for (; __n > 0; --__n, (void) ++__first)
 *__first = __tmp;
      return __first;
    }

  template<typename _Ite, typename _Seq, typename _Cat, typename _Size,
    typename _Tp>
    ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>
    __fill_n_a(const ::__gnu_debug::_Safe_iterator<_Ite, _Seq, _Cat>& __first,
        _Size __n, const _Tp& __value,
        std::input_iterator_tag);

  template<typename _OutputIterator, typename _Size, typename _Tp>
   
    inline _OutputIterator
    __fill_n_a(_OutputIterator __first, _Size __n, const _Tp& __value,
        std::output_iterator_tag)
    {

      static_assert(is_integral<_Size>{}, "fill_n must pass integral size");

      return __fill_n_a1(__first, __n, __value);
    }

  template<typename _OutputIterator, typename _Size, typename _Tp>
   
    inline _OutputIterator
    __fill_n_a(_OutputIterator __first, _Size __n, const _Tp& __value,
        std::input_iterator_tag)
    {

      static_assert(is_integral<_Size>{}, "fill_n must pass integral size");

      return __fill_n_a1(__first, __n, __value);
    }

  template<typename _OutputIterator, typename _Size, typename _Tp>
   
    inline _OutputIterator
    __fill_n_a(_OutputIterator __first, _Size __n, const _Tp& __value,
        std::random_access_iterator_tag)
    {

      static_assert(is_integral<_Size>{}, "fill_n must pass integral size");

      if (__n <= 0)
 return __first;

      ;

      std::__fill_a(__first, __first + __n, __value);
      return __first + __n;
    }
  template<typename _OI, typename _Size, typename _Tp>
   
    inline _OI
    fill_n(_OI __first, _Size __n, const _Tp& __value)
    {

     

      return std::__fill_n_a(__first, std::__size_to_integer(__n), __value,
          std::__iterator_category(__first));
    }

  template<bool _BoolType>
    struct __equal
    {
      template<typename _II1, typename _II2>

 static bool
 equal(_II1 __first1, _II1 __last1, _II2 __first2)
 {
   for (; __first1 != __last1; ++__first1, (void) ++__first2)
     if (!(*__first1 == *__first2))
       return false;
   return true;
 }
    };

  template<>
    struct __equal<true>
    {
      template<typename _Tp>

 static bool
 equal(const _Tp* __first1, const _Tp* __last1, const _Tp* __first2)
 {
   if (const size_t __len = (__last1 - __first1))
     return !std::__memcmp(__first1, __first2, __len);
   return true;
 }
    };

  template<typename _Tp, typename _Ref, typename _Ptr, typename _II>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value, bool>::__type
    __equal_aux1(std::_Deque_iterator<_Tp, _Ref, _Ptr>,
   std::_Deque_iterator<_Tp, _Ref, _Ptr>,
   _II);

  template<typename _Tp1, typename _Ref1, typename _Ptr1,
    typename _Tp2, typename _Ref2, typename _Ptr2>
    bool
    __equal_aux1(std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
   std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
   std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>);

  template<typename _II, typename _Tp, typename _Ref, typename _Ptr>
    typename __gnu_cxx::__enable_if<
      __is_random_access_iter<_II>::__value, bool>::__type
    __equal_aux1(_II, _II,
  std::_Deque_iterator<_Tp, _Ref, _Ptr>);

  template<typename _II1, typename _II2>
   
    inline bool
    __equal_aux1(_II1 __first1, _II1 __last1, _II2 __first2)
    {
      typedef typename iterator_traits<_II1>::value_type _ValueType1;
      const bool __simple = ((__is_integer<_ValueType1>::__value
         || __is_pointer<_ValueType1>::__value)
        && __memcmpable<_II1, _II2>::__value);
      return std::__equal<__simple>::equal(__first1, __last1, __first2);
    }

  template<typename _II1, typename _II2>
   
    inline bool
    __equal_aux(_II1 __first1, _II1 __last1, _II2 __first2)
    {
      return std::__equal_aux1(std::__niter_base(__first1),
          std::__niter_base(__last1),
          std::__niter_base(__first2));
    }

  template<typename _II1, typename _Seq1, typename _Cat1, typename _II2>
    bool
    __equal_aux(const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  _II2);

  template<typename _II1, typename _II2, typename _Seq2, typename _Cat2>
    bool
    __equal_aux(_II1, _II1,
  const ::__gnu_debug::_Safe_iterator<_II2, _Seq2, _Cat2>&);

  template<typename _II1, typename _Seq1, typename _Cat1,
    typename _II2, typename _Seq2, typename _Cat2>
    bool
    __equal_aux(const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_II1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_II2, _Seq2, _Cat2>&);

  template<typename, typename>
    struct __lc_rai
    {
      template<typename _II1, typename _II2>

 static _II1
 __newlast1(_II1, _II1 __last1, _II2, _II2)
 { return __last1; }

      template<typename _II>

 static bool
 __cnd2(_II __first, _II __last)
 { return __first != __last; }
    };

  template<>
    struct __lc_rai<random_access_iterator_tag, random_access_iterator_tag>
    {
      template<typename _RAI1, typename _RAI2>

 static _RAI1
 __newlast1(_RAI1 __first1, _RAI1 __last1,
     _RAI2 __first2, _RAI2 __last2)
 {
   const typename iterator_traits<_RAI1>::difference_type
     __diff1 = __last1 - __first1;
   const typename iterator_traits<_RAI2>::difference_type
     __diff2 = __last2 - __first2;
   return __diff2 < __diff1 ? __first1 + __diff2 : __last1;
 }

      template<typename _RAI>
 static bool
 __cnd2(_RAI, _RAI)
 { return true; }
    };

  template<typename _II1, typename _II2, typename _Compare>
   
    bool
    __lexicographical_compare_impl(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2,
       _Compare __comp)
    {
      typedef typename iterator_traits<_II1>::iterator_category _Category1;
      typedef typename iterator_traits<_II2>::iterator_category _Category2;
      typedef std::__lc_rai<_Category1, _Category2> __rai_type;

      __last1 = __rai_type::__newlast1(__first1, __last1, __first2, __last2);
      for (; __first1 != __last1 && __rai_type::__cnd2(__first2, __last2);
    ++__first1, (void)++__first2)
 {
   if (__comp(__first1, __first2))
     return true;
   if (__comp(__first2, __first1))
     return false;
 }
      return __first1 == __last1 && __first2 != __last2;
    }

  template<bool _BoolType>
    struct __lexicographical_compare
    {
      template<typename _II1, typename _II2>

 static bool
 __lc(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
 {
   using __gnu_cxx::__ops::__iter_less_iter;
   return std::__lexicographical_compare_impl(__first1, __last1,
           __first2, __last2,
           __iter_less_iter());
 }

      template<typename _II1, typename _II2>

 static int
 __3way(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
 {
   while (__first1 != __last1)
     {
       if (__first2 == __last2)
  return +1;
       if (*__first1 < *__first2)
  return -1;
       if (*__first2 < *__first1)
  return +1;
       ++__first1;
       ++__first2;
     }
   return int(__first2 == __last2) - 1;
 }
    };

  template<>
    struct __lexicographical_compare<true>
    {
      template<typename _Tp, typename _Up>

 static bool
 __lc(const _Tp* __first1, const _Tp* __last1,
      const _Up* __first2, const _Up* __last2)
 { return __3way(__first1, __last1, __first2, __last2) < 0; }

      template<typename _Tp, typename _Up>

 static ptrdiff_t
 __3way(const _Tp* __first1, const _Tp* __last1,
        const _Up* __first2, const _Up* __last2)
 {
   const size_t __len1 = __last1 - __first1;
   const size_t __len2 = __last2 - __first2;
   if (const size_t __len = std::min(__len1, __len2))
     if (int __result = std::__memcmp(__first1, __first2, __len))
       return __result;
   return ptrdiff_t(__len1 - __len2);
 }
    };

  template<typename _II1, typename _II2>
   
    inline bool
    __lexicographical_compare_aux1(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2)
    {
      typedef typename iterator_traits<_II1>::value_type _ValueType1;
      typedef typename iterator_traits<_II2>::value_type _ValueType2;
      const bool __simple =
 (__is_memcmp_ordered_with<_ValueType1, _ValueType2>::__value
  && __is_pointer<_II1>::__value
  && __is_pointer<_II2>::__value







  );

      return std::__lexicographical_compare<__simple>::__lc(__first1, __last1,
           __first2, __last2);
    }

  template<typename _Tp1, typename _Ref1, typename _Ptr1,
    typename _Tp2>
    bool
    __lexicographical_compare_aux1(
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 _Tp2*, _Tp2*);

  template<typename _Tp1,
    typename _Tp2, typename _Ref2, typename _Ptr2>
    bool
    __lexicographical_compare_aux1(_Tp1*, _Tp1*,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>);

  template<typename _Tp1, typename _Ref1, typename _Ptr1,
    typename _Tp2, typename _Ref2, typename _Ptr2>
    bool
    __lexicographical_compare_aux1(
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 std::_Deque_iterator<_Tp1, _Ref1, _Ptr1>,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>,
 std::_Deque_iterator<_Tp2, _Ref2, _Ptr2>);

  template<typename _II1, typename _II2>
   
    inline bool
    __lexicographical_compare_aux(_II1 __first1, _II1 __last1,
      _II2 __first2, _II2 __last2)
    {
      return std::__lexicographical_compare_aux1(std::__niter_base(__first1),
       std::__niter_base(__last1),
       std::__niter_base(__first2),
       std::__niter_base(__last2));
    }

  template<typename _Iter1, typename _Seq1, typename _Cat1,
    typename _II2>
    bool
    __lexicographical_compare_aux(
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  _II2, _II2);

  template<typename _II1,
    typename _Iter2, typename _Seq2, typename _Cat2>
    bool
    __lexicographical_compare_aux(
  _II1, _II1,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&);

  template<typename _Iter1, typename _Seq1, typename _Cat1,
    typename _Iter2, typename _Seq2, typename _Cat2>
    bool
    __lexicographical_compare_aux(
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_Iter1, _Seq1, _Cat1>&,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&,
  const ::__gnu_debug::_Safe_iterator<_Iter2, _Seq2, _Cat2>&);

  template<typename _ForwardIterator, typename _Tp, typename _Compare>
   
    _ForwardIterator
    __lower_bound(_ForwardIterator __first, _ForwardIterator __last,
    const _Tp& __val, _Compare __comp)
    {
      typedef typename iterator_traits<_ForwardIterator>::difference_type
 _DistanceType;

      _DistanceType __len = std::distance(__first, __last);

      while (__len > 0)
 {
   _DistanceType __half = __len >> 1;
   _ForwardIterator __middle = __first;
   std::advance(__middle, __half);
   if (__comp(__middle, __val))
     {
       __first = __middle;
       ++__first;
       __len = __len - __half - 1;
     }
   else
     __len = __half;
 }
      return __first;
    }
  template<typename _ForwardIterator, typename _Tp>
   
    inline _ForwardIterator
    lower_bound(_ForwardIterator __first, _ForwardIterator __last,
  const _Tp& __val)
    {

     
     

      ;

      return std::__lower_bound(__first, __last, __val,
    __gnu_cxx::__ops::__iter_less_val());
    }



  inline constexpr int
  __lg(int __n)
  { return (int)sizeof(int) * 8 - 1 - __builtin_clz(__n); }

  inline constexpr unsigned
  __lg(unsigned __n)
  { return (int)sizeof(int) * 8 - 1 - __builtin_clz(__n); }

  inline constexpr long
  __lg(long __n)
  { return (int)sizeof(long) * 8 - 1 - __builtin_clzl(__n); }

  inline constexpr unsigned long
  __lg(unsigned long __n)
  { return (int)sizeof(long) * 8 - 1 - __builtin_clzl(__n); }

  inline constexpr long long
  __lg(long long __n)
  { return (int)sizeof(long long) * 8 - 1 - __builtin_clzll(__n); }

  inline constexpr unsigned long long
  __lg(unsigned long long __n)
  { return (int)sizeof(long long) * 8 - 1 - __builtin_clzll(__n); }


  template<typename _II1, typename _II2>
   
    inline bool
    equal(_II1 __first1, _II1 __last1, _II2 __first2)
    {

     
     
     


      ;

      return std::__equal_aux(__first1, __last1, __first2);
    }
  template<typename _IIter1, typename _IIter2, typename _BinaryPredicate>
   
    inline bool
    equal(_IIter1 __first1, _IIter1 __last1,
   _IIter2 __first2, _BinaryPredicate __binary_pred)
    {

     
     
      ;

      for (; __first1 != __last1; ++__first1, (void)++__first2)
 if (!bool(__binary_pred(*__first1, *__first2)))
   return false;
      return true;
    }



  template<typename _II1, typename _II2>
   
    inline bool
    __equal4(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
    {
      using _RATag = random_access_iterator_tag;
      using _Cat1 = typename iterator_traits<_II1>::iterator_category;
      using _Cat2 = typename iterator_traits<_II2>::iterator_category;
      using _RAIters = __and_<is_same<_Cat1, _RATag>, is_same<_Cat2, _RATag>>;
      if (_RAIters())
 {
   auto __d1 = std::distance(__first1, __last1);
   auto __d2 = std::distance(__first2, __last2);
   if (__d1 != __d2)
     return false;
   return std::equal(__first1, __last1, __first2);
 }

      for (; __first1 != __last1 && __first2 != __last2;
   ++__first1, (void)++__first2)
 if (!(*__first1 == *__first2))
   return false;
      return __first1 == __last1 && __first2 == __last2;
    }


  template<typename _II1, typename _II2, typename _BinaryPredicate>
   
    inline bool
    __equal4(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2,
      _BinaryPredicate __binary_pred)
    {
      using _RATag = random_access_iterator_tag;
      using _Cat1 = typename iterator_traits<_II1>::iterator_category;
      using _Cat2 = typename iterator_traits<_II2>::iterator_category;
      using _RAIters = __and_<is_same<_Cat1, _RATag>, is_same<_Cat2, _RATag>>;
      if (_RAIters())
 {
   auto __d1 = std::distance(__first1, __last1);
   auto __d2 = std::distance(__first2, __last2);
   if (__d1 != __d2)
     return false;
   return std::equal(__first1, __last1, __first2,
           __binary_pred);
 }

      for (; __first1 != __last1 && __first2 != __last2;
   ++__first1, (void)++__first2)
 if (!bool(__binary_pred(*__first1, *__first2)))
   return false;
      return __first1 == __last1 && __first2 == __last2;
    }
  template<typename _II1, typename _II2>
   
    inline bool
    equal(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2)
    {

     
     
     


      ;
      ;

      return std::__equal4(__first1, __last1, __first2, __last2);
    }
  template<typename _IIter1, typename _IIter2, typename _BinaryPredicate>
   
    inline bool
    equal(_IIter1 __first1, _IIter1 __last1,
   _IIter2 __first2, _IIter2 __last2, _BinaryPredicate __binary_pred)
    {

     
     
      ;
      ;

      return std::__equal4(__first1, __last1, __first2, __last2,
          __binary_pred);
    }
  template<typename _II1, typename _II2>
   
    inline bool
    lexicographical_compare(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2)
    {





     
     
     
     
      ;
      ;

      return std::__lexicographical_compare_aux(__first1, __last1,
      __first2, __last2);
    }
  template<typename _II1, typename _II2, typename _Compare>
   
    inline bool
    lexicographical_compare(_II1 __first1, _II1 __last1,
       _II2 __first2, _II2 __last2, _Compare __comp)
    {

     
     
      ;
      ;

      return std::__lexicographical_compare_impl
 (__first1, __last1, __first2, __last2,
  __gnu_cxx::__ops::__iter_comp_iter(__comp));
    }
  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
   
    pair<_InputIterator1, _InputIterator2>
    __mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _BinaryPredicate __binary_pred)
    {
      while (__first1 != __last1 && __binary_pred(__first1, __first2))
 {
   ++__first1;
   ++__first2;
 }
      return pair<_InputIterator1, _InputIterator2>(__first1, __first2);
    }
  template<typename _InputIterator1, typename _InputIterator2>
   
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2)
    {

     
     
     


      ;

      return std::__mismatch(__first1, __last1, __first2,
        __gnu_cxx::__ops::__iter_equal_to_iter());
    }
  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
   
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _BinaryPredicate __binary_pred)
    {

     
     
      ;

      return std::__mismatch(__first1, __last1, __first2,
 __gnu_cxx::__ops::__iter_comp_iter(__binary_pred));
    }



  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
   
    pair<_InputIterator1, _InputIterator2>
    __mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
        _InputIterator2 __first2, _InputIterator2 __last2,
        _BinaryPredicate __binary_pred)
    {
      while (__first1 != __last1 && __first2 != __last2
      && __binary_pred(__first1, __first2))
 {
   ++__first1;
   ++__first2;
 }
      return pair<_InputIterator1, _InputIterator2>(__first1, __first2);
    }
  template<typename _InputIterator1, typename _InputIterator2>
   
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _InputIterator2 __last2)
    {

     
     
     


      ;
      ;

      return std::__mismatch(__first1, __last1, __first2, __last2,
        __gnu_cxx::__ops::__iter_equal_to_iter());
    }
  template<typename _InputIterator1, typename _InputIterator2,
    typename _BinaryPredicate>
   
    inline pair<_InputIterator1, _InputIterator2>
    mismatch(_InputIterator1 __first1, _InputIterator1 __last1,
      _InputIterator2 __first2, _InputIterator2 __last2,
      _BinaryPredicate __binary_pred)
    {

     
     
      ;
      ;

      return std::__mismatch(__first1, __last1, __first2, __last2,
        __gnu_cxx::__ops::__iter_comp_iter(__binary_pred));
    }





  template<typename _InputIterator, typename _Predicate>
   
    inline _InputIterator
    __find_if(_InputIterator __first, _InputIterator __last,
       _Predicate __pred, input_iterator_tag)
    {
      while (__first != __last && !__pred(__first))
 ++__first;
      return __first;
    }


  template<typename _RandomAccessIterator, typename _Predicate>
   
    _RandomAccessIterator
    __find_if(_RandomAccessIterator __first, _RandomAccessIterator __last,
       _Predicate __pred, random_access_iterator_tag)
    {
      typename iterator_traits<_RandomAccessIterator>::difference_type
 __trip_count = (__last - __first) >> 2;

      for (; __trip_count > 0; --__trip_count)
 {
   if (__pred(__first))
     return __first;
   ++__first;

   if (__pred(__first))
     return __first;
   ++__first;

   if (__pred(__first))
     return __first;
   ++__first;

   if (__pred(__first))
     return __first;
   ++__first;
 }

      switch (__last - __first)
 {
 case 3:
   if (__pred(__first))
     return __first;
   ++__first;

 case 2:
   if (__pred(__first))
     return __first;
   ++__first;

 case 1:
   if (__pred(__first))
     return __first;
   ++__first;

 case 0:
 default:
   return __last;
 }
    }

  template<typename _Iterator, typename _Predicate>
   
    inline _Iterator
    __find_if(_Iterator __first, _Iterator __last, _Predicate __pred)
    {
      return __find_if(__first, __last, __pred,
         std::__iterator_category(__first));
    }

  template<typename _InputIterator, typename _Predicate>
   
    typename iterator_traits<_InputIterator>::difference_type
    __count_if(_InputIterator __first, _InputIterator __last, _Predicate __pred)
    {
      typename iterator_traits<_InputIterator>::difference_type __n = 0;
      for (; __first != __last; ++__first)
 if (__pred(__first))
   ++__n;
      return __n;
    }

  template<typename _ForwardIterator, typename _Predicate>
   
    _ForwardIterator
    __remove_if(_ForwardIterator __first, _ForwardIterator __last,
  _Predicate __pred)
    {
      __first = std::__find_if(__first, __last, __pred);
      if (__first == __last)
 return __first;
      _ForwardIterator __result = __first;
      ++__first;
      for (; __first != __last; ++__first)
 if (!__pred(__first))
   {
     *__result = std::move(*__first);
     ++__result;
   }
      return __result;
    }


  template<typename _ForwardIterator1, typename _ForwardIterator2,
    typename _BinaryPredicate>
   
    bool
    __is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
       _ForwardIterator2 __first2, _BinaryPredicate __pred)
    {


      for (; __first1 != __last1; ++__first1, (void)++__first2)
 if (!__pred(__first1, __first2))
   break;

      if (__first1 == __last1)
 return true;



      _ForwardIterator2 __last2 = __first2;
      std::advance(__last2, std::distance(__first1, __last1));
      for (_ForwardIterator1 __scan = __first1; __scan != __last1; ++__scan)
 {
   if (__scan != std::__find_if(__first1, __scan,
     __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan)))
     continue;

   auto __matches
     = std::__count_if(__first2, __last2,
   __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan));
   if (0 == __matches ||
       std::__count_if(__scan, __last1,
   __gnu_cxx::__ops::__iter_comp_iter(__pred, __scan))
       != __matches)
     return false;
 }
      return true;
    }
  template<typename _ForwardIterator1, typename _ForwardIterator2>
   
    inline bool
    is_permutation(_ForwardIterator1 __first1, _ForwardIterator1 __last1,
     _ForwardIterator2 __first2)
    {

     
     
     


      ;

      return std::__is_permutation(__first1, __last1, __first2,
       __gnu_cxx::__ops::__iter_equal_to_iter());
    }



}
       






namespace std __attribute__ ((__visibility__ ("default")))
{







  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    begin(_Container& __cont) -> decltype(__cont.begin())
    { return __cont.begin(); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    begin(const _Container& __cont) -> decltype(__cont.begin())
    { return __cont.begin(); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    end(_Container& __cont) -> decltype(__cont.end())
    { return __cont.end(); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    end(const _Container& __cont) -> decltype(__cont.end())
    { return __cont.end(); }





  template<typename _Tp, size_t _Nm>
    [[__nodiscard__]]
    inline constexpr _Tp*
    begin(_Tp (&__arr)[_Nm]) noexcept
    { return __arr; }






  template<typename _Tp, size_t _Nm>
    [[__nodiscard__]]
    inline constexpr _Tp*
    end(_Tp (&__arr)[_Nm]) noexcept
    { return __arr + _Nm; }



  template<typename _Tp> class valarray;

  template<typename _Tp> _Tp* begin(valarray<_Tp>&) noexcept;
  template<typename _Tp> const _Tp* begin(const valarray<_Tp>&) noexcept;
  template<typename _Tp> _Tp* end(valarray<_Tp>&) noexcept;
  template<typename _Tp> const _Tp* end(const valarray<_Tp>&) noexcept;






  template<typename _Container>
    [[__nodiscard__]]
    constexpr auto
    cbegin(const _Container& __cont) noexcept(noexcept(std::begin(__cont)))
      -> decltype(std::begin(__cont))
    { return std::begin(__cont); }






  template<typename _Container>
    [[__nodiscard__]]
    constexpr auto
    cend(const _Container& __cont) noexcept(noexcept(std::end(__cont)))
      -> decltype(std::end(__cont))
    { return std::end(__cont); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    rbegin(_Container& __cont) -> decltype(__cont.rbegin())
    { return __cont.rbegin(); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    rbegin(const _Container& __cont) -> decltype(__cont.rbegin())
    { return __cont.rbegin(); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    rend(_Container& __cont) -> decltype(__cont.rend())
    { return __cont.rend(); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    rend(const _Container& __cont) -> decltype(__cont.rend())
    { return __cont.rend(); }






  template<typename _Tp, size_t _Nm>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<_Tp*>
    rbegin(_Tp (&__arr)[_Nm]) noexcept
    { return reverse_iterator<_Tp*>(__arr + _Nm); }






  template<typename _Tp, size_t _Nm>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<_Tp*>
    rend(_Tp (&__arr)[_Nm]) noexcept
    { return reverse_iterator<_Tp*>(__arr); }






  template<typename _Tp>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<const _Tp*>
    rbegin(initializer_list<_Tp> __il) noexcept
    { return reverse_iterator<const _Tp*>(__il.end()); }






  template<typename _Tp>
    [[__nodiscard__]]
    inline constexpr reverse_iterator<const _Tp*>
    rend(initializer_list<_Tp> __il) noexcept
    { return reverse_iterator<const _Tp*>(__il.begin()); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    crbegin(const _Container& __cont) -> decltype(std::rbegin(__cont))
    { return std::rbegin(__cont); }






  template<typename _Container>
    [[__nodiscard__]]
    inline constexpr auto
    crend(const _Container& __cont) -> decltype(std::rend(__cont))
    { return std::rend(__cont); }
  template <typename _Container>
    [[nodiscard]]
    constexpr auto
    size(const _Container& __cont) noexcept(noexcept(__cont.size()))
    -> decltype(__cont.size())
    { return __cont.size(); }




  template <typename _Tp, size_t _Nm>
    [[nodiscard]]
    constexpr size_t
    size(const _Tp (&)[_Nm]) noexcept
    { return _Nm; }





  template <typename _Container>
    [[nodiscard]] constexpr auto
    empty(const _Container& __cont) noexcept(noexcept(__cont.empty()))
    -> decltype(__cont.empty())
    { return __cont.empty(); }




  template <typename _Tp, size_t _Nm>
    [[nodiscard]] constexpr bool
    empty(const _Tp (&)[_Nm]) noexcept
    { return false; }





  template <typename _Tp>
    [[nodiscard]] constexpr bool
    empty(initializer_list<_Tp> __il) noexcept
    { return __il.size() == 0;}





  template <typename _Container>
    [[nodiscard]]
    constexpr auto
    data(_Container& __cont) noexcept(noexcept(__cont.data()))
    -> decltype(__cont.data())
    { return __cont.data(); }





  template <typename _Container>
    [[nodiscard]]
    constexpr auto
    data(const _Container& __cont) noexcept(noexcept(__cont.data()))
    -> decltype(__cont.data())
    { return __cont.data(); }





  template <typename _Tp, size_t _Nm>
    [[nodiscard]]
    constexpr _Tp*
    data(_Tp (&__array)[_Nm]) noexcept
    { return __array; }





  template <typename _Tp>
    [[nodiscard]]
    constexpr const _Tp*
    data(initializer_list<_Tp> __il) noexcept
    { return __il.begin(); }

}



namespace std __attribute__ ((__visibility__ ("default")))
{


  template<typename _Tp, std::size_t _Nm>
    struct __array_traits
    {
      typedef _Tp _Type[_Nm];
      typedef __is_swappable<_Tp> _Is_swappable;
      typedef __is_nothrow_swappable<_Tp> _Is_nothrow_swappable;

      static constexpr _Tp&
      _S_ref(const _Type& __t, std::size_t __n) noexcept
      { return const_cast<_Tp&>(__t[__n]); }

      static constexpr _Tp*
      _S_ptr(const _Type& __t) noexcept
      { return const_cast<_Tp*>(__t); }
    };

 template<typename _Tp>
   struct __array_traits<_Tp, 0>
   {
     struct _Type { };
     typedef true_type _Is_swappable;
     typedef true_type _Is_nothrow_swappable;

     static constexpr _Tp&
     _S_ref(const _Type&, std::size_t) noexcept
     { return *static_cast<_Tp*>(nullptr); }

     static constexpr _Tp*
     _S_ptr(const _Type&) noexcept
     { return nullptr; }
   };
  template<typename _Tp, std::size_t _Nm>
    struct array
    {
      typedef _Tp value_type;
      typedef value_type* pointer;
      typedef const value_type* const_pointer;
      typedef value_type& reference;
      typedef const value_type& const_reference;
      typedef value_type* iterator;
      typedef const value_type* const_iterator;
      typedef std::size_t size_type;
      typedef std::ptrdiff_t difference_type;
      typedef std::reverse_iterator<iterator> reverse_iterator;
      typedef std::reverse_iterator<const_iterator> const_reverse_iterator;


      typedef __array_traits<_Tp, _Nm> _AT_Type;
      typename _AT_Type::_Type _M_elems;




      void
      fill(const value_type& __u)
      { std::fill_n(begin(), size(), __u); }

      void
      swap(array& __other)
      noexcept(_AT_Type::_Is_nothrow_swappable::value)
      { std::swap_ranges(begin(), end(), __other.begin()); }


      [[__gnu__::__const__, __nodiscard__]]
      constexpr iterator
      begin() noexcept
      { return iterator(data()); }

      [[__nodiscard__]]
      constexpr const_iterator
      begin() const noexcept
      { return const_iterator(data()); }

      [[__gnu__::__const__, __nodiscard__]]
      constexpr iterator
      end() noexcept
      { return iterator(data() + _Nm); }

      [[__nodiscard__]]
      constexpr const_iterator
      end() const noexcept
      { return const_iterator(data() + _Nm); }

      [[__gnu__::__const__, __nodiscard__]]
      constexpr reverse_iterator
      rbegin() noexcept
      { return reverse_iterator(end()); }

      [[__nodiscard__]]
      constexpr const_reverse_iterator
      rbegin() const noexcept
      { return const_reverse_iterator(end()); }

      [[__gnu__::__const__, __nodiscard__]]
      constexpr reverse_iterator
      rend() noexcept
      { return reverse_iterator(begin()); }

      [[__nodiscard__]]
      constexpr const_reverse_iterator
      rend() const noexcept
      { return const_reverse_iterator(begin()); }

      [[__nodiscard__]]
      constexpr const_iterator
      cbegin() const noexcept
      { return const_iterator(data()); }

      [[__nodiscard__]]
      constexpr const_iterator
      cend() const noexcept
      { return const_iterator(data() + _Nm); }

      [[__nodiscard__]]
      constexpr const_reverse_iterator
      crbegin() const noexcept
      { return const_reverse_iterator(end()); }

      [[__nodiscard__]]
      constexpr const_reverse_iterator
      crend() const noexcept
      { return const_reverse_iterator(begin()); }


      [[__gnu__::__const__, __nodiscard__]]
      constexpr size_type
      size() const noexcept { return _Nm; }

      [[__gnu__::__const__, __nodiscard__]]
      constexpr size_type
      max_size() const noexcept { return _Nm; }

      [[__gnu__::__const__, __nodiscard__]]
      constexpr bool
      empty() const noexcept { return size() == 0; }


      [[__nodiscard__]]
      constexpr reference
      operator[](size_type __n) noexcept
      {
 ;
 return _AT_Type::_S_ref(_M_elems, __n);
      }

      [[__nodiscard__]]
      constexpr const_reference
      operator[](size_type __n) const noexcept
      {

 ;

 return _AT_Type::_S_ref(_M_elems, __n);
      }

      constexpr reference
      at(size_type __n)
      {
 if (__n >= _Nm)
   std::__throw_out_of_range_fmt(("array::at: __n (which is %zu) " ">= _Nm (which is %zu)")
                                 ,
     __n, _Nm);
 return _AT_Type::_S_ref(_M_elems, __n);
      }

      constexpr const_reference
      at(size_type __n) const
      {


 return __n < _Nm ? _AT_Type::_S_ref(_M_elems, __n)
   : (std::__throw_out_of_range_fmt(("array::at: __n (which is %zu) " ">= _Nm (which is %zu)")
                                    ,
        __n, _Nm),
      _AT_Type::_S_ref(_M_elems, 0));
      }

      [[__nodiscard__]]
      constexpr reference
      front() noexcept
      {
 ;
 return *begin();
      }

      [[__nodiscard__]]
      constexpr const_reference
      front() const noexcept
      {

 ;

 return _AT_Type::_S_ref(_M_elems, 0);
      }

      [[__nodiscard__]]
      constexpr reference
      back() noexcept
      {
 ;
 return _Nm ? *(end() - 1) : *end();
      }

      [[__nodiscard__]]
      constexpr const_reference
      back() const noexcept
      {

 ;

 return _Nm ? _AT_Type::_S_ref(_M_elems, _Nm - 1)
             : _AT_Type::_S_ref(_M_elems, 0);
      }

      [[__gnu__::__const__, __nodiscard__]]
      constexpr pointer
      data() noexcept
      { return _AT_Type::_S_ptr(_M_elems); }

      [[__nodiscard__]]
      constexpr const_pointer
      data() const noexcept
      { return _AT_Type::_S_ptr(_M_elems); }
    };


  template<typename _Tp, typename... _Up>
    array(_Tp, _Up...)
      -> array<enable_if_t<(is_same_v<_Tp, _Up> && ...), _Tp>,
        1 + sizeof...(_Up)>;



  template<typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
   
    inline bool
    operator==(const array<_Tp, _Nm>& __one, const array<_Tp, _Nm>& __two)
    { return std::equal(__one.begin(), __one.end(), __two.begin()); }
  template<typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
   
    inline bool
    operator!=(const array<_Tp, _Nm>& __one, const array<_Tp, _Nm>& __two)
    { return !(__one == __two); }

  template<typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
   
    inline bool
    operator<(const array<_Tp, _Nm>& __a, const array<_Tp, _Nm>& __b)
    {
      return std::lexicographical_compare(__a.begin(), __a.end(),
       __b.begin(), __b.end());
    }

  template<typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
   
    inline bool
    operator>(const array<_Tp, _Nm>& __one, const array<_Tp, _Nm>& __two)
    { return __two < __one; }

  template<typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
   
    inline bool
    operator<=(const array<_Tp, _Nm>& __one, const array<_Tp, _Nm>& __two)
    { return !(__one > __two); }

  template<typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
   
    inline bool
    operator>=(const array<_Tp, _Nm>& __one, const array<_Tp, _Nm>& __two)
    { return !(__one < __two); }



  template<typename _Tp, std::size_t _Nm>
   
    inline


    typename enable_if<
      __array_traits<_Tp, _Nm>::_Is_swappable::value
    >::type



    swap(array<_Tp, _Nm>& __one, array<_Tp, _Nm>& __two)
    noexcept(noexcept(__one.swap(__two)))
    { __one.swap(__two); }


  template<typename _Tp, std::size_t _Nm>
    typename enable_if<
      !__array_traits<_Tp, _Nm>::_Is_swappable::value>::type
    swap(array<_Tp, _Nm>&, array<_Tp, _Nm>&) = delete;


  template<std::size_t _Int, typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
    constexpr _Tp&
    get(array<_Tp, _Nm>& __arr) noexcept
    {
      static_assert(_Int < _Nm, "array index is within bounds");
      return __array_traits<_Tp, _Nm>::_S_ref(__arr._M_elems, _Int);
    }

  template<std::size_t _Int, typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
    constexpr _Tp&&
    get(array<_Tp, _Nm>&& __arr) noexcept
    {
      static_assert(_Int < _Nm, "array index is within bounds");
      return std::move(std::get<_Int>(__arr));
    }

  template<std::size_t _Int, typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
    constexpr const _Tp&
    get(const array<_Tp, _Nm>& __arr) noexcept
    {
      static_assert(_Int < _Nm, "array index is within bounds");
      return __array_traits<_Tp, _Nm>::_S_ref(__arr._M_elems, _Int);
    }

  template<std::size_t _Int, typename _Tp, std::size_t _Nm>
    [[__nodiscard__]]
    constexpr const _Tp&&
    get(const array<_Tp, _Nm>&& __arr) noexcept
    {
      static_assert(_Int < _Nm, "array index is within bounds");
      return std::move(std::get<_Int>(__arr));
    }
  template<typename _Tp, size_t _Nm>
    struct tuple_size<array<_Tp, _Nm>>
    : public integral_constant<size_t, _Nm> { };


  template<size_t _Ind, typename _Tp, size_t _Nm>
    struct tuple_element<_Ind, array<_Tp, _Nm>>
    {
      static_assert(_Ind < _Nm, "array index is in range");
      using type = _Tp;
    };


  template<typename _Tp, size_t _Nm>
    inline constexpr size_t tuple_size_v<array<_Tp, _Nm>> = _Nm;

  template<typename _Tp, size_t _Nm>
    inline constexpr size_t tuple_size_v<const array<_Tp, _Nm>> = _Nm;


  template<typename _Tp, size_t _Nm>
    struct __is_tuple_like_impl<array<_Tp, _Nm>> : true_type
    { };


}


template <class T, class... Ts>
inline __attribute__((always_inline)) constexpr std::array<T, sizeof...(Ts)> make_array(Ts... values) {
    return {T(values)...};
}





constexpr auto kernel_compile_time_args = make_array<std::uint32_t>(1);

template <uint32_t Idx>
constexpr uint32_t get_ct_arg() {
    static_assert(Idx < kernel_compile_time_args.size(), "Index out of range");
    return kernel_compile_time_args[Idx];
}





       


namespace tt {

enum CBIndex : std::uint8_t {
    c_0 = 0,
    c_1 = 1,
    c_2 = 2,
    c_3 = 3,
    c_4 = 4,
    c_5 = 5,
    c_6 = 6,
    c_7 = 7,
    c_8 = 8,
    c_9 = 9,
    c_10 = 10,
    c_11 = 11,
    c_12 = 12,
    c_13 = 13,
    c_14 = 14,
    c_15 = 15,
    c_16 = 16,
    c_17 = 17,
    c_18 = 18,
    c_19 = 19,
    c_20 = 20,
    c_21 = 21,
    c_22 = 22,
    c_23 = 23,
    c_24 = 24,
    c_25 = 25,
    c_26 = 26,
    c_27 = 27,
    c_28 = 28,
    c_29 = 29,
    c_30 = 30,
    c_31 = 31,
    SIZE = 32
};


enum CB : std::uint8_t {

    c_in0 = 0,
    c_in1 = 1,
    c_in2 = 2,
    c_in3 = 3,
    c_in4 = 4,
    c_in5 = 5,
    c_in6 = 6,
    c_in7 = 7,


    dataflow0 = 8,
    dataflow1 = 9,
    dataflow2 = 10,
    dataflow3 = 11,
    dataflow4 = 12,
    dataflow5 = 13,
    dataflow6 = 14,
    dataflow7 = 15,


    c_out0 = 16,
    c_out1 = 17,
    c_out2 = 18,
    c_out3 = 19,
    c_out4 = 20,
    c_out5 = 21,
    c_out6 = 22,
    c_out7 = 23,


    c_intermed0 = 24,
    c_intermed1 = 25,
    c_intermed2 = 26,
    c_intermed3 = 27,
    c_intermed4 = 28,
    c_intermed5 = 29,
    c_intermed6 = 30,
    c_intermed7 = 31,
};





enum DstMode : std::uint8_t {
    Full = 0,
    Half = 1,
    Tile = 2,
    NUM_DST_MODES = 3,
};


enum HlkOperand : std::uint8_t {
    in0 = 0,
    in1 = 1,
    in2 = 2,
    in3 = 3,
    in4 = 4,
    in5 = 5,
    in6 = 6,
    in7 = 7,

    param0 = 8,
    param1 = 9,
    param2 = 10,
    param3 = 11,
    param4 = 12,
    param5 = 13,
    param6 = 14,
    param7 = 15,

    out0 = 16,
    out1 = 17,
    out2 = 18,
    out3 = 19,
    out4 = 20,
    out5 = 21,
    out6 = 22,
    out7 = 23,

    intermed0 = 24,
    intermed1 = 25,
    intermed2 = 26,
    intermed3 = 27,
    intermed4 = 28,
    intermed5 = 29,
    intermed6 = 30,
    intermed7 = 31,
};

constexpr std::uint32_t NUM_MAX_IN_BUFFERS_PER_CORE = HlkOperand::in7 - HlkOperand::in0 + 1;
constexpr std::uint32_t NUM_MAX_PARAM_BUFFERS_PER_CORE = HlkOperand::param7 - HlkOperand::param0 + 1;
constexpr std::uint32_t NUM_MAX_OUT_BUFFERS_PER_CORE = HlkOperand::out7 - HlkOperand::out0 + 1;
constexpr std::uint32_t NUM_MAX_INTERMED_BUFFERS_PER_CORE = HlkOperand::intermed7 - HlkOperand::intermed0 + 1;

}
       

       





       



       

namespace std __attribute__ ((__visibility__ ("default")))
{

  typedef enum memory_order
    {
      memory_order_relaxed,
      memory_order_consume,
      memory_order_acquire,
      memory_order_release,
      memory_order_acq_rel,
      memory_order_seq_cst
    } memory_order;



  enum __memory_order_modifier
    {
      __memory_order_mask = 0x0ffff,
      __memory_order_modifier_mask = 0xffff0000,
      __memory_order_hle_acquire = 0x10000,
      __memory_order_hle_release = 0x20000
    };


  constexpr memory_order
  operator|(memory_order __m, __memory_order_modifier __mod)
  {
    return memory_order(int(__m) | int(__mod));
  }

  constexpr memory_order
  operator&(memory_order __m, __memory_order_modifier __mod)
  {
    return memory_order(int(__m) & int(__mod));
  }




  constexpr memory_order
  __cmpexch_failure_order2(memory_order __m) noexcept
  {
    return __m == memory_order_acq_rel ? memory_order_acquire
      : __m == memory_order_release ? memory_order_relaxed : __m;
  }

  constexpr memory_order
  __cmpexch_failure_order(memory_order __m) noexcept
  {
    return memory_order(__cmpexch_failure_order2(__m & __memory_order_mask)
      | __memory_order_modifier(__m & __memory_order_modifier_mask));
  }

  constexpr bool
  __is_valid_cmpexch_failure_order(memory_order __m) noexcept
  {
    return (__m & __memory_order_mask) != memory_order_release
 && (__m & __memory_order_mask) != memory_order_acq_rel;
  }


  template<typename _IntTp>
    struct __atomic_base;



  inline __attribute__((__always_inline__)) void
  atomic_thread_fence(memory_order __m) noexcept
  { __atomic_thread_fence(int(__m)); }

  inline __attribute__((__always_inline__)) void
  atomic_signal_fence(memory_order __m) noexcept
  { __atomic_signal_fence(int(__m)); }


  template<typename _Tp>
    inline _Tp
    kill_dependency(_Tp __y) noexcept
    {
      _Tp __ret(__y);
      return __ret;
    }
  template<typename _Tp>
    struct atomic;

  template<typename _Tp>
    struct atomic<_Tp*>;



    typedef bool __atomic_flag_data_type;
  extern "C" {

  struct __atomic_flag_base
  {
    __atomic_flag_data_type _M_i ;
  };

  }






  struct atomic_flag : public __atomic_flag_base
  {
    atomic_flag() noexcept = default;
    ~atomic_flag() noexcept = default;
    atomic_flag(const atomic_flag&) = delete;
    atomic_flag& operator=(const atomic_flag&) = delete;
    atomic_flag& operator=(const atomic_flag&) volatile = delete;


    constexpr atomic_flag(bool __i) noexcept
      : __atomic_flag_base{ _S_init(__i) }
    { }

    inline __attribute__((__always_inline__)) bool
    test_and_set(memory_order __m = memory_order_seq_cst) noexcept
    {
      return __atomic_test_and_set (&_M_i, int(__m));
    }

    inline __attribute__((__always_inline__)) bool
    test_and_set(memory_order __m = memory_order_seq_cst) volatile noexcept
    {
      return __atomic_test_and_set (&_M_i, int(__m));
    }
    inline __attribute__((__always_inline__)) void
    clear(memory_order __m = memory_order_seq_cst) noexcept
    {
      memory_order __b __attribute__ ((__unused__))
 = __m & __memory_order_mask;
      do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_consume)) __builtin_unreachable(); } while (false);
      do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acquire)) __builtin_unreachable(); } while (false);
      do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);

      __atomic_clear (&_M_i, int(__m));
    }

    inline __attribute__((__always_inline__)) void
    clear(memory_order __m = memory_order_seq_cst) volatile noexcept
    {
      memory_order __b __attribute__ ((__unused__))
 = __m & __memory_order_mask;
      do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_consume)) __builtin_unreachable(); } while (false);
      do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acquire)) __builtin_unreachable(); } while (false);
      do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);

      __atomic_clear (&_M_i, int(__m));
    }

  private:
    static constexpr __atomic_flag_data_type
    _S_init(bool __i)
    { return __i ? 1 : 0; }
  };
  template<typename _ITp>
    struct __atomic_base
    {
      using value_type = _ITp;
      using difference_type = value_type;

    private:
      typedef _ITp __int_type;

      static constexpr int _S_alignment =
 sizeof(_ITp) > alignof(_ITp) ? sizeof(_ITp) : alignof(_ITp);

      alignas(_S_alignment) __int_type _M_i ;

    public:
      __atomic_base() noexcept = default;
      ~__atomic_base() noexcept = default;
      __atomic_base(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) volatile = delete;


      constexpr __atomic_base(__int_type __i) noexcept : _M_i (__i) { }

      operator __int_type() const noexcept
      { return load(); }

      operator __int_type() const volatile noexcept
      { return load(); }

      __int_type
      operator=(__int_type __i) noexcept
      {
 store(__i);
 return __i;
      }

      __int_type
      operator=(__int_type __i) volatile noexcept
      {
 store(__i);
 return __i;
      }

      __int_type
      operator++(int) noexcept
      { return fetch_add(1); }

      __int_type
      operator++(int) volatile noexcept
      { return fetch_add(1); }

      __int_type
      operator--(int) noexcept
      { return fetch_sub(1); }

      __int_type
      operator--(int) volatile noexcept
      { return fetch_sub(1); }

      __int_type
      operator++() noexcept
      { return __atomic_add_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator++() volatile noexcept
      { return __atomic_add_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator--() noexcept
      { return __atomic_sub_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator--() volatile noexcept
      { return __atomic_sub_fetch(&_M_i, 1, int(memory_order_seq_cst)); }

      __int_type
      operator+=(__int_type __i) noexcept
      { return __atomic_add_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator+=(__int_type __i) volatile noexcept
      { return __atomic_add_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator-=(__int_type __i) noexcept
      { return __atomic_sub_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator-=(__int_type __i) volatile noexcept
      { return __atomic_sub_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator&=(__int_type __i) noexcept
      { return __atomic_and_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator&=(__int_type __i) volatile noexcept
      { return __atomic_and_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator|=(__int_type __i) noexcept
      { return __atomic_or_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator|=(__int_type __i) volatile noexcept
      { return __atomic_or_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator^=(__int_type __i) noexcept
      { return __atomic_xor_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      __int_type
      operator^=(__int_type __i) volatile noexcept
      { return __atomic_xor_fetch(&_M_i, __i, int(memory_order_seq_cst)); }

      bool
      is_lock_free() const noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }

      bool
      is_lock_free() const volatile noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }

      inline __attribute__((__always_inline__)) void
      store(__int_type __i, memory_order __m = memory_order_seq_cst) noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acquire)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_consume)) __builtin_unreachable(); } while (false);

 __atomic_store_n(&_M_i, __i, int(__m));
      }

      inline __attribute__((__always_inline__)) void
      store(__int_type __i,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acquire)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_consume)) __builtin_unreachable(); } while (false);

 __atomic_store_n(&_M_i, __i, int(__m));
      }

      inline __attribute__((__always_inline__)) __int_type
      load(memory_order __m = memory_order_seq_cst) const noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_release)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);

 return __atomic_load_n(&_M_i, int(__m));
      }

      inline __attribute__((__always_inline__)) __int_type
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_release)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);

 return __atomic_load_n(&_M_i, int(__m));
      }

      inline __attribute__((__always_inline__)) __int_type
      exchange(__int_type __i,
        memory_order __m = memory_order_seq_cst) noexcept
      {
 return __atomic_exchange_n(&_M_i, __i, int(__m));
      }


      inline __attribute__((__always_inline__)) __int_type
      exchange(__int_type __i,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return __atomic_exchange_n(&_M_i, __i, int(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
       memory_order __m1, memory_order __m2) noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
       memory_order __m1,
       memory_order __m2) volatile noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
       memory_order __m = memory_order_seq_cst) noexcept
      {
 return compare_exchange_weak(__i1, __i2, __m,
         __cmpexch_failure_order(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__int_type& __i1, __int_type __i2,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return compare_exchange_weak(__i1, __i2, __m,
         __cmpexch_failure_order(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
         memory_order __m1, memory_order __m2) noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
         memory_order __m1,
         memory_order __m2) volatile noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_i, &__i1, __i2, 0,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
         memory_order __m = memory_order_seq_cst) noexcept
      {
 return compare_exchange_strong(__i1, __i2, __m,
           __cmpexch_failure_order(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__int_type& __i1, __int_type __i2,
   memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return compare_exchange_strong(__i1, __i2, __m,
           __cmpexch_failure_order(__m));
      }
      inline __attribute__((__always_inline__)) __int_type
      fetch_add(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_add(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_add(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_add(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_sub(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_sub(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_sub(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_sub(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_and(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_and(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_and(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_and(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_or(__int_type __i,
        memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_or(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_or(__int_type __i,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_or(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_xor(__int_type __i,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_xor(&_M_i, __i, int(__m)); }

      inline __attribute__((__always_inline__)) __int_type
      fetch_xor(__int_type __i,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_xor(&_M_i, __i, int(__m)); }
    };



  template<typename _PTp>
    struct __atomic_base<_PTp*>
    {
    private:
      typedef _PTp* __pointer_type;

      __pointer_type _M_p ;


      constexpr ptrdiff_t
      _M_type_size(ptrdiff_t __d) const { return __d * sizeof(_PTp); }

      constexpr ptrdiff_t
      _M_type_size(ptrdiff_t __d) const volatile { return __d * sizeof(_PTp); }

    public:
      __atomic_base() noexcept = default;
      ~__atomic_base() noexcept = default;
      __atomic_base(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) = delete;
      __atomic_base& operator=(const __atomic_base&) volatile = delete;


      constexpr __atomic_base(__pointer_type __p) noexcept : _M_p (__p) { }

      operator __pointer_type() const noexcept
      { return load(); }

      operator __pointer_type() const volatile noexcept
      { return load(); }

      __pointer_type
      operator=(__pointer_type __p) noexcept
      {
 store(__p);
 return __p;
      }

      __pointer_type
      operator=(__pointer_type __p) volatile noexcept
      {
 store(__p);
 return __p;
      }

      __pointer_type
      operator++(int) noexcept
      { return fetch_add(1); }

      __pointer_type
      operator++(int) volatile noexcept
      { return fetch_add(1); }

      __pointer_type
      operator--(int) noexcept
      { return fetch_sub(1); }

      __pointer_type
      operator--(int) volatile noexcept
      { return fetch_sub(1); }

      __pointer_type
      operator++() noexcept
      { return __atomic_add_fetch(&_M_p, _M_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator++() volatile noexcept
      { return __atomic_add_fetch(&_M_p, _M_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator--() noexcept
      { return __atomic_sub_fetch(&_M_p, _M_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator--() volatile noexcept
      { return __atomic_sub_fetch(&_M_p, _M_type_size(1),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator+=(ptrdiff_t __d) noexcept
      { return __atomic_add_fetch(&_M_p, _M_type_size(__d),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator+=(ptrdiff_t __d) volatile noexcept
      { return __atomic_add_fetch(&_M_p, _M_type_size(__d),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator-=(ptrdiff_t __d) noexcept
      { return __atomic_sub_fetch(&_M_p, _M_type_size(__d),
      int(memory_order_seq_cst)); }

      __pointer_type
      operator-=(ptrdiff_t __d) volatile noexcept
      { return __atomic_sub_fetch(&_M_p, _M_type_size(__d),
      int(memory_order_seq_cst)); }

      bool
      is_lock_free() const noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_p),
     reinterpret_cast<void *>(-__alignof(_M_p)));
      }

      bool
      is_lock_free() const volatile noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_p),
     reinterpret_cast<void *>(-__alignof(_M_p)));
      }

      inline __attribute__((__always_inline__)) void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;

 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acquire)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_consume)) __builtin_unreachable(); } while (false);

 __atomic_store_n(&_M_p, __p, int(__m));
      }

      inline __attribute__((__always_inline__)) void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acquire)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_consume)) __builtin_unreachable(); } while (false);

 __atomic_store_n(&_M_p, __p, int(__m));
      }

      inline __attribute__((__always_inline__)) __pointer_type
      load(memory_order __m = memory_order_seq_cst) const noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_release)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);

 return __atomic_load_n(&_M_p, int(__m));
      }

      inline __attribute__((__always_inline__)) __pointer_type
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      {
 memory_order __b __attribute__ ((__unused__))
   = __m & __memory_order_mask;
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_release)) __builtin_unreachable(); } while (false);
 do { if (std::__is_constant_evaluated() && !bool(__b != memory_order_acq_rel)) __builtin_unreachable(); } while (false);

 return __atomic_load_n(&_M_p, int(__m));
      }

      inline __attribute__((__always_inline__)) __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) noexcept
      {
 return __atomic_exchange_n(&_M_p, __p, int(__m));
      }


      inline __attribute__((__always_inline__)) __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return __atomic_exchange_n(&_M_p, __p, int(__m));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1,
       memory_order __m2) noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1,
       memory_order __m2) volatile noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 1,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1,
         memory_order __m2) noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 0,
        int(__m1), int(__m2));
      }

      inline __attribute__((__always_inline__)) bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1,
         memory_order __m2) volatile noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__m2))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange_n(&_M_p, &__p1, __p2, 0,
        int(__m1), int(__m2));
      }
      inline __attribute__((__always_inline__)) __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_add(&_M_p, _M_type_size(__d), int(__m)); }

      inline __attribute__((__always_inline__)) __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_add(&_M_p, _M_type_size(__d), int(__m)); }

      inline __attribute__((__always_inline__)) __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      { return __atomic_fetch_sub(&_M_p, _M_type_size(__d), int(__m)); }

      inline __attribute__((__always_inline__)) __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      { return __atomic_fetch_sub(&_M_p, _M_type_size(__d), int(__m)); }
    };

}

namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Tp>
    struct atomic;



  template<>
  struct atomic<bool>
  {
    using value_type = bool;

  private:
    __atomic_base<bool> _M_base;

  public:
    atomic() noexcept = default;
    ~atomic() noexcept = default;
    atomic(const atomic&) = delete;
    atomic& operator=(const atomic&) = delete;
    atomic& operator=(const atomic&) volatile = delete;

    constexpr atomic(bool __i) noexcept : _M_base(__i) { }

    bool
    operator=(bool __i) noexcept
    { return _M_base.operator=(__i); }

    bool
    operator=(bool __i) volatile noexcept
    { return _M_base.operator=(__i); }

    operator bool() const noexcept
    { return _M_base.load(); }

    operator bool() const volatile noexcept
    { return _M_base.load(); }

    bool
    is_lock_free() const noexcept { return _M_base.is_lock_free(); }

    bool
    is_lock_free() const volatile noexcept { return _M_base.is_lock_free(); }


    static constexpr bool is_always_lock_free = 1 == 2;


    void
    store(bool __i, memory_order __m = memory_order_seq_cst) noexcept
    { _M_base.store(__i, __m); }

    void
    store(bool __i, memory_order __m = memory_order_seq_cst) volatile noexcept
    { _M_base.store(__i, __m); }

    bool
    load(memory_order __m = memory_order_seq_cst) const noexcept
    { return _M_base.load(__m); }

    bool
    load(memory_order __m = memory_order_seq_cst) const volatile noexcept
    { return _M_base.load(__m); }

    bool
    exchange(bool __i, memory_order __m = memory_order_seq_cst) noexcept
    { return _M_base.exchange(__i, __m); }

    bool
    exchange(bool __i,
      memory_order __m = memory_order_seq_cst) volatile noexcept
    { return _M_base.exchange(__i, __m); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2, memory_order __m1,
     memory_order __m2) noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2, memory_order __m1,
     memory_order __m2) volatile noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2,
     memory_order __m = memory_order_seq_cst) noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m); }

    bool
    compare_exchange_weak(bool& __i1, bool __i2,
       memory_order __m = memory_order_seq_cst) volatile noexcept
    { return _M_base.compare_exchange_weak(__i1, __i2, __m); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2, memory_order __m1,
       memory_order __m2) noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2, memory_order __m1,
       memory_order __m2) volatile noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m1, __m2); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2,
       memory_order __m = memory_order_seq_cst) noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m); }

    bool
    compare_exchange_strong(bool& __i1, bool __i2,
      memory_order __m = memory_order_seq_cst) volatile noexcept
    { return _M_base.compare_exchange_strong(__i1, __i2, __m); }
  };
  template<typename _Tp>
    struct atomic
    {
      using value_type = _Tp;

    private:

      static constexpr int _S_min_alignment
 = (sizeof(_Tp) & (sizeof(_Tp) - 1)) || sizeof(_Tp) > 16
 ? 0 : sizeof(_Tp);

      static constexpr int _S_alignment
        = _S_min_alignment > alignof(_Tp) ? _S_min_alignment : alignof(_Tp);

      alignas(_S_alignment) _Tp _M_i ;

      static_assert(__is_trivially_copyable(_Tp),
      "std::atomic requires a trivially copyable type");

      static_assert(sizeof(_Tp) > 0,
      "Incomplete or zero-sized types are not supported");
    public:
      atomic() = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(_Tp __i) noexcept : _M_i(__i) { }

      operator _Tp() const noexcept
      { return load(); }

      operator _Tp() const volatile noexcept
      { return load(); }

      _Tp
      operator=(_Tp __i) noexcept
      { store(__i); return __i; }

      _Tp
      operator=(_Tp __i) volatile noexcept
      { store(__i); return __i; }

      bool
      is_lock_free() const noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }

      bool
      is_lock_free() const volatile noexcept
      {

 return __atomic_is_lock_free(sizeof(_M_i),
     reinterpret_cast<void *>(-_S_alignment));
      }


      static constexpr bool is_always_lock_free
 = __atomic_always_lock_free(sizeof(_M_i), 0);


      void
      store(_Tp __i, memory_order __m = memory_order_seq_cst) noexcept
      {
 __atomic_store(std::__addressof(_M_i), std::__addressof(__i), int(__m));
      }

      void
      store(_Tp __i, memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 __atomic_store(std::__addressof(_M_i), std::__addressof(__i), int(__m));
      }

      _Tp
      load(memory_order __m = memory_order_seq_cst) const noexcept
      {
 alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_load(std::__addressof(_M_i), __ptr, int(__m));
 return *__ptr;
      }

      _Tp
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_load(std::__addressof(_M_i), __ptr, int(__m));
 return *__ptr;
      }

      _Tp
      exchange(_Tp __i, memory_order __m = memory_order_seq_cst) noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_exchange(std::__addressof(_M_i), std::__addressof(__i),
     __ptr, int(__m));
 return *__ptr;
      }

      _Tp
      exchange(_Tp __i,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      {
        alignas(_Tp) unsigned char __buf[sizeof(_Tp)];
 _Tp* __ptr = reinterpret_cast<_Tp*>(__buf);
 __atomic_exchange(std::__addressof(_M_i), std::__addressof(__i),
     __ptr, int(__m));
 return *__ptr;
      }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i, memory_order __s,
       memory_order __f) noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__f))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange(std::__addressof(_M_i),
      std::__addressof(__e),
      std::__addressof(__i),
      true, int(__s), int(__f));
      }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i, memory_order __s,
       memory_order __f) volatile noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__f))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange(std::__addressof(_M_i),
      std::__addressof(__e),
      std::__addressof(__i),
      true, int(__s), int(__f));
      }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i,
       memory_order __m = memory_order_seq_cst) noexcept
      { return compare_exchange_weak(__e, __i, __m,
                                     __cmpexch_failure_order(__m)); }

      bool
      compare_exchange_weak(_Tp& __e, _Tp __i,
       memory_order __m = memory_order_seq_cst) volatile noexcept
      { return compare_exchange_weak(__e, __i, __m,
                                     __cmpexch_failure_order(__m)); }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i, memory_order __s,
         memory_order __f) noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__f))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange(std::__addressof(_M_i),
      std::__addressof(__e),
      std::__addressof(__i),
      false, int(__s), int(__f));
      }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i, memory_order __s,
         memory_order __f) volatile noexcept
      {
 do { if (std::__is_constant_evaluated() && !bool(__is_valid_cmpexch_failure_order(__f))) __builtin_unreachable(); } while (false);

 return __atomic_compare_exchange(std::__addressof(_M_i),
      std::__addressof(__e),
      std::__addressof(__i),
      false, int(__s), int(__f));
      }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i,
          memory_order __m = memory_order_seq_cst) noexcept
      { return compare_exchange_strong(__e, __i, __m,
                                       __cmpexch_failure_order(__m)); }

      bool
      compare_exchange_strong(_Tp& __e, _Tp __i,
       memory_order __m = memory_order_seq_cst) volatile noexcept
      { return compare_exchange_strong(__e, __i, __m,
                                       __cmpexch_failure_order(__m)); }
    };



  template<typename _Tp>
    struct atomic<_Tp*>
    {
      using value_type = _Tp*;
      using difference_type = ptrdiff_t;

      typedef _Tp* __pointer_type;
      typedef __atomic_base<_Tp*> __base_type;
      __base_type _M_b;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__pointer_type __p) noexcept : _M_b(__p) { }

      operator __pointer_type() const noexcept
      { return __pointer_type(_M_b); }

      operator __pointer_type() const volatile noexcept
      { return __pointer_type(_M_b); }

      __pointer_type
      operator=(__pointer_type __p) noexcept
      { return _M_b.operator=(__p); }

      __pointer_type
      operator=(__pointer_type __p) volatile noexcept
      { return _M_b.operator=(__p); }

      __pointer_type
      operator++(int) noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b++;
      }

      __pointer_type
      operator++(int) volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b++;
      }

      __pointer_type
      operator--(int) noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b--;
      }

      __pointer_type
      operator--(int) volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b--;
      }

      __pointer_type
      operator++() noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return ++_M_b;
      }

      __pointer_type
      operator++() volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return ++_M_b;
      }

      __pointer_type
      operator--() noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return --_M_b;
      }

      __pointer_type
      operator--() volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return --_M_b;
      }

      __pointer_type
      operator+=(ptrdiff_t __d) noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.operator+=(__d);
      }

      __pointer_type
      operator+=(ptrdiff_t __d) volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.operator+=(__d);
      }

      __pointer_type
      operator-=(ptrdiff_t __d) noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.operator-=(__d);
      }

      __pointer_type
      operator-=(ptrdiff_t __d) volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.operator-=(__d);
      }

      bool
      is_lock_free() const noexcept
      { return _M_b.is_lock_free(); }

      bool
      is_lock_free() const volatile noexcept
      { return _M_b.is_lock_free(); }


      static constexpr bool is_always_lock_free
 = 1 == 2;


      void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) noexcept
      { return _M_b.store(__p, __m); }

      void
      store(__pointer_type __p,
     memory_order __m = memory_order_seq_cst) volatile noexcept
      { return _M_b.store(__p, __m); }

      __pointer_type
      load(memory_order __m = memory_order_seq_cst) const noexcept
      { return _M_b.load(__m); }

      __pointer_type
      load(memory_order __m = memory_order_seq_cst) const volatile noexcept
      { return _M_b.load(__m); }

      __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) noexcept
      { return _M_b.exchange(__p, __m); }

      __pointer_type
      exchange(__pointer_type __p,
        memory_order __m = memory_order_seq_cst) volatile noexcept
      { return _M_b.exchange(__p, __m); }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1, memory_order __m2) noexcept
      { return _M_b.compare_exchange_weak(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m1,
       memory_order __m2) volatile noexcept
      { return _M_b.compare_exchange_weak(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
       memory_order __m = memory_order_seq_cst) noexcept
      {
 return compare_exchange_weak(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }

      bool
      compare_exchange_weak(__pointer_type& __p1, __pointer_type __p2,
      memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return compare_exchange_weak(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1, memory_order __m2) noexcept
      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m1,
         memory_order __m2) volatile noexcept
      { return _M_b.compare_exchange_strong(__p1, __p2, __m1, __m2); }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
         memory_order __m = memory_order_seq_cst) noexcept
      {
 return _M_b.compare_exchange_strong(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }

      bool
      compare_exchange_strong(__pointer_type& __p1, __pointer_type __p2,
      memory_order __m = memory_order_seq_cst) volatile noexcept
      {
 return _M_b.compare_exchange_strong(__p1, __p2, __m,
         __cmpexch_failure_order(__m));
      }
      __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.fetch_add(__d, __m);
      }

      __pointer_type
      fetch_add(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.fetch_add(__d, __m);
      }

      __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.fetch_sub(__d, __m);
      }

      __pointer_type
      fetch_sub(ptrdiff_t __d,
  memory_order __m = memory_order_seq_cst) volatile noexcept
      {

 static_assert( is_object<_Tp>::value, "pointer to object type" );

 return _M_b.fetch_sub(__d, __m);
      }
    };



  template<>
    struct atomic<char> : __atomic_base<char>
    {
      typedef char __integral_type;
      typedef __atomic_base<char> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<signed char> : __atomic_base<signed char>
    {
      typedef signed char __integral_type;
      typedef __atomic_base<signed char> __base_type;

      atomic() noexcept= default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<unsigned char> : __atomic_base<unsigned char>
    {
      typedef unsigned char __integral_type;
      typedef __atomic_base<unsigned char> __base_type;

      atomic() noexcept= default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<short> : __atomic_base<short>
    {
      typedef short __integral_type;
      typedef __atomic_base<short> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<unsigned short> : __atomic_base<unsigned short>
    {
      typedef unsigned short __integral_type;
      typedef __atomic_base<unsigned short> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<int> : __atomic_base<int>
    {
      typedef int __integral_type;
      typedef __atomic_base<int> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<unsigned int> : __atomic_base<unsigned int>
    {
      typedef unsigned int __integral_type;
      typedef __atomic_base<unsigned int> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<long> : __atomic_base<long>
    {
      typedef long __integral_type;
      typedef __atomic_base<long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<unsigned long> : __atomic_base<unsigned long>
    {
      typedef unsigned long __integral_type;
      typedef __atomic_base<unsigned long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<long long> : __atomic_base<long long>
    {
      typedef long long __integral_type;
      typedef __atomic_base<long long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<unsigned long long> : __atomic_base<unsigned long long>
    {
      typedef unsigned long long __integral_type;
      typedef __atomic_base<unsigned long long> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };


  template<>
    struct atomic<wchar_t> : __atomic_base<wchar_t>
    {
      typedef wchar_t __integral_type;
      typedef __atomic_base<wchar_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free = 1 == 2;

    };
  template<>
    struct atomic<char16_t> : __atomic_base<char16_t>
    {
      typedef char16_t __integral_type;
      typedef __atomic_base<char16_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free
 = 1 == 2;

    };


  template<>
    struct atomic<char32_t> : __atomic_base<char32_t>
    {
      typedef char32_t __integral_type;
      typedef __atomic_base<char32_t> __base_type;

      atomic() noexcept = default;
      ~atomic() noexcept = default;
      atomic(const atomic&) = delete;
      atomic& operator=(const atomic&) = delete;
      atomic& operator=(const atomic&) volatile = delete;

      constexpr atomic(__integral_type __i) noexcept : __base_type(__i) { }

      using __base_type::operator __integral_type;
      using __base_type::operator=;


      static constexpr bool is_always_lock_free
 = 1 == 2;

    };



  typedef atomic<bool> atomic_bool;


  typedef atomic<char> atomic_char;


  typedef atomic<signed char> atomic_schar;


  typedef atomic<unsigned char> atomic_uchar;


  typedef atomic<short> atomic_short;


  typedef atomic<unsigned short> atomic_ushort;


  typedef atomic<int> atomic_int;


  typedef atomic<unsigned int> atomic_uint;


  typedef atomic<long> atomic_long;


  typedef atomic<unsigned long> atomic_ulong;


  typedef atomic<long long> atomic_llong;


  typedef atomic<unsigned long long> atomic_ullong;


  typedef atomic<wchar_t> atomic_wchar_t;







  typedef atomic<char16_t> atomic_char16_t;


  typedef atomic<char32_t> atomic_char32_t;






  typedef atomic<int8_t> atomic_int8_t;


  typedef atomic<uint8_t> atomic_uint8_t;


  typedef atomic<int16_t> atomic_int16_t;


  typedef atomic<uint16_t> atomic_uint16_t;


  typedef atomic<int32_t> atomic_int32_t;


  typedef atomic<uint32_t> atomic_uint32_t;


  typedef atomic<int64_t> atomic_int64_t;


  typedef atomic<uint64_t> atomic_uint64_t;



  typedef atomic<int_least8_t> atomic_int_least8_t;


  typedef atomic<uint_least8_t> atomic_uint_least8_t;


  typedef atomic<int_least16_t> atomic_int_least16_t;


  typedef atomic<uint_least16_t> atomic_uint_least16_t;


  typedef atomic<int_least32_t> atomic_int_least32_t;


  typedef atomic<uint_least32_t> atomic_uint_least32_t;


  typedef atomic<int_least64_t> atomic_int_least64_t;


  typedef atomic<uint_least64_t> atomic_uint_least64_t;



  typedef atomic<int_fast8_t> atomic_int_fast8_t;


  typedef atomic<uint_fast8_t> atomic_uint_fast8_t;


  typedef atomic<int_fast16_t> atomic_int_fast16_t;


  typedef atomic<uint_fast16_t> atomic_uint_fast16_t;


  typedef atomic<int_fast32_t> atomic_int_fast32_t;


  typedef atomic<uint_fast32_t> atomic_uint_fast32_t;


  typedef atomic<int_fast64_t> atomic_int_fast64_t;


  typedef atomic<uint_fast64_t> atomic_uint_fast64_t;




  typedef atomic<intptr_t> atomic_intptr_t;


  typedef atomic<uintptr_t> atomic_uintptr_t;


  typedef atomic<size_t> atomic_size_t;


  typedef atomic<ptrdiff_t> atomic_ptrdiff_t;



  typedef atomic<intmax_t> atomic_intmax_t;


  typedef atomic<uintmax_t> atomic_uintmax_t;



  inline bool
  atomic_flag_test_and_set_explicit(atomic_flag* __a,
        memory_order __m) noexcept
  { return __a->test_and_set(__m); }

  inline bool
  atomic_flag_test_and_set_explicit(volatile atomic_flag* __a,
        memory_order __m) noexcept
  { return __a->test_and_set(__m); }
  inline void
  atomic_flag_clear_explicit(atomic_flag* __a, memory_order __m) noexcept
  { __a->clear(__m); }

  inline void
  atomic_flag_clear_explicit(volatile atomic_flag* __a,
        memory_order __m) noexcept
  { __a->clear(__m); }

  inline bool
  atomic_flag_test_and_set(atomic_flag* __a) noexcept
  { return atomic_flag_test_and_set_explicit(__a, memory_order_seq_cst); }

  inline bool
  atomic_flag_test_and_set(volatile atomic_flag* __a) noexcept
  { return atomic_flag_test_and_set_explicit(__a, memory_order_seq_cst); }

  inline void
  atomic_flag_clear(atomic_flag* __a) noexcept
  { atomic_flag_clear_explicit(__a, memory_order_seq_cst); }

  inline void
  atomic_flag_clear(volatile atomic_flag* __a) noexcept
  { atomic_flag_clear_explicit(__a, memory_order_seq_cst); }
  template<typename _Tp>
    using __atomic_val_t = __type_identity_t<_Tp>;
  template<typename _Tp>
    using __atomic_diff_t = typename atomic<_Tp>::difference_type;




  template<typename _ITp>
    inline bool
    atomic_is_lock_free(const atomic<_ITp>* __a) noexcept
    { return __a->is_lock_free(); }

  template<typename _ITp>
    inline bool
    atomic_is_lock_free(const volatile atomic<_ITp>* __a) noexcept
    { return __a->is_lock_free(); }

  template<typename _ITp>
    inline void
    atomic_init(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { __a->store(__i, memory_order_relaxed); }

  template<typename _ITp>
    inline void
    atomic_init(volatile atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { __a->store(__i, memory_order_relaxed); }

  template<typename _ITp>
    inline void
    atomic_store_explicit(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i,
     memory_order __m) noexcept
    { __a->store(__i, __m); }

  template<typename _ITp>
    inline void
    atomic_store_explicit(volatile atomic<_ITp>* __a, __atomic_val_t<_ITp> __i,
     memory_order __m) noexcept
    { __a->store(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_load_explicit(const atomic<_ITp>* __a, memory_order __m) noexcept
    { return __a->load(__m); }

  template<typename _ITp>
    inline _ITp
    atomic_load_explicit(const volatile atomic<_ITp>* __a,
    memory_order __m) noexcept
    { return __a->load(__m); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange_explicit(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->exchange(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange_explicit(volatile atomic<_ITp>* __a,
        __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->exchange(__i, __m); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak_explicit(atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2,
       memory_order __m1,
       memory_order __m2) noexcept
    { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak_explicit(volatile atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2,
       memory_order __m1,
       memory_order __m2) noexcept
    { return __a->compare_exchange_weak(*__i1, __i2, __m1, __m2); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong_explicit(atomic<_ITp>* __a,
         __atomic_val_t<_ITp>* __i1,
         __atomic_val_t<_ITp> __i2,
         memory_order __m1,
         memory_order __m2) noexcept
    { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong_explicit(volatile atomic<_ITp>* __a,
         __atomic_val_t<_ITp>* __i1,
         __atomic_val_t<_ITp> __i2,
         memory_order __m1,
         memory_order __m2) noexcept
    { return __a->compare_exchange_strong(*__i1, __i2, __m1, __m2); }


  template<typename _ITp>
    inline void
    atomic_store(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { atomic_store_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline void
    atomic_store(volatile atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { atomic_store_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_load(const atomic<_ITp>* __a) noexcept
    { return atomic_load_explicit(__a, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_load(const volatile atomic<_ITp>* __a) noexcept
    { return atomic_load_explicit(__a, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange(atomic<_ITp>* __a, __atomic_val_t<_ITp> __i) noexcept
    { return atomic_exchange_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_exchange(volatile atomic<_ITp>* __a,
      __atomic_val_t<_ITp> __i) noexcept
    { return atomic_exchange_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak(atomic<_ITp>* __a,
     __atomic_val_t<_ITp>* __i1,
     __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_weak_explicit(__a, __i1, __i2,
         memory_order_seq_cst,
         memory_order_seq_cst);
    }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_weak(volatile atomic<_ITp>* __a,
     __atomic_val_t<_ITp>* __i1,
     __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_weak_explicit(__a, __i1, __i2,
         memory_order_seq_cst,
         memory_order_seq_cst);
    }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong(atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_strong_explicit(__a, __i1, __i2,
           memory_order_seq_cst,
           memory_order_seq_cst);
    }

  template<typename _ITp>
    inline bool
    atomic_compare_exchange_strong(volatile atomic<_ITp>* __a,
       __atomic_val_t<_ITp>* __i1,
       __atomic_val_t<_ITp> __i2) noexcept
    {
      return atomic_compare_exchange_strong_explicit(__a, __i1, __i2,
           memory_order_seq_cst,
           memory_order_seq_cst);
    }
  template<typename _ITp>
    inline _ITp
    atomic_fetch_add_explicit(atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_add(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_add_explicit(volatile atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_add(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub_explicit(atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_sub(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub_explicit(volatile atomic<_ITp>* __a,
         __atomic_diff_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_sub(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and_explicit(__atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_and(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and_explicit(volatile __atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_and(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or_explicit(__atomic_base<_ITp>* __a,
        __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->fetch_or(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or_explicit(volatile __atomic_base<_ITp>* __a,
        __atomic_val_t<_ITp> __i,
        memory_order __m) noexcept
    { return __a->fetch_or(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor_explicit(__atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_xor(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor_explicit(volatile __atomic_base<_ITp>* __a,
         __atomic_val_t<_ITp> __i,
         memory_order __m) noexcept
    { return __a->fetch_xor(__i, __m); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_add(atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_add_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_add(volatile atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_add_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub(atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_sub_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_sub(volatile atomic<_ITp>* __a,
       __atomic_diff_t<_ITp> __i) noexcept
    { return atomic_fetch_sub_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and(__atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_and_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_and(volatile __atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_and_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or(__atomic_base<_ITp>* __a,
      __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_or_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_or(volatile __atomic_base<_ITp>* __a,
      __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_or_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor(__atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_xor_explicit(__a, __i, memory_order_seq_cst); }

  template<typename _ITp>
    inline _ITp
    atomic_fetch_xor(volatile __atomic_base<_ITp>* __a,
       __atomic_val_t<_ITp> __i) noexcept
    { return atomic_fetch_xor_explicit(__a, __i, memory_order_seq_cst); }

}





       






namespace kernel_profiler {

constexpr static uint32_t PADDING_MARKER = ((1 << 16) - 1);
constexpr static uint32_t NOC_ALIGNMENT_FACTOR = 4;

static constexpr int SUM_COUNT = 2;

enum BufferIndex {
    ID_HH,
    ID_HL,
    ID_LH,
    ID_LL,
    GUARANTEED_MARKER_1_H,
    GUARANTEED_MARKER_1_L,
    GUARANTEED_MARKER_2_H,
    GUARANTEED_MARKER_2_L,
    GUARANTEED_MARKER_3_H,
    GUARANTEED_MARKER_3_L,
    GUARANTEED_MARKER_4_H,
    GUARANTEED_MARKER_4_L,
    CUSTOM_MARKERS
};

enum ControlBuffer {
    HOST_BUFFER_END_INDEX_BR_ER,
    HOST_BUFFER_END_INDEX_NC,
    HOST_BUFFER_END_INDEX_T0,
    HOST_BUFFER_END_INDEX_T1,
    HOST_BUFFER_END_INDEX_T2,
    DEVICE_BUFFER_END_INDEX_BR_ER,
    DEVICE_BUFFER_END_INDEX_NC,
    DEVICE_BUFFER_END_INDEX_T0,
    DEVICE_BUFFER_END_INDEX_T1,
    DEVICE_BUFFER_END_INDEX_T2,
    FW_RESET_H,
    FW_RESET_L,
    DRAM_PROFILER_ADDRESS,
    RUN_COUNTER,
    NOC_X,
    NOC_Y,
    FLAT_ID,
    CORE_COUNT_PER_DRAM,
    DROPPED_ZONES,
    PROFILER_DONE,
};

enum PacketTypes { ZONE_START, ZONE_END, ZONE_TOTAL, TS_DATA, TS_EVENT };


constexpr static std::uint32_t PROFILER_L1_CONTROL_VECTOR_SIZE = 32;
constexpr static std::uint32_t PROFILER_L1_CONTROL_BUFFER_SIZE = PROFILER_L1_CONTROL_VECTOR_SIZE * sizeof(uint32_t);
constexpr static std::uint32_t PROFILER_L1_MARKER_UINT32_SIZE = 2;
constexpr static std::uint32_t PROFILER_L1_PROGRAM_ID_COUNT = 2;
constexpr static std::uint32_t PROFILER_L1_GUARANTEED_MARKER_COUNT = 4;
constexpr static std::uint32_t PROFILER_L1_OPTIONAL_MARKER_COUNT = 250;
constexpr static std::uint32_t PROFILER_L1_OP_MIN_OPTIONAL_MARKER_COUNT = 2;
constexpr static std::uint32_t PROFILER_L1_VECTOR_SIZE =
    (PROFILER_L1_OPTIONAL_MARKER_COUNT + PROFILER_L1_GUARANTEED_MARKER_COUNT + PROFILER_L1_PROGRAM_ID_COUNT) *
    PROFILER_L1_MARKER_UINT32_SIZE;
constexpr static std::uint32_t PROFILER_L1_BUFFER_SIZE = PROFILER_L1_VECTOR_SIZE * sizeof(uint32_t);

}

constexpr static std::uint32_t PROFILER_OP_SUPPORT_COUNT = 1000;
constexpr static std::uint32_t PROFILER_FULL_HOST_VECTOR_SIZE_PER_RISC =
    kernel_profiler::PROFILER_L1_MARKER_UINT32_SIZE *
    (kernel_profiler::PROFILER_L1_PROGRAM_ID_COUNT + kernel_profiler::PROFILER_L1_GUARANTEED_MARKER_COUNT +
     kernel_profiler::PROFILER_L1_OP_MIN_OPTIONAL_MARKER_COUNT) *
    PROFILER_OP_SUPPORT_COUNT;
constexpr static std::uint32_t PROFILER_FULL_HOST_BUFFER_SIZE_PER_RISC =
    PROFILER_FULL_HOST_VECTOR_SIZE_PER_RISC * sizeof(uint32_t);

static_assert(PROFILER_FULL_HOST_BUFFER_SIZE_PER_RISC > kernel_profiler::PROFILER_L1_BUFFER_SIZE);
       
using CommonDataFormat = DataFormat;


       








typedef int ptrdiff_t;
typedef unsigned int size_t;
typedef struct {
  long long __max_align_ll __attribute__((__aligned__(__alignof__(long long))));
  long double __max_align_ld __attribute__((__aligned__(__alignof__(long double))));
} max_align_t;






  typedef decltype(nullptr) nullptr_t;

extern "C++"
{

namespace std
{

  using ::max_align_t;
}



namespace std
{




  enum class byte : unsigned char {};

  template<typename _IntegerType> struct __byte_operand { };
  template<> struct __byte_operand<bool> { using __type = byte; };
  template<> struct __byte_operand<char> { using __type = byte; };
  template<> struct __byte_operand<signed char> { using __type = byte; };
  template<> struct __byte_operand<unsigned char> { using __type = byte; };
  template<> struct __byte_operand<wchar_t> { using __type = byte; };



  template<> struct __byte_operand<char16_t> { using __type = byte; };
  template<> struct __byte_operand<char32_t> { using __type = byte; };
  template<> struct __byte_operand<short> { using __type = byte; };
  template<> struct __byte_operand<unsigned short> { using __type = byte; };
  template<> struct __byte_operand<int> { using __type = byte; };
  template<> struct __byte_operand<unsigned int> { using __type = byte; };
  template<> struct __byte_operand<long> { using __type = byte; };
  template<> struct __byte_operand<unsigned long> { using __type = byte; };
  template<> struct __byte_operand<long long> { using __type = byte; };
  template<> struct __byte_operand<unsigned long long> { using __type = byte; };
  template<typename _IntegerType>
    struct __byte_operand<const _IntegerType>
    : __byte_operand<_IntegerType> { };
  template<typename _IntegerType>
    struct __byte_operand<volatile _IntegerType>
    : __byte_operand<_IntegerType> { };
  template<typename _IntegerType>
    struct __byte_operand<const volatile _IntegerType>
    : __byte_operand<_IntegerType> { };

  template<typename _IntegerType>
    using __byte_op_t = typename __byte_operand<_IntegerType>::__type;

  template<typename _IntegerType>
    [[__gnu__::__always_inline__]]
    constexpr __byte_op_t<_IntegerType>
    operator<<(byte __b, _IntegerType __shift) noexcept
    { return (byte)(unsigned char)((unsigned)__b << __shift); }

  template<typename _IntegerType>
    [[__gnu__::__always_inline__]]
    constexpr __byte_op_t<_IntegerType>
    operator>>(byte __b, _IntegerType __shift) noexcept
    { return (byte)(unsigned char)((unsigned)__b >> __shift); }

  [[__gnu__::__always_inline__]]
  constexpr byte
  operator|(byte __l, byte __r) noexcept
  { return (byte)(unsigned char)((unsigned)__l | (unsigned)__r); }

  [[__gnu__::__always_inline__]]
  constexpr byte
  operator&(byte __l, byte __r) noexcept
  { return (byte)(unsigned char)((unsigned)__l & (unsigned)__r); }

  [[__gnu__::__always_inline__]]
  constexpr byte
  operator^(byte __l, byte __r) noexcept
  { return (byte)(unsigned char)((unsigned)__l ^ (unsigned)__r); }

  [[__gnu__::__always_inline__]]
  constexpr byte
  operator~(byte __b) noexcept
  { return (byte)(unsigned char)~(unsigned)__b; }

  template<typename _IntegerType>
    [[__gnu__::__always_inline__]]
    constexpr __byte_op_t<_IntegerType>&
    operator<<=(byte& __b, _IntegerType __shift) noexcept
    { return __b = __b << __shift; }

  template<typename _IntegerType>
    [[__gnu__::__always_inline__]]
    constexpr __byte_op_t<_IntegerType>&
    operator>>=(byte& __b, _IntegerType __shift) noexcept
    { return __b = __b >> __shift; }

  [[__gnu__::__always_inline__]]
  constexpr byte&
  operator|=(byte& __l, byte __r) noexcept
  { return __l = __l | __r; }

  [[__gnu__::__always_inline__]]
  constexpr byte&
  operator&=(byte& __l, byte __r) noexcept
  { return __l = __l & __r; }

  [[__gnu__::__always_inline__]]
  constexpr byte&
  operator^=(byte& __l, byte __r) noexcept
  { return __l = __l ^ __r; }

  template<typename _IntegerType>
    [[nodiscard,__gnu__::__always_inline__]]
    constexpr _IntegerType
    to_integer(__byte_op_t<_IntegerType> __b) noexcept
    { return _IntegerType(__b); }


}

}


constexpr static std::uint32_t DPRINT_BUFFER_SIZE = 204;




constexpr static std::uint32_t DPRINT_BUFFERS_COUNT = 5;


enum DebugPrintHartIndex : unsigned int {
    DPRINT_RISCV_INDEX_NC = 0,
    DPRINT_RISCV_INDEX_TR0 = 1,
    DPRINT_RISCV_INDEX_TR1 = 2,
    DPRINT_RISCV_INDEX_TR2 = 3,
    DPRINT_RISCV_INDEX_BR = 4,
    DPRINT_RISCV_INDEX_ER = 0,
    DPRINT_RISCV_INDEX_ER1 = 1,
};
enum DPrintTypeID : uint8_t {


    DPrintCSTR, DPrintENDL, DPrintSETW, DPrintUINT8, DPrintUINT16, DPrintUINT32, DPrintUINT64, DPrintINT8, DPrintINT16, DPrintINT32, DPrintINT64, DPrintFLOAT32, DPrintCHAR, DPrintRAISE, DPrintWAIT, DPrintBFLOAT16, DPrintSETPRECISION, DPrintFIXED, DPrintDEFAULTFLOAT, DPrintHEX, DPrintOCT, DPrintDEC, DPrintTILESLICE, DPrintU32_ARRAY, DPrintTYPED_U32_ARRAY,

    DPrintTypeID_Count,

};
static_assert(DPrintTypeID_Count < 64, "Exceeded number of dprint types");
constexpr uint32_t DEBUG_PRINT_SERVER_STARTING_MAGIC = 0x98989898;
constexpr uint32_t DEBUG_PRINT_SERVER_DISABLED_MAGIC = 0xf8f8f8f8;



struct DebugPrintMemLayout {
    struct Aux {

        uint32_t wpos;
        uint32_t rpos;
        uint16_t core_x;
        uint16_t core_y;
    } aux __attribute__((packed));
    uint8_t data[DPRINT_BUFFER_SIZE - sizeof(Aux)];

    static size_t rpos_offs() { return 
                                      __builtin_offsetof (
                                      DebugPrintMemLayout::Aux
                                      , 
                                      rpos
                                      ) 
                                                                               + 
                                                                                 __builtin_offsetof (
                                                                                 DebugPrintMemLayout
                                                                                 , 
                                                                                 aux
                                                                                 )
                                                                                                                   ; }

} __attribute__((packed));

struct SliceRange {


    uint8_t h0, h1, hs, w0, w1, ws;

    static inline SliceRange hw0_32_16() {
        return SliceRange{.h0 = 0, .h1 = 32, .hs = 16, .w0 = 0, .w1 = 32, .ws = 16};
    }

    static inline SliceRange hw0_32_8() { return SliceRange{.h0 = 0, .h1 = 32, .hs = 8, .w0 = 0, .w1 = 32, .ws = 8}; }

    static inline SliceRange hw0_32_4() { return SliceRange{.h0 = 0, .h1 = 32, .hs = 4, .w0 = 0, .w1 = 32, .ws = 4}; }

    static inline SliceRange h0_w0_32() { return SliceRange{.h0 = 0, .h1 = 1, .hs = 1, .w0 = 0, .w1 = 32, .ws = 1}; }

    static inline SliceRange h0_32_w0() { return SliceRange{.h0 = 0, .h1 = 32, .hs = 1, .w0 = 0, .w1 = 1, .ws = 1}; }

    static inline SliceRange h0_32_w1() { return SliceRange{.h0 = 0, .h1 = 32, .hs = 1, .w0 = 1, .w1 = 2, .ws = 1}; }

    static inline SliceRange hw041() { return SliceRange{.h0 = 0, .h1 = 4, .hs = 1, .w0 = 0, .w1 = 4, .ws = 1}; }
} __attribute__((packed));

template <int MAX_BYTES = 0>
struct TileSliceHostDev {
    uint32_t cb_ptr;
    struct SliceRange slice_range;
    uint8_t cb_id;
    uint8_t data_format;
    uint8_t data_count;
    uint8_t endl_rows;
    uint8_t return_code;
    uint8_t pad;
    uint8_t data[MAX_BYTES];
} __attribute__((packed));

enum dprint_tileslice_return_code_enum {
    DPrintOK = 2,
    DPrintErrorBadTileIdx = 3,
    DPrintErrorBadPointer = 4,
    DPrintErrorUnsupportedFormat = 5,
    DPrintErrorMath = 6,
    DPrintErrorEthernet = 7,
};
enum TypedU32_ARRAY_Format {
    TypedU32_ARRAY_Format_INVALID,

    TypedU32_ARRAY_Format_Raw,
    TypedU32_ARRAY_Format_Tensix_Config_Register_Data_Format_Type,

    TypedU32_ARRAY_Format_COUNT,
};

static_assert(sizeof(DebugPrintMemLayout) == DPRINT_BUFFER_SIZE);

static_assert(sizeof(DebugPrintMemLayout().data) >= sizeof(uint32_t) * 8 * sizeof(uint32_t));


static inline constexpr uint32_t dprint_datum_size(const CommonDataFormat& format) {
    switch (format) {
        case CommonDataFormat::Bfp2:
        case CommonDataFormat::Bfp2_b:
        case CommonDataFormat::Bfp4:
        case CommonDataFormat::Bfp4_b:
        case CommonDataFormat::Bfp8:
        case CommonDataFormat::Bfp8_b: return 1;
        case CommonDataFormat::Float16:
        case CommonDataFormat::Float16_b: return 2;
        case CommonDataFormat::Float32: return 4;
        case CommonDataFormat::Int8: return 1;
        case CommonDataFormat::Lf8: return 1;
        case CommonDataFormat::UInt8: return 1;
        case CommonDataFormat::UInt16: return 2;
        case CommonDataFormat::UInt32: return 4;
        case CommonDataFormat::Int32: return 4;
        case CommonDataFormat::Invalid: return 0;
        default: return 0;
    }
}

static inline constexpr bool is_bfp(const CommonDataFormat& format) {
    switch (format) {
        case CommonDataFormat::Bfp2:
        case CommonDataFormat::Bfp2_b:
        case CommonDataFormat::Bfp4:
        case CommonDataFormat::Bfp4_b:
        case CommonDataFormat::Bfp8:
        case CommonDataFormat::Bfp8_b: return true;
        case CommonDataFormat::Float16:
        case CommonDataFormat::Float16_b:
        case CommonDataFormat::Float32:
        case CommonDataFormat::Int8:
        case CommonDataFormat::Lf8:
        case CommonDataFormat::UInt8:
        case CommonDataFormat::UInt16:
        case CommonDataFormat::UInt32:
        case CommonDataFormat::Int32:
        case CommonDataFormat::Invalid:
        default: return false;
    }
}

static inline constexpr bool is_supported_format(const CommonDataFormat& format) {
    switch (format) {
        case CommonDataFormat::Bfp2:
        case CommonDataFormat::Bfp2_b:
        case CommonDataFormat::Bfp4: return false;
        case CommonDataFormat::Bfp4_b: return true;
        case CommonDataFormat::Bfp8: return false;
        case CommonDataFormat::Bfp8_b: return true;
        case CommonDataFormat::Float16: return false;
        case CommonDataFormat::Float16_b: return true;
        case CommonDataFormat::Float32: return true;
        case CommonDataFormat::Int8:
        case CommonDataFormat::UInt8:
        case CommonDataFormat::UInt16:
        case CommonDataFormat::UInt32:
        case CommonDataFormat::Int32: return true;
        case CommonDataFormat::Lf8:
        case CommonDataFormat::Invalid:
        default: return false;
    }
}


constexpr static std::uint32_t MAX_RISCV_PER_CORE = 5;

template <uint32_t RiscCount>
struct profiler_msg_template_t {
    uint32_t control_vector[kernel_profiler::PROFILER_L1_CONTROL_VECTOR_SIZE];
    uint32_t buffer[RiscCount][kernel_profiler::PROFILER_L1_VECTOR_SIZE];
};
static constexpr uint32_t PROFILER_RISC_COUNT = static_cast<uint32_t>(TensixProcessorTypes::COUNT);

using profiler_msg_t = profiler_msg_template_t<PROFILER_RISC_COUNT>;





constexpr uint32_t RUN_MSG_INIT = 0x40;
constexpr uint32_t RUN_MSG_GO = 0x80;
constexpr uint32_t RUN_MSG_RESET_READ_PTR = 0xc0;
constexpr uint32_t RUN_MSG_RESET_READ_PTR_FROM_HOST = 0xe0;
constexpr uint32_t RUN_MSG_DONE = 0;


constexpr uint32_t RUN_SYNC_MSG_INIT = 0x40;
constexpr uint32_t RUN_SYNC_MSG_GO = 0x80;

constexpr uint32_t RUN_SYNC_MSG_LOAD = 0x1;
constexpr uint32_t RUN_SYNC_MSG_WAITING_FOR_RESET = 0x2;
constexpr uint32_t RUN_SYNC_MSG_INIT_SYNC_REGISTERS = 0x3;
constexpr uint32_t RUN_SYNC_MSG_DONE = 0;
constexpr uint32_t RUN_SYNC_MSG_ALL_GO = 0x80808080;
constexpr uint32_t RUN_SYNC_MSG_ALL_INIT = 0x40404040;
constexpr uint32_t RUN_SYNC_MSG_ALL_SUBORDINATES_DONE = 0;

struct ncrisc_halt_msg_t {
    volatile uint32_t resume_addr;
    volatile uint32_t stack_save;
};

enum dispatch_mode {
    DISPATCH_MODE_DEV,
    DISPATCH_MODE_HOST,
};

enum dispatch_core_processor_classes {

    DISPATCH_CLASS_TENSIX_DM0 = 0,
    DISPATCH_CLASS_TENSIX_DM1 = 1,
    DISPATCH_CLASS_TENSIX_COMPUTE = 2,


    DISPATCH_CLASS_ETH_DM0 = 0,
    DISPATCH_CLASS_ETH_DM1 = 1,

    DISPATCH_CLASS_MAX = 3,
};

enum dispatch_core_processor_masks {
    DISPATCH_CLASS_MASK_TENSIX_ENABLE_DM0 = 1 << DISPATCH_CLASS_TENSIX_DM0,
    DISPATCH_CLASS_MASK_TENSIX_ENABLE_DM1 = 1 << DISPATCH_CLASS_TENSIX_DM1,
    DISPATCH_CLASS_MASK_TENSIX_ENABLE_COMPUTE = 1 << DISPATCH_CLASS_TENSIX_COMPUTE,

    DISPATCH_CLASS_MASK_ETH_DM0 = 1 << DISPATCH_CLASS_ETH_DM0,
    DISPATCH_CLASS_MASK_ETH_DM1 = 1 << DISPATCH_CLASS_ETH_DM1,
};

enum noc_index {
    NOC_0 = 0,
    NOC_1 = 1,
};

enum noc_mode : uint8_t {
    DM_DEDICATED_NOC = 0,
    DM_DYNAMIC_NOC = 1,
    DM_INVALID_NOC = 2,
};



struct rta_offset_t {
    volatile uint16_t rta_offset;
    volatile uint16_t crta_offset;
};


constexpr auto NUM_PROGRAMMABLE_CORE_TYPES = 3u;
constexpr auto NUM_PROCESSORS_PER_CORE_TYPE = 5u;
enum dispatch_enable_flags : uint8_t {
    DISPATCH_ENABLE_FLAG_PRELOAD = 1 << 7,
};

struct kernel_config_msg_t {
    volatile uint16_t watcher_kernel_ids[DISPATCH_CLASS_MAX];
    volatile uint16_t ncrisc_kernel_size16;


    volatile uint32_t kernel_config_base[NUM_PROGRAMMABLE_CORE_TYPES];
    volatile uint16_t sem_offset[NUM_PROGRAMMABLE_CORE_TYPES];
    volatile uint16_t local_cb_offset;
    volatile uint16_t remote_cb_offset;
    rta_offset_t rta_offset[DISPATCH_CLASS_MAX];
    volatile uint8_t mode;
    volatile uint8_t pad1[1];
    volatile uint32_t kernel_text_offset[NUM_PROCESSORS_PER_CORE_TYPE];
    volatile uint32_t local_cb_mask;

    volatile uint8_t brisc_noc_id;
    volatile uint8_t brisc_noc_mode;
    volatile uint8_t min_remote_cb_start_index;
    volatile uint8_t exit_erisc_kernel;




    volatile uint32_t host_assigned_id;
    volatile uint8_t sub_device_origin_x;
    volatile uint8_t sub_device_origin_y;
    volatile uint8_t enables;

    volatile uint8_t preload;
} __attribute__((packed));


static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             kernel_config_base
             ) 
                                                               % sizeof(uint32_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             sem_offset
             ) 
                                                       % sizeof(uint16_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             local_cb_offset
             ) 
                                                            % sizeof(uint16_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             remote_cb_offset
             ) 
                                                             % sizeof(uint16_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             remote_cb_offset
             ) 
                                                             % sizeof(uint16_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             rta_offset
             ) 
                                                       % sizeof(uint16_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             kernel_text_offset
             ) 
                                                               % sizeof(uint32_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             local_cb_mask
             ) 
                                                          % sizeof(uint32_t) == 0);
static_assert(
             __builtin_offsetof (
             kernel_config_msg_t
             , 
             host_assigned_id
             ) 
                                                             % sizeof(uint32_t) == 0);

struct go_msg_t {
    union {
        uint32_t all;
        struct {
            uint8_t dispatch_message_offset;
            uint8_t master_x;
            uint8_t master_y;
            uint8_t signal;
        };
    };
} __attribute__((packed));

struct launch_msg_t {
    kernel_config_msg_t kernel_config;
} __attribute__((packed));

struct subordinate_sync_msg_t {
    union {
        volatile uint32_t all;
        struct {
            volatile uint8_t dm1;
            volatile uint8_t trisc0;
            volatile uint8_t trisc1;
            volatile uint8_t trisc2;
        };
    };
};

constexpr int num_waypoint_bytes_per_riscv = 4;
struct debug_waypoint_msg_t {
    volatile uint8_t waypoint[num_waypoint_bytes_per_riscv];
};


struct debug_sanitize_noc_addr_msg_t {
    volatile uint64_t noc_addr;
    volatile uint32_t l1_addr;
    volatile uint32_t len;
    volatile uint16_t which_risc;
    volatile uint16_t return_code;
    volatile uint8_t is_multicast;
    volatile uint8_t is_write;
    volatile uint8_t is_target;
    volatile uint8_t pad;
};


struct debug_insert_delays_msg_t {
    volatile uint8_t read_delay_riscv_mask = 0;
    volatile uint8_t write_delay_riscv_mask = 0;
    volatile uint8_t atomic_delay_riscv_mask = 0;
    volatile uint8_t feedback = 0;
};

enum debug_sanitize_noc_return_code_enum {

    DebugSanitizeNocOK = 2,
    DebugSanitizeNocAddrUnderflow = 3,
    DebugSanitizeNocAddrOverflow = 4,
    DebugSanitizeNocAddrZeroLength = 5,
    DebugSanitizeNocTargetInvalidXY = 6,
    DebugSanitizeNocMulticastNonWorker = 7,
    DebugSanitizeNocMulticastInvalidRange = 8,
    DebugSanitizeNocAlignment = 9,
    DebugSanitizeNocMixedVirtualandPhysical = 10,
    DebugSanitizeInlineWriteDramUnsupported = 11,
    DebugSanitizeNocAddrMailbox = 12,
    DebugSanitizeNocLinkedTransactionViolation = 13,
};

struct debug_assert_msg_t {
    volatile uint16_t line_num;
    volatile uint8_t tripped;
    volatile uint8_t which;
};

enum debug_assert_type_t {
    DebugAssertOK = 2,
    DebugAssertTripped = 3,
    DebugAssertNCriscNOCReadsFlushedTripped = 4,
    DebugAssertNCriscNOCNonpostedWritesSentTripped = 5,
    DebugAssertNCriscNOCNonpostedAtomicsFlushedTripped = 6,
    DebugAssertNCriscNOCPostedWritesSentTripped = 7
};


enum riscv_id_t {
    DebugBrisc = 0,
    DebugNCrisc = 1,
    DebugTrisc0 = 2,
    DebugTrisc1 = 3,
    DebugTrisc2 = 4,
    DebugErisc = 5,
    DebugSubordinateErisc = 6,
    DebugIErisc = 7,
    DebugSubordinateIErisc = 8,
    DebugNumUniqueRiscs = 9,
    DebugDebugMaxRiscvId = 15,
};

enum debug_transaction_type_t { TransactionRead = 0, TransactionWrite = 1, TransactionAtomic = 2, TransactionNumTypes };

struct debug_pause_msg_t {
    volatile uint8_t flags[DebugDebugMaxRiscvId];
};

constexpr static int DEBUG_RING_BUFFER_ELEMENTS = 32;
constexpr static int DEBUG_RING_BUFFER_SIZE = DEBUG_RING_BUFFER_ELEMENTS * sizeof(uint32_t);
struct debug_ring_buf_msg_t {
    int16_t current_ptr;
    uint16_t wrapped;
    uint32_t data[DEBUG_RING_BUFFER_ELEMENTS];
};

struct debug_stack_usage_t {
    struct usage_t {

        volatile uint16_t min_free;
        volatile uint16_t watcher_kernel_id;
    } cpu[DebugDebugMaxRiscvId];
};

enum watcher_enable_msg_t {
    WatcherDisabled = 2,
    WatcherEnabled = 3,
};


constexpr static std::uint32_t MAX_NUM_NOCS_PER_CORE = 2;

struct watcher_msg_t {
    volatile uint32_t enable;
    struct debug_waypoint_msg_t debug_waypoint[MAX_RISCV_PER_CORE];
    struct debug_sanitize_noc_addr_msg_t sanitize_noc[MAX_NUM_NOCS_PER_CORE];
    std::atomic<bool> noc_linked_status[MAX_NUM_NOCS_PER_CORE];
    uint8_t pad_0[2];
    struct debug_assert_msg_t assert_status;
    struct debug_pause_msg_t pause_status;
    struct debug_stack_usage_t stack_usage;
    struct debug_insert_delays_msg_t debug_insert_delays;
    struct debug_ring_buf_msg_t debug_ring_buf;
};

struct dprint_buf_msg_t {
    DebugPrintMemLayout data[DPRINT_BUFFERS_COUNT];
    uint32_t pad;
};


static constexpr uint32_t TT_ARCH_MAX_NOC_WRITE_ALIGNMENT = 16;

static constexpr uint32_t PROFILER_NOC_ALIGNMENT_PAD_COUNT = 6;

enum class AddressableCoreType : uint8_t {
    TENSIX = 0,
    ETH = 1,
    PCIE = 2,
    DRAM = 3,
    HARVESTED = 4,
    UNKNOWN = 5,
    COUNT = 6,
};

struct addressable_core_t {
    volatile uint8_t x, y;
    volatile AddressableCoreType type;
};






constexpr static std::uint32_t MAX_VIRTUAL_NON_WORKER_CORES = 29;


constexpr static std::uint32_t MAX_PHYSICAL_NON_WORKER_CORES = 35;
constexpr static std::uint32_t MAX_HARVESTED_ON_AXIS = 2;
constexpr static std::uint8_t CORE_COORD_INVALID = 0xFF;
struct core_info_msg_t {
    volatile uint64_t noc_pcie_addr_base;
    volatile uint64_t noc_pcie_addr_end;
    volatile uint64_t noc_dram_addr_base;
    volatile uint64_t noc_dram_addr_end;
    addressable_core_t non_worker_cores[MAX_PHYSICAL_NON_WORKER_CORES];
    addressable_core_t virtual_non_worker_cores[MAX_VIRTUAL_NON_WORKER_CORES];
    volatile uint8_t harvested_coords[MAX_HARVESTED_ON_AXIS];
    volatile uint8_t virtual_harvested_coords[MAX_HARVESTED_ON_AXIS];
    volatile uint8_t noc_size_x;
    volatile uint8_t noc_size_y;
    volatile uint8_t worker_grid_size_x;
    volatile uint8_t worker_grid_size_y;
    volatile uint8_t absolute_logical_x;
    volatile uint8_t absolute_logical_y;
    volatile uint32_t l1_unreserved_start;
    uint8_t pad;
};

constexpr uint32_t launch_msg_buffer_num_entries = 8;
struct mailboxes_t {
    struct ncrisc_halt_msg_t ncrisc_halt;
    struct subordinate_sync_msg_t subordinate_sync;
    volatile uint32_t launch_msg_rd_ptr;

    struct launch_msg_t launch[launch_msg_buffer_num_entries];
    volatile struct go_msg_t go_message;
    struct watcher_msg_t watcher;
    struct dprint_buf_msg_t dprint_buf;
    struct core_info_msg_t core_info;

    uint32_t pads_2[PROFILER_NOC_ALIGNMENT_PAD_COUNT];
    profiler_msg_t profiler;
};


static_assert(sizeof(watcher_msg_t) % sizeof(uint32_t) == 0);
static_assert(sizeof(kernel_config_msg_t) % sizeof(uint32_t) == 0);
static_assert(sizeof(core_info_msg_t) % sizeof(uint32_t) == 0);

struct eth_word_t {
    volatile uint32_t bytes_sent;
    volatile uint32_t dst_cmd_valid;
    uint32_t reserved_0;
    uint32_t reserved_1;
};

enum class SyncCBConfigRegion : uint8_t {
    DB_TENSIX = 0,
    TENSIX = 1,
    ROUTER_ISSUE = 2,
    ROUTER_COMPLETION = 3,
};

struct routing_info_t {
    volatile uint32_t routing_enabled;
    volatile uint32_t src_sent_valid_cmd;
    volatile uint32_t dst_acked_valid_cmd;
    volatile uint32_t unused_arg0;
    eth_word_t fd_buffer_msgs[2];
};





       





       




namespace eth_iram_mem {
struct address_map {
    static constexpr std::int32_t ERISC_IRAM_BASE = 0xFFC00000;
    static constexpr std::int32_t ERISC_IRAM_SIZE = 16 * 1024;
    static constexpr std::int32_t ERISC_KERNEL_BASE = ERISC_IRAM_BASE;
};
};

namespace eth_l1_mem {

struct address_map {




    static constexpr std::int32_t ERISC_BARRIER_SIZE = 32;
    static constexpr std::int32_t MAX_SIZE = 256 * 1024 - ERISC_BARRIER_SIZE;


    static constexpr std::int32_t APP_FIRMWARE_SIZE = 32 * 1024;
    static constexpr std::int32_t ROUTING_FW_RESERVED_SIZE = 28 * 1024;



    static constexpr std::int32_t ERISC_MEM_BANK_TO_NOC_XY_SIZE = 1024;

    static constexpr std::int32_t ERISC_MEM_BANK_OFFSET_SIZE = 1024;



    static constexpr std::int32_t ERISC_L1_KERNEL_CONFIG_SIZE = 96 * 4 + 16 * 16;


    static constexpr std::int32_t FIRMWARE_BASE = 0x9040;
    static constexpr std::int32_t L1_EPOCH_Q_BASE = 0x9000;
    static constexpr std::int32_t KERNEL_BASE = 0xA840;
    static constexpr std::int32_t ROUTING_FW_RESERVED_BASE = L1_EPOCH_Q_BASE + APP_FIRMWARE_SIZE;

    static constexpr std::int32_t MAX_L1_LOADING_ADDR = 0x3E000;
    static constexpr std::int32_t ROUTING_ENABLED_ERISC_L1_UNRESERVED_BASE =
        ROUTING_FW_RESERVED_BASE + ROUTING_FW_RESERVED_SIZE;
    static constexpr std::int32_t ROUTING_ENABLED_ERISC_L1_UNRESERVED_SIZE =
        MAX_L1_LOADING_ADDR - ROUTING_ENABLED_ERISC_L1_UNRESERVED_BASE;

    static constexpr std::int32_t ERISC_L1_UNRESERVED_BASE = ROUTING_ENABLED_ERISC_L1_UNRESERVED_BASE;



    static constexpr std::int32_t ERISC_L1_UNRESERVED_SIZE = MAX_L1_LOADING_ADDR - ERISC_L1_UNRESERVED_BASE;

    static_assert((ERISC_L1_UNRESERVED_BASE % 32) == 0);


    static constexpr std::int32_t MAX_NUM_CONCURRENT_TRANSACTIONS = 8;
    static constexpr std::int32_t ERISC_APP_ROUTING_INFO_SIZE = 48;
    static constexpr std::int32_t ERISC_APP_SYNC_INFO_SIZE = 160 + 16 * MAX_NUM_CONCURRENT_TRANSACTIONS;

    static constexpr std::int32_t ERISC_APP_ROUTING_INFO_BASE = MAX_L1_LOADING_ADDR;
    static constexpr std::int32_t ERISC_APP_SYNC_INFO_BASE = ERISC_APP_ROUTING_INFO_BASE + ERISC_APP_ROUTING_INFO_SIZE;

    static constexpr std::int32_t ERISC_MEM_MAILBOX_BASE = ERISC_APP_SYNC_INFO_BASE + ERISC_APP_SYNC_INFO_SIZE;

    static constexpr std::uint32_t ERISC_MEM_MAILBOX_SIZE = 5072;
    static constexpr std::uint32_t ERISC_MEM_MAILBOX_END = ERISC_MEM_MAILBOX_BASE + ERISC_MEM_MAILBOX_SIZE;
    static constexpr std::int32_t ERISC_L1_KERNEL_CONFIG_BASE = ERISC_MEM_MAILBOX_END;
    static constexpr std::int32_t FABRIC_ROUTER_CONFIG_BASE =
        (ERISC_L1_KERNEL_CONFIG_BASE + ERISC_L1_KERNEL_CONFIG_SIZE + 31) & ~31;
    static constexpr std::int32_t FABRIC_ROUTER_CONFIG_SIZE = 2064;

    static constexpr std::int32_t ERISC_BARRIER_BASE =
        (FABRIC_ROUTER_CONFIG_BASE + FABRIC_ROUTER_CONFIG_SIZE + 31) & ~31;
    static_assert(ERISC_BARRIER_BASE < MAX_SIZE, "Erisc config region is greater than MAX_SIZE");





    static constexpr std::int32_t ERISC_MEM_BANK_TO_NOC_SCRATCH = ROUTING_ENABLED_ERISC_L1_UNRESERVED_BASE;
    static constexpr std::int32_t ERISC_MEM_BANK_TO_NOC_SIZE = ERISC_MEM_BANK_TO_NOC_XY_SIZE + ERISC_MEM_BANK_OFFSET_SIZE;
    static_assert(ERISC_MEM_BANK_TO_NOC_SCRATCH + ERISC_MEM_BANK_TO_NOC_SIZE <= MAX_L1_LOADING_ADDR);

    static constexpr std::int32_t LAUNCH_ERISC_APP_FLAG = L1_EPOCH_Q_BASE + 4;

    template <std::size_t A, std::size_t B>
    struct TAssertEquality {
        static_assert(A == B, "Not equal");
        static constexpr bool _cResult = (A == B);
    };

    static constexpr std::int32_t RISC_LOCAL_MEM_BASE =
        0xffb00000;




    static constexpr std::uint32_t RETRAIN_COUNT_ADDR = 0x1EDC;
    static constexpr std::uint32_t RETRAIN_FORCE_ADDR = 0x1EFC;

    static constexpr std::uint32_t CRC_ERR_ADDR = 0x1F7C;


    static constexpr std::uint32_t CORR_CW_HI_ADDR = 0x1F90;
    static constexpr std::uint32_t UNCORR_CW_HI_ADDR = 0x1F98;

    static constexpr uint32_t ETH_LINK_REMOTE_INFO_ADDR = 0x1EC0;
    static constexpr std::uint32_t INTERMESH_ETH_LINK_CONFIG_ADDR = 0x104C;
    static constexpr std::uint32_t INTERMESH_ETH_LINK_STATUS_ADDR = 0x1104;
};
}













       

       



inline __attribute__((always_inline)) unsigned int mulsi3(unsigned int a, unsigned int b) {
    return a * b;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_7(uint32_t n) {
    return (((uint64_t)n * 0x92492493) >> 32) >> 2;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_12(uint32_t n) {
    return (((uint64_t)n * 0xAAAAAAAB) >> 32) >> 3;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_56(uint32_t n) {
    return (((uint64_t)n * 0x24924925) >> 32) >> 3;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_63(uint32_t n) {
    return (((uint64_t)n * 0x82082083) >> 32) >> 5;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_70(uint32_t n) {
    return (((uint64_t)n * 0xEA0EA0EB) >> 32) >> 6;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_80(uint32_t n) {
    return (((uint64_t)n * 0xCCCCCCCD) >> 32) >> 6;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_94(uint32_t n) {
    return (((uint64_t)n * 0xAE4C415D) >> 32) >> 6;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_110(uint32_t n) {
    return (((uint64_t)n * 0x094F2095) >> 32) >> 2;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_120(uint32_t n) {
    return (((uint64_t)n * 0x88888889) >> 32) >> 6;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_124(uint32_t n) {
    return (((uint64_t)n * 0x08421085) >> 32) >> 2;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_130(uint32_t n) {
    return (((uint64_t)n * 0xFC0FC0FD) >> 32) >> 7;
}

inline __attribute__((always_inline)) uint32_t fast_udiv_140(uint32_t n) {
    return (((uint64_t)n * 0xEA0EA0EB) >> 32) >> 7;
}

template <uint32_t d>
inline __attribute__((always_inline)) uint32_t udivsi3_const_divisor(uint32_t n) {



    if constexpr (d == 7) {
        return fast_udiv_7(n);
    } else if constexpr (d == 12) {

        return fast_udiv_12(n);
    } else if constexpr (d == 56) {

        return fast_udiv_56(n);
    } else if constexpr (d == 70) {
        return fast_udiv_70(n);
    } else if constexpr (d == 80) {
        return fast_udiv_80(n);
    } else if constexpr (d == 94) {

        return fast_udiv_94(n);
    } else if constexpr (d == 110) {
        return fast_udiv_110(n);
    } else if constexpr (d == 120) {
        return fast_udiv_120(n);
    } else if constexpr (d == 124) {
        return fast_udiv_124(n);
    } else if constexpr (d == 130) {
        return fast_udiv_130(n);
    } else if constexpr (d == 140) {
        return fast_udiv_140(n);
    } else {

        const unsigned n_uword_bits = sizeof(uint32_t) * 8;
        unsigned int q;
        unsigned int r;
        unsigned sr;

        if (d == 0) {
            return 0;
        }
        if (n == 0) {
            return 0;
        }
        sr = __builtin_clz(d) - __builtin_clz(n);

        if (sr > n_uword_bits - 1) {
            return 0;
        }
        if (sr == n_uword_bits - 1) {
            return n;
        }
        ++sr;


        q = n << (n_uword_bits - sr);
        r = n >> sr;
        unsigned int carry = 0;
        for (; sr > 0; --sr) {

            r = (r << 1) | (q >> (n_uword_bits - 1));
            q = (q << 1) | carry;







            const int s = (unsigned int)(d - r - 1) >> (n_uword_bits - 1);
            carry = s & 1;
            r -= d & s;
        }
        q = (q << 1) | carry;
        return q;
    }
}
template <uint32_t d>
inline __attribute__((always_inline)) uint32_t umodsi3_const_divisor(uint32_t a) {
    return a - udivsi3_const_divisor<d>(a) * d;
}
const uint32_t OPERAND_START_STREAM = 8;



inline __attribute__((always_inline)) uint32_t get_operand_stream_id(int operand) {
    return OPERAND_START_STREAM + operand;
}




inline __attribute__((always_inline)) volatile uint32_t* get_cb_tiles_received_ptr(int operand) {
    return (volatile uint32_t*)(uintptr_t)(((0xFFB40000) + (((uint32_t)(get_operand_stream_id(operand))) * (0x1000)) + (((uint32_t)(4)) << 2))
                                                                              );
}

inline __attribute__((always_inline)) volatile uint32_t* get_cb_tiles_acked_ptr(int operand) {
    return (volatile uint32_t*)(uintptr_t)(((0xFFB40000) + (((uint32_t)(get_operand_stream_id(operand))) * (0x1000)) + (((uint32_t)(3)) << 2))
                                                                               );
}

inline __attribute__((always_inline)) volatile uint32_t* get_cq_finish_ptr() {
    return (volatile uint32_t*)(uintptr_t)(((0xFFB40000) + (((uint32_t)(get_operand_stream_id(0))) * (0x1000)) + (((uint32_t)(3)) << 2))
                                                                         );
}

inline __attribute__((always_inline)) volatile uint32_t* get_sync_register_ptr() {
    return (volatile uint32_t*)(uintptr_t)(((0xFFB40000) + (((uint32_t)(0)) * (0x1000)) + (((uint32_t)(12)) << 2)));
}
const uint32_t STREAM_RESTART_CHECK_MASK = (0x1 << 3) - 1;

const uint32_t MAX_TILES_PER_PHASE = 2048;




extern uint8_t my_x[2];


extern uint8_t my_y[2];

inline void WRITE_REG(uint32_t addr, uint32_t val) {
    volatile __attribute__((rvtt_reg_ptr)) uint32_t* ptr = (volatile __attribute__((rvtt_reg_ptr)) uint32_t*)addr;
    ptr[0] = val;
}

inline uint32_t READ_REG(uint32_t addr) {
    volatile __attribute__((rvtt_reg_ptr)) uint32_t* ptr = (volatile __attribute__((rvtt_reg_ptr)) uint32_t*)addr;
    return ptr[0];
}

inline uint32_t dram_io_incr_ptr(uint32_t curr_ptr, uint32_t incr, uint32_t buf_size_q_slots) {
    uint32_t next_ptr = curr_ptr + incr;
    uint32_t double_buf_size_q_slots = 2 * buf_size_q_slots;
    if (next_ptr >= double_buf_size_q_slots) {
        next_ptr -= double_buf_size_q_slots;
    }
    return next_ptr;
}

inline __attribute__((always_inline)) uint32_t dram_io_empty(uint32_t rd_ptr, uint32_t wr_ptr) {
    return (rd_ptr == wr_ptr);
}

inline __attribute__((always_inline)) uint32_t
dram_io_local_empty(uint32_t local_rd_ptr, uint32_t rd_ptr, uint32_t wr_ptr) {
    if (rd_ptr == wr_ptr) {
        return true;
    }

    uint32_t case1 = rd_ptr < wr_ptr && (local_rd_ptr < rd_ptr || local_rd_ptr >= wr_ptr);
    uint32_t case2 = rd_ptr > wr_ptr && wr_ptr <= local_rd_ptr && local_rd_ptr < rd_ptr;

    return case1 || case2;
}

inline uint32_t dram_io_full(uint32_t rd_ptr, uint32_t wr_ptr, uint32_t buf_size_q_slots) {
    uint32_t wr_ptr_reduced_by_q_slots = wr_ptr - buf_size_q_slots;
    uint32_t rd_ptr_reduced_by_q_slots = rd_ptr - buf_size_q_slots;
    uint32_t case1 = (wr_ptr_reduced_by_q_slots == rd_ptr);
    uint32_t case2 = (rd_ptr_reduced_by_q_slots == wr_ptr);
    return case1 || case2;
}

inline __attribute__((always_inline)) uint32_t buf_ptr_inc_wrap(uint32_t buf_ptr, uint32_t inc, uint32_t buf_size) {
    uint32_t result = buf_ptr + inc;
    if (result >= buf_size) {
        result -= buf_size;
    }
    return result;
}

inline __attribute__((always_inline)) uint32_t buf_ptr_dec_wrap(uint32_t buf_ptr, uint32_t dec, uint32_t buf_size) {
    uint32_t result = buf_ptr;
    if (dec > result) {
        result += buf_size;
    }
    result -= dec;
    return result;
}
inline void assert_trisc_reset() {
    uint32_t soft_reset_0 = READ_REG((0xFFB12000 | 0x1B0));
    uint32_t trisc_reset_mask = 0x07000;
    WRITE_REG((0xFFB12000 | 0x1B0), soft_reset_0 | trisc_reset_mask);
}

inline void deassert_trisc_reset() {
    uint32_t soft_reset_0 = READ_REG((0xFFB12000 | 0x1B0));
    uint32_t trisc_reset_mask = 0x07000;
    WRITE_REG((0xFFB12000 | 0x1B0), soft_reset_0 & ~trisc_reset_mask);
}

inline void deassert_all_reset() { WRITE_REG((0xFFB12000 | 0x1B0), 0x00000); }

inline void assert_just_ncrisc_reset() { WRITE_REG((0xFFB12000 | 0x1B0), 0x40000); }

inline uint32_t special_mult(uint32_t a, uint32_t special_b) {
    if (special_b == ((32 * 32 * 1 + 64 + 32) >> 4)) {
        return a * ((32 * 32 * 1 + 64 + 32) >> 4);
    } else if (special_b == ((32 * 32 * 2 + 32) >> 4)) {
        return a * ((32 * 32 * 2 + 32) >> 4);
    } else if (special_b == ((512 + 64 + 32) >> 4)) {
        return a * ((512 + 64 + 32) >> 4);
    } else if (special_b == ((256 + 64 + 32) >> 4)) {
        return a * ((256 + 64 + 32) >> 4);
    } else if (special_b == ((32 * 32 * 4 + 32) >> 4)) {
        return a * ((32 * 32 * 4 + 32) >> 4);
    }

    while (true);
    return 0;
}






inline __attribute__((always_inline)) void invalidate_l1_cache() {



}
inline void riscv_wait(uint32_t cycles) {
    volatile uint __attribute__((rvtt_reg_ptr))* clock_lo = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr))*>((0xFFB12000 | 0x1F0));
    volatile uint __attribute__((rvtt_reg_ptr))* clock_hi = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr))*>((0xFFB12000 | 0x1F8));
    uint64_t wall_clock_timestamp = clock_lo[0] | ((uint64_t)clock_hi[0] << 32);
    uint64_t wall_clock = 0;
    do {



        wall_clock = clock_lo[0] | ((uint64_t)clock_hi[0] << 32);
    } while (wall_clock < (wall_clock_timestamp + cycles));
}


inline __attribute__((always_inline)) void flush_erisc_icache() {






#pragma GCC unroll 128
    for (int i = 0; i < 128; i++) {
        asm("nop");
    }

}




       







inline volatile __attribute__((rvtt_l1_ptr)) DebugPrintMemLayout* get_debug_print_buffer() {
    return (&(((mailboxes_t __attribute__((rvtt_l1_ptr))*)16)->dprint_buf.data[DPRINT_RISCV_INDEX_TR1]));





}
       

       

namespace std __attribute__ ((__visibility__ ("default")))
{


  namespace rel_ops
  {
    template <class _Tp>
      inline bool
      operator!=(const _Tp& __x, const _Tp& __y)
      { return !(__x == __y); }
    template <class _Tp>
      inline bool
      operator>(const _Tp& __x, const _Tp& __y)
      { return __y < __x; }
    template <class _Tp>
      inline bool
      operator<=(const _Tp& __x, const _Tp& __y)
      { return !(__y < __x); }
    template <class _Tp>
      inline bool
      operator>=(const _Tp& __x, const _Tp& __y)
      { return !(__x < __y); }
  }


}
namespace std __attribute__ ((__visibility__ ("default")))
{

  template <typename _Tp, typename _Up = _Tp>
   
    inline _Tp
    exchange(_Tp& __obj, _Up&& __new_val)
    noexcept(__and_<is_nothrow_move_constructible<_Tp>,
      is_nothrow_assignable<_Tp&, _Up>>::value)
    { return std::__exchange(__obj, std::forward<_Up>(__new_val)); }




  template<typename _Tp>
    [[nodiscard]]
    constexpr add_const_t<_Tp>&
    as_const(_Tp& __t) noexcept
    { return __t; }

  template<typename _Tp>
    void as_const(const _Tp&&) = delete;

}

namespace internal_ {
void risc_context_switch();
}

struct BF16 {
    uint16_t val;
    BF16(uint16_t val) : val(val) {}
} __attribute__((packed));
struct F32 {
    float val;
    F32(float val) : val(val) {}
} __attribute__((packed));
struct U32 {
    uint32_t val;
    U32(uint32_t val) : val(val) {}
} __attribute__((packed));

struct ENDL {
    char tmp;
} __attribute__((packed));
struct SETPRECISION {
    char p;
    SETPRECISION(char pa) : p(pa) {}
} __attribute__((packed));
struct FIXED {
    char tmp;
} __attribute__((packed));
struct DEFAULTFLOAT {
    char tmp;
} __attribute__((packed));
struct HEX {
    char tmp;
} __attribute__((packed));
struct OCT {
    char tmp;
} __attribute__((packed));
struct DEC {
    char tmp;
} __attribute__((packed));
struct SETW {
    char w;
    SETW(char w) : w(w) {}
} __attribute__((packed));
struct U32_ARRAY {
    uint32_t* ptr;
    uint32_t len;
    U32_ARRAY(uint32_t* ptr, uint32_t len) : ptr(ptr), len(len) {}
} __attribute__((packed));
struct TYPED_U32_ARRAY : public U32_ARRAY {
    TYPED_U32_ARRAY(uint16_t my_type, uint16_t my_subtype, uint32_t* ptr, uint32_t len) : U32_ARRAY(ptr, len + 1) {
        ptr[len] = ((uint32_t)my_type << 16) + (uint32_t)my_subtype;
    }
} __attribute__((packed));





struct RAISE {
    uint32_t code;
    RAISE(uint32_t val) : code(val) {}
} __attribute__((packed));
struct WAIT {
    uint32_t code;
    WAIT(uint32_t val) : code(val) {}
} __attribute__((packed));


inline uint32_t DebugPrintStrLen(const char* val) {
    const char* end = val;
    while (*end) {
        end++;
    };
    return uint32_t(end - val) + 1;
}



template <typename T>
uint8_t DebugPrintTypeToId();
template <typename T>
uint32_t DebugPrintTypeToSize(T val) {
    return sizeof(T);
};
template <typename T>
const uint8_t* DebugPrintTypeAddr(T* val) {
    return reinterpret_cast<const uint8_t*>(val);
}
template <>
uint32_t DebugPrintTypeToSize<U32_ARRAY>(U32_ARRAY val) {
    return val.len * sizeof(uint32_t);
}
template <>
const uint8_t* DebugPrintTypeAddr<U32_ARRAY>(U32_ARRAY* val) {
    return (const uint8_t*)val->ptr;
}
template <>
uint32_t DebugPrintTypeToSize<TYPED_U32_ARRAY>(TYPED_U32_ARRAY val) {
    return val.len * sizeof(uint32_t);
}
template <>
const uint8_t* DebugPrintTypeAddr<TYPED_U32_ARRAY>(TYPED_U32_ARRAY* val) {
    return (const uint8_t*)val->ptr;
}

template <>
uint8_t DebugPrintTypeToId<const char*>() {
    return DPrintCSTR;
}
template <>
uint8_t DebugPrintTypeToId<char*>() {
    return DPrintCSTR;
}
template <>
uint8_t DebugPrintTypeToId<ENDL>() {
    return DPrintENDL;
}
template <>
uint8_t DebugPrintTypeToId<SETW>() {
    return DPrintSETW;
}
template <>
uint8_t DebugPrintTypeToId<uint8_t>() {
    return DPrintUINT8;
}
template <>
uint8_t DebugPrintTypeToId<uint16_t>() {
    return DPrintUINT16;
}
template <>
uint8_t DebugPrintTypeToId<uint32_t>() {
    return DPrintUINT32;
}
template <>
uint8_t DebugPrintTypeToId<uint64_t>() {
    return DPrintUINT64;
}
template <>
uint8_t DebugPrintTypeToId<int8_t>() {
    return DPrintINT8;
}
template <>
uint8_t DebugPrintTypeToId<int16_t>() {
    return DPrintINT16;
}
template <>
uint8_t DebugPrintTypeToId<int32_t>() {
    return DPrintINT32;
}
template <>
uint8_t DebugPrintTypeToId<int64_t>() {
    return DPrintINT64;
}
template <>
uint8_t DebugPrintTypeToId<int>() {
    return DPrintINT32;
}
template <>
uint8_t DebugPrintTypeToId<float>() {
    return DPrintFLOAT32;
}
template <>
uint8_t DebugPrintTypeToId<char>() {
    return DPrintCHAR;
}
template <>
uint8_t DebugPrintTypeToId<RAISE>() {
    return DPrintRAISE;
}
template <>
uint8_t DebugPrintTypeToId<WAIT>() {
    return DPrintWAIT;
}
template <>
uint8_t DebugPrintTypeToId<BF16>() {
    return DPrintBFLOAT16;
}
template <>
uint8_t DebugPrintTypeToId<SETPRECISION>() {
    return DPrintSETPRECISION;
}
template <>
uint8_t DebugPrintTypeToId<FIXED>() {
    return DPrintFIXED;
}
template <>
uint8_t DebugPrintTypeToId<DEFAULTFLOAT>() {
    return DPrintDEFAULTFLOAT;
}
template <>
uint8_t DebugPrintTypeToId<HEX>() {
    return DPrintHEX;
}
template <>
uint8_t DebugPrintTypeToId<OCT>() {
    return DPrintOCT;
}
template <>
uint8_t DebugPrintTypeToId<DEC>() {
    return DPrintDEC;
}
template <>
uint8_t DebugPrintTypeToId<F32>() {
    return DPrintFLOAT32;
}
template <>
uint8_t DebugPrintTypeToId<U32>() {
    return DPrintUINT32;
}
template <>
uint8_t DebugPrintTypeToId<U32_ARRAY>() {
    return DPrintU32_ARRAY;
}
template <>
uint8_t DebugPrintTypeToId<TYPED_U32_ARRAY>() {
    return DPrintTYPED_U32_ARRAY;
}
static_assert(sizeof(int) == 4);


template <>
uint32_t DebugPrintTypeToSize<const char*>(const char* val) {
    return DebugPrintStrLen(val);
}
template <>
const uint8_t* DebugPrintTypeAddr<const char*>(const char** val) {
    return reinterpret_cast<const uint8_t*>(*val);
}
template <>
uint32_t DebugPrintTypeToSize<char*>(char* val) {
    return DebugPrintStrLen(val);
}
template <>
const uint8_t* DebugPrintTypeAddr<char*>(char** val) {
    return reinterpret_cast<const uint8_t*>(*val);
}

struct DebugPrinter {
    DebugPrinter() {
    }
};

struct DebugPrintData {
    uint32_t sz;
    const uint8_t* data_ptr;
    uint8_t type_id;
};

__attribute__((__noinline__)) void debug_print(DebugPrinter& dp, DebugPrintData data) {
    volatile __attribute__((rvtt_l1_ptr)) DebugPrintMemLayout* dprint_buffer = get_debug_print_buffer();
    if (dprint_buffer->aux.wpos == DEBUG_PRINT_SERVER_DISABLED_MAGIC) {

        return;
    }

    uint32_t payload_sz = data.sz;
    const uint8_t* valaddr = data.data_ptr;
    uint8_t typecode = data.type_id;
    constexpr int code_sz = 1;
    constexpr int sz_sz = 1;
    uint32_t wpos = dprint_buffer->aux.wpos;
    auto sum_sz = payload_sz + code_sz + sz_sz;
    if (wpos + sum_sz >= sizeof(DebugPrintMemLayout().data)) {

        ;
        while (dprint_buffer->aux.rpos < dprint_buffer->aux.wpos) {
            invalidate_l1_cache();




            if (dprint_buffer->aux.wpos == DEBUG_PRINT_SERVER_DISABLED_MAGIC) {
                return;
            };
        }
        ;
        dprint_buffer->aux.wpos = 0;

        dprint_buffer->aux.rpos = 0;
        wpos = 0;
        if (payload_sz > sizeof(DebugPrintMemLayout::data) - 2) {
            volatile uint8_t* printbuf = dprint_buffer->data;
            uint32_t remaining_payload_size = payload_sz;
            while (remaining_payload_size > sizeof(DebugPrintMemLayout::data) - 2) {
                const uint32_t curr_payload_size = sizeof(DebugPrintMemLayout::data) - 2;
                remaining_payload_size -= curr_payload_size;

                printbuf[wpos] = typecode;
                wpos += code_sz;
                printbuf[wpos] = curr_payload_size;
                wpos += sz_sz;
                for (uint32_t j = 0; j < curr_payload_size - 1; j++) {
                    printbuf[wpos + j] = *valaddr;
                    valaddr++;
                }
                printbuf[wpos + curr_payload_size - 1] = '\0';
                wpos += curr_payload_size;
                dprint_buffer->aux.wpos = wpos;
                ;
                while (dprint_buffer->aux.rpos < dprint_buffer->aux.wpos) {
                    invalidate_l1_cache();




                    if (dprint_buffer->aux.wpos == DEBUG_PRINT_SERVER_DISABLED_MAGIC) {
                        return;
                    };
                }
                ;
                wpos = 0;

                remaining_payload_size += 1;
                dprint_buffer->aux.rpos = 0;
            }
            payload_sz = remaining_payload_size;
        }
    }

    volatile uint8_t* printbuf = dprint_buffer->data;

    printbuf[wpos] = typecode;
    wpos += code_sz;
    printbuf[wpos] = payload_sz;
    wpos += sz_sz;
    for (uint32_t j = 0; j < payload_sz; j++) {
        printbuf[wpos + j] = valaddr[j];
    }
    wpos += payload_sz;



    dprint_buffer->aux.wpos = wpos;
}

template <typename T>
__attribute__((__noinline__)) DebugPrinter operator<<(DebugPrinter dp, T val) {







    return dp;
}


template DebugPrinter operator<< <const char*>(DebugPrinter dp, const char* val);
template DebugPrinter operator<< <ENDL>(DebugPrinter, ENDL val);
template DebugPrinter operator<< <SETW>(DebugPrinter, SETW val);
template DebugPrinter operator<< <uint8_t>(DebugPrinter, uint8_t val);
template DebugPrinter operator<< <uint16_t>(DebugPrinter, uint16_t val);
template DebugPrinter operator<< <uint32_t>(DebugPrinter, uint32_t val);
template DebugPrinter operator<< <uint64_t>(DebugPrinter, uint64_t val);
template DebugPrinter operator<< <int8_t>(DebugPrinter, int8_t val);
template DebugPrinter operator<< <int16_t>(DebugPrinter, int16_t val);
template DebugPrinter operator<< <int32_t>(DebugPrinter, int32_t val);
template DebugPrinter operator<< <int64_t>(DebugPrinter, int64_t val);
template DebugPrinter operator<< <float>(DebugPrinter, float val);
template DebugPrinter operator<< <char>(DebugPrinter, char val);
template DebugPrinter operator<< <RAISE>(DebugPrinter, RAISE val);
template DebugPrinter operator<< <WAIT>(DebugPrinter, WAIT val);
template DebugPrinter operator<< <FIXED>(DebugPrinter, FIXED val);
template DebugPrinter operator<< <DEFAULTFLOAT>(DebugPrinter, DEFAULTFLOAT val);
template DebugPrinter operator<< <HEX>(DebugPrinter, HEX val);
template DebugPrinter operator<< <OCT>(DebugPrinter, OCT val);
template DebugPrinter operator<< <DEC>(DebugPrinter, DEC val);
template DebugPrinter operator<< <SETPRECISION>(DebugPrinter, SETPRECISION val);
template DebugPrinter operator<< <BF16>(DebugPrinter, BF16 val);
template DebugPrinter operator<< <F32>(DebugPrinter, F32 val);
template DebugPrinter operator<< <U32>(DebugPrinter, U32 val);







       






       






       







       



constexpr static std::uint32_t NUM_CIRCULAR_BUFFERS = 32;
constexpr static std::uint32_t UINT32_WORDS_PER_LOCAL_CIRCULAR_BUFFER_CONFIG = 4;
constexpr static std::uint32_t UINT32_WORDS_PER_REMOTE_CIRCULAR_BUFFER_CONFIG = 2;
constexpr static std::uint32_t CIRCULAR_BUFFER_COMPUTE_WORD_SIZE = 16;
constexpr static std::uint32_t CIRCULAR_BUFFER_COMPUTE_ADDR_SHIFT = 4;


constexpr static std::uint32_t REMOTE_CIRCULAR_BUFFER_ALIGNED_PAGE_SIZE = (static_cast<uint32_t>( 16 >= 16 ? 16 : 16));

struct RemoteSenderCBInterface {
    uint32_t config_ptr;
    uint32_t fifo_start_addr;
    uint32_t fifo_limit_page_aligned;
    uint32_t fifo_page_size;

    uint32_t fifo_wr_ptr;



    uint32_t receiver_noc_xy_ptr;




    uint32_t aligned_pages_sent_ptr;
    uint32_t num_receivers;
};

struct RemoteReceiverCBInterface {
    uint32_t config_ptr;
    uint32_t fifo_start_addr;
    uint32_t fifo_limit_page_aligned;
    uint32_t fifo_page_size;

    uint32_t fifo_rd_ptr;

    uint32_t sender_noc_x;
    uint32_t sender_noc_y;



    uint32_t aligned_pages_acked_ptr;
};


static_assert(
    
   __builtin_offsetof (
   RemoteSenderCBInterface
   , 
   fifo_start_addr
   ) 
                                                      == 
                                                         __builtin_offsetof (
                                                         RemoteReceiverCBInterface
                                                         , 
                                                         fifo_start_addr
                                                         )
                                                                                                             ,
    "fifo_start_addr must be at the same offset in RemoteSenderCBInterface and RemoteReceiverCBInterface");
static_assert(
    
   __builtin_offsetof (
   RemoteSenderCBInterface
   , 
   fifo_limit_page_aligned
   ) 
                                                              ==
        
       __builtin_offsetof (
       RemoteReceiverCBInterface
       , 
       fifo_limit_page_aligned
       )
                                                                   ,
    "fifo_limit_page_aligned must be at the same offset in RemoteSenderCBInterface and RemoteReceiverCBInterface");
static_assert(
    
   __builtin_offsetof (
   RemoteSenderCBInterface
   , 
   fifo_wr_ptr
   ) 
                                                  == 
                                                     __builtin_offsetof (
                                                     RemoteReceiverCBInterface
                                                     , 
                                                     fifo_rd_ptr
                                                     )
                                                                                                     ,
    "fifo_wr_ptr and fifo_rd_ptr must be at the same offset in RemoteSenderCBInterface and RemoteReceiverCBInterface");
static_assert(
    
   __builtin_offsetof (
   RemoteSenderCBInterface
   , 
   config_ptr
   ) 
                                                 == 
                                                    __builtin_offsetof (
                                                    RemoteReceiverCBInterface
                                                    , 
                                                    config_ptr
                                                    )
                                                                                                   ,
    "config_ptr must be at the same offset in RemoteSenderCBInterface and RemoteReceiverCBInterface");

struct LocalCBInterface {
    uint32_t fifo_size;
    uint32_t fifo_limit;
    uint32_t fifo_page_size;
    uint32_t fifo_num_pages;

    uint32_t fifo_rd_ptr;
    uint32_t fifo_wr_ptr;


    union {
        uint32_t tiles_acked_received_init;
        struct {
            uint16_t tiles_acked;
            uint16_t tiles_received;
        };
    };


    uint32_t fifo_wr_tile_ptr;
};

struct CBInterface {
    union {
        LocalCBInterface local_cb_interface;
        RemoteSenderCBInterface remote_sender_cb_interface;
        RemoteReceiverCBInterface remote_receiver_cb_interface;
    };
};


extern CBInterface cb_interface[NUM_CIRCULAR_BUFFERS];

inline __attribute__((always_inline)) LocalCBInterface& get_local_cb_interface(uint32_t cb_id) { return cb_interface[cb_id].local_cb_interface; }

inline __attribute__((always_inline)) RemoteSenderCBInterface& get_remote_sender_cb_interface(uint32_t cb_id) {
    return cb_interface[cb_id].remote_sender_cb_interface;
}

inline __attribute__((always_inline)) RemoteReceiverCBInterface& get_remote_receiver_cb_interface(uint32_t cb_id) {
    return cb_interface[cb_id].remote_receiver_cb_interface;
}


constexpr uint32_t cb_addr_shift = CIRCULAR_BUFFER_COMPUTE_ADDR_SHIFT;




       




constexpr static int16_t DEBUG_RING_BUFFER_STARTING_INDEX = -1;
using dprint_tslice_ptr_t = bool;


using dprint_tslice_cb_t = bool;



struct tile_info_t {
    uint32_t tile_dim_r;
    uint32_t tile_dim_c;
    uint32_t tile_size;
    uint32_t face_dim_r;
    uint32_t face_dim_c;
    uint32_t num_faces;
    uint32_t cb_ptr;
    uint8_t data_format;
};
template <int MAX_BYTES = 32 * 2>
struct TileSlice : TileSliceHostDev<MAX_BYTES> {
    static inline uint32_t get_data_index(tile_info_t& tile_info, uint32_t h, uint32_t w, bool untilize) {
        if (untilize) {
            uint32_t row_in_face = h % tile_info.face_dim_r;
            uint32_t col_in_face = w % tile_info.face_dim_c;
            uint32_t face_idx_r = h / tile_info.face_dim_r;
            uint32_t face_idx_c = w / tile_info.face_dim_c;
            uint32_t num_faces_c = tile_info.tile_dim_c / tile_info.face_dim_c;
            uint32_t face_idx = face_idx_r * num_faces_c + face_idx_c;
            return face_idx * tile_info.face_dim_r * tile_info.face_dim_c + row_in_face * tile_info.face_dim_c +
                   col_in_face;
        } else {
            return w + h * tile_info.tile_dim_r;
        }
    }
    static inline uint32_t get_exponent_index(tile_info_t& tile_info, uint32_t h, uint32_t w, bool untilize) {
        if (untilize) {

            uint32_t row_in_face = h % tile_info.face_dim_r;
            uint32_t col_in_face = w % tile_info.face_dim_c;
            uint32_t face_idx_r = h / tile_info.face_dim_r;
            uint32_t face_idx_c = w / tile_info.face_dim_c;
            uint32_t num_faces_c = tile_info.tile_dim_c / tile_info.face_dim_c;
            uint32_t face_idx = face_idx_r * num_faces_c + face_idx_c;
            return face_idx * tile_info.face_dim_r + row_in_face;
        } else {

            return (w + h * tile_info.tile_dim_r) / tile_info.face_dim_c;
        }
    }

    __attribute__((__noinline__)) TileSlice(
        uint8_t cb,
        int tile_idx,
        const SliceRange& slice_range,
        bool endl_rows = true,
        bool print_untilized = true) {
    }
} __attribute__((packed));

using TSLICE = TileSlice<64>;

template <>
uint8_t DebugPrintTypeToId<TileSlice<64>>() {
    return DPrintTILESLICE;
}
template <>
uint8_t DebugPrintTypeToId<TileSlice<128>>() {
    return DPrintTILESLICE;
}

template DebugPrinter operator<< <TSLICE>(DebugPrinter, TSLICE val);




extern uint16_t dram_bank_to_noc_xy[2][12];
extern int32_t bank_to_dram_offset[12];
extern uint16_t l1_bank_to_noc_xy[2][56];
extern int32_t bank_to_l1_offset[56];

void l1_to_local_mem_copy(uint32_t* dst, uint32_t __attribute__((rvtt_l1_ptr))* src, int32_t len);

inline void do_crt1(uint32_t __attribute__((rvtt_l1_ptr))* data_image) {

    extern uint32_t __ldm_bss_start[];
    extern uint32_t __ldm_bss_end[];
    wzerorange(__ldm_bss_start, __ldm_bss_end);


    extern uint32_t __ldm_data_start[];
    extern uint32_t __ldm_data_end[];
    l1_to_local_mem_copy(__ldm_data_start, data_image, __ldm_data_end - __ldm_data_start);
}

inline void noc_bank_table_init(uint64_t mem_bank_to_noc_addr) {
    int32_t dram_to_noc_size_bytes = sizeof(dram_bank_to_noc_xy);
    l1_to_local_mem_copy((uint*)dram_bank_to_noc_xy, (uint __attribute__((rvtt_l1_ptr))*)mem_bank_to_noc_addr, dram_to_noc_size_bytes >> 2);
    int32_t l1_to_noc_size_bytes = sizeof(l1_bank_to_noc_xy);
    l1_to_local_mem_copy((uint*)l1_bank_to_noc_xy, (uint __attribute__((rvtt_l1_ptr))*)(mem_bank_to_noc_addr + dram_to_noc_size_bytes), l1_to_noc_size_bytes >> 2);

    int32_t dram_offsets_size_bytes = sizeof(bank_to_dram_offset);
    l1_to_local_mem_copy((uint*)bank_to_dram_offset, (uint __attribute__((rvtt_l1_ptr))*)(mem_bank_to_noc_addr + dram_to_noc_size_bytes + l1_to_noc_size_bytes), dram_offsets_size_bytes >> 2);
    int32_t l1_offsets_size_bytes = sizeof(bank_to_l1_offset);
    l1_to_local_mem_copy((uint*)bank_to_l1_offset, (uint __attribute__((rvtt_l1_ptr))*)(mem_bank_to_noc_addr + dram_to_noc_size_bytes + l1_to_noc_size_bytes + dram_offsets_size_bytes), l1_offsets_size_bytes >> 2);
}

inline __attribute__((always_inline))
uint32_t firmware_config_init(
    __attribute__((rvtt_l1_ptr)) mailboxes_t* const mailboxes, uint32_t core_type_index, uint32_t dispatch_class) {
    extern uint32_t __attribute__((rvtt_l1_ptr))* rta_l1_base;
    extern uint32_t __attribute__((rvtt_l1_ptr))* crta_l1_base;
    extern uint32_t __attribute__((rvtt_l1_ptr))* sem_l1_base[ProgrammableCoreType::COUNT];


    uint32_t kernel_config_base[ProgrammableCoreType::COUNT];
    launch_msg_t* launch_msg_address = &(mailboxes->launch[mailboxes->launch_msg_rd_ptr]);
#pragma GCC unroll ProgrammableCoreType::COUNT
    for (uint32_t index = 0; index < ProgrammableCoreType::COUNT; index++) {
        kernel_config_base[index] = launch_msg_address->kernel_config.kernel_config_base[index];
        sem_l1_base[index] =
            (uint32_t __attribute__((rvtt_l1_ptr))*)(kernel_config_base[index] + launch_msg_address->kernel_config.sem_offset[index]);
    }
    rta_l1_base = (uint32_t __attribute__((rvtt_l1_ptr))*)(kernel_config_base[core_type_index] +
                                        launch_msg_address->kernel_config.rta_offset[dispatch_class].rta_offset);
    crta_l1_base = (uint32_t __attribute__((rvtt_l1_ptr))*)(kernel_config_base[core_type_index] +
                                         launch_msg_address->kernel_config.rta_offset[dispatch_class].crta_offset);

    return kernel_config_base[core_type_index];
}

inline __attribute__((always_inline))
void wait_for_go_message() {
    __attribute__((rvtt_l1_ptr)) mailboxes_t* const mailboxes = (__attribute__((rvtt_l1_ptr)) mailboxes_t*)(16);

    while (mailboxes->go_message.signal != RUN_MSG_GO) {
        invalidate_l1_cache();
    }
}
inline __attribute__((always_inline)) void configure_gathering() {
}

inline __attribute__((always_inline)) void configure_l1_data_cache() {
}

inline __attribute__((always_inline)) void disable_relaxed_memory_ordering() {
}

inline __attribute__((always_inline)) void configure_csr() {
    configure_gathering();
    configure_l1_data_cache();
    disable_relaxed_memory_ordering();
}





       





       





       





namespace ckernel
{

struct p_setrwc
{
    constexpr static uint CLR_A = 0x1;
    constexpr static uint CLR_B = 0x2;
    constexpr static uint CLR_AB = 0x3;
    constexpr static uint CLR_NONE = 0x0;

    constexpr static uint SET_A = 0x1;
    constexpr static uint SET_B = 0x2;
    constexpr static uint SET_AB = 0x3;
    constexpr static uint SET_D = 0x4;
    constexpr static uint SET_AD = 0x5;
    constexpr static uint SET_BD = 0x6;
    constexpr static uint SET_ABD = 0x7;
    constexpr static uint SET_F = 0x8;
    constexpr static uint SET_A_F = 0x9;
    constexpr static uint SET_B_F = 0xa;
    constexpr static uint SET_AB_F = 0xb;
    constexpr static uint SET_D_F = 0xc;
    constexpr static uint SET_AD_F = 0xd;
    constexpr static uint SET_BD_F = 0xe;
    constexpr static uint SET_ABD_F = 0xf;

    constexpr static uint CR_A = 0x1;
    constexpr static uint CR_B = 0x2;
    constexpr static uint CR_AB = 0x3;
    constexpr static uint CR_D = 0x4;
    constexpr static uint CR_AD = 0x5;
    constexpr static uint CR_BD = 0x6;
    constexpr static uint CR_ABD = 0x7;
    constexpr static uint C_TO_CR_MODE = 0x8;
};

struct p_setibrwc
{
    constexpr static uint SET_BIAS = 0x0;
    constexpr static uint INC_BIAS = 0x1;
    constexpr static uint CR_NONE = 0x0;
    constexpr static uint CR_BIAS = 0x1;
};

struct p_unpacr
{
    constexpr static uint RAREFYB_DISABLE = 0x0;
    constexpr static uint RAREFYB_ENABLE = 0x1;

    constexpr static uint TILE0_ADDRCNT_CONTEXT = (0);
    constexpr static uint TILE1_ADDRCNT_CONTEXT = (0);
    constexpr static uint TILE2_ADDRCNT_CONTEXT = (1);
    constexpr static uint TILE3_ADDRCNT_CONTEXT = (1);
    constexpr static uint TILE0_CFG_CONTEXT = (0);
    constexpr static uint TILE1_CFG_CONTEXT = (0);
    constexpr static uint TILE2_CFG_CONTEXT = (0);
    constexpr static uint TILE3_CFG_CONTEXT = (0);
    constexpr static uint AUTO_INC_CONTEXT = (1);
};
struct p_unpacr_nop
{
    constexpr static uint UNP_POP = 0b000;
    constexpr static uint UNP_NOP = 0b010;

    constexpr static uint UNP_ZEROSRC = 0b001;
    constexpr static uint UNP_NEGINFSRC = 0b101;

    constexpr static uint UNP_SET_DVALID = 0b111;

    constexpr static uint UNP_ZEROSRC_RESET_ALL_BANKS = 0b1001;
    constexpr static uint UNP_ZEROSRC_STALL_RESET_WR_RDY = 0b10001;
    constexpr static uint UNP_ZEROSRC_SET_DVALID = 0b1000001;

    constexpr static uint UNP0 = 0x0;
    constexpr static uint UNP1 = 0x1;
};

struct p_srcb
{
    constexpr static uint FORWARD_PASS = 0x0;
    constexpr static uint BACKWARD_PASS = 0x1;
};

constexpr static uint SETADC_CH0(uint cnt)
{
    return cnt;
}

constexpr static uint SETADC_CH1(uint cnt)
{
    return cnt << 2;
}

constexpr static uint SETADC_CH01(uint cnt)
{
    return cnt << 2 | cnt;
}

struct p_setadc
{
    constexpr static uint UNP0 = 0b001;
    constexpr static uint UNP1 = 0b010;
    constexpr static uint UNP_A = 0b001;
    constexpr static uint UNP_B = 0b010;
    constexpr static uint UNP_AB = 0b011;
    constexpr static uint PAC = 0b100;

    constexpr static uint SET_X = 0;
    constexpr static uint SET_Y = 1;
    constexpr static uint SET_Z = 2;
    constexpr static uint SET_W = 3;

    constexpr static uint X = 1;
    constexpr static uint Y = 2;
    constexpr static uint XY = 3;
    constexpr static uint Z = 1;
    constexpr static uint W = 2;
    constexpr static uint ZW = 3;

    constexpr static uint CH_0 = 0;
    constexpr static uint CH_1 = 1;
};

struct p_pacr
{
    constexpr static uint P_ZERO_OUTPUT_DISABLED = 0x0;
    constexpr static uint P_ZERO_OUTPUT_ENABLED = 0x1;
};





struct p_ind
{
    constexpr static uint HIER_REGFILE = 0x0;
    constexpr static uint HIER_L1 = 0x1;

    constexpr static uint INC_NONE = 0x0;
    constexpr static uint INC_2B = 0x1;
    constexpr static uint INC_4B = 0x2;
    constexpr static uint INC_16B = 0x3;

    constexpr static uint LD_16B = 0;
    constexpr static uint LD_32bit = 1;
    constexpr static uint LD_16bit = 2;
    constexpr static uint LD_8bit = 3;
};

struct p_mov
{
    constexpr static uint DEST_NORM = 0;
    constexpr static uint DEST_32B_LOW = 1;
};

struct p_mova2d
{
    constexpr static uint MATH_HALO_ROWS = 0x0;
    constexpr static uint MOV_1_ROW = 0x0;
    constexpr static uint MOV_8_ROWS = 0x2;
};

struct p_movd2a
{
    constexpr static uint MOV_1_ROW = 0x0;
    constexpr static uint MOV_4_ROWS = 0x2;
};

struct p_movb2d
{
    constexpr static uint SRC_ZERO_OFFSET = 0x0;
    constexpr static uint SRC_ROW16_OFFSET = 0x10;
    constexpr static uint MOV_1_ROW = 0x0;
    constexpr static uint MOV_1_ROW_D0_BRCST = 0x1;
    constexpr static uint MOV_8_ROW_BRCST = 0x2;
    constexpr static uint MOV_8_ROW_BRCST_D0_BRCST = 0x3;
    constexpr static uint MOV_4_ROWS = 0x4;
    constexpr static uint MOV_4_ROWS_D0_BRCST = 0x5;
};

struct p_movd2b
{
    constexpr static uint SRC_ZERO_OFFSET = 0x0;
    constexpr static uint SRC_ROW16_OFFSET = 0x10;
    constexpr static uint MOV_1_ROW = 0x0;
    constexpr static uint MOV_4_ROWS = 0x2;
};

struct p_movb2a
{
    constexpr static uint SRCA_ZERO_OFFSET = 0x0;
    constexpr static uint SRCB_ZERO_OFFSET = 0x0;
    constexpr static uint SRCB_ROW16_OFFSET = 0x10;
    constexpr static uint MOV_1_ROW = 0x0;
    constexpr static uint MOV_4_ROWS = 0x2;
};

struct p_stall
{

    constexpr static uint NONE = 0x0;
    constexpr static uint THCON = 0x1;
    constexpr static uint UNPACK0 = 0x2;
    constexpr static uint UNPACK1 = 0x4;
    constexpr static uint UNPACK = UNPACK0 | UNPACK1;
    constexpr static uint PACK0 = 0x8;
    constexpr static uint PACK1 = 0x10;
    constexpr static uint PACK2 = 0x20;
    constexpr static uint PACK3 = 0x40;
    constexpr static uint PACK = PACK0 | PACK1 | PACK2 | PACK3;
    constexpr static uint MATH = 0x80;


    constexpr static uint SRCA_CLR = 0x100;
    constexpr static uint SRCB_CLR = 0x200;
    constexpr static uint SRCA_VLD = 0x400;
    constexpr static uint SRCB_VLD = 0x800;
    constexpr static uint XMOV = 0x1000;
    constexpr static uint TRISC_CFG = 0x2000;
    constexpr static uint SFPU1 = 0x4000;
    constexpr static uint WAIT_SFPU = 0x4000;
    constexpr static uint ALL_THREAD_RES = THCON | UNPACK | PACK | MATH | XMOV;


    constexpr static uint STALL_TDMA = 0x1;
    constexpr static uint STALL_SYNC = 0x2;
    constexpr static uint STALL_PACK = 0x4;
    constexpr static uint STALL_UNPACK = 0x8;

    constexpr static uint STALL_XMOV = 0x10;
    constexpr static uint STALL_THCON = 0x20;
    constexpr static uint STALL_MATH = 0x40;
    constexpr static uint STALL_CFG = 0x80;
    constexpr static uint STALL_SFPU = 0x100;
    constexpr static uint STALL_THREAD = 0x1ff;

    constexpr static uint STALL_ON_ZERO = 0x1;
    constexpr static uint STALL_ON_MAX = 0x2;

    constexpr static uint SEMAPHORE_0 = 0x1;
    constexpr static uint SEMAPHORE_1 = 0x2;
    constexpr static uint SEMAPHORE_2 = 0x4;
    constexpr static uint SEMAPHORE_3 = 0x8;
    constexpr static uint SEMAPHORE_4 = 0x10;
    constexpr static uint SEMAPHORE_5 = 0x20;
    constexpr static uint SEMAPHORE_6 = 0x40;
    constexpr static uint SEMAPHORE_7 = 0x80;
    constexpr static uint SEMAPHORE_BIAS = SEMAPHORE_4;
};

struct p_zeroacc
{
    constexpr static uint CLR_SPECIFIC = 0b000;
    constexpr static uint CLR_16 = 0b001;
    constexpr static uint CLR_HALF = 0b010;
    constexpr static uint CLR_ALL = 0b011;
    constexpr static uint CLR_HALF_32B = 0b110;
    constexpr static uint CLR_ALL_32B = 0b111;
};

struct p_zerosrc
{
    constexpr static uint CLR_A = 0x1;
    constexpr static uint CLR_B = 0x2;
    constexpr static uint CLR_AB = 0x3;
};

struct p_shiftx
{
    constexpr static uint SHIFT_1 = 0x0;
    constexpr static uint SHIFT_2 = 0x1;
    constexpr static uint SHIFT_4 = 0x2;
    constexpr static uint SHIFT_8 = 0x3;

    constexpr static uint RESERVED0 = 0x0;
    constexpr static uint RESERVED1 = 0x1;
    constexpr static uint RIGHT_AWAY0 = 0x2;
    constexpr static uint LEFT_TOWARD0 = 0x3;
};

struct p_cfg
{
    constexpr static uint WRCFG_128b = 0x1;
    constexpr static uint WRCFG_32b = 0x0;
};

struct p_alu
{
    constexpr static uint AND = 0x0;
    constexpr static uint OR = 0x1;
    constexpr static uint XOR = 0x2;
};

struct p_gpool
{
    constexpr static uint DIM_1X16 = 0x0;
    constexpr static uint DIM_16X16 = 0x1;
    constexpr static uint INDEX_DIS = 0x0;
    constexpr static uint INDEX_EN = 0x1;
};

struct p_elwise
{
    constexpr static uint SRCB_NO_BCAST = 0x0;
    constexpr static uint DEST_ACCUM_EN = 0x1;
    constexpr static uint DEST_ACCUM_DIS = 0x0;
    constexpr static uint SRCB_BCAST_COL = 0x1;
    constexpr static uint SRCB_BCAST_ROW = 0x2;
    constexpr static uint SRCB_BCAST_ALL = 0x3;

    constexpr static uint CLR_A = 0x1;
    constexpr static uint CLR_B = 0x2;
    constexpr static uint CLR_AB = 0x3;
};

struct p_sfpu
{

    constexpr static uint LREG0 = 0;
    constexpr static uint LREG1 = 1;
    constexpr static uint LREG2 = 2;
    constexpr static uint LREG3 = 3;
    constexpr static uint LREG4 = 4;
    constexpr static uint LREG5 = 5;
    constexpr static uint LREG6 = 6;
    constexpr static uint LREG7 = 7;


    constexpr static uint LCONST_0_8373 = 8;
    constexpr static uint LCONST_0 = 9;
    constexpr static uint LCONST_1 = 10;


    constexpr static uint LREG11 = 11;
    constexpr static uint LREG12 = 12;
    constexpr static uint LREG13 = 13;
    constexpr static uint LREG14 = 14;
    constexpr static uint LCONST_neg1 = 11;

    constexpr static uint LTILEID = 15;

    constexpr static uint kCONST_1_FP16B = 0x3F80;
    constexpr static uint kCONST_1_FP16A = 0x3C00;
    constexpr static uint kCONST_0 = 0x0000;
    constexpr static uint kCONST_Exp_8Bit = 0;
    constexpr static uint kCONST_Exp_5Bit = 1;
};

struct p_sfpswap
{

    constexpr static uint UNCONDITIONALLY = 0;
    constexpr static uint ALL_ROWS_MAX = 1;
    constexpr static uint ROWS_01_MAX = 2;
    constexpr static uint ROWS_02_MAX = 3;
    constexpr static uint ROWS_03_MAX = 4;
    constexpr static uint ROW_0_MAX = 5;
    constexpr static uint ROW_1_MAX = 6;
    constexpr static uint ROW_2_MAX = 5;
    constexpr static uint ROW_3_MAX = 6;
};

struct p_exp
{
    constexpr static uint FRAC_BITS = 3;
    constexpr static uint C23_73 = 0x4340;





    constexpr static uint ADJ_EXP = 0xBD3F;
};

struct p_setdmareg
{
    constexpr static uint PAYLOAD_IMMEDIATE = 0;
    constexpr static uint PAYLOAD_16BIT = 0;
    constexpr static uint PAYLOAD_32BIT = 1;
    constexpr static uint PAYLOAD_128BIT = 2;
    constexpr static uint PAYLOAD_TILE_HEADER = 3;

    constexpr static uint MODE_IMMEDIATE = 0;
    constexpr static uint MODE_SIGNAL = 1;
};

struct p_mop
{
    constexpr static uint MASK_LOOP = 0;
    constexpr static uint DOUBLE_LOOP = 1;
};

struct p_adddmareg
{
    constexpr static uint REG_PLUS_REG = 0;
    constexpr static uint REG_PLUS_IMM = 1;
};

constexpr static uint REG2FLOP_FLOP_INDEX(uint addr)
{
    return addr - 52;
}

struct p_reg2flop
{
    constexpr static uint WRITE_16B = 0;
    constexpr static uint WRITE_4B = 1;
    constexpr static uint WRITE_2B = 2;
    constexpr static uint WRITE_1B = 3;
};





}




       

namespace ckernel
{

enum VectorMode
{
    None = 0,
    R = 1,
    C = 2,
    RC = 4,
    RC_custom = 6,
    Invalid = 0xFF,
};

enum ReduceDim
{
    REDUCE_ROW,
    REDUCE_COL,
    REDUCE_SCALAR,
};

enum TileDim
{
    R_IDX = 0,
    C_IDX = 1,
};

enum PoolType
{
    SUM,
    AVG,
    MAX,
};

enum DataCopyType
{
    A2D,
    B2D,
};

enum EltwiseBinaryType
{
    ELWMUL,
    ELWDIV,
    ELWADD,
    ELWSUB,
    ELWLESS,
};

enum class EltwiseBinaryReuseDestType
{
    NONE = 0,
    DEST_TO_SRCA = 1,
    DEST_TO_SRCB = 2,
};

enum DstSync
{
    SyncHalf = 0,
    SyncFull = 1,
};

enum BroadcastType
{
    NONE = 0x0,
    COL = 0x1,
    ROW = 0x2,
    SCALAR = 0x3,
};

enum src_op_id_e
{
    OP_SRC0 = 0,
    OP_SRC1 = 1,
    OP_SRC2 = 2,
    OP_SRC3 = 3,
    OP_SRC4 = 4,
};

enum local_op_id_e
{
    OP_LOCAL0 = 0,
    OP_LOCAL1 = 1,
    OP_LOCAL2 = 2,
    OP_LOCAL3 = 3,
    OP_LOCAL4 = 4,
};

enum out_op_id_e
{
    OUT_ID0 = 0,
    OUT_ID1 = 1,
    OUT_ID2 = 2,
    OUT_ID3 = 3,
    OUT_ID4 = 4,
};

enum ReluType
{
    NO_RELU,
    ZERO_RELU,
    MIN_THRESHOLD_RELU,
    MAX_THRESHOLD_RELU,
};

constexpr bool UnpackToDestEn = true;
constexpr bool UnpackToDestDis = false;
enum struct StochRndType
{
    None = 0,
    Fpu = 1,
    Pack = 2,
    All = 0xf,
};


enum InstrModLoadStore
{
    DEFAULT = 0,
    FP16A = 1,
    FP16B = 2,
    FP32 = 3,
    INT32 = 4,
    INT8 = 5,
    LO16 = 6,
    HI16 = 7,
    INT32_2S_COMP = 12,
    INT8_2S_COMP = 13,
    LO16_ONLY = 14,
    HI16_ONLY = 15
};

}




       








       



       

namespace ckernel
{

constexpr uint8_t ADDR_MOD_0 = 0;
constexpr uint8_t ADDR_MOD_1 = 1;
constexpr uint8_t ADDR_MOD_2 = 2;
constexpr uint8_t ADDR_MOD_3 = 3;
constexpr uint8_t ADDR_MOD_4 = 4;
constexpr uint8_t ADDR_MOD_5 = 5;
constexpr uint8_t ADDR_MOD_6 = 6;
constexpr uint8_t ADDR_MOD_7 = 7;

constexpr uint32_t SRC_INCR_MASK = 0x3F;
constexpr uint32_t DEST_INCR_MASK = 0x3FF;



struct addr_mod_t
{

    struct addr_mod_src_t
    {
        uint8_t incr = 0;
        uint8_t clr = 0;
        uint8_t cr = 0;

        constexpr uint8_t val() const
        {
            return (incr & SRC_INCR_MASK) | ((cr & 0x1) << 6) | ((clr & 0x1) << 7);
        }
    };


    struct addr_mod_dest_t
    {
        int16_t incr = 0;
        uint8_t clr = 0;
        uint8_t cr = 0;
        uint8_t c_to_cr = 0;

        constexpr uint16_t val() const
        {
            return (incr & DEST_INCR_MASK) | ((cr & 0x1) << 10) | ((clr & 0x1) << 11) | ((c_to_cr & 0x1) << 12);
        }
    };


    struct addr_mod_fidelity_t
    {
        uint8_t incr = 0;
        uint8_t clr = 0;

        constexpr uint16_t val() const
        {
            return (incr & 0x3) | ((clr & 0x1) << 2);
        }
    };


    struct addr_mod_bias_t
    {
        uint8_t incr = 0;
        uint8_t clr = 0;

        constexpr uint16_t val() const
        {
            return (incr & 0xF) | ((clr & 0x1) << 4);
        }
    };


    addr_mod_src_t srca = {};
    addr_mod_src_t srcb = {};
    addr_mod_dest_t dest = {};
    addr_mod_fidelity_t fidelity = {};
    addr_mod_bias_t bias = {};
    addr_mod_src_t pack_ysrc = {};
    addr_mod_src_t pack_ydst = {};


    constexpr uint16_t src_val() const
    {
        return srca.val() | (srcb.val() << 8);
    }

    constexpr uint16_t pack_val() const
    {
        return pack_ysrc.val() | (pack_ydst.val() << 6);
    }


    constexpr static uint32_t addr_mod_src_reg_addr[] = {
        7,
        9,
        11,
        13,
        15,
        17,
        19,
        21};

    constexpr static uint32_t addr_mod_dest_reg_addr[] = {
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30};

    constexpr static uint32_t addr_mod_bias_reg_addr[] = {
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55};

    constexpr static uint32_t addr_mod_pack_reg_addr[] = {
        31, 32, 33, 34};


    __attribute__((always_inline)) inline void set(const uint8_t mod_index) const
    {


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((addr_mod_src_reg_addr[mod_index]) << 16) + ((srca.val() | (srcb.val() << 8)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((addr_mod_dest_reg_addr[mod_index]) << 16) + ((dest.val() | (fidelity.val() << 13)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((addr_mod_bias_reg_addr[mod_index]) << 16) + ((bias.val()) << 0))))));
    }
};

struct addr_mod_pack_t
{

    struct addr_mod_vals_t
    {
        uint8_t incr = 0;
        uint8_t clr = 0;
        uint8_t cr = 0;

        constexpr uint8_t val() const
        {
            return (incr & 0xF) | ((cr & 0x1) << 4) | ((clr & 0x1) << 5);
        }
    };

    struct addr_mod_reduced_t
    {
        uint8_t incr = 0;
        uint8_t clr = 0;

        constexpr uint8_t val() const
        {
            return (incr & 0x1) | ((clr & 0x1) << 1);
        }
    };


    addr_mod_vals_t y_src = {};
    addr_mod_vals_t y_dst = {};
    addr_mod_reduced_t z_src = {};
    addr_mod_reduced_t z_dst = {};

    __attribute__((always_inline)) inline constexpr uint16_t pack_val() const
    {
        return y_src.val() | (y_dst.val() << 6) | (z_src.val() << 12) | (z_dst.val() << 14);
    }


    constexpr static uint32_t addr_mod_pack_reg_addr[] = {
        31, 32, 33, 34};


    __attribute__((always_inline)) inline void set(const uint8_t mod_index) const
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((addr_mod_pack_reg_addr[mod_index]) << 16) + ((pack_val()) << 0))))));
    }
};

}




       
namespace ckernel
{

enum Srcs
{
    SrcA = 0,
    SrcB = 1,
    SrcC = 2
};

enum Unpackers
{
    Unp0 = 0,
    Unp1 = 1,
    UnpAll = 2
};

enum DstStart
{
    StartZero = 0,
    StartHalf = 1
};

enum DstClear
{
    ClearRow = 0,
    Clear16Rows = 1,
    ClearHalf = 2,
    ClearFull = 3
};

enum ThreadId
{
    UnpackThreadId = 0,
    MathThreadId = 1,
    PackThreadId = 2
};

enum DstTileLayout
{
    Default,
    Interleaved,






};

enum DstTileFaceLayout
{
    RowMajor,
    ColMajor,
};

enum DstTileShape
{
    Tile32x32 = 0,
    Tile32x16 = 1,
    Tile16x16 = 2
};
enum class ParallelPackerMode
{
    Disabled,
    SingleFTEntry,
    MultiFTEntry,
    TileParallel
};

enum register_space_e
{
    TDMA_REGS = 0x0,
    LOCAL_REGS = 0x1,
    ADDR_COUNTERS = 0x2
};

enum PackSelMask
{
    PACK_ALL = 0xF,
    PACK_0 = 0x1,
    PACK_1 = 0x2,
    PACK_2 = 0x4,
    PACK_3 = 0x8,
    PACK_01 = 0x3,
    PACK_23 = 0xC
};

enum SortDir : bool
{
    ArgMax = false,
    ArgMin = true,
};

constexpr std::uint32_t FACE_HEIGHT = 16;
constexpr std::uint32_t FACE_WIDTH = 16;
constexpr std::uint32_t TILE_HEIGHT = 32;
constexpr std::uint32_t TILE_WIDTH = 32;
constexpr std::uint32_t DATUMS_PER_ROW = 16;
constexpr std::uint32_t TILE_HEADER_SIZE = 1;

constexpr std::uint32_t FACE_R_DIM = FACE_HEIGHT;
constexpr std::uint32_t FACE_C_DIM = FACE_WIDTH;

constexpr std::uint32_t TILE_R_DIM = TILE_HEIGHT;
constexpr std::uint32_t TILE_C_DIM = TILE_WIDTH;

constexpr std::uint32_t TILE_NUM_FACES = ((TILE_R_DIM * TILE_C_DIM) / (FACE_R_DIM * FACE_C_DIM));

constexpr uint32_t DEST_NUM_TILES_FP16 = (DEST_REGISTER_FULL_SIZE * DEST_FACE_WIDTH) / (TILE_HEIGHT * TILE_HEIGHT);
constexpr uint32_t DEST_NUM_TILES_FP16_HALF = DEST_NUM_TILES_FP16 / 2;
static_assert((DEST_NUM_TILES_FP16 & (DEST_NUM_TILES_FP16 - 1)) == 0);





constexpr static std::uint32_t GET_L1_HEADERLESS_TILE_SIZE(uint format)
{
    switch (format & 0xF)
    {
        case ((uint8_t)DataFormat::Int32):
        case ((uint8_t)DataFormat::Float32):
            return (4096 >> 4);
        case ((uint8_t)DataFormat::Float16):
        case ((uint8_t)DataFormat::Float16_b):
            return (2048 >> 4);
        case ((uint8_t)DataFormat::Bfp8):
        case ((uint8_t)DataFormat::Bfp8_b):
            return ((1024 >> 4) + (64 >> 4));
        case ((uint8_t)DataFormat::Bfp4):
        case ((uint8_t)DataFormat::Bfp4_b):
            return ((512 >> 4) + (64 >> 4));
        case ((uint8_t)DataFormat::Bfp2):
        case ((uint8_t)DataFormat::Bfp2_b):
            return ((256 >> 4) + (64 >> 4));
        case ((uint8_t)DataFormat::Int8):
        case ((uint8_t)DataFormat::Lf8):
            return (1024 >> 4);
        default:
            return ((1024 >> 4) + (64 >> 4));
    };
}

constexpr static bool IS_BFP_FORMAT(uint format)
{
    switch (format & 0xF)
    {
        case ((uint8_t)DataFormat::Bfp8):
        case ((uint8_t)DataFormat::Bfp8_b):
        case ((uint8_t)DataFormat::Bfp4):
        case ((uint8_t)DataFormat::Bfp4_b):
        case ((uint8_t)DataFormat::Bfp2):
        case ((uint8_t)DataFormat::Bfp2_b):
            return true;
        default:
            return false;
    };
}

constexpr static bool IS_BFP_A_FORMAT(uint format)
{
    switch (format & 0xF)
    {
        case ((uint8_t)DataFormat::Bfp8):
        case ((uint8_t)DataFormat::Bfp4):
        case ((uint8_t)DataFormat::Bfp2):
            return true;
        default:
            return false;
    };
}

constexpr static bool IS_A_FORMAT(uint format)
{
    switch (format & 0xF)
    {
        case ((uint8_t)DataFormat::Lf8):
        case ((uint8_t)DataFormat::Float16):
        case ((uint8_t)DataFormat::Bfp8):
        case ((uint8_t)DataFormat::Bfp4):
        case ((uint8_t)DataFormat::Bfp2):
            return true;
        default:
            return false;
    };
}

constexpr static std::uint32_t SCALE_DATUM_SIZE(uint format, uint datum_count)
{
    switch (static_cast<DataFormat>(format & 0xF))
    {
        case DataFormat::Int32:
        case DataFormat::Float32:
            return datum_count << 2;

        case DataFormat::Float16:
        case DataFormat::Float16_b:
        case DataFormat::UInt16:
            return datum_count << 1;

        default:
            return datum_count;
    };
}




enum class ActivationType
{
    Celu = 0,
    Elu = 1,
    Gelu = 2,
    Hardtanh = 3,
    Hardsigmoid = 4,
};

enum class BinaryOp : uint8_t
{
    ADD = 0,
    SUB = 1,
    MUL = 2,
    DIV = 3,
    RSUB = 4,
    POW = 5,
    XLOGY = 6,
    RSHFT = 7,
    LSHFT = 8,
    LOGICAL_RSHFT = 9
};

}




       


namespace ckernel
{


struct p_gpr
{
    constexpr static uint ZERO = 0;
    constexpr static uint DBG_RESERVED = 1;
    constexpr static uint DBG_MSG = 2;
    constexpr static uint DBG_CKID = 3;
};


struct p_gpr_unpack
{
    constexpr static uint OPERAND_BASE_ADDR = 4;
    constexpr static uint OPERAND_OFFSET_ADDR = 5;
    constexpr static uint ZERO_0 = 8;
    constexpr static uint ZERO_1 = 9;
    constexpr static uint ZERO_2 = 10;
    constexpr static uint ZERO_3 = 11;
    constexpr static uint TMP0 = 12;
    constexpr static uint TMP1 = 13;
    constexpr static uint TILE_SIZE = 14;
    constexpr static uint TILE_OFFSET = 15;
    constexpr static uint L1_BUFFER_ADDR = 17;
    constexpr static uint TMP_LO = 18;
    constexpr static uint TMP_HI = 19;
    constexpr static uint PERF_FIRST_UNP_LO = 32;
    constexpr static uint PERF_FIRST_UNP_HI = 33;
    constexpr static uint TILE_SIZE_A = 36;
    constexpr static uint TILE_SIZE_B = 37;
    constexpr static uint KT_DIM = 38;
    constexpr static uint FACE_DIM_16x16 = 40;
    constexpr static uint FACE_DIM_8x16 = 41;
    constexpr static uint FACE_DIM_4x16 = 42;
    constexpr static uint FACE_DIM_2x16 = 43;
    constexpr static uint FACE_DIM_1x16 = 44;
    constexpr static uint PERF_UNPACK_NUM_TILES_0 = 45;
    constexpr static uint PERF_UNPACK_NUM_TILES_1 = 46;
    constexpr static uint PERF_UNPACK_NUM_TILES_2 = 47;
    constexpr static uint PERF_UNPACK_NUM_TILES_3 = 48;
    constexpr static uint UNPACK_STRIDE = 52;

    constexpr static uint SR_UNPACK_TILIZER_STATE_0 = 54;
    constexpr static uint SR_UNPACK_TILIZER_STATE_1 = 55;
    constexpr static uint SR_UNPACK_UNTILIZER_STATE_0 = 56;
    constexpr static uint SR_UNPACK_UNTILIZER_STATE_1 = 57;
    constexpr static uint SR_UNPACK_UNTILIZER_STATE_2 = 58;
    constexpr static uint SR_UNPACK_UNTILIZER_STATE_3 = 59;
};


struct p_gpr_math
{
    constexpr static uint PERF_DBUS_CNTL = 4;
    constexpr static uint PERF_MEM_DUMP_CNTL_CLEAR = 5;
    constexpr static uint PERF_MEM_DUMP_CNTL_SET = 6;
    constexpr static uint PERF_CNT_START = 7;
    constexpr static uint PERF_CNT_STOP = 8;
    constexpr static uint PERF_EPOCH_BASE_ADDR = 9;
    constexpr static uint PERF_EPOCH_OFFSET = 10;
    constexpr static uint DEST_OP0_BASE = 48;
    constexpr static uint DEST_OP1_BASE = 49;
    constexpr static uint DEST_REGW_OFFSET = 50;
    constexpr static uint DEST_REGW_INCR = 51;
    constexpr static uint DEST_REGW_OFFSET2 = 52;
    constexpr static uint DEST_REGW_INCR2 = 53;
    constexpr static uint TMP0 = 60;
    constexpr static uint NUM_DRAM_REQS = 61;
};


struct p_gpr_pack
{
    constexpr static uint DEST_OFFSET_LO = 4;
    constexpr static uint DEST_OFFSET_HI = 8;
    constexpr static uint OUTPUT_ADDR = 12;
    constexpr static uint TILE_HEADER = 16;

    constexpr static uint TEMP_TILE_OFFSET = 20;
    constexpr static uint NUM_MSGS_RECEIVED = 24;
    constexpr static uint ONE_MSG_RECEIVED = 25;
    constexpr static uint HEADER_ADDR = 26;
    constexpr static uint TMP0 = 28;
    constexpr static uint TMP1 = 29;
    constexpr static uint TMP_LO = 30;
    constexpr static uint TMP_HI = 31;
    constexpr static uint PACK_STREAM_SYNC = 32;
    constexpr static uint OUTPUT_ADDR_OFFSET = 50;
    constexpr static uint PERF_PACK_NUM_TILES = 51;
    constexpr static uint EXP0_SEC_SIZE_BFP = 52;
    constexpr static uint EXP1_SEC_SIZE_BFP8 = 53;
    constexpr static uint EXP2_SEC_SIZE_BFP8 = 54;
    constexpr static uint EXP3_SEC_SIZE_BFP8 = 55;
    constexpr static uint EXP1_SEC_SIZE_BFP4 = 57;
    constexpr static uint EXP2_SEC_SIZE_BFP4 = 58;
    constexpr static uint EXP3_SEC_SIZE_BFP4 = 59;
    constexpr static uint EXP1_SEC_SIZE_BFP2 = 61;
    constexpr static uint EXP2_SEC_SIZE_BFP2 = 62;
    constexpr static uint EXP3_SEC_SIZE_BFP2 = 63;
};

}

namespace ckernel
{

constexpr uint PACK_FLUSH_COUNTERS =
    (1 << 0) | (1 << 8) |
    (1 << 16);

constexpr uint RESET_VAL = 0;
constexpr uint KERNEL_IN_PROGRESS = 15;
constexpr uint KERNEL_COMPLETE = 1;

extern volatile uint __attribute__((rvtt_reg_ptr)) *reg_base;
extern volatile uint __attribute__((rvtt_reg_ptr)) *pc_buf_base;
extern volatile uint __attribute__((rvtt_reg_ptr)) *regfile;




}
extern volatile uint32_t __instrn_buffer[];
namespace ckernel
{
constexpr volatile uint32_t(__attribute__((rvtt_reg_ptr)) &instrn_buffer)[] = __instrn_buffer;



extern volatile uint __attribute__((rvtt_reg_ptr)) *mailbox_base[4];
extern volatile uint __attribute__((rvtt_reg_ptr)) *dbg_event_scratch;
extern volatile uint __attribute__((rvtt_reg_ptr)) *trisc_l1_mailbox;
extern volatile uint8_t __attribute__((rvtt_l1_ptr)) *debug_buffer;

extern uint32_t cfg_state_id;
extern uint32_t dest_offset_id;
extern uint32_t dbg_event_index;
extern uint32_t dbg_event_end;

extern volatile uint16_t __attribute__((rvtt_reg_ptr)) *debug_mailbox_base;
extern uint8_t mailbox_index;
const extern uint8_t mailbox_end;


namespace internal
{
}

inline void tensix_sync()
{
    volatile uint foo = 0;
    volatile uint *fooptr = &foo;

    pc_buf_base[1] = foo;


    *fooptr = pc_buf_base[1];
}

inline void mop_sync()
{
    volatile uint foo = 0;
    volatile uint *fooptr = &foo;

    pc_buf_base[2] = foo;


    *fooptr = pc_buf_base[2];
}

inline void sync_regfile_write(const uint index);


template <typename T>
static constexpr bool is_valid(const T val, const uint8_t wid)
{
    const T mask = (1 << wid) - 1;
    return (val & mask) == val;
}

inline void mmio_register_write(register_space_e space, uint addr, uint data)
{
    const uint regaddr = (space << 6) | (addr & 0x3F);
    reg_base[regaddr] = data;
}

inline uint8_t semaphore_read(const uint8_t index)
{
    return pc_buf_base[PC_BUF_SEMAPHORE_BASE + index];
}

inline void semaphore_post(const uint8_t index)
{
    pc_buf_base[PC_BUF_SEMAPHORE_BASE + index] = 0;
}

inline void semaphore_get(const uint8_t index)
{
    pc_buf_base[PC_BUF_SEMAPHORE_BASE + index] = 1;
}


template <uint WaitRes = p_stall::NONE>
inline void t6_semaphore_post(const uint8_t index)
{
    if constexpr (WaitRes != p_stall::NONE)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_SYNC) << 15) + ((WaitRes) << 0))))));
    }

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa4 << 24) + (((semaphore::t6_sem(index)) << 2))))));
}


template <uint WaitRes = p_stall::NONE>
inline void t6_semaphore_get(const uint8_t index)
{
    if constexpr (WaitRes != p_stall::NONE)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_SYNC) << 15) + ((WaitRes) << 0))))));
    }

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa5 << 24) + (((semaphore::t6_sem(index)) << 2))))));
}

template <uint WaitRes>
inline void t6_semaphore_wait_on_max(const uint8_t index)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa6 << 24) + (((WaitRes) << 15) + ((semaphore::t6_sem(index)) << 2) + ((p_stall::STALL_ON_MAX) << 0))))));
}

template <uint WaitRes>
inline void t6_semaphore_wait_on_zero(const uint8_t index)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa6 << 24) + (((WaitRes) << 15) + ((semaphore::t6_sem(index)) << 2) + ((p_stall::STALL_ON_ZERO) << 0))))));
}


inline void t6_semaphore_init(const uint8_t index, const uint8_t min_value, const uint8_t max_value)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa3 << 24) + (((max_value) << 20) + ((min_value) << 16) + ((semaphore::t6_sem(index)) << 2))))));
}

inline void t6_mutex_acquire(const uint8_t index)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa0 << 24) + (((index) << 0))))));
}

inline void t6_mutex_release(const uint8_t index)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa1 << 24) + (((index) << 0))))));
}


inline uint cfg_addr(uint cfg_addr32)
{
    return (cfg_state_id == 0) ? cfg_addr32 : (47 * 4) + cfg_addr32;
}

inline void cfg_write(uint cfg_addr32, uint data)
{

    volatile uint __attribute__((rvtt_reg_ptr)) *cfg_regs = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEF0000);
    cfg_regs[cfg_addr(cfg_addr32)] = data;
}

inline uint cfg_read(uint cfg_addr32)
{

    volatile uint *cfg_regs = reinterpret_cast<volatile uint *>(0xFFEF0000);
    return cfg_regs[cfg_addr(cfg_addr32)];
}


inline volatile uint *__attribute__((rvtt_reg_ptr)) get_cfg_pointer()
{
    if (cfg_state_id == 0)
    {
        return reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEF0000);
    }

    return reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEF0000 + 47 * 16);
}

inline volatile uint short *__attribute__((rvtt_reg_ptr)) get_cfg16_pointer()
{
    if (cfg_state_id == 0)
    {
        return reinterpret_cast<volatile uint short __attribute__((rvtt_reg_ptr)) *>(0xFFEF0000);
    }

    return reinterpret_cast<volatile uint short __attribute__((rvtt_reg_ptr)) *>(0xFFEF0000 + 47 * 16);
}

inline void flip_cfg_state_id()
{
    cfg_state_id = 1 - cfg_state_id;
    ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((0) << 16) + ((cfg_state_id) << 0)));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
}

inline void reset_cfg_state_id()
{
    cfg_state_id = 0;
}

inline void reset_dest_offset_id()
{
    dest_offset_id = 0;
}

inline void update_dest_offset_id()
{

    dest_offset_id = 1 - dest_offset_id;
}

inline uint32_t get_dest_buffer_base()
{
    return (0 != dest_offset_id) ? DEST_REGISTER_HALF_SIZE : 0x0;
}


inline void mop_run(const uint8_t type, const uint8_t count)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((type) << 23) + ((count - 1) << 16) + ((0) << 0))))));
}





inline uint reg_read(uint32_t addr)
{
    volatile uint __attribute__((rvtt_reg_ptr)) *p_reg = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(addr);
    return p_reg[0];
}

inline void reg_write(uint32_t addr, uint32_t data)
{
    volatile uint __attribute__((rvtt_reg_ptr)) *p_reg = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(addr);
    p_reg[0] = data;
}

inline void wait(uint32_t cycles)
{
    volatile uint __attribute__((rvtt_reg_ptr)) *clock_lo = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>((0xFFB12000 | 0x1F0));
    volatile uint __attribute__((rvtt_reg_ptr)) *clock_hi = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>((0xFFB12000 | 0x1F8));
    uint64_t wall_clock_timestamp = clock_lo[0] | ((uint64_t)clock_hi[0] << 32);
    uint64_t wall_clock = 0;
    do
    {
        wall_clock = clock_lo[0] | ((uint64_t)clock_hi[0] << 32);
    } while (wall_clock < (wall_clock_timestamp + cycles));
}


inline void zeroacc()
{

    addr_mod_t {
        .srca = {.incr = 0},
        .srcb = {.incr = 0},
        .dest = {.incr = 0},
    }
        .set(ADDR_MOD_1);
    ckernel::instrn_buffer[0] = ((0x10 << 24) + (((p_zeroacc::CLR_ALL) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0)));
}

inline void zerosrc()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x11 << 24) + (((0) << 4) + ((0) << 3) + ((1) << 2) + ((3) << 0))))));
}

inline void sync_regfile_write(const uint index)
{
    volatile uint foo = 0x0;
    volatile uint *fooptr = &foo;
    *fooptr = regfile[index];
}

inline void cfg_rmw(uint32_t cfg_addr32, uint32_t cfg_shamt, uint32_t cfg_mask, uint32_t val)
{
    uint32_t wrdata = val;



    const uint32_t addr = (cfg_state_id == 0) ? cfg_addr32 : (47 * 4) + cfg_addr32;


    volatile uint __attribute__((rvtt_reg_ptr)) *cfg_regs = reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEF0000);
    uint32_t cfg_data = cfg_regs[addr];


    wrdata <<= cfg_shamt;
    wrdata &= cfg_mask;


    cfg_data &= ~cfg_mask;


    cfg_data |= wrdata;


    cfg_regs[addr] = cfg_data;
}

inline void cfg_rmw_gpr(uint32_t cfg_addr32, uint32_t cfg_shamt, uint32_t cfg_mask, uint32_t gpr_index)
{
    const uint32_t wrdata = regfile[gpr_index];
    cfg_rmw(cfg_addr32, cfg_shamt, cfg_mask, wrdata);
}

template <uint CfgAddr32, uint Shamt, uint Mask>
inline void cfg_reg_rmw_tensix(uint32_t val)
{
    uint32_t wrdata = val << Shamt;
    uint8_t mask_b0 = Mask & 0xff;

    if (mask_b0 != 0)
    {
        uint8_t data_b0 = wrdata & 0xff;
        ckernel::instrn_buffer[0] = ((0xb3 << 24) + (((mask_b0) << 16) + ((data_b0) << 8) + ((CfgAddr32) << 0)));
    }
    wrdata >>= 8;
    uint8_t mask_b1 = (Mask >> 8) & 0xff;

    if (mask_b1 != 0)
    {
        uint8_t data_b1 = (wrdata) & 0xff;
        ckernel::instrn_buffer[0] = ((0xb4 << 24) + (((mask_b1) << 16) + ((data_b1) << 8) + ((CfgAddr32) << 0)));
    }

    wrdata >>= 8;
    uint8_t mask_b2 = (Mask >> 16) & 0xff;

    if (mask_b2 != 0)
    {
        uint8_t data_b2 = (wrdata) & 0xff;
        ckernel::instrn_buffer[0] = ((0xb5 << 24) + (((mask_b2) << 16) + ((data_b2) << 8) + ((CfgAddr32) << 0)));
    }

    wrdata >>= 8;
    uint8_t mask_b3 = (Mask >> 24) & 0xff;
    if (mask_b3 != 0)
    {
        uint8_t data_b3 = (wrdata) & 0xff;
        ckernel::instrn_buffer[0] = ((0xb6 << 24) + (((mask_b3) << 16) + ((data_b3) << 8) + ((CfgAddr32) << 0)));
    }
}

inline void mailbox_write(const uint8_t thread, const uint32_t data)
{
    mailbox_base[thread + 1][0] = data;
}


inline uint32_t mailbox_read(const uint8_t thread)
{
    return mailbox_base[thread + 1][0];
}

inline bool mailbox_not_empty(const uint8_t thread)
{
    return mailbox_base[thread + 1][1] > 0;
}

inline void mailbox_write_full(const uint8_t thread, const uint32_t data)
{
    mailbox_base[thread][0] = data;
}


inline uint32_t mailbox_read_full(const uint8_t thread)
{
    return mailbox_base[thread][0];
}

inline bool mailbox_not_empty_full(const uint8_t thread)
{
    return mailbox_base[thread][1] > 0;
}

inline void trisc_l1_mailbox_write(const uint data)
{
    trisc_l1_mailbox[0] = data;
}

inline uint trisc_l1_mailbox_read()
{
    return trisc_l1_mailbox[0];
}

template <class T>
inline std::uint32_t memory_cast(T *object_ptr)
{
    return reinterpret_cast<uint32_t>(object_ptr);
}

inline void record_mailbox_value(uint16_t event_value)
{
    if (mailbox_index < mailbox_end)
    {
        debug_mailbox_base[mailbox_index] = event_value;
        mailbox_index++;
    }
}

inline void record_mailbox_value_with_index(uint8_t index, uint16_t event_value)
{
    if (index < mailbox_end)
    {
        debug_mailbox_base[index] = event_value;
    }
}


inline void clear_mailbox_values(uint16_t value = 0)
{
    for (int i = 0; i < mailbox_end; i++)
    {
        debug_mailbox_base[i] = value;
    }
}

inline uint64_t read_wall_clock()
{
    uint32_t timestamp_low = reg_read((0xFFB12000 | 0x1F0));
    uint32_t timestamp_high = reg_read((0xFFB12000 | 0x1F8));
    return ((uint64_t)timestamp_high << 32) | timestamp_low;
}

inline void record_kernel_runtime(uint64_t kernel_runtime)
{
    debug_mailbox_base[mailbox_end - 4] = kernel_runtime & 0xffff;
    debug_mailbox_base[mailbox_end - 3] = (kernel_runtime >> 16) & 0xffff;
    debug_mailbox_base[mailbox_end - 2] = (kernel_runtime >> 32) & 0xffff;
    debug_mailbox_base[mailbox_end - 1] = (kernel_runtime >> 48) & 0xffff;
}

void debug_dump(const uint8_t *data, uint32_t byte_size);
void debug_dump_seek(uint8_t offset);

inline void init_prng_seed(const uint seed)
{

    volatile uint __attribute__((rvtt_reg_ptr)) *cfg = get_cfg_pointer();
    cfg[164] = seed;


    for (int i = 0; i < 600; i++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    }
}

inline constexpr bool is_valid_instruction_mode(InstrModLoadStore mode)
{
    return mode == InstrModLoadStore::INT32_2S_COMP || mode == InstrModLoadStore::INT32 || mode == InstrModLoadStore::LO16;
}

}





       







constexpr std::uint32_t default_tile_dims[2] = {32, 32};

struct llk_unpack_A_params_t {
    std::uint32_t unpA_operand;
};

struct llk_unpack_AB_matmul_params_t {
    std::uint32_t unpA_operand;
    std::uint32_t unpB_operand;
    std::uint32_t transpose_xy_srca;
};

struct llk_unpack_AB_params_t {
    std::uint32_t unpA_operand;
    std::uint32_t unpB_operand;
};

struct llk_unpack_reduce_params_t {
    std::uint32_t unpA_operand;

};

struct llk_unpack_tilize_params_t {
    std::uint32_t unpA_operand;
    std::uint32_t unpA_block_c_dim;
};

struct llk_unpack_untilize_params_t {
    std::uint32_t unpA_operand;
};





struct llk_math_eltwise_binary_params_t {
    std::int32_t unused;
};

struct llk_math_eltwise_unary_params_t {
    std::int32_t sfpu_params[6];
    std::int32_t unused;
};

struct llk_math_matmul_params_t {
    std::int32_t unused;
};

struct llk_math_reduce_params_t {
    std::int32_t unused;
};





struct llk_relu_config_t {
    std::uint32_t
        ApplyRelu : 16;
    std::uint32_t Threshold : 16;
};

union llk_relu_config_u {
    llk_relu_config_t f;
    std::uint32_t val;
};

struct llk_pack_params_t {
    std::uint32_t pack_output;
    llk_relu_config_u relu_config;
    bool srnd_fpu_en;
};

using namespace ckernel;


       

constexpr std::int32_t unpack_src_format[32] = {
    5,5,5,5,5,5,5,5,5,255,5,5,5,5,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,
};
constexpr std::int32_t unpack_dst_format[32] = {
    5,5,5,5,5,5,5,5,5,255,5,5,5,5,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,
};
       

constexpr uint8_t unpack_tile_num_faces[32] = {
    4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,
};
constexpr uint8_t unpack_partial_face[32] = {
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
};
constexpr uint8_t unpack_tile_face_r_dim[32] = {
    16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,
};
constexpr uint8_t unpack_narrow_tile[32] = {
    0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
};
constexpr uint8_t unpack_tile_r_dim[32] = {
    32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,
};
constexpr uint8_t unpack_tile_c_dim[32] = {
    32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,
};
constexpr uint16_t unpack_tile_size[32] = {
    2048,2048,2048,2048,2048,2048,2048,2048,2048,1088,2048,2048,2048,2048,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,1088,
};
constexpr std::int32_t MATH_FIDELITY = 4;
constexpr bool APPROX = false;
constexpr bool DST_ACCUM_MODE = false;











       









       







namespace ckernel
{

struct dbg_cfgreg
{
    constexpr static uint32_t THREAD_0_CFG = 0;
    constexpr static uint32_t THREAD_1_CFG = 1;
    constexpr static uint32_t THREAD_2_CFG = 2;
    constexpr static uint32_t HW_CFG_0 = 3;
    constexpr static uint32_t HW_CFG_1 = 4;
    constexpr static uint32_t HW_CFG_SIZE = 187;
    constexpr static uint32_t THREAD_CFG_SIZE = 57;
};

struct dbg_array_id
{
    constexpr static uint32_t SRCA = 0;
    constexpr static uint32_t SRCB = 1;
    constexpr static uint32_t DEST = 2;
};

struct dbg_daisy_id
{
    constexpr static uint32_t INSTR_ISSUE_0 = 4;
    constexpr static uint32_t INSTR_ISSUE_1 = 5;
    constexpr static uint32_t INSTR_ISSUE_2 = 6;
};

typedef struct
{
    uint32_t sig_sel : 16;
    uint32_t daisy_sel : 8;
    uint32_t rd_sel : 4;
    uint32_t reserved_0 : 1;
    uint32_t en : 1;
    uint32_t reserved_1 : 2;
} dbg_bus_cntl_t;

typedef union
{
    uint32_t val;
    dbg_bus_cntl_t f;
} dbg_bus_cntl_u;

;

typedef struct
{
    uint32_t en : 1;
    uint32_t reserved : 31;
} dbg_array_rd_en_t;

typedef union
{
    uint32_t val;
    dbg_array_rd_en_t f;
} dbg_array_rd_en_u;

typedef struct
{
    uint32_t row_addr : 12;
    uint32_t row_32b_sel : 4;
    uint32_t array_id : 3;
    uint32_t bank_id : 1;
    uint32_t reserved : 12;
} dbg_array_rd_cmd_t;

typedef union
{
    uint32_t val;
    dbg_array_rd_cmd_t f;
} dbg_array_rd_cmd_u;

typedef struct
{
    uint32_t unp : 2;
    uint32_t pack : 4;
    uint32_t reserved : 26;
} dbg_soft_reset_t;

typedef union
{
    uint32_t val;
    dbg_soft_reset_t f;
} dbg_soft_reset_u;

;

template <ThreadId thread_id>
inline void dbg_thread_halt()
{
    static_assert(
        (thread_id == ThreadId::MathThreadId) || (thread_id == ThreadId::UnpackThreadId) || (thread_id == ThreadId::PackThreadId),
        "Invalid thread id set in dbg_wait_for_thread_idle(...)");

    if constexpr (thread_id == ThreadId::UnpackThreadId)
    {

        tensix_sync();

        mailbox_write(ThreadId::MathThreadId, 1);

        volatile uint32_t temp = mailbox_read(ThreadId::MathThreadId);
    }
    else if constexpr (thread_id == ThreadId::MathThreadId)
    {

        tensix_sync();

        volatile uint32_t temp = mailbox_read(ThreadId::UnpackThreadId);

        while (semaphore_read(semaphore::MATH_PACK) > 0)
        {
        };
    }
}

template <ThreadId thread_id>
inline void dbg_thread_unhalt()
{
    static_assert(
        (thread_id == ThreadId::MathThreadId) || (thread_id == ThreadId::UnpackThreadId) || (thread_id == ThreadId::PackThreadId),
        "Invalid thread id set in dbg_wait_for_thread_idle(...)");

    if constexpr (thread_id == ThreadId::MathThreadId)
    {

        dbg_soft_reset_u dbg_soft_reset;
        dbg_soft_reset.val = 0;
        dbg_soft_reset.f.pack = 1;
        reg_write((0xFFB12000 | 0x1B0), dbg_soft_reset.val);
        wait(5);
        dbg_soft_reset.val = 0;
        reg_write((0xFFB12000 | 0x1B0), dbg_soft_reset.val);


        tensix_sync();


        mailbox_write(ThreadId::UnpackThreadId, 1);
    }
}

inline void dbg_get_array_row(const uint32_t array_id, const uint32_t row_addr, uint32_t *rd_data)
{

    std::uint32_t dest_offset = 0;
    if (array_id == dbg_array_id::DEST)
    {
        dest_offset = (dest_offset_id == 1) ? DEST_REGISTER_HALF_SIZE : 0;
    }

    if (array_id == dbg_array_id::SRCA)
    {







        addr_mod_t {
            .srca = {.incr = 0, .clr = 0, .cr = 0},
            .srcb = {.incr = 0, .clr = 0, .cr = 0},
            .dest = {.incr = 0, .clr = 0, .cr = 0},
        }
            .set(ADDR_MOD_0);


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((0) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((0) << 14) + ((2) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::SFPU1) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((0b01) << 22) + ((0) << 0))))));


        ckernel::instrn_buffer[0] = ((0x09 << 24) + (((0) << 23) + ((row_addr) << 17) + ((0) << 15) + ((p_mova2d::MOV_1_ROW) << 12) + ((0) << 0)));


        tensix_sync();
    }
    else if (array_id == dbg_array_id::SRCB)
    {
        addr_mod_t {
            .srca = {.incr = 0, .clr = 0, .cr = 0},
            .srcb = {.incr = 0, .clr = 0, .cr = 0},
            .dest = {.incr = 0, .clr = 0, .cr = 0},
        }
            .set(ADDR_MOD_0);


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x57 << 24) + (((0b10) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((0b10) << 22) + ((0) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x57 << 24) + (((0b10) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x18 << 24) + (((ADDR_MOD_0) << 15) + ((0) << 10) + ((row_addr >> 1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((0b10) << 22) + ((0) << 0))))));


        tensix_sync();
    }


    std::uint32_t hw_row_addr = (array_id == dbg_array_id::SRCA) ? 0 : ((array_id == dbg_array_id::DEST) ? dest_offset + row_addr : row_addr & 0x1);

    std::uint32_t hw_array_id = (array_id == dbg_array_id::SRCA) ? dbg_array_id::DEST : array_id;

    std::uint32_t hw_bank_id = 0;

    bool sel_datums_15_8 = hw_array_id != dbg_array_id::DEST;

    dbg_array_rd_en_u dbg_array_rd_en;
    dbg_array_rd_en.val = 0;
    dbg_array_rd_en.f.en = 0x1;
    reg_write((0xFFB12000 | 0x060), dbg_array_rd_en.val);

    dbg_array_rd_cmd_u dbg_array_rd_cmd;
    dbg_array_rd_cmd.val = 0;
    dbg_array_rd_cmd.f.array_id = hw_array_id;
    dbg_array_rd_cmd.f.bank_id = hw_bank_id;

    for (uint32_t i = 0; i < 8; i++)
    {
        dbg_array_rd_cmd.f.row_addr = sel_datums_15_8 ? (hw_row_addr | ((i >= 4) ? (1 << 6) : 0)) : hw_row_addr;
        dbg_array_rd_cmd.f.row_32b_sel = i;
        reg_write((0xFFB12000 | 0x064), dbg_array_rd_cmd.val);
        wait(5);
        rd_data[i] = reg_read((0xFFB12000 | 0x06C));
    }


    dbg_array_rd_cmd.val = 0;
    reg_write((0xFFB12000 | 0x064), dbg_array_rd_cmd.val);
    dbg_array_rd_en.val = 0;
    reg_write((0xFFB12000 | 0x060), dbg_array_rd_en.val);


    if (array_id == dbg_array_id::SRCA)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((0) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((0) << 14) + ((2) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((1) << 22) + ((0) << 0))))));
    }
}

inline std::uint32_t dbg_read_cfgreg(const uint32_t cfgreg_id, const uint32_t addr)
{
    uint32_t hw_base_addr = 0;

    switch (cfgreg_id)
    {
        case dbg_cfgreg::HW_CFG_1:
            hw_base_addr = dbg_cfgreg::HW_CFG_SIZE;
            break;
        case dbg_cfgreg::THREAD_0_CFG:
        case dbg_cfgreg::THREAD_1_CFG:
        case dbg_cfgreg::THREAD_2_CFG:
            hw_base_addr = 2 * dbg_cfgreg::HW_CFG_SIZE + cfgreg_id * dbg_cfgreg::THREAD_CFG_SIZE;
            break;
        default:
            break;
    }

    uint32_t hw_addr = hw_base_addr + (addr & 0x7ff);
    reg_write((0xFFB12000 | 0x058), hw_addr);

    wait(1);

    return reg_read((0xFFB12000 | 0x078));
}

}










       







       



namespace ckernel
{

class ckernel_template
{
    const uint m_outer_loop_len;
    const uint m_inner_loop_len;
    uint m_loop_op0;
    uint m_loop_op1;
    uint m_end_op0, m_end_op1, m_start_op0;
    uint m_loop0_last_instr;

    uint m_loop1_last_instr;
public:
    ckernel_template(uint outer_loop_len, uint inner_loop_len, uint loop_op);
    ckernel_template(uint outer_loop_len, uint inner_loop_len, uint loop_op0, uint loop_op1);
    void set_loop_op0(uint loop_op);
    void set_loop_op1(uint loop_op);
    void set_end_ops(uint end_op0, uint end_op1);
    void set_end_op(uint end_op0);
    void set_start_op(uint start_op0);
    void set_last_inner_loop_instr(uint op);
    void set_last_outer_loop_instr(uint op);

    void program(volatile uint *instrn_buffer);
    static void run(volatile uint *instrn_buffer);
    void program_and_run(volatile uint *instrn_buffer);
};

class ckernel_unpack_template
{
    const bool m_unpackB;
    const bool m_unpack_halo;

    const uint m_A0_instr, m_A1_instr, m_A2_instr, m_A3_instr;
    const uint m_B_instr;

    const uint m_skipA_instr;
    const uint m_skipB_instr;

public:
    ckernel_unpack_template(
        bool unpackB,
        bool unpackHalo,
        uint A0_instr,
        uint A1_instr,
        uint A2_instr,
        uint A3_instr,
        uint skipA_instr,

        uint B_instr,
        uint skipB_instr) :
        m_unpackB(unpackB),
        m_unpack_halo(unpackHalo),
        m_A0_instr(A0_instr),
        m_A1_instr(A1_instr),
        m_A2_instr(A2_instr),
        m_A3_instr(A3_instr),
        m_B_instr(B_instr),
        m_skipA_instr(skipA_instr),
        m_skipB_instr(skipB_instr)
    {
    }

public:

    static constexpr uint DEF_ZEROSRCA = ((0x43 << 24) + (((p_unpacr_nop::UNP0) << 23) + ((p_unpacr_nop::UNP_ZEROSRC) << 0)));
    static constexpr uint DEF_NINFSRCA = ((0x43 << 24) + (((p_unpacr_nop::UNP0) << 23) + ((p_unpacr_nop::UNP_NEGINFSRC) << 0)));
    static constexpr uint DEF_UNPACR_NOP = ((0x43 << 24) + (((p_unpacr_nop::UNP0) << 23) + ((p_unpacr_nop::UNP_NOP) << 0)));


    static constexpr uint DEF_SKIP_A = ((0x55 << 24) + (((0b001) << 21) + ((0) << 15) + ((0) << 12) + ((0) << 9) + ((1) << 6)));
    static constexpr uint DEF_SKIP_B = ((0x55 << 24) + (((0b010) << 21) + ((0) << 15) + ((0) << 12) + ((0) << 9) + ((1) << 6)));


    static constexpr uint DEF_A_instr = ((0x42 << 24) + (((0) << 23) + ((0b1) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((0) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_A_cntx_ovrd_instr = ((0x42 << 24) + (((0) << 23) + ((0b1) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));


    static constexpr uint DEF_B_rarefy_instr = ((0x42 << 24) + (((1) << 23) + ((0b01) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((0) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_ENABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));


    static constexpr uint DEF_B_rarefy_cntx_ovrd_instr = ((0x42 << 24) + (((1) << 23) + ((0b01) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_ENABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));


    static constexpr uint DEF_B_cntx_ovrd_no_z_inc_instr = ((0x42 << 24) + (((1) << 23) + ((0b00) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));


    static constexpr uint DEF_B_cntx_ovrd_instr = ((0x42 << 24) + (((1) << 23) + ((0b01) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));


    static constexpr uint DEF_B_instr = ((0x42 << 24) + (((1) << 23) + ((0b01) << 15) + ((0) << 13) + ((0) << 10) + ((0) << 8) + ((0) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));


    static constexpr uint DEF_A0_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE0_CFG_CONTEXT) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A1_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE1_CFG_CONTEXT) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A2_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE2_CFG_CONTEXT) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A3_instr = ((0x42 << 24) + (((0) << 23) + ((0b01) << 15) + ((0) << 13) + ((p_unpacr::TILE3_CFG_CONTEXT) << 10) + ((p_unpacr::TILE3_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;


    static constexpr uint DEF_A0_last_instr = ((0x42 << 24) + (((0) << 23) + ((0b01) << 15) + ((0) << 13) + ((p_unpacr::TILE0_CFG_CONTEXT) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A1_last_instr = ((0x42 << 24) + (((0) << 23) + ((0b01) << 15) + ((0) << 13) + ((p_unpacr::TILE1_CFG_CONTEXT) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A2_last_instr = ((0x42 << 24) + (((0) << 23) + ((0b01) << 15) + ((0) << 13) + ((p_unpacr::TILE2_CFG_CONTEXT) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;


    static constexpr uint SKIP_A0_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((1) << 13) + ((p_unpacr::TILE0_CFG_CONTEXT) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint SKIP_A1_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((1) << 13) + ((p_unpacr::TILE1_CFG_CONTEXT) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint SKIP_A2_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((1) << 13) + ((p_unpacr::TILE2_CFG_CONTEXT) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint SKIP_A3_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((1) << 13) + ((p_unpacr::TILE3_CFG_CONTEXT) << 10) + ((p_unpacr::TILE3_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;


    static constexpr uint DEF_A0_fconv_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE0_CFG_CONTEXT) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A1_fconv_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE1_CFG_CONTEXT) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A2_fconv_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE2_CFG_CONTEXT) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A3_fconv_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE3_CFG_CONTEXT) << 10) + ((p_unpacr::TILE3_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;


    static constexpr uint DEF_A0_fconv_last_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE0_CFG_CONTEXT) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A1_fconv_last_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE1_CFG_CONTEXT) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;
    static constexpr uint DEF_A2_fconv_last_instr = ((0x42 << 24) + (((0) << 23) + ((0b00) << 15) + ((0) << 13) + ((p_unpacr::TILE2_CFG_CONTEXT) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((p_unpacr::AUTO_INC_CONTEXT) << 3) + ((1) << 2) + ((0) << 1) + ((1) << 0)))
                                                                                                                                                          ;

    static constexpr uint DEF_Strip0_instr = ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((0) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip1_instr = ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((1) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip2_instr = ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((2) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip3_instr = ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((3) << 10) + ((p_unpacr::TILE3_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((0) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));

    static constexpr uint DEF_Strip0_last_instr = ((0x42 << 24) + (((0) << 23) + ((1) << 15) + ((0) << 13) + ((0) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip1_last_instr = ((0x42 << 24) + (((0) << 23) + ((1) << 15) + ((0) << 13) + ((1) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip2_last_instr = ((0x42 << 24) + (((0) << 23) + ((1) << 15) + ((0) << 13) + ((2) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip3_last_instr = ((0x42 << 24) + (((0) << 23) + ((1) << 15) + ((0) << 13) + ((3) << 10) + ((p_unpacr::TILE3_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));

    static constexpr uint DEF_Strip0_data_valid_instr =
        ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((0) << 10) + ((p_unpacr::TILE0_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip1_data_valid_instr =
        ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((1) << 10) + ((p_unpacr::TILE1_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip2_data_valid_instr =
        ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((2) << 10) + ((p_unpacr::TILE2_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));
    static constexpr uint DEF_Strip3_data_valid_instr =
        ((0x42 << 24) + (((0) << 23) + ((0) << 15) + ((0) << 13) + ((3) << 10) + ((p_unpacr::TILE3_ADDRCNT_CONTEXT) << 8) + ((1) << 7) + ((1) << 6) + ((p_unpacr::RAREFYB_DISABLE) << 5) + ((0) << 4) + ((0) << 3) + ((0) << 2) + ((0) << 1) + ((1) << 0)));




    static ckernel_unpack_template lzA(bool neginf, uint A_instr = DEF_A_cntx_ovrd_instr, uint skipA_instr = DEF_SKIP_A);

    static ckernel_unpack_template lA(uint A_instr = DEF_A_cntx_ovrd_instr, uint skipA_instr = DEF_SKIP_A);

    static ckernel_unpack_template lB(uint B_instr = DEF_B_cntx_ovrd_instr, uint skipB_instr = DEF_SKIP_B);

    static ckernel_unpack_template lhA(const uint32_t halo_mask);

    static ckernel_unpack_template flhA(const uint32_t halo_mask);

    static ckernel_unpack_template lBhA(const uint32_t halo_mask, const bool rarefy = true);

    static ckernel_unpack_template flBhA(const uint32_t halo_mask);

    static ckernel_unpack_template lBA(
        uint A_instr = DEF_A_instr,
        uint skipA_instr = DEF_SKIP_A,

        uint B_instr = DEF_B_instr,
        uint skipB_instr = DEF_SKIP_B);


    static ckernel_unpack_template loopx1instr(uint instr0, uint skip0 = ((0x02 << 24) + 0));
    static ckernel_unpack_template loopx2instr(uint instr0, uint instr1, uint skip0 = ((0x02 << 24) + 0), uint skip1 = ((0x02 << 24) + 0));

    void program(volatile uint *instrn_buffer) const;
    static void run(volatile uint *instrn_buffer, const uint8_t count, const uint32_t zmask);
    static void run(volatile uint *instrn_buffer, const uint8_t count);
    void program_and_run(volatile uint *instrn_buffer, const uint8_t count, const uint32_t zmask = 0);
};

inline ckernel_template::ckernel_template(uint outer_loop_len, uint inner_loop_len, uint loop_op) :
    m_outer_loop_len(outer_loop_len),
    m_inner_loop_len(inner_loop_len),
    m_loop_op0(loop_op),
    m_loop_op1(((0x02 << 24) + 0)),
    m_end_op0(((0x02 << 24) + 0)),
    m_end_op1(((0x02 << 24) + 0)),
    m_start_op0(((0x02 << 24) + 0))
{
    m_loop0_last_instr = loop_op;
    m_loop1_last_instr = loop_op;
}

inline ckernel_template::ckernel_template(uint outer_loop_len, uint inner_loop_len, uint loop_op0, uint loop_op1) :
    m_outer_loop_len(outer_loop_len),
    m_inner_loop_len(inner_loop_len),
    m_loop_op0(loop_op0),
    m_loop_op1(loop_op1),
    m_end_op0(((0x02 << 24) + 0)),
    m_end_op1(((0x02 << 24) + 0)),
    m_start_op0(((0x02 << 24) + 0))
{
    m_loop0_last_instr = loop_op1;
    m_loop1_last_instr = loop_op1;
}

inline void ckernel_template::set_loop_op0(uint loop_op)
{
    m_loop_op0 = loop_op;
}

inline void ckernel_template::set_loop_op1(uint loop_op)
{
    m_loop_op1 = loop_op;
}

inline void ckernel_template::set_end_ops(uint end_op0, uint end_op1)
{
    m_end_op0 = end_op0;
    m_end_op1 = end_op1;
}

inline void ckernel_template::set_end_op(uint end_op0)
{
    set_end_ops(end_op0, ((0x02 << 24) + 0));
}

inline void ckernel_template::set_start_op(uint start_op0)
{
    m_start_op0 = start_op0;
}

inline void ckernel_template::set_last_inner_loop_instr(uint op)
{
    m_loop1_last_instr = op;
}

inline void ckernel_template::set_last_outer_loop_instr(uint op)
{
    m_loop0_last_instr = op;
}

inline void ckernel_template::program_and_run(volatile uint *instrn_buffer)
{
    program(instrn_buffer);
    run(instrn_buffer);
}

inline void ckernel_template::run(volatile uint *instrn_buffer)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((1) << 23) + ((0) << 16) + ((0) << 0))))));
}

inline void ckernel_template::program(volatile uint *instrn_buffer)
{
    volatile uint *mop_cfg = reinterpret_cast<volatile uint *>(0xFFB80000);

    mop_sync();

    mop_cfg[0] = m_outer_loop_len;
    mop_cfg[1] = m_inner_loop_len;
    mop_cfg[2] = m_start_op0;
    mop_cfg[3] = m_end_op0;
    mop_cfg[4] = m_end_op1;
    mop_cfg[5] = m_loop_op0;
    mop_cfg[6] = m_loop_op1;
    mop_cfg[7] = m_loop0_last_instr;
    mop_cfg[8] = m_loop1_last_instr;
}

inline void ckernel_unpack_template::program_and_run(volatile uint *instrn_buffer, const uint8_t count, const uint32_t zmask)
{
    program(instrn_buffer);
    run(instrn_buffer, count, zmask);
}

inline void ckernel_unpack_template::run(volatile uint *instrn_buffer, const uint8_t count, const uint32_t zmask)
{
    ckernel::instrn_buffer[0] = ((0x03 << 24) + (((zmask >> 16) << 0)));
    ckernel::instrn_buffer[0] = ((0x01 << 24) + (((0) << 23) + ((count - 1) << 16) + ((zmask & 0xFFFF) << 0)));
}


inline void ckernel_unpack_template::run(volatile uint *instrn_buffer, const uint8_t count)
{
    ckernel::instrn_buffer[0] = ((0x01 << 24) + (((0) << 23) + ((count - 1) << 16) + ((0) << 0)));
}

inline void ckernel_unpack_template::program(volatile uint *instrn_buffer) const
{
    volatile uint *mop_cfg = reinterpret_cast<volatile uint *>(0xFFB80000);

    mop_sync();

    mop_cfg[1] = m_unpackB | (m_unpack_halo << 1);
    mop_cfg[2] = m_B_instr;
    mop_cfg[3] = m_A0_instr;
    mop_cfg[4] = m_A1_instr;
    mop_cfg[5] = m_A2_instr;
    mop_cfg[6] = m_A3_instr;
    mop_cfg[7] = m_skipA_instr;
    mop_cfg[8] = m_skipB_instr;
}

inline ckernel_unpack_template ckernel_unpack_template::lA(uint A_instr, uint skipA_instr)
{
    return ckernel_unpack_template(
        false,
        false,
        A_instr,
        0,
        0,
        0,
        skipA_instr,
        0,
        0);
}

inline ckernel_unpack_template ckernel_unpack_template::lB(uint B_instr, uint skipB_instr)
{
    return ckernel_unpack_template(
        false,
        false,
        B_instr,
        0,
        0,
        0,
        skipB_instr,
        0,
        0);
}

inline ckernel_unpack_template ckernel_unpack_template::lzA(bool neginf, uint A_instr, uint skipA_instr)
{
    return ckernel_unpack_template(
        false,
        true,
        neginf ? DEF_NINFSRCA : DEF_ZEROSRCA,
        A_instr,
        DEF_UNPACR_NOP,
        DEF_UNPACR_NOP,
        skipA_instr,
        0,
        0);
}

inline ckernel_unpack_template ckernel_unpack_template::lhA(const uint32_t halo_mask)
{

    const uint last_mask = (halo_mask == 0x1) ? 0x1 : (halo_mask <= 0x3) ? 0x2 : (halo_mask <= 0x7) ? 0x4 : 0;

    return ckernel_unpack_template(
        false,
        true,
        ((halo_mask >> 0) & 0x1) ? ((last_mask >> 0) & 0x1) ? DEF_A0_last_instr : DEF_A0_instr : SKIP_A0_instr,
        ((halo_mask >> 1) & 0x1) ? ((last_mask >> 1) & 0x1) ? DEF_A1_last_instr : DEF_A1_instr : SKIP_A1_instr,
        ((halo_mask >> 2) & 0x1) ? ((last_mask >> 2) & 0x1) ? DEF_A2_last_instr : DEF_A2_instr : SKIP_A2_instr,
        ((halo_mask >> 3) & 0x1) ? DEF_A3_instr : SKIP_A3_instr,
        DEF_SKIP_A,
        0,
        0);
}

inline ckernel_unpack_template ckernel_unpack_template::flhA(const uint32_t halo_mask)
{

    const uint last_mask = (halo_mask == 0x1) ? 0x1 : (halo_mask <= 0x3) ? 0x2 : (halo_mask <= 0x7) ? 0x4 : 0;

    return ckernel_unpack_template(
        false,
        true,
        ((halo_mask >> 0) & 0x1) ? ((last_mask >> 0) & 0x1) ? DEF_A0_fconv_last_instr : DEF_A0_fconv_instr : SKIP_A0_instr,
        ((halo_mask >> 1) & 0x1) ? ((last_mask >> 1) & 0x1) ? DEF_A1_fconv_last_instr : DEF_A1_fconv_instr : SKIP_A1_instr,
        ((halo_mask >> 2) & 0x1) ? ((last_mask >> 2) & 0x1) ? DEF_A2_fconv_last_instr : DEF_A2_fconv_instr : SKIP_A2_instr,
        ((halo_mask >> 3) & 0x1) ? DEF_A3_fconv_instr : SKIP_A3_instr,
        ((0x02 << 24) + 0),
        0,
        0);
}

inline ckernel_unpack_template ckernel_unpack_template::lBhA(const uint32_t halo_mask, const bool rarefy)
{

    const uint last_mask = (halo_mask == 0x1) ? 0x1 : (halo_mask <= 0x3) ? 0x2 : (halo_mask <= 0x7) ? 0x4 : 0;

    return ckernel_unpack_template(
        true,
        true,
        ((halo_mask >> 0) & 0x1) ? ((last_mask >> 0) & 0x1) ? DEF_A0_last_instr : DEF_A0_instr : SKIP_A0_instr,
        ((halo_mask >> 1) & 0x1) ? ((last_mask >> 1) & 0x1) ? DEF_A1_last_instr : DEF_A1_instr : SKIP_A1_instr,
        ((halo_mask >> 2) & 0x1) ? ((last_mask >> 2) & 0x1) ? DEF_A2_last_instr : DEF_A2_instr : SKIP_A2_instr,
        ((halo_mask >> 3) & 0x1) ? DEF_A3_instr : SKIP_A3_instr,
        DEF_SKIP_A,
        rarefy ? DEF_B_rarefy_cntx_ovrd_instr : DEF_B_cntx_ovrd_instr,
        DEF_SKIP_B);
}

inline ckernel_unpack_template ckernel_unpack_template::flBhA(const uint32_t halo_mask)
{

    const uint last_mask = (halo_mask == 0x1) ? 0x1 : (halo_mask <= 0x3) ? 0x2 : (halo_mask <= 0x7) ? 0x4 : 0;

    return ckernel_unpack_template(
        true,
        true,
        ((halo_mask >> 0) & 0x1) ? ((last_mask >> 0) & 0x1) ? DEF_A0_fconv_last_instr : DEF_A0_fconv_instr : SKIP_A0_instr,
        ((halo_mask >> 1) & 0x1) ? ((last_mask >> 1) & 0x1) ? DEF_A1_fconv_last_instr : DEF_A1_fconv_instr : SKIP_A1_instr,
        ((halo_mask >> 2) & 0x1) ? ((last_mask >> 2) & 0x1) ? DEF_A2_fconv_last_instr : DEF_A2_fconv_instr : SKIP_A2_instr,
        ((halo_mask >> 3) & 0x1) ? DEF_A3_fconv_instr : SKIP_A3_instr,
        ((0x02 << 24) + 0),
        DEF_B_cntx_ovrd_no_z_inc_instr,
        DEF_SKIP_B);
}

inline ckernel_unpack_template ckernel_unpack_template::lBA(
    uint A_instr,
    uint skipA_instr,

    uint B_instr,
    uint skipB_instr)
{
    return ckernel_unpack_template(
        true,
        false,
        A_instr,
        0,
        0,
        0,
        skipA_instr,
        B_instr,
        skipB_instr);
}

inline ckernel_unpack_template ckernel_unpack_template::loopx1instr(uint instr0, uint skip0)
{
    return ckernel_unpack_template::lA(instr0, skip0);
}

inline ckernel_unpack_template ckernel_unpack_template::loopx2instr(uint instr0, uint instr1, uint skip0, uint skip1)
{

    return ckernel_unpack_template::lBA(instr0, skip0, instr1, skip1);
}

}




       










       






       
       

namespace sfpi {

typedef __xtt_vector __rvtt_vec_t;
constexpr unsigned int SFP_LREG_COUNT = 8;


constexpr unsigned int SFP_DESTREG_STRIDE = 2;
constexpr unsigned int SFP_DESTREG_MAX_SIZE = 1024;
constexpr unsigned int SFP_DESTREG_MAX_ADDR = (SFP_DESTREG_MAX_SIZE / SFP_DESTREG_STRIDE);

constexpr unsigned int SFPLOAD_MOD0_FMT_SRCB = 0;
constexpr unsigned int SFPLOAD_MOD0_FMT_FP16A = 1;
constexpr unsigned int SFPLOAD_MOD0_FMT_FP16B = 2;
constexpr unsigned int SFPLOAD_MOD0_FMT_FP32 = 3;
constexpr unsigned int SFPLOAD_MOD0_FMT_INT32_TO_SM = 12;
constexpr unsigned int SFPLOAD_ADDR_MODE_NOINC = 3;

constexpr unsigned int SFPSTORE_MOD0_FMT_SRCB = 0;
constexpr unsigned int SFPSTORE_MOD0_FMT_FP16A = 1;
constexpr unsigned int SFPSTORE_MOD0_FMT_FP16B = 2;
constexpr unsigned int SFPSTORE_MOD0_FMT_FP32 = 3;
constexpr unsigned int SFPSTORE_MOD0_FMT_INT32_TO_SM = 12;
constexpr unsigned int SFPSTORE_ADDR_MODE_NOINC = 3;

constexpr unsigned int SFPMOV_MOD1_COMPSIGN = 1;

constexpr unsigned int SFPMAD_MOD1_OFFSET_NONE = 0;

constexpr unsigned int SFPLOADI_MOD0_FLOATB = 0;
constexpr unsigned int SFPLOADI_MOD0_FLOATA = 1;
constexpr unsigned int SFPLOADI_MOD0_USHORT = 2;
constexpr unsigned int SFPLOADI_MOD0_SHORT = 4;
constexpr unsigned int SFPLOADI_MOD0_UPPER = 8;
constexpr unsigned int SFPLOADI_MOD0_LOWER = 10;
constexpr unsigned int SFPXLOADI_MOD0_32BIT_MASK = 16;
constexpr unsigned int SFPXLOADI_MOD0_INT32 = 16;
constexpr unsigned int SFPXLOADI_MOD0_UINT32 = 17;
constexpr unsigned int SFPXLOADI_MOD0_FLOAT = 18;

constexpr unsigned int SFPEXMAN_MOD1_PAD8 = 0;
constexpr unsigned int SFPEXMAN_MOD1_PAD9 = 1;

constexpr unsigned int SFPEXEXP_MOD1_DEBIAS = 0;
constexpr unsigned int SFPEXEXP_MOD1_NODEBIAS = 1;
constexpr unsigned int SFPEXEXP_MOD1_SET_CC_SGN_EXP = 2;
constexpr unsigned int SFPEXEXP_MOD1_SET_CC_COMP_EXP = 8;
constexpr unsigned int SFPEXEXP_MOD1_SET_CC_SGN_COMP_EXP = 10;

constexpr unsigned int SFPABS_MOD1_INT = 0;
constexpr unsigned int SFPABS_MOD1_FLOAT = 1;

constexpr unsigned int SFPIADD_MOD1_ARG_LREG_DST = 0;
constexpr unsigned int SFPIADD_MOD1_ARG_IMM = 1;
constexpr unsigned int SFPIADD_MOD1_ARG_2SCOMP_LREG_DST = 2;
constexpr unsigned int SFPIADD_MOD1_CC_LT0 = 0;
constexpr unsigned int SFPIADD_MOD1_CC_NONE = 4;
constexpr unsigned int SFPIADD_MOD1_CC_GTE0 = 8;

constexpr unsigned int SFPXIADD_MOD1_SIGNED = 8;
constexpr unsigned int SFPXIADD_MOD1_IS_SUB = 16;
constexpr unsigned int SFPXIADD_MOD1_12BIT = 32;
constexpr unsigned int SFPXIADD_MOD1_16BIT = 64;

constexpr unsigned int SFPXCMP_MOD1_CC_NONE = 0;
constexpr unsigned int SFPXCMP_MOD1_CC_LT = 1;
constexpr unsigned int SFPXCMP_MOD1_CC_EQ = 2;
constexpr unsigned int SFPXCMP_MOD1_CC_GTE = 3;
constexpr unsigned int SFPXCMP_MOD1_CC_NE = 4;
constexpr unsigned int SFPXCMP_MOD1_CC_LTE = 5;
constexpr unsigned int SFPXCMP_MOD1_CC_GT = 6;
constexpr unsigned int SFPXCMP_MOD1_CC_MASK = 7;

constexpr unsigned int SFPXSCMP_MOD1_FMT_A = 8;
constexpr unsigned int SFPXSCMP_MOD1_FMT_B = 16;
constexpr unsigned int SFPXSCMP_MOD1_FMT_FLOAT = 32;
constexpr unsigned int SFPXSCMP_MOD1_FMT_MASK = 0x38;

constexpr unsigned int SFPXBOOL_MOD1_OR = 1;
constexpr unsigned int SFPXBOOL_MOD1_AND = 2;
constexpr unsigned int SFPXBOOL_MOD1_NOT = 3;

constexpr unsigned int SFPSETCC_MOD1_LREG_LT0 = 0;
constexpr unsigned int SFPSETCC_MOD1_IMM_BIT0 = 1;
constexpr unsigned int SFPSETCC_MOD1_LREG_NE0 = 2;
constexpr unsigned int SFPSETCC_MOD1_LREG_GTE0 = 4;
constexpr unsigned int SFPSETCC_MOD1_LREG_EQ0 = 6;
constexpr unsigned int SFPSETCC_MOD1_COMP = 8;



constexpr unsigned int SFPENCC_IMM12_NEITHER = 0;
constexpr unsigned int SFPENCC_IMM12_BOTH = 3;

constexpr unsigned int SFPENCC_MOD1_EU_R1 = 0;
constexpr unsigned int SFPENCC_MOD1_EC_R1 = 1;
constexpr unsigned int SFPENCC_MOD1_EI_R1 = 2;
constexpr unsigned int SFPENCC_MOD1_EU_RI = 8;
constexpr unsigned int SFPENCC_MOD1_EC_RI = 9;
constexpr unsigned int SFPENCC_MOD1_EI_RI = 10;

constexpr unsigned int SFPPUSHC_MOD1_PUSH = 0;
constexpr unsigned int SFPPUSHC_MOD1_REPLACE = 1;

constexpr unsigned int SFPLZ_MOD1_CC_NONE = 0;
constexpr unsigned int SFPLZ_MOD1_CC_NE0 = 2;
constexpr unsigned int SFPLZ_MOD1_CC_COMP = 8;
constexpr unsigned int SFPLZ_MOD1_CC_EQ0 = 10;
constexpr unsigned int SFPLZ_MOD1_NOSGN_MASK = 4;
constexpr unsigned int SFPLZ_MOD1_NOSGN_CC_NONE = 4;
constexpr unsigned int SFPLZ_MOD1_NOSGN_CC_NE0 = 6;
constexpr unsigned int SFPLZ_MOD1_NOSGN_CC_COMP = 12;
constexpr unsigned int SFPLZ_MOD1_NOSGN_CC_EQ0 = 14;

constexpr unsigned int SFPSDIVP2_MOD1_ADD = 1;

constexpr unsigned int SFPLUT_MOD0_SGN_UPDATE = 0;
constexpr unsigned int SFPLUT_MOD0_SGN_RETAIN = 4;

constexpr unsigned int SFPLUTFP32_MOD0_FP32_3ENTRY_TABLE = 0;
constexpr unsigned int SFPLUTFP32_MOD0_FP16_6ENTRY_TABLE1 = 2;
constexpr unsigned int SFPLUTFP32_MOD0_FP16_6ENTRY_TABLE2 = 3;
constexpr unsigned int SFPLUTFP32_MOD0_FP16_3ENTRY_TABLE = 10;
constexpr unsigned int SFPLUTFP32_MOD0_SGN_UPDATE = 0;
constexpr unsigned int SFPLUTFP32_MOD0_SGN_RETAIN = 4;

constexpr unsigned int SFPCAST_MOD1_INT32_TO_FP32_RNE = 0;
constexpr unsigned int SFPCAST_MOD1_INT32_TO_FP32_RNS = 1;

__attribute__((__deprecated__("use SFPCAST_MOD1_INT32_TO_FP32_RNE instead")))
constexpr unsigned int SFPCAST_MOD1_RND_EVEN = SFPCAST_MOD1_INT32_TO_FP32_RNE;
__attribute__((__deprecated__("use SFPCAST_MOD1_INT32_TO_FP32_RNS instead")))
constexpr unsigned int SFPCAST_MOD1_RND_STOCH = SFPCAST_MOD1_INT32_TO_FP32_RNS;

constexpr unsigned int SFPSTOCHRND_RND_EVEN = 0;
constexpr unsigned int SFPSTOCHRND_RND_STOCH = 1;
constexpr unsigned int SFPSTOCHRND_MOD1_FP32_TO_FP16A = 0;
constexpr unsigned int SFPSTOCHRND_MOD1_FP32_TO_FP16B = 1;
constexpr unsigned int SFPSTOCHRND_MOD1_FP32_TO_UINT8 = 2;
constexpr unsigned int SFPSTOCHRND_MOD1_FP32_TO_INT8 = 3;
constexpr unsigned int SFPSTOCHRND_MOD1_INT32_TO_UINT8 = 4;
constexpr unsigned int SFPSTOCHRND_MOD1_INT32_TO_INT8 = 5;
constexpr unsigned int SFPSTOCHRND_MOD1_FP32_TO_UINT16 = 6;
constexpr unsigned int SFPSTOCHRND_MOD1_FP32_TO_INT16 = 7;
constexpr unsigned int SFPSTOCHRND_MOD1_CONV_MASK = 7;
constexpr unsigned int SFPSTOCHRND_MOD1_IMM8 = 8;

constexpr unsigned int SFPSHFT2_MOD1_COPY4 = 0;
constexpr unsigned int SFPSHFT2_MOD1_SUBVEC_CHAINED_COPY4 = 1;
constexpr unsigned int SFPSHFT2_MOD1_SUBVEC_SHFLROR1_AND_COPY4 = 2;
constexpr unsigned int SFPSHFT2_MOD1_SUBVEC_SHFLROR1 = 3;
constexpr unsigned int SFPSHFT2_MOD1_SUBVEC_SHFLSHR1 = 4;
constexpr unsigned int SFPSHFT2_MOD1_SHFT_LREG = 5;
constexpr unsigned int SFPSHFT2_MOD1_SHFT_IMM = 6;

constexpr unsigned int SFPSWAP_MOD1_SWAP = 0;
constexpr unsigned int SFPSWAP_MOD1_VEC_MIN_MAX = 1;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN01_MAX23 = 2;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN02_MAX13 = 3;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN03_MAX12 = 4;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN0_MAX123 = 5;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN1_MAX023 = 6;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN2_MAX013 = 7;
constexpr unsigned int SFPSWAP_MOD1_SUBVEC_MIN3_MAX012 = 8;

constexpr unsigned int SFPCONFIG_DEST_MACRO_INST0 = 0;
constexpr unsigned int SFPCONFIG_DEST_MACRO_INST1 = 1;
constexpr unsigned int SFPCONFIG_DEST_MACRO_INST2 = 2;
constexpr unsigned int SFPCONFIG_DEST_MACRO_INST3 = 3;
constexpr unsigned int SFPCONFIG_DEST_MACRO_SEQ0 = 4;
constexpr unsigned int SFPCONFIG_DEST_MACRO_SEQ1 = 5;
constexpr unsigned int SFPCONFIG_DEST_MACRO_SEQ2 = 6;
constexpr unsigned int SFPCONFIG_DEST_MACRO_SEQ3 = 7;
constexpr unsigned int SFPCONFIG_DEST_MACRO_CTRL = 8;
constexpr unsigned int SFPCONFIG_DEST_LREG11 = 11;
constexpr unsigned int SFPCONFIG_DEST_LREG12 = 12;
constexpr unsigned int SFPCONFIG_DEST_LREG13 = 13;
constexpr unsigned int SFPCONFIG_DEST_LREG14 = 14;
constexpr unsigned int SFPCONFIG_DEST_SFPU_CTRL = 15;

constexpr unsigned int SFPCONFIG_MOD1_SRC_R0_LREG0 = 0;

constexpr unsigned int CREG_IDX_0P837300003 = 8;
constexpr unsigned int CREG_IDX_0 = 9;
constexpr unsigned int CREG_IDX_1 = 10;
constexpr unsigned int CREG_IDX_PRGM0 = 11;
constexpr unsigned int CREG_IDX_PRGM1 = 12;
constexpr unsigned int CREG_IDX_PRGM2 = 13;
constexpr unsigned int CREG_IDX_PRGM3 = 14;
constexpr unsigned int CREG_IDX_NEG_1 = CREG_IDX_PRGM0;
constexpr unsigned int CREG_IDX_TILEID = 15;

}




       
namespace sfpi {


class s2vFloat16 {
 public:
    enum Format {
        fp16a = SFPLOADI_MOD0_FLOATA,
        fp16b = SFPLOADI_MOD0_FLOATB
    };

 private:
    uint32_t value;
    Format format;

    static __attribute__((always_inline)) inline uint32_t fp32_to_fp16a(const float val);
    static __attribute__((always_inline)) inline uint32_t fp32_to_fp16b(const float val);

 public:
    __attribute__((always_inline)) inline s2vFloat16(const float in, const Format f = fp16b);
    __attribute__((always_inline)) inline s2vFloat16(const int32_t in, const Format f = fp16b);
    __attribute__((always_inline)) inline s2vFloat16(const uint32_t in, const Format f = fp16b);

    __attribute__((always_inline)) inline s2vFloat16 negate() const { return s2vFloat16(value ^ 0x8000, format); }

    __attribute__((always_inline)) inline uint32_t get() const { return value; }
    __attribute__((always_inline)) inline uint32_t get_format() const { return format; }
};


class s2vFloat16a : public s2vFloat16 {
 public:
    __attribute__((always_inline)) inline s2vFloat16a(const float in) : s2vFloat16(in, fp16a) {}
    __attribute__((always_inline)) inline s2vFloat16a(const double in) : s2vFloat16(static_cast<float>(in), fp16a) {}
    __attribute__((always_inline)) inline s2vFloat16a(const int in) : s2vFloat16(static_cast<int32_t>(in), fp16a) {}
    __attribute__((always_inline)) inline s2vFloat16a(const int32_t in) : s2vFloat16(in, fp16a) {}
    __attribute__((always_inline)) inline s2vFloat16a(const unsigned int in) : s2vFloat16(static_cast<uint32_t>(in), fp16a) {}
    __attribute__((always_inline)) inline s2vFloat16a(const uint32_t in) : s2vFloat16(in, fp16a) {}
};


class s2vFloat16b : public s2vFloat16 {
 public:
    __attribute__((always_inline)) inline s2vFloat16b(const float in) : s2vFloat16(in, fp16b) {}
    __attribute__((always_inline)) inline s2vFloat16b(const double in) : s2vFloat16(static_cast<float>(in), fp16b) {}
    __attribute__((always_inline)) inline s2vFloat16b(const int in) : s2vFloat16(static_cast<int32_t>(in), fp16b) {}
    __attribute__((always_inline)) inline s2vFloat16b(const int32_t in) : s2vFloat16(in, fp16b) {}
    __attribute__((always_inline)) inline s2vFloat16b(const unsigned int in) : s2vFloat16(static_cast<uint32_t>(in), fp16b) {}
    __attribute__((always_inline)) inline s2vFloat16b(const uint32_t in) : s2vFloat16(in, fp16b) {}
};


__attribute__((always_inline)) inline s2vFloat16::s2vFloat16(const float in, const Format f)
{
    value = (f == fp16a) ? fp32_to_fp16a(in) : fp32_to_fp16b(in);
    format = f;
}

__attribute__((always_inline)) inline s2vFloat16::s2vFloat16(const int32_t in, const Format f)
{
    value = in;
    format = f;
}

__attribute__((always_inline)) inline s2vFloat16::s2vFloat16(const uint32_t in, const Format f)
{
    value = in;
    format = f;
}

__attribute__((always_inline)) inline uint32_t s2vFloat16::fp32_to_fp16a(const float val)
{
    union {
        float vfloat;
        uint32_t vui;
    } tmp;

    tmp.vfloat = val;



    const unsigned int b = tmp.vui + 0x00001000;
    const unsigned int e = (b & 0x7F800000) >> 23;
    const unsigned int m = b & 0x007FFFFF;
    const unsigned int result =
        (b & 0x80000000) >> 16 |
        (e > 112) * ((((e - 112) << 10) &0x7C00) | m >> 13) |
        ((e < 113) & (e > 101)) * ((((0x007FF000 + m) >> (125 -e )) + 1) >> 1) |
        (e > 143) * 0x7FFF;
    return result;
}

__attribute__((always_inline)) inline uint32_t s2vFloat16::fp32_to_fp16b(const float val)
{
    union {
        float vfloat;
        uint32_t vui;
    } tmp;

    tmp.vfloat = val;

    return tmp.vui >> 16;
}

};

namespace sfpi {



class vFloat;
class vInt;
class vUInt;
enum class LRegs;


class __vBase;
class __vIntBase;
class __vConstFloat;
class __vConstIntBase;
class __vCond;
class __vCCCtrl;
class __vCCCtrlBase;


__attribute__((always_inline)) inline unsigned int __f32asui(const float val)
{
    union Converter {
        const float f;
        const uint32_t i;

        constexpr Converter(const float inf) : f(inf) {}
    } tmp(val);

    return tmp.i;
}


template<class Type, int N>
class __RegFile {

public:
    __attribute__((always_inline)) inline Type operator[](const int x) const;
};


class __vRegBase {
protected:
    int reg;

public:
    constexpr explicit __vRegBase(int r) : reg(r) {}
    constexpr int get() const { return reg; }
};


class __vRegBaseInitializer {
    int n;

 public:
    constexpr __vRegBaseInitializer(int in) : n(in) {}
    constexpr int get() const { return n; }
};


class __vDReg : public __vRegBase {
private:
    template<class Type, int N> friend class __RegFile;
    constexpr explicit __vDReg(const __vRegBaseInitializer i) : __vRegBase(i.get() * SFP_DESTREG_STRIDE) {}

public:

    template <typename vecType, typename std::enable_if_t<std::is_base_of<__vBase, vecType>::value>* = nullptr>
    __attribute__((always_inline)) inline vecType operator=(const vecType vec) const;
    __attribute__((always_inline)) inline void operator=(const __vDReg dreg) const;
    __attribute__((always_inline)) inline vFloat operator=(const __vConstFloat creg) const;
    __attribute__((always_inline)) inline vFloat operator=(const s2vFloat16 f) const;
    __attribute__((always_inline)) inline vInt operator=(const int i) const;
    __attribute__((always_inline)) inline vUInt operator=(const unsigned int i) const;
    __attribute__((always_inline)) inline vFloat operator=(const float f) const;
    __attribute__((always_inline)) inline vFloat operator=(const double d) const;


    __attribute__((always_inline)) inline vFloat operator+(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator-(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator-() const;
    __attribute__((always_inline)) inline vFloat operator*(const vFloat b) const;


    __attribute__((always_inline)) inline __vCond operator==(const float x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const float x) const;
    __attribute__((always_inline)) inline __vCond operator<(const float x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const float x) const;
    __attribute__((always_inline)) inline __vCond operator>(const float x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const float x) const;

    __attribute__((always_inline)) inline __vCond operator==(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator<(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator>(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const s2vFloat16 x) const;

    __attribute__((always_inline)) inline __vCond operator==(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator<(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator>(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const vFloat x) const;
};


class __DestReg {
 private:
    __RegFile<__vDReg, SFP_DESTREG_MAX_ADDR> dreg;

 public:
    __attribute__((always_inline)) inline const __vDReg operator[](const int i) const { return dreg[i]; }

    __attribute__((always_inline)) inline void operator++() const { __builtin_rvtt_ttincrwc(0, SFP_DESTREG_STRIDE, 0, 0); }
    __attribute__((always_inline)) inline void operator++(const int) const { __builtin_rvtt_ttincrwc(0, SFP_DESTREG_STRIDE, 0, 0); }
    __attribute__((always_inline)) inline void operator+=(const int i) const { __builtin_rvtt_ttincrwc(0, SFP_DESTREG_STRIDE * i, 0, 0); }
};


class __vLReg : public __vRegBase {
 private:
    template<class Type, int N> friend class __RegFile;
    constexpr explicit __vLReg(const __vRegBaseInitializer i) : __vRegBase(i.get()) {}

 public:
    __attribute__((always_inline)) inline __rvtt_vec_t operator=(__vBase& v) const;
};

class __LReg {
 private:
    __RegFile<__vLReg, SFP_LREG_COUNT> lreg;

 public:
    __attribute__((always_inline)) inline const __vLReg operator[](const enum LRegs lr) const { return lreg[static_cast<std::underlying_type<LRegs>::type>(lr)]; }
};


class __vConstFloat : public __vRegBase {
public:
    constexpr explicit __vConstFloat(int r) : __vRegBase(r) {}

    __attribute__((always_inline)) inline void operator=(const float in) const;
    __attribute__((always_inline)) inline void operator=(const s2vFloat16 in) const;


    __attribute__((always_inline)) inline vFloat operator+(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator-(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator*(const vFloat b) const;

    __attribute__((always_inline)) inline __vCond operator==(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator<(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator>(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const vFloat x) const;
};

class __vConstIntBase : public __vRegBase {
public:
    constexpr explicit __vConstIntBase(int r) : __vRegBase(r) {}

    __attribute__((always_inline)) inline void operator=(const int in) const;


    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator+(const vType b) const;
    __attribute__((always_inline)) inline vInt operator+(int32_t b) const;

    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator-(const vType b) const;
    __attribute__((always_inline)) inline vInt operator-(int32_t b) const;

    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator&(const vType b) const;
    __attribute__((always_inline)) inline vInt operator&(int32_t b) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator|(const vType b) const;
    __attribute__((always_inline)) inline vInt operator|(int32_t b) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator^(const vType b) const;
    __attribute__((always_inline)) inline vInt operator^(int32_t b) const;

    __attribute__((always_inline)) inline __vCond operator==(const vInt x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const vInt x) const;
    __attribute__((always_inline)) inline __vCond operator<(const vInt x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const vInt x) const;
    __attribute__((always_inline)) inline __vCond operator>(const vInt x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const vInt x) const;
};


class __vBase {
protected:
    bool initialized;
    __rvtt_vec_t v;

    __attribute__((always_inline)) inline void assign(const __rvtt_vec_t t);

public:
    __attribute__((always_inline)) inline __vBase() : initialized(false) {}

    __attribute__((always_inline)) inline __rvtt_vec_t get() const { return v; }
    __attribute__((always_inline)) inline __rvtt_vec_t& get() { return v; }


    __attribute__((always_inline)) inline void operator=(__vLReg lr);
};


class vFloat : public __vBase {
private:
    __attribute__((always_inline)) inline void loadf(const float val);
    __attribute__((always_inline)) inline void loadf16(const s2vFloat16 val);

public:
    vFloat() = default;

    __attribute__((always_inline)) inline vFloat(const __vDReg dreg);
    __attribute__((always_inline)) inline vFloat(const __vConstFloat creg);
    __attribute__((always_inline)) inline vFloat(const s2vFloat16 f) { loadf16(f); }
    __attribute__((always_inline)) inline vFloat(const float f) { loadf(f); }
    __attribute__((always_inline)) inline vFloat(const __rvtt_vec_t& t) { assign(t); }
    __attribute__((always_inline)) inline vFloat(__vLReg lr) { __vBase::operator=(lr); }


    __attribute__((always_inline)) inline vFloat operator=(const vFloat in) { assign(in.v); return v; }
    __attribute__((always_inline)) inline vFloat operator=(__vLReg lr) { __vBase::operator=(lr); return v; }


    __attribute__((always_inline)) inline vFloat operator+(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator+=(const vFloat);
    __attribute__((always_inline)) inline vFloat operator-(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator-(const float b) const;
    __attribute__((always_inline)) inline vFloat operator-(const s2vFloat16 b) const;
    __attribute__((always_inline)) inline vFloat operator-=(const vFloat);
    __attribute__((always_inline)) inline vFloat operator-() const;
    __attribute__((always_inline)) inline vFloat operator*(const vFloat b) const;
    __attribute__((always_inline)) inline vFloat operator*=(const vFloat);
    __attribute__((always_inline)) inline vFloat operator++(const int) { *this += 1; return *this; }
    __attribute__((always_inline)) inline vFloat operator++() { vFloat tmp = *this; *this += 1; return tmp; }
    __attribute__((always_inline)) inline vFloat operator--(const int) { *this -= 1; return *this; }
    __attribute__((always_inline)) inline vFloat operator--() { vFloat tmp = *this; *this -= 1; return tmp; }


    __attribute__((always_inline)) inline __vCond operator==(const float x) const;
    __attribute__((always_inline)) inline __vCond operator==(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator==(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const float x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator!=(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator<(const float x) const;
    __attribute__((always_inline)) inline __vCond operator<(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator<(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const float x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator<=(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator>(const float x) const;
    __attribute__((always_inline)) inline __vCond operator>(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator>(const vFloat x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const float x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const s2vFloat16 x) const;
    __attribute__((always_inline)) inline __vCond operator>=(const vFloat x) const;
};


class __vIntBase : public __vBase {
 protected:
    __attribute__((always_inline)) inline void loadss(int16_t val);
    __attribute__((always_inline)) inline void loadus(uint16_t val);
    __attribute__((always_inline)) inline void loadsi(int32_t val);
    __attribute__((always_inline)) inline void loadui(uint32_t val);

 public:
    __vIntBase() = default;
    __attribute__((always_inline)) inline __vIntBase(const __rvtt_vec_t& in) { assign(in); }
    __attribute__((always_inline)) inline __vIntBase(const __vConstIntBase creg);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline explicit operator vType() const { return vType(v); }


    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator&(const vType b) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline void operator&=(const vType b);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator|(const vType b) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator|=(const vType b);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator^(const vType b) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator^=(const vType b);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator~() const;


    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType add(int32_t val, unsigned int mod) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator+(const __vIntBase val) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator+(const __vConstIntBase val) const;

    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType sub(int32_t val, unsigned int mod) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator-(const __vIntBase val) const;
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator-(const __vConstIntBase val) const;

    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline void add_eq(int32_t val, unsigned int mod);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator+=(const __vIntBase val);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator+=(const __vConstIntBase val);

    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline void sub_eq(int32_t val, unsigned int mod);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator-=(const __vIntBase val);
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vType operator-=(const __vConstIntBase val);
};

class vInt : public __vIntBase {
    friend class vUInt;

public:
    vInt() = default;
    __attribute__((always_inline)) inline vInt(const __vDReg dreg);
    __attribute__((always_inline)) inline vInt(const __rvtt_vec_t& in) { assign(in); }
    __attribute__((always_inline)) inline vInt(const __vConstIntBase creg) { v = __builtin_rvtt_sfpreadlreg(creg.get()); initialized = true; }
    __attribute__((always_inline)) inline vInt(const __vIntBase in) { assign(in.get()); };
    __attribute__((always_inline)) inline vInt(short val) { loadss(val); }
    __attribute__((always_inline)) inline vInt(int val) { loadsi(val); }
    __attribute__((always_inline)) inline vInt(int32_t val) { loadsi(val); }
    __attribute__((always_inline)) inline vInt(unsigned short val) { loadus(val); }
    __attribute__((always_inline)) inline vInt(unsigned int val) { loadui(val); }
    __attribute__((always_inline)) inline vInt(uint32_t val) { loadui(val); }
    __attribute__((always_inline)) inline vInt(__vLReg lr) { __vBase::operator=(lr); }
    __attribute__((always_inline)) inline vInt(const __vCond vc);


    __attribute__((always_inline)) inline vInt operator=(const vInt in) { assign(in.v); return v; }
    __attribute__((always_inline)) inline vInt operator=(__vLReg lr) { __vBase::operator=(lr); return v; }


    __attribute__((always_inline)) inline vInt operator&(int32_t b) const { return this->__vIntBase::operator&(vInt(b)); }
    __attribute__((always_inline)) inline vInt operator&(const vInt b) const { return this->__vIntBase::operator&(b); }
    __attribute__((always_inline)) inline vInt operator&=(const vInt b) { this->__vIntBase::operator&=(b); return v; }
    __attribute__((always_inline)) inline vInt operator|(int32_t b) const { return this->__vIntBase::operator|(vInt(b)); }
    __attribute__((always_inline)) inline vInt operator|(const vInt b) const { return this->__vIntBase::operator|(b); }
    __attribute__((always_inline)) inline vInt operator|=(const vInt b) { this->__vIntBase::operator|=(b); return v; }
    __attribute__((always_inline)) inline vInt operator^(int32_t b) const { return this->__vIntBase::operator^(vInt(b)); }
    __attribute__((always_inline)) inline vInt operator^(const vInt b) const { return this->__vIntBase::operator^(b); }
    __attribute__((always_inline)) inline vInt operator^=(const vInt b) { this->__vIntBase::operator^=(b); return v; }
    __attribute__((always_inline)) inline vInt operator~() const { return this->__vIntBase::operator~<vInt>(); }

    __attribute__((always_inline)) inline vInt operator+() const { return *this + 0; }
    __attribute__((always_inline)) inline vInt operator-() const { return vInt(0) - *this; }

    __attribute__((always_inline)) inline vInt operator+(int32_t val) const { return this->__vIntBase::add<vInt>(val, SFPXIADD_MOD1_SIGNED); }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vInt operator+(const vType val) const { return this->__vIntBase::operator+<vInt>(val); }
    __attribute__((always_inline)) inline vInt operator+(const __vConstIntBase val) const { return this->__vIntBase::operator+<vInt>(val); }

    __attribute__((always_inline)) inline vInt operator-(int32_t val) const { return this->__vIntBase::sub<vInt>(val, SFPXIADD_MOD1_SIGNED); }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vInt operator-(const vType val) const { return this->__vIntBase::operator-<vInt>(val); }
    __attribute__((always_inline)) inline vInt operator-(const __vConstIntBase val) const { return this->__vIntBase::operator-<vInt>(val); }

    __attribute__((always_inline)) inline vInt operator+=(int32_t val) { this->__vIntBase::add_eq<vInt>(val, SFPXIADD_MOD1_SIGNED); return v; }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vInt operator+=(const vType val) { this->__vIntBase::operator+=<vInt>(val); return v; }
    __attribute__((always_inline)) inline vInt operator+=(const __vConstIntBase val) { this->__vIntBase::operator-=<vInt>(val); return v; }

    __attribute__((always_inline)) inline vInt operator-=(int32_t val) { this->__vIntBase::sub_eq<vInt>(val, SFPXIADD_MOD1_SIGNED); return v; }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vInt operator-=(const vType val) { this->__vIntBase::operator-=<vInt>(val); return v; }
    __attribute__((always_inline)) inline vInt operator-=(const __vConstIntBase val) { this->__vIntBase::operator-=<vInt>(val); return v; }

    __attribute__((always_inline)) inline vInt operator++(const int) { *this += 1; return *this; }
    __attribute__((always_inline)) inline vInt operator++() { vInt tmp = *this; *this += 1; return tmp; }
    __attribute__((always_inline)) inline vInt operator--(const int) { *this -= 1; return *this; }
    __attribute__((always_inline)) inline vInt operator--() { vInt tmp = *this; *this -= 1; return tmp; }

    __attribute__((always_inline)) inline vInt operator<<(unsigned amt) const;
    __attribute__((always_inline)) inline vInt operator<<=(unsigned amt) { *this = *this << amt; return *this; }
    __attribute__((always_inline)) inline vInt operator<<(vInt amt) const;
    __attribute__((always_inline)) inline vInt operator<<=(vInt amt) { *this = *this << amt; return *this; }
    __attribute__((always_inline)) inline const __vCond operator==(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator!=(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator<(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator<=(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator>(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator>=(int32_t val) const;

    __attribute__((always_inline)) inline const __vCond operator==(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator!=(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator<(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator<=(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator>(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator>=(const __vIntBase src) const;
};


class vUInt : public __vIntBase {
    friend class vInt;

private:

public:
    vUInt() = default;
    __attribute__((always_inline)) inline vUInt(const __vDReg dreg);
    __attribute__((always_inline)) inline vUInt(const __rvtt_vec_t& in) { assign(in); }
    __attribute__((always_inline)) inline vUInt(const __vConstIntBase creg) { v = __builtin_rvtt_sfpreadlreg(creg.get()); initialized = true; }
    __attribute__((always_inline)) inline vUInt(const __vIntBase in) { assign(in.get()); }
    __attribute__((always_inline)) inline vUInt(short val) { loadss(val); }
    __attribute__((always_inline)) inline vUInt(int val) { loadsi(val); }
    __attribute__((always_inline)) inline vUInt(int32_t val) { loadsi(val); }
    __attribute__((always_inline)) inline vUInt(unsigned short val) { loadus(val); }
    __attribute__((always_inline)) inline vUInt(unsigned int val) { loadui(val); }
    __attribute__((always_inline)) inline vUInt(uint32_t val) { loadui(val); }
    __attribute__((always_inline)) inline vUInt(__vLReg lr) { __vBase::operator=(lr); }
    __attribute__((always_inline)) inline vUInt(const __vCond vc);


    __attribute__((always_inline)) inline vUInt operator=(const vUInt in ) { assign(in.v); return v; }
    __attribute__((always_inline)) inline vUInt operator=(__vLReg lr) { __vBase::operator=(lr); return v; }


    __attribute__((always_inline)) inline vUInt operator&(uint32_t b) const { return this->__vIntBase::operator&(vUInt(b)); }
    __attribute__((always_inline)) inline vUInt operator&(const vUInt b) const { return this->__vIntBase::operator&(b); }
    __attribute__((always_inline)) inline vUInt operator&=(const vUInt b) { this->__vIntBase::operator&=(b); return v; }
    __attribute__((always_inline)) inline vUInt operator|(const vUInt b) const { return this->__vIntBase::operator|(b); }
    __attribute__((always_inline)) inline vUInt operator|(const vUInt b) { return this->__vIntBase::operator|(b); }
    __attribute__((always_inline)) inline vUInt operator|=(const vUInt b) { this->__vIntBase::operator|=(b); return v; }
    __attribute__((always_inline)) inline vUInt operator^(const vUInt b) const { return this->__vIntBase::operator^(b); }
    __attribute__((always_inline)) inline vUInt operator^(const vUInt b) { return this->__vIntBase::operator^(b); }
    __attribute__((always_inline)) inline vUInt operator^=(const vUInt b) { this->__vIntBase::operator^=(b); return v; }
    __attribute__((always_inline)) inline vUInt operator~() const { return this->__vIntBase::operator~<vUInt>(); }

    __attribute__((always_inline)) inline vUInt operator+(int32_t val) const { return this->__vIntBase::add<vUInt>(val, 0); }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vUInt operator+(const vType val) const { return this->__vIntBase::operator+<vUInt>(val); }
    __attribute__((always_inline)) inline vUInt operator+(const __vConstIntBase val) const { return this->__vIntBase::operator+<vUInt>(val); }

    __attribute__((always_inline)) inline vUInt operator-(int32_t val) const { return this->__vIntBase::sub<vUInt>(val, 0); }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vUInt operator-(const vType val) const { return this->__vIntBase::operator-<vUInt>(val); }
    __attribute__((always_inline)) inline vUInt operator-(const __vConstIntBase val) const { return this->__vIntBase::operator+<vUInt>(val); }

    __attribute__((always_inline)) inline vUInt operator+=(int32_t val) { this->__vIntBase::add_eq<vUInt>(val, 0); return v; }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vUInt operator+=(const vType val) { this->__vIntBase::operator+=<vUInt>(val); return v; }
    __attribute__((always_inline)) inline vUInt operator+=(const __vConstIntBase val) { this->__vIntBase::operator+=<vUInt>(val); return v; }

    __attribute__((always_inline)) inline vUInt operator-=(int32_t val) { this->__vIntBase::sub_eq<vUInt>(val, 0); return v; }
    template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>* = nullptr>
    __attribute__((always_inline)) inline vUInt operator-=(const vType val) { this->__vIntBase::operator-=<vUInt>(val); return v; }
    __attribute__((always_inline)) inline vUInt operator-=(const __vConstIntBase val) { this->__vIntBase::operator-=<vUInt>(val); return v; }

    __attribute__((always_inline)) inline vUInt operator++(const int) { *this += 1; return *this; }
    __attribute__((always_inline)) inline vUInt operator++() { vUInt tmp = *this; *this += 1; return tmp; }
    __attribute__((always_inline)) inline vUInt operator--(const int) { *this -= 1; return *this; }
    __attribute__((always_inline)) inline vUInt operator--() { vUInt tmp = *this; *this -= 1; return tmp; }

    __attribute__((always_inline)) inline vUInt operator<<(unsigned amt) const;
    __attribute__((always_inline)) inline vUInt operator<<=(unsigned amt) { *this = *this << amt; return *this; }
    __attribute__((always_inline)) inline vUInt operator<<(vInt amt) const;
    __attribute__((always_inline)) inline vUInt operator<<=(vInt amt) { *this = *this << amt; return *this; }

    __attribute__((always_inline)) inline vUInt operator>>(unsigned amt) const;
    __attribute__((always_inline)) inline vUInt operator>>=(unsigned amt) { *this = *this >> amt; return *this; }
    __attribute__((always_inline)) inline vUInt operator>>(vInt amt) const;
    __attribute__((always_inline)) inline vUInt operator>>=(vInt amt) { *this = *this >> amt; return *this; }


    __attribute__((always_inline)) inline const __vCond operator==(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator!=(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator<(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator<=(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator>(int32_t val) const;
    __attribute__((always_inline)) inline const __vCond operator>=(int32_t val) const;

    __attribute__((always_inline)) inline const __vCond operator==(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator!=(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator<(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator<=(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator>(const __vIntBase src) const;
    __attribute__((always_inline)) inline const __vCond operator>=(const __vIntBase src) const;
};


class __vCond {
    friend class __vCCCtrl;
    friend class vInt;
    friend class vUInt;

 private:
    enum class vBoolOpType {
        vBoolOr = SFPXBOOL_MOD1_OR,
        vBoolAnd = SFPXBOOL_MOD1_AND,
        vBoolNot = SFPXBOOL_MOD1_NOT,
    };

    int result;

    __attribute__((always_inline)) inline int get() const { return result; }

 public:
    enum __vCondOpType {
        __vCondLT = SFPXCMP_MOD1_CC_LT,
        __vCondNE = SFPXCMP_MOD1_CC_NE,
        __vCondGTE = SFPXCMP_MOD1_CC_GTE,
        __vCondEQ = SFPXCMP_MOD1_CC_EQ,
        __vCondLTE = SFPXCMP_MOD1_CC_LTE,
        __vCondGT = SFPXCMP_MOD1_CC_GT,
    };


    __attribute__((always_inline)) inline __vCond(vBoolOpType t, const __vCond& a, const __vCond& b) { result = __builtin_rvtt_sfpxbool((int)t, a.get(), b.get()); }


    __attribute__((always_inline)) inline __vCond(const __vCondOpType t, const vFloat a, const float b)
    { result = __builtin_rvtt_wh_sfpxfcmps(ckernel::instrn_buffer, a.get(), __f32asui(b), 0, 0, t | SFPXSCMP_MOD1_FMT_FLOAT); }

    __attribute__((always_inline)) inline __vCond(const __vCondOpType t, const vFloat a, const s2vFloat16 b)
    { result = __builtin_rvtt_wh_sfpxfcmps(ckernel::instrn_buffer, a.get(), b.get(), 0, 0, t | ((b.get_format() == SFPLOADI_MOD0_FLOATA) ? SFPXSCMP_MOD1_FMT_A : SFPXSCMP_MOD1_FMT_B)); }

    __attribute__((always_inline)) inline __vCond(const __vCondOpType t, const vFloat a, const vFloat b)
    { result = __builtin_rvtt_wh_sfpxfcmpv(a.get(), b.get(), t); }


    __attribute__((always_inline)) inline __vCond(const __vCondOpType t, const __vIntBase a, int32_t b, uint32_t mod)
    { result = __builtin_rvtt_sfpxicmps(ckernel::instrn_buffer, a.get(), b, 0, 0, mod | t); }

    __attribute__((always_inline)) inline __vCond(const __vCondOpType t, const __vIntBase a, const __vIntBase b, uint32_t mod)
    { result = __builtin_rvtt_sfpxicmpv(a.get(), b.get(), mod | t); }


    __attribute__((always_inline)) inline __vCond(const vInt a) { result = __builtin_rvtt_sfpxicmps(ckernel::instrn_buffer, a.get(), 0, 0, 0, __vCondNE); }


    __attribute__((always_inline)) inline const __vCond operator&&(const __vCond& b) const { return __vCond(vBoolOpType::vBoolAnd, *this, b); }
    __attribute__((always_inline)) inline const __vCond operator||(const __vCond& b) const { return __vCond(vBoolOpType::vBoolOr, *this, b); }
    __attribute__((always_inline)) inline const __vCond operator!() const { return __vCond(vBoolOpType::vBoolNot, *this, *this); }
};


class __vCCCtrl {
protected:
    int top;
    int push_count;

public:
    __attribute__((always_inline)) inline __vCCCtrl();
    __attribute__((always_inline)) inline ~__vCCCtrl();

    __attribute__((always_inline)) inline void cc_if(const __vCond& op) const;
    __attribute__((always_inline)) inline void cc_if(const __vIntBase& b) const;
    __attribute__((always_inline)) inline void cc_else() const;
    __attribute__((always_inline)) inline void cc_elseif(const __vCond& cond) const;
    __attribute__((always_inline)) inline void cc_elseif(const __vIntBase& b) const;

    __attribute__((always_inline)) inline void mark_top();
    __attribute__((always_inline)) inline void push();
    __attribute__((always_inline)) inline void pop();

    static __attribute__((always_inline)) inline void enable_cc();
};


constexpr __vConstFloat vConst0(CREG_IDX_0);
constexpr __vConstFloat vConst1(CREG_IDX_1);
constexpr __vConstFloat vConstNeg1(CREG_IDX_NEG_1);


namespace sfpi_int {

__attribute__((always_inline)) inline vFloat fp_add(const vFloat a, const vFloat b)
{
    return __builtin_rvtt_wh_sfpadd(a.get(), b.get(), 0);
}

__attribute__((always_inline)) inline vFloat fp_mul(const vFloat a, const vFloat b)
{
    return __builtin_rvtt_wh_sfpmul(a.get(), b.get(), 0);
}

__attribute__((always_inline)) inline vFloat fp_sub(const vFloat a, const vFloat b)
{

  return fp_add(a, -b);
}

}

template<class TYPE, int N>
__attribute__((always_inline)) inline TYPE __RegFile<TYPE, N>::operator[](const int x) const {
    return TYPE(__vRegBaseInitializer(x));
}

__attribute__((always_inline)) inline vInt __vDReg::operator=(const int i) const
{
    vInt v(i);
    *this = v;
    return v;
}

__attribute__((always_inline)) inline vUInt __vDReg::operator=(const unsigned int i) const
{
    vUInt v(i);
    *this = v;
    return v;
}

__attribute__((always_inline)) inline vFloat __vDReg::operator+(const vFloat b) const {return sfpi_int::fp_add(vFloat(*this), b); }
__attribute__((always_inline)) inline vFloat __vDReg::operator-(const vFloat b) const { return sfpi_int::fp_sub(vFloat(*this), b); }
__attribute__((always_inline)) inline vFloat __vDReg::operator*(const vFloat b) const { return sfpi_int::fp_mul(vFloat(*this), b); }
__attribute__((always_inline)) inline __vCond __vDReg::operator==(const s2vFloat16 x) const {return __vCond(__vCond::__vCondEQ, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator!=(const s2vFloat16 x) const { return __vCond(__vCond::__vCondNE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator<(const s2vFloat16 x) const { return __vCond(__vCond::__vCondLT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator<=(const s2vFloat16 x) const { return __vCond(__vCond::__vCondLTE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator>(const s2vFloat16 x) const { return __vCond(__vCond::__vCondGT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator>=(const s2vFloat16 x) const { return __vCond(__vCond::__vCondGTE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator==(const vFloat x) const {return __vCond(__vCond::__vCondEQ, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator!=(const vFloat x) const { return __vCond(__vCond::__vCondNE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator<(const vFloat x) const { return __vCond(__vCond::__vCondLT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator<=(const vFloat x) const { return __vCond(__vCond::__vCondLTE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator>(const vFloat x) const { return __vCond(__vCond::__vCondGT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator>=(const vFloat x) const { return __vCond(__vCond::__vCondGTE, vFloat(*this), x); }

__attribute__((always_inline)) inline vFloat __vDReg::operator-() const
{
    vFloat tmp = *this;
    return __builtin_rvtt_wh_sfpmov(tmp.get(), SFPMOV_MOD1_COMPSIGN);
}


__attribute__((always_inline)) inline void __vBase::assign(const __rvtt_vec_t in)
{
    v = (initialized) ? __builtin_rvtt_wh_sfpassign_lv(v, in) : in;
    initialized = true;
}

__attribute__((always_inline)) inline void __vBase::operator=(__vLReg lr)
{
    v = __builtin_rvtt_sfpreadlreg(lr.get());
    initialized = true;
}

__attribute__((always_inline)) inline __rvtt_vec_t __vLReg::operator=(__vBase& v) const
{
    __builtin_rvtt_sfppreservelreg(v.get(), reg);
    return v.get();
}


__attribute__((always_inline)) inline vFloat vFloat::operator+(const vFloat b) const { return sfpi_int::fp_add(*this, b); }
__attribute__((always_inline)) inline vFloat vFloat::operator-(const vFloat b) const { return sfpi_int::fp_sub(*this, b); }
__attribute__((always_inline)) inline vFloat vFloat::operator-(const float b) const { return sfpi_int::fp_add(*this, vFloat(-b)); }
__attribute__((always_inline)) inline vFloat vFloat::operator-(const s2vFloat16 b) const { return sfpi_int::fp_add(*this, b.negate()); }
__attribute__((always_inline)) inline vFloat vFloat::operator*(const vFloat b) const { return sfpi_int::fp_mul(*this, b); }
__attribute__((always_inline)) inline __vCond vFloat::operator==(const s2vFloat16 x) const { return __vCond(__vCond::__vCondEQ, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator!=(const s2vFloat16 x) const { return __vCond(__vCond::__vCondNE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator<(const s2vFloat16 x) const { return __vCond(__vCond::__vCondLT, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator<=(const s2vFloat16 x) const { return __vCond(__vCond::__vCondLTE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator>(const s2vFloat16 x) const { return __vCond(__vCond::__vCondGT, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator>=(const s2vFloat16 x) const { return __vCond(__vCond::__vCondGTE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator==(const vFloat x) const { return __vCond(__vCond::__vCondEQ, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator!=(const vFloat x) const { return __vCond(__vCond::__vCondNE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator<(const vFloat x) const { return __vCond(__vCond::__vCondLT, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator<=(const vFloat x) const { return __vCond(__vCond::__vCondLTE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator>(const vFloat x) const { return __vCond(__vCond::__vCondGT, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator>=(const vFloat x) const { return __vCond(__vCond::__vCondGTE, *this, x); }

__attribute__((always_inline)) inline vFloat vFloat::operator*=(const vFloat m)
{
    assign(__builtin_rvtt_wh_sfpmul(v, m.get(), SFPMAD_MOD1_OFFSET_NONE));
    return v;
}

__attribute__((always_inline)) inline vFloat vFloat::operator+=(const vFloat a)
{
    assign(__builtin_rvtt_wh_sfpadd(v, a.get(), SFPMAD_MOD1_OFFSET_NONE));
    return v;
}

__attribute__((always_inline)) inline vFloat vFloat::operator-() const
{
    return __builtin_rvtt_wh_sfpmov(v, SFPMOV_MOD1_COMPSIGN);
    return v;
}

__attribute__((always_inline)) inline void vFloat::loadf16(const s2vFloat16 val)
{
    assign(__builtin_rvtt_wh_sfpxloadi(ckernel::instrn_buffer, val.get_format(), val.get(), 0, 0));
}


__attribute__((always_inline)) inline void __vIntBase::loadss(int16_t val)
{
    assign(__builtin_rvtt_wh_sfpxloadi(ckernel::instrn_buffer, SFPLOADI_MOD0_SHORT, val, 0, 0));
}

__attribute__((always_inline)) inline void __vIntBase::loadus(uint16_t val)
{
    assign(__builtin_rvtt_wh_sfpxloadi(ckernel::instrn_buffer, SFPLOADI_MOD0_USHORT, val, 0, 0));
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator&(const vType b) const
{
    return __builtin_rvtt_wh_sfpand(v, b.get());
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline void __vIntBase::operator&=(const vType b)
{
    v = __builtin_rvtt_wh_sfpand(v, b.get());
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator|(const vType b) const
{
    return __builtin_rvtt_wh_sfpor(v, b.get());
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator|=(const vType b)
{
    v = __builtin_rvtt_wh_sfpor(v, b.get());
    return v;
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator~() const
{
    return __builtin_rvtt_wh_sfpnot(v);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::add(int32_t val, unsigned int mod_base) const
{
    return __builtin_rvtt_wh_sfpxiadd_i(ckernel::instrn_buffer, v, val, 0, 0, mod_base);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator+(const __vIntBase val) const
{
    return __builtin_rvtt_wh_sfpxiadd_v(val.get(), v, 0);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator+(const __vConstIntBase val) const
{
    __rvtt_vec_t c = __builtin_rvtt_sfpreadlreg(val.get());
    return __builtin_rvtt_wh_sfpxiadd_v(c, v, 0);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::sub(int32_t val, unsigned int mod_base) const
{
    return __builtin_rvtt_wh_sfpxiadd_i(ckernel::instrn_buffer, v, val, 0, 0, mod_base | SFPXIADD_MOD1_IS_SUB);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator-(const __vIntBase val) const
{
    return __builtin_rvtt_wh_sfpxiadd_v(val.get(), v, SFPXIADD_MOD1_IS_SUB);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator-(const __vConstIntBase val) const
{
    __rvtt_vec_t c = __builtin_rvtt_sfpreadlreg(val.get());
    return __builtin_rvtt_wh_sfpxiadd_v(c, v, SFPXIADD_MOD1_IS_SUB);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline void __vIntBase::add_eq(int32_t val, unsigned int mod_base)
{
    assign(__builtin_rvtt_wh_sfpxiadd_i(ckernel::instrn_buffer, v, val, 0, 0, mod_base));
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator+=(const __vIntBase val)
{
    assign(__builtin_rvtt_wh_sfpxiadd_v(v, val.get(), 0));
    return v;
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator+=(const __vConstIntBase val)
{
    __rvtt_vec_t c = __builtin_rvtt_sfpreadlreg(val.get());
    assign(__builtin_rvtt_wh_sfpxiadd_v(c, v, 0));
    return v;
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline void __vIntBase::sub_eq(int32_t val, unsigned int mod_base)
{
    assign(__builtin_rvtt_wh_sfpxiadd_i(ckernel::instrn_buffer, v, val, 0, 0, mod_base | SFPXIADD_MOD1_IS_SUB));
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator-=(const __vIntBase val)
{
    assign(__builtin_rvtt_wh_sfpxiadd_v(val.get(), v, SFPXIADD_MOD1_IS_SUB));
    return v;
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator-=(const __vConstIntBase val)
{
    __rvtt_vec_t c = __builtin_rvtt_sfpreadlreg(val.get());
    assign(__builtin_rvtt_wh_sfpxiadd_v(c, v, SFPXIADD_MOD1_IS_SUB));
    return v;
}


__attribute__((always_inline)) inline vFloat operator+(const float a, const vFloat b) { return b + a; }
__attribute__((always_inline)) inline vFloat operator*(const float a, const vFloat b) { return b * a; }
__attribute__((always_inline)) inline vFloat operator-(const float a, const vFloat b) { return vFloat(a) - b; }
__attribute__((always_inline)) inline __vCond operator==(const float a, const vFloat b) { return b == a; }
__attribute__((always_inline)) inline __vCond operator!=(const float a, const vFloat b) { return b != a; }
__attribute__((always_inline)) inline __vCond operator<(const float a, const vFloat b) { return b > a; }
__attribute__((always_inline)) inline __vCond operator<=(const float a, const vFloat b) { return b >= a; }
__attribute__((always_inline)) inline __vCond operator>(const float a, const vFloat b) { return b < a; }
__attribute__((always_inline)) inline __vCond operator>=(const float a, const vFloat b) { return b <= a; }
__attribute__((always_inline)) inline __vCond operator==(const s2vFloat16 a, const vFloat b) { return b == a; }
__attribute__((always_inline)) inline __vCond operator!=(const s2vFloat16 a, const vFloat b) { return b != a; }
__attribute__((always_inline)) inline __vCond operator<(const s2vFloat16 a, const vFloat b) { return b > a; }
__attribute__((always_inline)) inline __vCond operator<=(const s2vFloat16 a, const vFloat b) { return b >= a; }
__attribute__((always_inline)) inline __vCond operator>(const s2vFloat16 a, const vFloat b) { return b < a; }
__attribute__((always_inline)) inline __vCond operator>=(const s2vFloat16 a, const vFloat b) { return b <= a; }

__attribute__((always_inline)) inline vInt operator+(const int32_t a, const vInt b) { return b + a; }
__attribute__((always_inline)) inline vInt operator-(const int32_t a, const vInt b) { return vInt(a) - b; }
__attribute__((always_inline)) inline vInt operator&(const int32_t a, const vInt b) { return b & a; }
__attribute__((always_inline)) inline vInt operator|(const int32_t a, const vInt b) { return b | a; }
__attribute__((always_inline)) inline vInt operator^(const int32_t a, const vInt b) { return b ^ a; }
__attribute__((always_inline)) inline __vCond operator==(const int32_t a, const vInt b) { return b == a; }
__attribute__((always_inline)) inline __vCond operator!=(const int32_t a, const vInt b) { return b != a; }
__attribute__((always_inline)) inline __vCond operator<(const int32_t a, const vInt b) { return b > a; }
__attribute__((always_inline)) inline __vCond operator<=(const int32_t a, const vInt b) { return b >= a; }
__attribute__((always_inline)) inline __vCond operator>(const int32_t a, const vInt b) { return b < a; }
__attribute__((always_inline)) inline __vCond operator>=(const int32_t a, const vInt b) { return b <= a; }

__attribute__((always_inline)) inline vUInt operator+(const int32_t a, const vUInt b) { return b + a; }
__attribute__((always_inline)) inline vUInt operator-(const int32_t a, const vUInt b) { return vUInt(a) - b; }
__attribute__((always_inline)) inline vUInt operator&(const int32_t a, const vUInt b) { return b & a; }
__attribute__((always_inline)) inline vUInt operator|(const int32_t a, const vUInt b) { return b | a; }
__attribute__((always_inline)) inline vUInt operator^(const int32_t a, const vUInt b) { return b ^ a; }
__attribute__((always_inline)) inline __vCond operator==(const int32_t a, const vUInt b) { return b == a; }
__attribute__((always_inline)) inline __vCond operator!=(const int32_t a, const vUInt b) { return b != a; }
__attribute__((always_inline)) inline __vCond operator<(const int32_t a, const vUInt b) { return b > a; }
__attribute__((always_inline)) inline __vCond operator<=(const int32_t a, const vUInt b) { return b >= a; }
__attribute__((always_inline)) inline __vCond operator>(const int32_t a, const vUInt b) { return b < a; }
__attribute__((always_inline)) inline __vCond operator>=(const int32_t a, const vUInt b) { return b <= a; }


__attribute__((always_inline)) inline vFloat __vConstFloat::operator+(const vFloat b) const { return vFloat(*this) + b; }
__attribute__((always_inline)) inline vFloat __vConstFloat::operator-(const vFloat b) const { return vFloat(*this) - b; }
__attribute__((always_inline)) inline vFloat __vConstFloat::operator*(const vFloat b) const { return vFloat(*this) * b; }
__attribute__((always_inline)) inline __vCond __vConstFloat::operator==(const vFloat x) const { return __vCond(__vCond::__vCondEQ, *this, x); }
__attribute__((always_inline)) inline __vCond __vConstFloat::operator!=(const vFloat x) const { return __vCond(__vCond::__vCondNE, *this, x); }
__attribute__((always_inline)) inline __vCond __vConstFloat::operator<(const vFloat x) const { return __vCond(__vCond::__vCondLT, *this, x); }
__attribute__((always_inline)) inline __vCond __vConstFloat::operator<=(const vFloat x) const { return __vCond(__vCond::__vCondLTE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vConstFloat::operator>(const vFloat x) const { return __vCond(__vCond::__vCondGT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vConstFloat::operator>=(const vFloat x) const { return __vCond(__vCond::__vCondGTE, *this, x); }

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vConstIntBase::operator+(const vType b) const { return vType(*this) + b; }
__attribute__((always_inline)) inline vInt __vConstIntBase::operator+(int32_t b) const { return vInt(*this) + b; }

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vConstIntBase::operator-(const vType b) const { return vType(*this) - b; }
__attribute__((always_inline)) inline vInt __vConstIntBase::operator-(int32_t b) const { return vInt(*this) - b; }

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vConstIntBase::operator&(const vType b) const { return vType(*this) & b; }
__attribute__((always_inline)) inline vInt __vConstIntBase::operator&(int32_t b) const { return vInt(*this) & vInt(b); }

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vConstIntBase::operator|(const vType b) const { return vType(*this) | b; }
__attribute__((always_inline)) inline vInt __vConstIntBase::operator|(int32_t b) const { return vInt(*this) | vInt(b); }

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vConstIntBase::operator^(const vType b) const { return vType(*this) ^ b; }
__attribute__((always_inline)) inline vInt __vConstIntBase::operator^(int32_t b) const { return vInt(*this) ^ vInt(b); }

__attribute__((always_inline)) inline __vCond __vConstIntBase::operator==(const vInt x) const { return __vCond(__vCond::__vCondEQ, __vIntBase(*this), x, 0); }
__attribute__((always_inline)) inline __vCond __vConstIntBase::operator!=(const vInt x) const { return __vCond(__vCond::__vCondNE, __vIntBase(*this), x, 0); }
__attribute__((always_inline)) inline __vCond __vConstIntBase::operator<(const vInt x) const { return __vCond(__vCond::__vCondLT, __vIntBase(*this), x, 0); }
__attribute__((always_inline)) inline __vCond __vConstIntBase::operator<=(const vInt x) const { return __vCond(__vCond::__vCondLTE, __vIntBase(*this), x, 0); }
__attribute__((always_inline)) inline __vCond __vConstIntBase::operator>(const vInt x) const { return __vCond(__vCond::__vCondGT, __vIntBase(*this), x, 0); }
__attribute__((always_inline)) inline __vCond __vConstIntBase::operator>=(const vInt x) const { return __vCond(__vCond::__vCondGTE, __vIntBase(*this), x, 0); }


vInt vInt::operator<<(unsigned amt) const {
  return __builtin_rvtt_wh_sfpshft_i(ckernel::instrn_buffer, get(), amt, 0, 0);
}
vInt vInt::operator<<(vInt amt) const {
  return __builtin_rvtt_wh_sfpshft_v(get(), amt.get());
}
vUInt vUInt::operator<<(unsigned amt) const {
  return __builtin_rvtt_wh_sfpshft_i(ckernel::instrn_buffer, get(), amt, 0, 0);
}
vUInt vUInt::operator<<(vInt amt) const {
  return __builtin_rvtt_wh_sfpshft_v(get(), amt.get());
}
vUInt vUInt::operator>>(unsigned amt) const {
  return __builtin_rvtt_wh_sfpshft_i(ckernel::instrn_buffer, get(), -amt, 0, 0);
}
vUInt vUInt::operator>>(vInt amt) const {
  return __builtin_rvtt_wh_sfpshft_v(get(), (-amt).get());
}



__attribute__((always_inline)) inline vFloat::vFloat(const __vConstFloat creg)
{
    v = __builtin_rvtt_sfpreadlreg(creg.get());
    initialized = true;
}

__attribute__((always_inline)) inline __vIntBase::__vIntBase(const __vConstIntBase creg)
{
    v = __builtin_rvtt_sfpreadlreg(creg.get());
    initialized = true;
}

__attribute__((always_inline)) inline vInt::vInt(const __vCond vc)
{
    v = __builtin_rvtt_sfpxcondi(vc.get());
    initialized = true;
}

__attribute__((always_inline)) inline const __vCond vInt::operator==(int32_t val) const { return __vCond(__vCond::__vCondEQ, *this, val, SFPXIADD_MOD1_SIGNED); }
__attribute__((always_inline)) inline const __vCond vInt::operator!=(int32_t val) const { return __vCond(__vCond::__vCondNE, *this, val, SFPXIADD_MOD1_SIGNED); }
__attribute__((always_inline)) inline const __vCond vInt::operator<(int32_t val) const { return __vCond(__vCond::__vCondLT, *this, val, SFPXIADD_MOD1_SIGNED); }
__attribute__((always_inline)) inline const __vCond vInt::operator<=(int32_t val) const { return __vCond(__vCond::__vCondLTE, *this, val, SFPXIADD_MOD1_SIGNED); }
__attribute__((always_inline)) inline const __vCond vInt::operator>(int32_t val) const { return __vCond(__vCond::__vCondGT, *this, val, SFPXIADD_MOD1_SIGNED); }
__attribute__((always_inline)) inline const __vCond vInt::operator>=(int32_t val) const { return __vCond(__vCond::__vCondGTE, *this, val, SFPXIADD_MOD1_SIGNED); }

__attribute__((always_inline)) inline const __vCond vInt::operator==(const __vIntBase src) const { return __vCond(__vCond::__vCondEQ, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vInt::operator!=(const __vIntBase src) const { return __vCond(__vCond::__vCondNE, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vInt::operator<(const __vIntBase src) const { return __vCond(__vCond::__vCondLT, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vInt::operator<=(const __vIntBase src) const { return __vCond(__vCond::__vCondLTE, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vInt::operator>(const __vIntBase src) const { return __vCond(__vCond::__vCondGT, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vInt::operator>=(const __vIntBase src) const { return __vCond(__vCond::__vCondGTE, src, *this, 0); }


__attribute__((always_inline)) inline vUInt::vUInt(const __vCond vc)
{
    v = __builtin_rvtt_sfpxcondi(vc.get());
    initialized = true;
}

__attribute__((always_inline)) inline const __vCond vUInt::operator==(int32_t val) const { return __vCond(__vCond::__vCondEQ, *this, val, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator!=(int32_t val) const { return __vCond(__vCond::__vCondNE, *this, val, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator<(int32_t val) const { return __vCond(__vCond::__vCondLT, *this, val, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator<=(int32_t val) const { return __vCond(__vCond::__vCondLTE, *this, val, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator>(int32_t val) const { return __vCond(__vCond::__vCondGT, *this, val, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator>=(int32_t val) const { return __vCond(__vCond::__vCondGTE, *this, val, 0); }

__attribute__((always_inline)) inline const __vCond vUInt::operator==(const __vIntBase src) const { return __vCond(__vCond::__vCondEQ, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator!=(const __vIntBase src) const { return __vCond(__vCond::__vCondNE, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator<(const __vIntBase src) const { return __vCond(__vCond::__vCondLT, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator<=(const __vIntBase src) const { return __vCond(__vCond::__vCondLTE, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator>(const __vIntBase src) const { return __vCond(__vCond::__vCondGT, src, *this, 0); }
__attribute__((always_inline)) inline const __vCond vUInt::operator>=(const __vIntBase src) const { return __vCond(__vCond::__vCondGTE, src, *this, 0); }


__attribute__((always_inline)) inline __vCCCtrl::__vCCCtrl() : push_count(0)
{
    push();
}

__attribute__((always_inline)) inline void __vCCCtrl::cc_if(const __vCond& op) const
{
    __builtin_rvtt_sfpxcondb(op.get(), top);
}

__attribute__((always_inline)) inline void __vCCCtrl::cc_if(const __vIntBase& v) const
{
    __builtin_rvtt_sfpxcondb(__vCond(__vCond::__vCondNE, v, 0, 0).get(), top);
}

__attribute__((always_inline)) inline void __vCCCtrl::cc_elseif(const __vCond& op) const
{
    cc_if(op);
}

__attribute__((always_inline)) inline void __vCCCtrl::cc_elseif(const __vIntBase& v) const
{
    cc_if(v);
}

__attribute__((always_inline)) inline void __vCCCtrl::cc_else() const
{
    __builtin_rvtt_wh_sfpcompc();
}

__attribute__((always_inline)) inline __vCCCtrl::~__vCCCtrl()
{
    while (push_count != 0) {
        pop();
    }
}

__attribute__((always_inline)) inline void __vCCCtrl::mark_top()
{
    top = __builtin_rvtt_sfpxvif();
}

__attribute__((always_inline)) inline void __vCCCtrl::push()
{
    push_count++;
    __builtin_rvtt_wh_sfppushc(0);
}

__attribute__((always_inline)) inline void __vCCCtrl::pop()
{
    push_count--;
    __builtin_rvtt_wh_sfppopc(0);
}

__attribute__((always_inline)) inline void __vCCCtrl::enable_cc()
{
    __builtin_rvtt_wh_sfpencc(SFPENCC_IMM12_BOTH, SFPENCC_MOD1_EI_RI);
}


constexpr __DestReg dst_reg;
constexpr __LReg l_reg;

}
       

namespace sfpi {


constexpr __vConstFloat vConst0p8373(CREG_IDX_0P837300003);
constexpr __vConstFloat vConstFloatPrgm0(CREG_IDX_PRGM1);
constexpr __vConstFloat vConstFloatPrgm1(CREG_IDX_PRGM2);
constexpr __vConstFloat vConstFloatPrgm2(CREG_IDX_PRGM3);

constexpr __vConstIntBase vConstTileId(CREG_IDX_TILEID);
constexpr __vConstIntBase vConstIntPrgm0(CREG_IDX_PRGM1);
constexpr __vConstIntBase vConstIntPrgm1(CREG_IDX_PRGM2);
constexpr __vConstIntBase vConstIntPrgm2(CREG_IDX_PRGM3);


__attribute__((always_inline)) inline __vCond __vDReg::operator==(const float x) const {return __vCond(__vCond::__vCondEQ, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator!=(const float x) const { return __vCond(__vCond::__vCondNE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator<(const float x) const { return __vCond(__vCond::__vCondLT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator<=(const float x) const { return __vCond(__vCond::__vCondLTE, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator>(const float x) const { return __vCond(__vCond::__vCondGT, vFloat(*this), x); }
__attribute__((always_inline)) inline __vCond __vDReg::operator>=(const float x) const { return __vCond(__vCond::__vCondGTE, vFloat(*this), x); }

template <>
__attribute__((always_inline)) inline vFloat __vDReg::operator=(const vFloat vec) const
{
    __builtin_rvtt_wh_sfpstore(ckernel::instrn_buffer, vec.get(), SFPSTORE_MOD0_FMT_SRCB, SFPSTORE_ADDR_MODE_NOINC, reg, 0, 0);
    return vec;
}

__attribute__((always_inline)) inline vFloat __vDReg::operator=(const double d) const
{
    vFloat v(static_cast<float>(d));
    *this = v;
    return v;
}

__attribute__((always_inline)) inline vFloat __vDReg::operator=(s2vFloat16 f) const
{
    vFloat v(f);
    *this = v;
    return v;
}

__attribute__((always_inline)) inline vFloat __vDReg::operator=(const float f) const
{
    vFloat v(f);
    *this = v;
    return v;
}

template <typename vecType, typename std::enable_if_t<std::is_base_of<__vBase, vecType>::value>*>
__attribute__((always_inline)) inline vecType __vDReg::operator=(const vecType vec) const
{
    __builtin_rvtt_wh_sfpstore(ckernel::instrn_buffer, vec.get(), SFPSTORE_MOD0_FMT_INT32_TO_SM, SFPSTORE_ADDR_MODE_NOINC, reg, 0, 0);
    return vec;
}

__attribute__((always_inline)) inline void __vDReg::operator=(const __vDReg dreg) const
{
    vFloat tmp = dreg;
    __builtin_rvtt_wh_sfpstore(ckernel::instrn_buffer, tmp.get(), SFPSTORE_MOD0_FMT_SRCB, SFPSTORE_ADDR_MODE_NOINC, reg, 0, 0);
}

__attribute__((always_inline)) inline vFloat __vDReg::operator=(const __vConstFloat creg) const
{
    __rvtt_vec_t lr = __builtin_rvtt_sfpreadlreg(creg.get());
    __builtin_rvtt_wh_sfpstore(ckernel::instrn_buffer, lr, SFPSTORE_MOD0_FMT_SRCB, SFPSTORE_ADDR_MODE_NOINC, reg, 0, 0);
    return vFloat(lr);
}


__attribute__((always_inline)) inline __vCond vFloat::operator==(const float x) const { return __vCond(__vCond::__vCondEQ, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator!=(const float x) const { return __vCond(__vCond::__vCondNE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator<(const float x) const { return __vCond(__vCond::__vCondLT, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator<=(const float x) const { return __vCond(__vCond::__vCondLTE, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator>(const float x) const { return __vCond(__vCond::__vCondGT, *this, x); }
__attribute__((always_inline)) inline __vCond vFloat::operator>=(const float x) const { return __vCond(__vCond::__vCondGTE, *this, x); }

__attribute__((always_inline)) inline vFloat vFloat::operator-=(const vFloat a)
{
    __rvtt_vec_t neg1 = __builtin_rvtt_sfpreadlreg(vConstNeg1.get());
    assign(__builtin_rvtt_wh_sfpmad(neg1, a.get(), v, SFPMAD_MOD1_OFFSET_NONE));
    return v;
}

__attribute__((always_inline)) inline vFloat::vFloat(const __vDReg dreg)
{
    v = __builtin_rvtt_wh_sfpload(ckernel::instrn_buffer, SFPLOAD_MOD0_FMT_SRCB, SFPLOAD_ADDR_MODE_NOINC, dreg.get(), 0, 0);
    initialized = true;
}

__attribute__((always_inline)) inline void vFloat::loadf(const float val)
{
    assign(__builtin_rvtt_wh_sfpxloadi(ckernel::instrn_buffer, SFPXLOADI_MOD0_FLOAT, __f32asui(val), 0, 0));
}


__attribute__((always_inline)) inline void __vIntBase::loadsi(int32_t val)
{
    assign(__builtin_rvtt_wh_sfpxloadi(ckernel::instrn_buffer, SFPXLOADI_MOD0_INT32, val, 0, 0));
}

__attribute__((always_inline)) inline void __vIntBase::loadui(uint32_t val)
{
    assign(__builtin_rvtt_wh_sfpxloadi(ckernel::instrn_buffer, SFPXLOADI_MOD0_UINT32, val, 0, 0));
}

__attribute__((always_inline)) inline vInt::vInt(const __vDReg dreg)
{
    v = __builtin_rvtt_wh_sfpload(ckernel::instrn_buffer, SFPLOAD_MOD0_FMT_INT32_TO_SM, SFPLOAD_ADDR_MODE_NOINC, dreg.get(), 0, 0);
    initialized = true;
}

__attribute__((always_inline)) inline vUInt::vUInt(const __vDReg dreg)
{
    v = __builtin_rvtt_wh_sfpload(ckernel::instrn_buffer, SFPLOAD_MOD0_FMT_INT32_TO_SM, SFPLOAD_ADDR_MODE_NOINC, dreg.get(), 0, 0);
    initialized = true;
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator^(const vType b) const
{
    return __builtin_rvtt_wh_sfpxor(v, b.get());
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vIntBase, vType>::value>*>
__attribute__((always_inline)) inline vType __vIntBase::operator^=(const vType b)
{
    v = __builtin_rvtt_wh_sfpxor(v, b.get());
    return v;
}

__attribute__((always_inline)) inline void __vConstFloat::operator=(const float in) const
{
    vFloat tmp = in;
    __builtin_rvtt_wh_sfpconfig_v(tmp.get(), get());
}

__attribute__((always_inline)) inline void __vConstFloat::operator=(const s2vFloat16 in) const
{
    vFloat tmp = in;
    __builtin_rvtt_wh_sfpconfig_v(tmp.get(), get());
}

__attribute__((always_inline)) inline void __vConstIntBase::operator=(const int in) const
{
    vInt tmp = in;
    __builtin_rvtt_wh_sfpconfig_v(tmp.get(), get());
}

enum class LRegs {
    LReg0 = 0,
    LReg1 = 1,
    LReg2 = 2,
    LReg3 = 3,
    LReg4 = 4,
    LReg5 = 5,
    LReg6 = 6,
    LReg7 = 7,
    LRegCount = SFP_LREG_COUNT,
};

}
       

namespace sfpi {




__attribute__((always_inline)) inline vFloat lut(const vFloat v, const vUInt l0, const vUInt l1, const vUInt l2)
{
    return __builtin_rvtt_wh_sfplut(l0.get(), l1.get(), l2.get(), v.get(), SFPLUT_MOD0_SGN_RETAIN);
}

__attribute__((always_inline)) inline vFloat lut_sign(const vFloat v, const vUInt l0, const vUInt l1, const vUInt l2)
{
    return __builtin_rvtt_wh_sfplut(l0.get(), l1.get(), l2.get(), v.get(), SFPLUT_MOD0_SGN_UPDATE);
}

__attribute__((always_inline)) inline vFloat lut2(const vFloat v, const vUInt l0, const vUInt l1, const vUInt l2)
{
    return __builtin_rvtt_wh_sfplutfp32_3r(l0.get(), l1.get(), l2.get(), v.get(), SFPLUTFP32_MOD0_FP16_3ENTRY_TABLE | SFPLUTFP32_MOD0_SGN_RETAIN)
                                                                                                                ;
}

__attribute__((always_inline)) inline vFloat lut2_sign(const vFloat v, const vUInt l0, const vUInt l1, const vUInt l2)
{
    return __builtin_rvtt_wh_sfplutfp32_3r(l0.get(), l1.get(), l2.get(), v.get(), SFPLUTFP32_MOD0_FP16_3ENTRY_TABLE | SFPLUTFP32_MOD0_SGN_UPDATE)
                                                                                                                ;
}

__attribute__((always_inline)) inline vFloat lut2(const vFloat v,
                        const vFloat a0, const vFloat a1, const vFloat a2,
                        const vFloat b0, const vFloat b1, const vFloat b2)
{
    return __builtin_rvtt_wh_sfplutfp32_6r(a0.get(), a1.get(), a2.get(), b0.get(), b1.get(), b2.get(), v.get(), SFPLUTFP32_MOD0_FP32_3ENTRY_TABLE | SFPLUTFP32_MOD0_SGN_RETAIN)

                                                                                                                ;
}

__attribute__((always_inline)) inline vFloat lut2_sign(const vFloat v,
                             const vFloat a0, const vFloat a1, const vFloat a2,
                             const vFloat b0, const vFloat b1, const vFloat b2)
{
    return __builtin_rvtt_wh_sfplutfp32_6r(a0.get(), a1.get(), a2.get(), b0.get(), b1.get(), b2.get(), v.get(), SFPLUTFP32_MOD0_FP32_3ENTRY_TABLE | SFPLUTFP32_MOD0_SGN_UPDATE)

                                                                                                                ;
}

__attribute__((always_inline)) inline vFloat lut2(const vFloat v,
                        const vUInt a01, const vUInt a23, const vUInt a45,
                        const vUInt b01, const vUInt b23, const vUInt b45, const int mode = 1)
{
    unsigned int mod = (mode == 1) ? SFPLUTFP32_MOD0_FP16_6ENTRY_TABLE1 : SFPLUTFP32_MOD0_FP16_6ENTRY_TABLE2;
    return __builtin_rvtt_wh_sfplutfp32_6r(a01.get(), a23.get(), a45.get(), b01.get(), b23.get(), b45.get(), v.get(), mod | SFPLUTFP32_MOD0_SGN_RETAIN)

                                                                                  ;
}

__attribute__((always_inline)) inline vFloat lut2_sign(const vFloat v,
                             const vUInt a01, const vUInt a23, const vUInt a45,
                             const vUInt b01, const vUInt b23, const vUInt b45, const int mode = 1)
{
    unsigned int mod = (mode == 1) ? SFPLUTFP32_MOD0_FP16_6ENTRY_TABLE1 : SFPLUTFP32_MOD0_FP16_6ENTRY_TABLE2;
    return __builtin_rvtt_wh_sfplutfp32_6r(a01.get(), a23.get(), a45.get(), b01.get(), b23.get(), b45.get(), v.get(), mod | SFPLUTFP32_MOD0_SGN_UPDATE)

                                                                                  ;
}

__attribute__((always_inline)) inline vInt exexp(const vFloat v)
{
    return __builtin_rvtt_wh_sfpexexp(v.get(), SFPEXEXP_MOD1_DEBIAS);
}

__attribute__((always_inline)) inline vInt exexp_nodebias(const vFloat v)
{
    return __builtin_rvtt_wh_sfpexexp(v.get(), SFPEXEXP_MOD1_NODEBIAS);
}

__attribute__((always_inline)) inline vInt exman8(const vFloat v)
{
    return __builtin_rvtt_wh_sfpexman(v.get(), SFPEXMAN_MOD1_PAD8);
}

__attribute__((always_inline)) inline vInt exman9(const vFloat v)
{
    return __builtin_rvtt_wh_sfpexman(v.get(), SFPEXMAN_MOD1_PAD9);
}

__attribute__((always_inline)) inline vFloat setexp(const vFloat v, const uint32_t exp)
{
    return __builtin_rvtt_wh_sfpsetexp_i(ckernel::instrn_buffer, exp, 0, 0, v.get());
}

__attribute__((always_inline)) inline vFloat setexp(const vFloat v, const __vIntBase exp)
{


    return __builtin_rvtt_wh_sfpsetexp_v(exp.get(), v.get());
}

__attribute__((always_inline)) inline vFloat setman(const vFloat v, const uint32_t man)
{
    return __builtin_rvtt_wh_sfpsetman_i(ckernel::instrn_buffer, man, 0, 0, v.get(), 0);
}

__attribute__((always_inline)) inline vFloat setman(const vFloat v, const __vIntBase man)
{


    return __builtin_rvtt_wh_sfpsetman_v(man.get(), v.get());
}

__attribute__((always_inline)) inline vFloat addexp(const vFloat in, const int32_t exp)
{
    return __builtin_rvtt_wh_sfpdivp2(ckernel::instrn_buffer, exp, 0, 0, in.get(), SFPSDIVP2_MOD1_ADD);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vBase, vType>::value>* = nullptr>
__attribute__((always_inline)) inline vType setsgn(const vType v, const int32_t sgn)
{
    return __builtin_rvtt_wh_sfpsetsgn_i(ckernel::instrn_buffer, sgn, 0, 0, v.get());
}

template <typename vTypeA, typename vTypeB,
    typename std::enable_if_t<std::is_base_of<__vBase, vTypeA>::value>* = nullptr,
    typename std::enable_if_t<std::is_base_of<__vBase, vTypeB>::value>* = nullptr>
__attribute__((always_inline)) inline vTypeA setsgn(const vTypeA v, const vTypeB sgn)
{


    return __builtin_rvtt_wh_sfpsetsgn_v(sgn.get(), v.get());
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vBase, vType>::value>* = nullptr>
__attribute__((always_inline)) inline vType setsgn(const vType v, const vInt sgn)
{


    return __builtin_rvtt_wh_sfpsetsgn_v(sgn.get(), v.get());
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vBase, vType>::value>* = nullptr>
__attribute__((always_inline)) inline vInt lz(const vType v)
{
    return vInt(__builtin_rvtt_wh_sfplz(v.get(), SFPLZ_MOD1_CC_NONE));
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vBase, vType>::value>* = nullptr>
__attribute__((always_inline)) inline vInt lz_nosgn(const vType v)
{
    return vInt(__builtin_rvtt_wh_sfplz(v.get(), SFPLZ_MOD1_NOSGN_CC_NONE));
}

__attribute__((always_inline)) inline vFloat abs(const vFloat v)
{
    return __builtin_rvtt_wh_sfpabs(v.get(), SFPABS_MOD1_FLOAT);
}

__attribute__((always_inline)) inline vInt abs(const vInt v)
{
    return __builtin_rvtt_wh_sfpabs(v.get(), SFPABS_MOD1_INT);
}

__attribute__((always_inline)) inline vUInt shft(const vUInt v, const vInt amt)
{
    return __builtin_rvtt_wh_sfpshft_v(v.get(), amt.get());
}

__attribute__((always_inline)) inline vUInt shft(const vUInt v, int amt)
{
  return __builtin_rvtt_wh_sfpshft_i(ckernel::instrn_buffer, v.get(), amt, 0, 0);
}

template <typename vType, typename std::enable_if_t<std::is_base_of<__vBase, vType>::value>* = nullptr>
__attribute__((always_inline)) inline vType reinterpret(const __vBase v)
{
    return vType(v.get());
}

__attribute__((always_inline)) inline vFloat int32_to_float(vInt in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpcast(in.get(), round_mode ? SFPCAST_MOD1_INT32_TO_FP32_RNS : SFPCAST_MOD1_INT32_TO_FP32_RNE);
}

__attribute__((always_inline)) inline vUInt float_to_fp16a(vFloat in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, 0, 0, 0, in.get(), SFPSTOCHRND_MOD1_FP32_TO_FP16A)


                                                                       ;
}

__attribute__((always_inline)) inline vUInt float_to_fp16b(vFloat in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, 0, 0, 0, in.get(), SFPSTOCHRND_MOD1_FP32_TO_FP16B)


                                                                       ;
}

__attribute__((always_inline)) inline vUInt float_to_uint8(vFloat in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, 0, 0, 0, in.get(), SFPSTOCHRND_MOD1_FP32_TO_UINT8)


                                                                       ;
}

__attribute__((always_inline)) inline vUInt float_to_int8(vFloat in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, 0, 0, 0, in.get(), SFPSTOCHRND_MOD1_FP32_TO_INT8)


                                                                      ;
}

__attribute__((always_inline)) inline vUInt int32_to_uint8(vInt in, vUInt descale, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_v(round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, descale.get(), in.get(), SFPSTOCHRND_MOD1_INT32_TO_UINT8)


                                                                        ;
}

__attribute__((always_inline)) inline vUInt int32_to_uint8(vInt in, unsigned int descale, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, descale, 0, 0, in.get(), SFPSTOCHRND_MOD1_INT32_TO_UINT8 | SFPSTOCHRND_MOD1_IMM8)


                                                                                                ;
}

__attribute__((always_inline)) inline vUInt int32_to_int8(vInt in, vUInt descale, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_v(round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, descale.get(), in.get(), SFPSTOCHRND_MOD1_INT32_TO_INT8)


                                                                       ;
}

__attribute__((always_inline)) inline vUInt int32_to_int8(vInt in, unsigned int descale, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, descale, 0, 0, in.get(), SFPSTOCHRND_MOD1_INT32_TO_INT8 | SFPSTOCHRND_MOD1_IMM8)


                                                                                               ;
}

__attribute__((always_inline)) inline vUInt float_to_uint16(vFloat in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, 0, 0, 0, in.get(), SFPSTOCHRND_MOD1_FP32_TO_UINT16)


                                                                        ;
}

__attribute__((always_inline)) inline vUInt float_to_int16(vFloat in, int round_mode = 1)
{
    return __builtin_rvtt_wh_sfpstochrnd_i(ckernel::instrn_buffer, round_mode ? SFPSTOCHRND_RND_STOCH : SFPSTOCHRND_RND_EVEN, 0, 0, 0, in.get(), SFPSTOCHRND_MOD1_FP32_TO_INT16)


                                                                       ;
}

__attribute__((always_inline)) inline void subvec_transp(__vBase& l0, __vBase& l1, __vBase& l2, __vBase& l3)
{
    __builtin_rvtt_wh_sfptransp(l0.get(), l1.get(), l2.get(), l3.get());
}

__attribute__((always_inline)) inline __rvtt_vec_t subvec_shflror1(const __vBase& src)

{
    return __builtin_rvtt_wh_sfpshft2_e(src.get(), SFPSHFT2_MOD1_SUBVEC_SHFLROR1);
}

__attribute__((always_inline)) inline __rvtt_vec_t subvec_shflshr1(const __vBase& src)

{
    return __builtin_rvtt_wh_sfpshft2_e(src.get(), SFPSHFT2_MOD1_SUBVEC_SHFLSHR1);
}

__attribute__((always_inline)) inline void vec_swap(__vBase& dst, __vBase& src)
{
    __builtin_rvtt_wh_sfpswap(dst.get(), src.get(), SFPSWAP_MOD1_SWAP);
}

__attribute__((always_inline)) inline void vec_min_max(__vBase& dst, __vBase& src)
{
    __builtin_rvtt_wh_sfpswap(dst.get(), src.get(), SFPSWAP_MOD1_VEC_MIN_MAX);
}

}




       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_abs_(const int iterations)
{

    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        sfpi::dst_reg[0] = sfpi::abs(v);
        sfpi::dst_reg++;
    }
}

}
}




       








       








       



namespace ckernel
{
namespace sfpu
{

template <int max_iter = 3>
__attribute__((always_inline)) inline sfpi::vFloat _sfpu_reciprocal_(const sfpi::vFloat in)
{

    sfpi::vFloat val = sfpi::setsgn(in, 1);

    val = setexp(val, 126);



    sfpi::vFloat vConstLn2Recip = sfpi::vConstFloatPrgm0;
    sfpi::vFloat two = sfpi::vConstFloatPrgm1;
    sfpi::vFloat result = vConstLn2Recip * (val * vConstLn2Recip + two);

    for (int s_iter = 0; s_iter < (max_iter - 1); s_iter++)
    {
        result = result * (val * result + two);
    }

    sfpi::vInt orig_exp = exexp(in);
    sfpi::vInt new_exp = exexp(result);



    new_exp -= orig_exp;
    new_exp += 126;

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(new_exp < 0);
    {


        result = 0.0F;
        new_exp = 0;
    }
    };


    return setexp(result, new_exp);
}

template <bool APPROXIMATION_MODE, int ITERATIONS, bool is_fp32_dest_acc_en>
inline void _calculate_reciprocal_(const int iterations)
{
#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat out = _sfpu_reciprocal_<APPROXIMATION_MODE ? 2 : 3>(in);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0.0F);
        {

            out = -out;
        }
        };

        if constexpr (is_fp32_dest_acc_en || APPROXIMATION_MODE)
        {
            sfpi::dst_reg[0] = out;
        }
        else
        {
            sfpi::dst_reg[0] = sfpi::reinterpret<sfpi::vFloat>(float_to_fp16b(out, 0));
        }

        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void _init_reciprocal_()
{
    sfpi::vConstFloatPrgm0 = 1.442695f;
    sfpi::vConstFloatPrgm1 = 2.0f;
}

}
}



namespace ckernel::sfpu
{

__attribute__((always_inline)) inline sfpi::vFloat _sfpu_exp_(sfpi::vFloat val)
{

    sfpi::vInt exp = exexp(val);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp >= 0);
    {
        val = setexp(val, 126);
    }
    };


    sfpi::vFloat tmp = val * sfpi::vConst0p8373 + sfpi::s2vFloat16b(0.863281);
    val = val * tmp + sfpi::vConst1;

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp >= 0);
    {
        val = val * val;
        for (int s_iter = 0; s_iter < 7; s_iter++)
        {
            exp = exp - 1;

            __cc.mark_top(); __cc.cc_if(exp >= 0);
            val = val * val;
        }
    }
    };

    return val;
}

template <bool APPROXIMATION_MODE>
__attribute__((always_inline)) inline sfpi::vFloat _calculate_exponential_body_(sfpi::vFloat in)
{
    sfpi::vFloat out;

    if constexpr (APPROXIMATION_MODE)
    {
        constexpr int FRAC_BITS = 3;
        constexpr uint SP_BIAS = 127 << FRAC_BITS;


        sfpi::vFloat vConstLn2Recip = sfpi::vConstFloatPrgm0;
        sfpi::vFloat conv = in * vConstLn2Recip;


        sfpi::vInt c23_73 = p_exp::C23_73;
        sfpi::vInt tmp = sfpi::reinterpret<sfpi::vInt>(conv) - c23_73;


        tmp += SP_BIAS;


        out = sfpi::reinterpret<sfpi::vFloat>(tmp << (10 - FRAC_BITS));
    }
    else
    {

        out = _sfpu_exp_(sfpi::setsgn(in, 0));

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            out = _sfpu_reciprocal_(out);
        }
        };
    }

    return out;
}

inline sfpi::vFloat _calculate_exponential_approx_(sfpi::vFloat in)
{

    sfpi::vFloat vConstLn2Recip = sfpi::vConstFloatPrgm0;
    sfpi::vFloat c23_73 = sfpi::vConstFloatPrgm1;
    sfpi::vInt adj_exp = sfpi::vConstIntPrgm2;
    in = in * vConstLn2Recip + c23_73;


    sfpi::vInt in_short = adj_exp + sfpi::reinterpret<sfpi::vInt>(in);


    in_short <<= 10 - p_exp::FRAC_BITS;
    return sfpi::reinterpret<sfpi::vFloat>(in_short);
}

template <bool APPROXIMATION_MODE, bool SCALE_EN, bool SKIP_POSITIVE_CHECK>
inline sfpi::vFloat _calculate_exponential_piecewise_(sfpi::vFloat in, const uint16_t exp_base_scale_factor )
{

    sfpi::vFloat result = 0.0f;
    if constexpr (SCALE_EN)
    {
        in = in * sfpi::s2vFloat16b(exp_base_scale_factor);
    }
    if constexpr (APPROXIMATION_MODE)
    {
        if constexpr (!SKIP_POSITIVE_CHECK)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in >= 89);
            {

                sfpi::vFloat in_inf = std::numeric_limits<float>::infinity();
                result = in_inf;
            }
            __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(in < -42);
            {

                result = 0.0f;
            }
            __cc.cc_else();
            {
                result = _calculate_exponential_approx_(in);
            }
            };
        }
        else
        {

            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < -42);
            {
                result = 0.0f;
            }
            __cc.cc_else();
            {
                result = _calculate_exponential_approx_(in);
            }
            };
        }
    }
    else
    {
        result = _sfpu_exp_(sfpi::setsgn(in, 0));

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            result = _sfpu_reciprocal_(result);
        }
        };
    }

    return result;
}

template <bool APPROXIMATION_MODE, bool SCALE_EN, int ITERATIONS, bool FAST_APPROX, bool SKIP_POSITIVE_CHECK>
void _calculate_exponential_(const uint16_t exp_base_scale_factor )
{
    if constexpr (FAST_APPROX && APPROXIMATION_MODE)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((4) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))))



              ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((5) << 20) + ((0) << 16) + ((3) << 14) + ((2) << 0))))))



              ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((6) << 20) + ((0) << 16) + ((3) << 14) + ((4) << 0))))))



              ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((7) << 20) + ((0) << 16) + ((3) << 14) + ((6) << 0))))))



              ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((4) << 20) + ((0) << 16) + ((3) << 14) + ((8) << 0))))))



              ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((5) << 20) + ((0) << 16) + ((3) << 14) + ((10) << 0))))))



               ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((6) << 20) + ((0) << 16) + ((3) << 14) + ((12) << 0))))))



               ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((7) << 20) + ((0) << 16) + ((3) << 14) + ((14) << 0))))))



               ;
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((0) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((1) << 20) + ((0) << 16) + ((3) << 14) + ((2) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((2) << 20) + ((0) << 16) + ((3) << 14) + ((4) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((3) << 20) + ((0) << 16) + ((3) << 14) + ((6) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((0) << 20) + ((0) << 16) + ((3) << 14) + ((8) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((1) << 20) + ((0) << 16) + ((3) << 14) + ((10) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((2) << 20) + ((0) << 16) + ((3) << 14) + ((12) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x93 << 24) + (((3) << 20) + ((0) << 16) + ((3) << 14) + ((14) << 0))))));





        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));


    }
    else
    {

        for (int d = 0; d < ITERATIONS; d++)
        {
            sfpi::vFloat val = sfpi::dst_reg[0];
            sfpi::vFloat result = _calculate_exponential_piecewise_<APPROXIMATION_MODE, SCALE_EN, SKIP_POSITIVE_CHECK>(val, exp_base_scale_factor);
            sfpi::dst_reg[0] = result;
            sfpi::dst_reg++;
        }
    }
}

constexpr auto bits = [](float x) constexpr { return __builtin_bit_cast(std::uint32_t, x); };
constexpr auto lo16 = [](float x) constexpr { return static_cast<std::uint16_t>(bits(x) & 0xFFFFu); };
constexpr auto hi16 = [](float x) constexpr { return static_cast<std::uint16_t>(bits(x) >> 16); };

template <bool APPROXIMATION_MODE, bool FAST_APPROX, uint32_t scale >
inline void _init_exponential_()
{
    if constexpr (FAST_APPROX && APPROXIMATION_MODE)
    {
        constexpr float LN2_RECIP = 1.4426950408889634f;
        constexpr float A = 256.0f * LN2_RECIP;
        constexpr float B_minus_C = 32500.818359375f;
        constexpr float THRESHOLD = -88.5f;

        constexpr float scale_fp32 = __builtin_bit_cast(float, scale);

        constexpr float A_scaled = A * scale_fp32;
        constexpr float THRESHOLD_scaled = THRESHOLD / scale_fp32;

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0xA) << 16) + ((lo16(THRESHOLD_scaled)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0x8) << 16) + ((hi16(THRESHOLD_scaled)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((14) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0xA) << 16) + ((lo16(A_scaled)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0x8) << 16) + ((hi16(A_scaled)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((12) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0xA) << 16) + ((lo16(B_minus_C)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0x8) << 16) + ((hi16(B_minus_C)) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((13) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0xA) << 16) + ((0x00E1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0x8) << 16) + ((0x9200) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));




        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x84 << 24) + (((12) << 16) + ((0) << 12) + ((13) << 8) + ((13) << 4) + ((0) << 0))))));





        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((0) << 12) + ((0) << 8) + ((14) << 4) + ((14) << 0))))));



        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7a << 24) + (((15) << 12) + ((0) << 8) + ((15) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0xA) << 16) + ((0x0004) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0x8) << 16) + ((0x1300) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((5) << 4) + ((0) << 0))))));







        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0xA) << 16) + ((0x85DF) << 0))))))


                   ;


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0x8) << 16) + ((0x6316) << 0))))))


                   ;


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((4) << 4) + ((0) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((8) << 4) + ((1) << 0))))));
    }
    else if constexpr (APPROXIMATION_MODE)
    {
        sfpi::vConstFloatPrgm0 = 1.442695f;
        sfpi::vConstFloatPrgm1 = sfpi::s2vFloat16b(p_exp::C23_73);
        sfpi::vConstFloatPrgm2 = sfpi::s2vFloat16b(p_exp::ADJ_EXP);
    }
    else
    {
        sfpi::vConstFloatPrgm0 = 1.442695f;
        sfpi::vConstFloatPrgm1 = 2.0f;
        sfpi::vConstFloatPrgm2 = 0.863281f;
    }
}

}




       





       



namespace ckernel::sfpu
{

class Converter
{
public:
    static float as_float(std::uint32_t value)
    {
        union
        {
            std::uint32_t u;
            float f;
        } converter {value};

        return converter.f;
    }
};

}



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE>
inline void _calculate_lrelu_(const int iterations, uint slope)
{
    sfpi::vFloat s = Converter::as_float(slope);

#pragma GCC unroll 0
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0.0f);
        {
            v *= s;
        }
        };

        sfpi::dst_reg[0] = v;

        sfpi::dst_reg++;
    }
}

__attribute__((always_inline)) inline sfpi::vFloat _relu_max_body_(sfpi::vFloat val, sfpi::vFloat threshold)
{
    sfpi::vFloat result = val;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result > threshold);
    {
        result = threshold;
    }
    };
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result < 0.0f);
    {
        result = 0.0f;
    }
    };
    return result;
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _relu_max_(const int iterations, uint uint_threshold)
{
    sfpi::vFloat threshold = sfpi::s2vFloat16(uint_threshold, sfpi::s2vFloat16::fp16a);
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat a = sfpi::dst_reg[0];
        sfpi::dst_reg[0] = _relu_max_body_(a, threshold);
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _relu_min_(const int iterations, uint uint_threshold)
{
    sfpi::vFloat threshold = sfpi::s2vFloat16(uint_threshold, sfpi::s2vFloat16::fp16a);
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat a = sfpi::dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(a < threshold);
        {
            a = 0.0f;
        }
        };
        sfpi::dst_reg[0] = a;
        sfpi::dst_reg++;
    }
}

}
}

namespace ckernel::sfpu
{


template <bool APPROXIMATION_MODE, ActivationType ACTIVATION_TYPE>
struct ActivationImpl;


template <bool APPROXIMATION_MODE>
struct ActivationImpl<APPROXIMATION_MODE, ActivationType::Celu>
{
    static inline void apply(sfpi::vFloat& v, float param0, float param1)
    {




        sfpi::vFloat alpha = param0;
        sfpi::vFloat alpha_recip = param1;

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0.0f);
        {

            sfpi::vFloat exp_val = _calculate_exponential_body_<APPROXIMATION_MODE>(v * alpha_recip);


            v = alpha * (exp_val - 1.0f);
        }
        };
    }
};


template <bool APPROXIMATION_MODE>
struct ActivationImpl<APPROXIMATION_MODE, ActivationType::Hardsigmoid>
{
    static inline void apply(sfpi::vFloat& v)
    {
        sfpi::vFloat tmp = (v * sfpi::vConstFloatPrgm0) + sfpi::vConstFloatPrgm1;
        v = _relu_max_body_(tmp, 1.0f);
    }
};


template <bool APPROXIMATION_MODE, ActivationType ACTIVATION_TYPE>
inline void apply_activation(sfpi::vFloat& v, float param0, float param1)
{
    ActivationImpl<APPROXIMATION_MODE, ACTIVATION_TYPE>::apply(v, param0, param1);
}


template <bool APPROXIMATION_MODE, ActivationType ACTIVATION_TYPE>
inline void apply_activation(sfpi::vFloat& v)
{
    ActivationImpl<APPROXIMATION_MODE, ACTIVATION_TYPE>::apply(v);
}

template <bool APPROXIMATION_MODE, ActivationType ACTIVATION_TYPE, int ITERATIONS = 8>
inline void _calculate_activation_(float param0, float param1)
{
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        apply_activation<APPROXIMATION_MODE, ACTIVATION_TYPE>(v, param0, param1);
        sfpi::dst_reg[0] = v;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, ActivationType ACTIVATION_TYPE, int ITERATIONS>
inline void _calculate_activation_()
{
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        apply_activation<APPROXIMATION_MODE, ACTIVATION_TYPE>(v);
        sfpi::dst_reg[0] = v;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
void _init_hardsigmoid_()
{
    sfpi::vConstFloatPrgm0 = 0.1668f;
    sfpi::vConstFloatPrgm1 = 0.5f;
}

}




       
namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS, InstrModLoadStore INSTRUCTION_MODE, bool SIGN_MAGNITUDE_FORMAT>
inline void _add_int_(const uint dst_offset)
{
    static_assert(is_valid_instruction_mode(INSTRUCTION_MODE), "INSTRUCTION_MODE must be one of: INT32_2S_COMP, INT32, LO16.");



    constexpr int sfpload_instr_mod = SIGN_MAGNITUDE_FORMAT ? INT32_2S_COMP : static_cast<std::underlying_type_t<InstrModLoadStore>>(INSTRUCTION_MODE);




#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));

        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((dst_offset * 64) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((4) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}




       









       




namespace ckernel
{
namespace sfpu
{

template <bool HAS_BASE_SCALING>
__attribute__((always_inline)) inline void _calculate_log_body_(const uint log_base_scale_factor)
{



    sfpi::vFloat in = sfpi::dst_reg[0];
    sfpi::vFloat x = setexp(in, 127);
    sfpi::vFloat a = sfpi::vConstFloatPrgm1;
    sfpi::vFloat b = sfpi::vConstFloatPrgm2;

    sfpi::vFloat series_result = x * (x * (x * a + b) + 2.0871) + -1.4753f;




    sfpi::vInt exp = exexp(in);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0);
    {
        exp = sfpi::setsgn(~exp + 1, 1);
    }
    };

    sfpi::vFloat expf = int32_to_float(exp, 0);
    sfpi::vFloat vConstLn2 = sfpi::vConstFloatPrgm0;
    sfpi::vFloat result = expf * vConstLn2 + series_result;

    if constexpr (HAS_BASE_SCALING)
    {
        result *= sfpi::s2vFloat16a(log_base_scale_factor);
    }




    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in == 0.0F);
    {
        result = -std::numeric_limits<float>::infinity();
    }
    };

    sfpi::dst_reg[0] = result;
}

__attribute__((always_inline)) inline sfpi::vFloat _calculate_log_body_no_init_(sfpi::vFloat base)
{

    sfpi::vFloat x = setexp(base, 127);


    sfpi::vFloat series_result = x * (x * (x * 0x2.44734p-4f - 0xd.e712ap-4f) + 0x2.4f5388p+0f) - 0x1.952992p+0f;


    sfpi::vInt exp = exexp(base);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0);
    {
        exp = sfpi::setsgn(~exp + 1, 1);
    }
    };
    sfpi::vFloat expf = int32_to_float(exp, 0);


    sfpi::vFloat vConstLn2 = 0.692871f;
    sfpi::vFloat log_result = expf * vConstLn2 + series_result;


    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(base == 0.0f);
    {
        log_result = -std::numeric_limits<float>::infinity();
    }
    };

    return log_result;
}

template <bool APPROXIMATION_MODE, bool HAS_BASE_SCALING, int ITERATIONS>
inline void _calculate_log_(const int iterations, uint log_base_scale_factor)
{
#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {
        _calculate_log_body_<HAS_BASE_SCALING>(log_base_scale_factor);
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void _init_log_()
{
    sfpi::vConstFloatPrgm0 = 0.692871f;


    sfpi::vConstFloatPrgm1 = 0.1058f;
    sfpi::vConstFloatPrgm2 = -0.7166f;
}

}
}



namespace ckernel
{
namespace sfpu
{

__attribute__((always_inline)) inline sfpi::vFloat _calculate_sfpu_binary_power_(sfpi::vFloat base, sfpi::vFloat pow)
{
    sfpi::vFloat original_base = base;


    sfpi::vInt pow_int = float_to_int16(pow, 0);
    sfpi::vFloat pow_rounded = int32_to_float(pow_int, 0);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pow_rounded == pow);
    {

        base = sfpi::setsgn(base, 0);
    }
    };


    sfpi::vFloat x = setexp(base, 127);


    sfpi::vFloat series_result = x * (x * (x * 0x2.44734p-4f - 0xd.e712ap-4f) + 0x2.4f5388p+0f) - 0x1.952992p+0f;


    sfpi::vInt exp = exexp(base);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0);
    {
        exp = sfpi::setsgn(~exp + 1, 1);
    }
    };
    sfpi::vFloat expf = int32_to_float(exp, 0);


    sfpi::vFloat vConstLn2 = 0.692871f;
    sfpi::vFloat log_result = expf * vConstLn2 + series_result;


    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(base == 0.0f);
    {
        log_result = -std::numeric_limits<float>::infinity();
    }
    };


    sfpi::vFloat val = pow * log_result;


    sfpi::vFloat result = _sfpu_exp_(sfpi::setsgn(val, 0));

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0);
    {
        result = _sfpu_reciprocal_(result);
    }
    };


    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(original_base < 0.0f);
    {

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pow_rounded == pow);
        {

            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pow_int & 0x1);
            {
                result = sfpi::setsgn(result, 1);
            }
            };
        }
        __cc.cc_else();
        {
            result = std::numeric_limits<float>::quiet_NaN();
        }
        };
    }
    };

    return result;
}

template <bool APPROXIMATION_MODE, BinaryOp BINOP, int ITERATIONS = 8>
inline void _calculate_sfpu_binary_(const uint dst_offset)
{
    static constexpr float nan = std::numeric_limits<float>::quiet_NaN();

    for (int d = 0; d < ITERATIONS; d++)
    {
        constexpr uint dst_tile_size = 32;
        sfpi::vFloat in0 = sfpi::dst_reg[0];
        sfpi::vFloat in1 = sfpi::dst_reg[dst_offset * dst_tile_size];
        sfpi::vFloat result = 0.0f;

        if constexpr (BINOP == BinaryOp::ADD)
        {
            result = in0 + in1;
        }
        else if constexpr (BINOP == BinaryOp::SUB)
        {
            result = in0 - in1;
        }
        else if constexpr (BINOP == BinaryOp::MUL)
        {
            result = in0 * in1;
        }
        else if constexpr (BINOP == BinaryOp::DIV)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in1 == 0);
            {
                { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in0 == 0);
                {
                    result = std::numeric_limits<float>::quiet_NaN();
                }
                __cc.cc_else();
                {
                    result = std::numeric_limits<float>::infinity();
                    result = sfpi::setsgn(result, in0);
                }
                };
            }
            __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(in0 == in1);
            {
                result = sfpi::vConst1;
            }
            __cc.cc_else();
            {
                result = in0 * sfpi::setsgn(_sfpu_reciprocal_<4>(in1), in1);
            }
            };
        }
        else if constexpr (BINOP == BinaryOp::RSUB)
        {
            result = in1 - in0;
        }
        else if constexpr (BINOP == BinaryOp::POW)
        {
            result = _calculate_sfpu_binary_power_(in0, in1);
        }
        else if constexpr (BINOP == BinaryOp::XLOGY)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if((in1 < 0.0f) || (in1 == nan));
            {
                result = nan;
            }
            __cc.cc_else();
            {
                sfpi::dst_reg[0] = in1;
                _calculate_log_body_<false>(0);
                result = sfpi::dst_reg[0] * in0;
            }
            };
        }

        sfpi::dst_reg[0] = result;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE , BinaryOp BINOP>
inline void _sfpu_binary_init_()
{
    if constexpr (BINOP == BinaryOp::DIV || BINOP == BinaryOp::POW)
    {
        _init_reciprocal_<APPROXIMATION_MODE>();
    }
    else if constexpr (BINOP == BinaryOp::XLOGY)
    {
        _init_log_<APPROXIMATION_MODE>();
    }
}

}
}




       
namespace ckernel
{
namespace sfpu
{

enum class BinaryBitwiseOp : uint8_t
{
    AND = 0,
    OR = 1,
    XOR = 2,
};

template <bool APPROXIMATION_MODE, BinaryBitwiseOp BITWISE_OP, InstrModLoadStore INSTRUCTION_MODE = INT32, int ITERATIONS = 8>
inline void _calculate_sfpu_binary_bitwise_(const uint dst_offset)
{
    constexpr auto instruction_mode = static_cast<std::underlying_type_t<InstrModLoadStore>>(INSTRUCTION_MODE);

    for (int d = 0; d < ITERATIONS; d++)
    {
        constexpr uint dst_tile_size = 64;

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((instruction_mode) << 16) + ((3) << 14) + ((0) << 0))))));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((1) << 20) + ((instruction_mode) << 16) + ((3) << 14) + ((dst_offset * dst_tile_size) << 0)));

        if constexpr (BITWISE_OP == BinaryBitwiseOp::AND)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7e << 24) + (((0) << 12) + ((1) << 8) + ((0) << 4) + ((0) << 0))))));
        }
        else if constexpr (BITWISE_OP == BinaryBitwiseOp::OR)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7f << 24) + (((0) << 12) + ((1) << 8) + ((0) << 4) + ((0) << 0))))));
        }
        else if constexpr (BITWISE_OP == BinaryBitwiseOp::XOR)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8d << 24) + (((0) << 12) + ((1) << 8) + ((0) << 4) + ((0) << 0))))));
        }

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((instruction_mode) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _cast_fp32_to_fp16a_(const int iterations)
{
#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((0) << 12) + ((0) << 8) + ((0) << 4) + ((8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((1) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_clamp_(const int iterations, uint param0, uint param1, uint param2)
{





    sfpi::s2vFloat16::Format format = sfpi::s2vFloat16::fp16a;


    sfpi::vFloat min = sfpi::s2vFloat16(param0, format);
    sfpi::vFloat max = sfpi::s2vFloat16(param1, format);
#pragma GCC unroll 0
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < min);
        {
            val = sfpi::s2vFloat16(param0, format);
        }
        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(val >= max);
        {
            val = sfpi::s2vFloat16(param1, format);
        }
        };

        sfpi::dst_reg[0] = val + sfpi::s2vFloat16b(param2);

        sfpi::dst_reg++;
    }
}

}
}




       





       



namespace ckernel
{
namespace sfpu
{

__attribute__((always_inline)) inline sfpi::vInt _sfpu_is_fp16_zero_(const sfpi::vFloat& v, uint exponent_size_8)
{
    if (exponent_size_8)
    {

        return v == 0.0F;
    }
    else
    {



        sfpi::vInt tmp = 0x3800;
        tmp += sfpi::reinterpret<sfpi::vInt>(v);

        return tmp == 0;
    }
}

}
}




       

enum SfpuType {
    tanh,
    hardtanh,
    gelu,
    exponential,
    exp_with_base,
    sigmoid,
    reciprocal,
    sqrt,
    lrelu,
    prelu,
    power,
    square,
    tanh_derivative,
    log,
    log_with_base,
    log1p,
    equal_zero,
    not_equal_zero,
    less_than_zero,
    greater_than_equal_zero,
    less_than_equal_zero,
    greater_than_zero,
    clamp,
    gelu_derivative,
    dropout,
    abs,
    abs_int32,
    sign,
    max,
    sine,
    cosine,
    tan,
    relu_max,
    relu_min,
    cast_fp32_to_fp16a,
    sigmoid_appx,
    gelu_appx,
    elu,
    min,
    exp2,
    heaviside,
    expm1,
    signbit,
    asin,
    acos,
    acosh,
    atan,
    asinh,
    atanh,
    erf,
    erfc,
    rsqrt,
    isfinite,
    isinf,
    isposinf,
    isneginf,
    isnan,
    logical_not_unary,
    erfinv,
    i0,
    i1,
    silu,
    mask,
    negative,
    quant_int32,
    requant_int32,
    dequant_int32,
    add_int32,
    add_uint32,
    add_uint16,
    add1,
    sub_int32,
    sub_uint16,
    mul_uint16,
    topk_local_sort,
    topk_merge,
    topk_rebuild,
    unary_ne,
    unary_eq,
    unary_gt,
    unary_lt,
    unary_ge,
    unary_le,
    unary_max,
    unary_min,
    softplus,
    tiled_prod,
    bitwise_xor,
    bitwise_not,
    bitwise_and,
    bitwise_or,
    right_shift,
    floor,
    trunc,
    frac,
    left_shift,
    remainder,
    fmod,
    ceil,
    unused,
    reshuffle_rows,
    cumsum,
    fill,
    alt_complex_rotate90,
    round,
    cpy_values,
    gcd,
    lcm,
};


namespace
{
constexpr std::uint32_t ONE = 1;
constexpr std::uint32_t ZERO = 0;
}

namespace ckernel
{
namespace sfpu
{

__attribute__((always_inline)) inline void _calculate_comp_init_flag_(bool check, sfpi::vFloat& flag1, sfpi::vFloat& flag2, float init)
{
    flag1 = init;
    if (check)
    {
        flag2 = init;
    }
}

template <bool APPROXIMATION_MODE, bool invert_output, bool check_zero, bool second_check, bool is_less_than_equal_zero, int ITERATIONS>
inline void _calculate_comp_(const int iterations, uint exponent_size_8)
{






    constexpr float output_0 = invert_output ? 0.0f : 1.0f;
    constexpr float output_1 = invert_output ? 1.0f : 0.0f;

    for (int d = ZERO; d < iterations; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        sfpi::vFloat flag1, flag2;
        if constexpr (check_zero)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(v, exponent_size_8));
            {
                _calculate_comp_init_flag_(second_check, flag1, flag2, output_0);
            }
            __cc.cc_else();
            {
                _calculate_comp_init_flag_(second_check, flag1, flag2, output_1);
            }
            };
        }
        else
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0.0F);
            {
                _calculate_comp_init_flag_(second_check, flag1, flag2, output_0);
            }
            __cc.cc_else();
            {
                _calculate_comp_init_flag_(second_check, flag1, flag2, output_1);
            }
            };
        }

        sfpi::vFloat result;
        if constexpr (second_check)
        {






            if constexpr (is_less_than_equal_zero)
            {
                result = sfpi::reinterpret<sfpi::vFloat>(sfpi::reinterpret<sfpi::vUInt>(flag1) | sfpi::reinterpret<sfpi::vUInt>(flag2));
            }
            else
            {






                result = sfpi::reinterpret<sfpi::vFloat>(sfpi::reinterpret<sfpi::vUInt>(flag1) & sfpi::reinterpret<sfpi::vUInt>(flag2));
            }
        }
        else
        {
            result = flag1;
        }

        sfpi::dst_reg[0] = result;

        sfpi::dst_reg++;
    }
}

template <SfpuType COMP_MODE>
inline void apply_zero_comp(sfpi::vFloat& v, uint exponent_size_8);

template <>
inline void apply_zero_comp<SfpuType::equal_zero>(sfpi::vFloat& v, uint exponent_size_8)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(v, exponent_size_8));
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp<SfpuType::not_equal_zero>(sfpi::vFloat& v, uint exponent_size_8)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(v, exponent_size_8));
    {
        v = ZERO;
    }
    __cc.cc_else();
    {
        v = ONE;
    }
    };
}

template <>
inline void apply_zero_comp<SfpuType::less_than_zero>(sfpi::vFloat& v, uint )
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= ZERO);
    {
        v = ZERO;
    }
    __cc.cc_else();
    {
        v = ONE;
    }
    };
}

template <>
inline void apply_zero_comp<SfpuType::greater_than_equal_zero>(sfpi::vFloat& v, uint )
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp<SfpuType::greater_than_zero>(sfpi::vFloat& v, uint )
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp<SfpuType::less_than_equal_zero>(sfpi::vFloat& v, uint )
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > ZERO);
    {
        v = ZERO;
    }
    __cc.cc_else();
    {
        v = ONE;
    }
    };
}

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void _calculate_zero_comp_(uint exponent_size_8)
{
    for (int d = ZERO; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        apply_zero_comp<COMP_MODE>(v, exponent_size_8);
        sfpi::dst_reg[0] = v;
        sfpi::dst_reg++;
    }
}

template <SfpuType COMP_MODE>
inline void apply_zero_comp_int(sfpi::vInt& v);

template <>
inline void apply_zero_comp_int<SfpuType::equal_zero>(sfpi::vInt& v)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp_int<SfpuType::not_equal_zero>(sfpi::vInt& v)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == ZERO);
    {
        v = ZERO;
    }
    __cc.cc_else();
    {
        v = ONE;
    }
    };
}

template <>
inline void apply_zero_comp_int<SfpuType::less_than_zero>(sfpi::vInt& v)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp_int<SfpuType::greater_than_zero>(sfpi::vInt& v)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp_int<SfpuType::less_than_equal_zero>(sfpi::vInt& v)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <>
inline void apply_zero_comp_int<SfpuType::greater_than_equal_zero>(sfpi::vInt& v)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= ZERO);
    {
        v = ONE;
    }
    __cc.cc_else();
    {
        v = ZERO;
    }
    };
}

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void _calculate_zero_comp_int_()
{
    for (int d = ZERO; d < ITERATIONS; d++)
    {
        sfpi::vInt v = sfpi::dst_reg[0];
        apply_zero_comp_int<COMP_MODE>(v);
        sfpi::dst_reg[0] = v;
        sfpi::dst_reg++;
    }
}

template <SfpuType COMP_MODE>
inline void apply_unary_comp_int(sfpi::vInt& val, const sfpi::vInt& v, const int scalar);

template <>
inline void apply_unary_comp_int<SfpuType::unary_ne>(sfpi::vInt& val, const sfpi::vInt& v, const int scalar)
{
    sfpi::vInt s = scalar;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0);
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v != scalar);
        {
            val = ONE;
        }
        };
    }
    __cc.cc_else();
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0);
        {
            sfpi::vInt xor_val = sfpi::reinterpret<sfpi::vInt>(sfpi::abs(sfpi::reinterpret<sfpi::vFloat>(v))) ^ -s;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(xor_val != 0);
            {
                val = ONE;
            }
            };
        }
        __cc.cc_else();
        {
            val = ONE;
        }
        };
    }
    };
}

template <>
inline void apply_unary_comp_int<SfpuType::unary_eq>(sfpi::vInt& val, const sfpi::vInt& v, const int scalar)
{
    sfpi::vInt s = scalar;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0);
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == scalar);
        {
            val = ONE;
        }
        };
    }
    __cc.cc_else();
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0);
        {
            sfpi::vInt xor_val = sfpi::reinterpret<sfpi::vInt>(sfpi::abs(sfpi::reinterpret<sfpi::vFloat>(v))) ^ -s;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(xor_val == 0);
            {
                val = ONE;
            }
            };
        }
        __cc.cc_else();
        {
            val = ZERO;
        }
        };
    }
    };
}

template <>
inline void apply_unary_comp_int<SfpuType::unary_gt>(sfpi::vInt& val, const sfpi::vInt& v, const int scalar)
{
    sfpi::vInt s = scalar;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0 && s < 0);
    {
        val = ONE;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v >= 0);
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > s);
        {
            val = ONE;
        }
        };
    }
    __cc.cc_else();
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0);
        {
            sfpi::vInt pos_val = setsgn(v, 0);
            sfpi::vInt pos_s = 0 - s;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pos_val < pos_s);
            {
                val = ONE;
            }
            };
        }
        __cc.cc_else();
        {
            val = ZERO;
        }
        };
    }
    };
}

template <>
inline void apply_unary_comp_int<SfpuType::unary_lt>(sfpi::vInt& val, const sfpi::vInt& v, const int scalar)
{
    sfpi::vInt s = scalar;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0 && s >= 0);
    {
        val = ONE;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v >= 0 && s < 0);
    {
        val = ZERO;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v >= 0);
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < s);
        {
            val = ONE;
        }
        };
    }
    __cc.cc_else();
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0);
        {
            sfpi::vInt pos_val = setsgn(v, 0);
            sfpi::vInt pos_s = 0 - s;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pos_val > pos_s);
            {
                val = ONE;
            }
            };
        }
        __cc.cc_else();
        {
            val = ZERO;
        }
        };
    }
    };
}

template <>
inline void apply_unary_comp_int<SfpuType::unary_ge>(sfpi::vInt& val, const sfpi::vInt& v, const int scalar)
{
    sfpi::vInt s = scalar;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0 && s < 0);
    {
        val = ONE;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v >= 0);
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= s);
        {
            val = ONE;
        }
        };
    }
    __cc.cc_else();
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0);
        {
            sfpi::vInt pos_val = setsgn(v, 0);
            sfpi::vInt pos_s = 0 - s;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pos_val <= pos_s);
            {
                val = ONE;
            }
            };
        }
        __cc.cc_else();
        {
            val = ZERO;
        }
        };
    }
    };
}

template <>
inline void apply_unary_comp_int<SfpuType::unary_le>(sfpi::vInt& val, const sfpi::vInt& v, const int scalar)
{
    sfpi::vInt s = scalar;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0 && s >= 0);
    {
        val = ONE;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v >= 0 && s < 0);
    {
        val = ZERO;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v >= 0);
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= s);
        {
            val = ONE;
        }
        };
    }
    __cc.cc_else();
    {
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0);
        {
            sfpi::vInt pos_val = setsgn(v, 0);
            sfpi::vInt pos_s = 0 - s;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(pos_val >= pos_s);
            {
                val = ONE;
            }
            };
        }
        __cc.cc_else();
        {
            val = ZERO;
        }
        };
    }
    };
}

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void _calculate_comp_unary_int_(int scalar)
{
#pragma GCC unroll 8
    for (int d = ZERO; d < ITERATIONS; d++)
    {
        sfpi::vInt v = sfpi::dst_reg[0];
        sfpi::vInt val = ZERO;

        apply_unary_comp_int<COMP_MODE>(val, v, scalar);

        sfpi::dst_reg[0] = val;
        sfpi::dst_reg++;
    }
}

template <SfpuType COMP_MODE>
inline void apply_unary_comp_float(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s);

template <>
inline void apply_unary_comp_float<SfpuType::unary_eq>(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == s);
    {
        val = ONE;
    }
    __cc.cc_else();
    {
        val = ZERO;
    }
    };
}

template <>
inline void apply_unary_comp_float<SfpuType::unary_ne>(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == s);
    {
        val = ZERO;
    }
    __cc.cc_else();
    {
        val = ONE;
    }
    };
}

template <>
inline void apply_unary_comp_float<SfpuType::unary_gt>(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > s);
    {
        val = ONE;
    }
    __cc.cc_else();
    {
        val = ZERO;
    }
    };
}

template <>
inline void apply_unary_comp_float<SfpuType::unary_lt>(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < s);
    {
        val = ONE;
    }
    __cc.cc_else();
    {
        val = ZERO;
    }
    };
}

template <>
inline void apply_unary_comp_float<SfpuType::unary_ge>(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= s);
    {
        val = ONE;
    }
    __cc.cc_else();
    {
        val = ZERO;
    }
    };
}

template <>
inline void apply_unary_comp_float<SfpuType::unary_le>(sfpi::vFloat& val, const sfpi::vFloat& v, const sfpi::vFloat& s)
{
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= s);
    {
        val = ONE;
    }
    __cc.cc_else();
    {
        val = ZERO;
    }
    };
}

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void _calculate_comp_unary_(uint value)
{
    sfpi::vFloat s = value;

#pragma GCC unroll 8
    for (int d = ZERO; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        sfpi::vFloat val;

        apply_unary_comp_float<COMP_MODE>(val, v, s);

        sfpi::dst_reg[0] = val;
        sfpi::dst_reg++;
    }
}

}
}





       


       
namespace lltt {

enum ExecBool : bool {NoExec, Exec};

template<ExecBool E = NoExec>
[[gnu::always_inline]] inline void
record(unsigned start, unsigned length) {
  __builtin_rvtt_ttreplay(nullptr, length, 0, 0, start, bool(E), true);
}

[[gnu::always_inline]] inline void replay(unsigned start, unsigned length) {
  __builtin_rvtt_ttreplay(nullptr, length, 0, 0, start, false, false);
}

[[gnu::always_inline]] constexpr std::uint32_t
replay_insn(unsigned start, unsigned length) {

  return (0x04 << 24) | (start << 14) | (length << 4);
}

}


namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE , int ITERATIONS >
inline void _calculate_cumsum_(const bool first)
{
    if (first)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((9) << 8) + ((4) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((9) << 8) + ((5) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((9) << 8) + ((6) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((9) << 8) + ((7) << 4) + ((0) << 0))))));
    }


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2 + 16) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(0, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2 + 16) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6 + 16) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(8, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6 + 16) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10 + 16) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(0, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10 + 16) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14 + 16) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(8, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12 + 16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14 + 16) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2 + 16 + 32) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(0, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((2 + 16 + 32) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6 + 16 + 32) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(8, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((6 + 16 + 32) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10 + 16 + 32) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(0, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((10 + 16 + 32) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14 + 16 + 32) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    lltt::replay(8, 8);
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12 + 16 + 32) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((14 + 16 + 32) << 0))))));
}

template <bool APPROXIMATION_MODE >
inline void _cumsum_init_()
{
    lltt::record(0, 16);

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((7) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((0) << 12) + ((1) << 8) + ((1) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((1) << 12) + ((2) << 8) + ((2) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((2) << 12) + ((3) << 8) + ((3) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((3) << 12) + ((4) << 8) + ((4) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((4) << 12) + ((5) << 8) + ((5) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((5) << 12) + ((6) << 8) + ((6) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((10) << 16) + ((6) << 12) + ((7) << 8) + ((7) << 4) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
}

}
}




       






namespace ckernel
{
namespace sfpu
{



template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_dropout_(const int iterations, uint probability, uint scale)
{


    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG1) << 20) + ((10) << 16) + ((scale & 0xFFFF) << 0)));
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG1) << 20) + ((8) << 16) + ((scale >> 16) << 0)));
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG2) << 20) + ((10) << 16) + ((probability & 0xFFFF) << 0)));
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG2) << 20) + ((8) << 16) + ((probability >> 16) << 0)));
#pragma GCC unroll 0
    for (int d = 0; d < iterations; d++)
    {




        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x86 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LREG1) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));







        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((9) << 8) + ((p_sfpu::LREG3) << 4) + ((8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x89 << 24) + (((0) << 12) + ((p_sfpu::LREG3) << 8) + ((p_sfpu::LREG3) << 4) + ((1) << 0))))));






        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((10) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));

        sfpi::dst_reg++;
    }
}

inline void _init_dropout_(const uint seed)
{
    init_prng_seed(seed);
}

}
}




       






namespace ckernel::sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_elu_(uint slope)
{
    const bool SCALE_EN = false;
    const bool SKIP_POSITIVE_CHECK = false;
    const uint16_t exp_base_scale_factor = p_sfpu::kCONST_1_FP16B;

    sfpi::vFloat s = Converter::as_float(slope);
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0.0f);
        {
            sfpi::vFloat v_exp = _calculate_exponential_piecewise_<APPROXIMATION_MODE, SCALE_EN, SKIP_POSITIVE_CHECK>(v, exp_base_scale_factor);
            v = s * (v_exp - 1.0f);
        }
        };

        sfpi::dst_reg[0] = v;

        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void _init_elu_()
{
    const uint32_t EXP_BASE_SCALE_FACTOR = 0x3F800000;
    const bool FAST_APPROX = false;
    _init_exponential_<APPROXIMATION_MODE, FAST_APPROX, EXP_BASE_SCALE_FACTOR>();
}

}





       





namespace ckernel::sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_exp2_()
{
    const bool SCALE_EN = false;
    const bool SKIP_POSITIVE_CHECK = false;
    const uint16_t exp_base_scale_factor = p_sfpu::kCONST_1_FP16B;

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];

        v = v * 0.6931471805f;

        sfpi::vFloat exp = _calculate_exponential_piecewise_<APPROXIMATION_MODE, SCALE_EN, SKIP_POSITIVE_CHECK>(v, exp_base_scale_factor);
        sfpi::dst_reg[0] = exp;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void _init_exp2_()
{
    const uint32_t EXP_BASE_SCALE_FACTOR = 0x3F800000;
    const bool FAST_APPROX = false;
    _init_exponential_<APPROXIMATION_MODE, FAST_APPROX, EXP_BASE_SCALE_FACTOR>();
}

}




       







       




namespace ckernel
{
namespace sfpu
{

inline void _sfpu_load_imm32_(const uint dest, const uint val)
{
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((dest) << 20) + ((10) << 16) + (((val & 0xFFFF)) << 0)));
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((dest) << 20) + ((8) << 16) + (((val >> 16) & 0xFFFF) << 0)));
}

inline void _sfpu_load_imm16_(const uint dest, const uint val)
{
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((dest) << 20) + ((2) << 16) + ((val) << 0)));
}

inline void _sfpu_load_config32_(const uint dest, const uint upper16, const uint lower16)
{


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((10) << 16) + ((lower16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((8) << 16) + ((upper16) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0) << 8) + ((dest) << 4) + ((0) << 0))))));
}

inline void _init_sfpu_config_reg()
{
    _sfpu_load_config32_(0xF, 0x0, 0x0);
}

}
}

namespace ckernel::sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_fill_(const float value)
{

    sfpi::vFloat fill_val = value;

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::dst_reg[0] = fill_val;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_fill_int_(const uint value)
{

    _sfpu_load_imm32_(p_sfpu::LREG1, value);

    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_fill_bitcast_(const uint32_t value_bit_mask)
{

    sfpi::vFloat fill_val = Converter::as_float(value_bit_mask);

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::dst_reg[0] = fill_val;
        sfpi::dst_reg++;
    }
}
}




       





       







       

namespace ckernel::sfpu
{

template <typename T>
constexpr T POLYVAL5(T coef4, T coef3, T coef2, T coef1, T coef0, T val)
{
    return (((((coef4 * val) + coef3) * val + coef2) * val + coef1) * val + coef0);
}
}


namespace ckernel::sfpu
{

inline sfpi::vFloat _calculate_pos_cdf_appx_(sfpi::vFloat val)
{
    sfpi::vFloat result;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 2.5f);
    {
        result = POLYVAL5<sfpi::vFloat>(0.0122792f, -0.05281024f, -0.03048313f, 0.41314081f, 0.49866379f, val);
    }
    __cc.cc_else();
    {





        result = 0.44656975f * val + 0.58216001f;
    }
    };

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result > 1.0f);
    {
        result = 1.0f;
    }
    };
    return result;
}


inline sfpi::vFloat _calculate_cdf_appx_(sfpi::vFloat val, bool scaled = false)
{
    sfpi::vFloat result = 0.0f;

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0f);
    {
        result = 1.0f - _calculate_pos_cdf_appx_(-val);
    }
    __cc.cc_else();
    {
        result = _calculate_pos_cdf_appx_(val);
    }
    };

    if (scaled)
    {
        result *= val;
    }
    return result;
}

}





namespace ckernel::sfpu
{

template <bool APPROXIMATION_MODE>
inline sfpi::vFloat _calculate_gelu_core_(sfpi::vFloat in)
{




    sfpi::vFloat result;
    if constexpr (APPROXIMATION_MODE)
    {
        result = in;
    }
    else
    {

        result = (in * in) * (in * sfpi::s2vFloat16b(0.044715f)) + in;
        result *= sfpi::s2vFloat16b(0.79788f);
    }

    return result;
}

template <int ITERATIONS>
inline void _calculate_gelu_appx_()
{
    sfpi::vUInt l0 = sfpi::l_reg[sfpi::LRegs::LReg0];
    sfpi::vUInt l1 = sfpi::l_reg[sfpi::LRegs::LReg1];
    sfpi::vUInt l2 = sfpi::l_reg[sfpi::LRegs::LReg2];
    sfpi::vUInt l4 = sfpi::l_reg[sfpi::LRegs::LReg4];
    sfpi::vUInt l5 = sfpi::l_reg[sfpi::LRegs::LReg5];
    sfpi::vUInt l6 = sfpi::l_reg[sfpi::LRegs::LReg6];

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat half = sfpi::vConstFloatPrgm0;
        sfpi::vFloat half_in = in * half;
        sfpi::vFloat result = lut2_sign(in, l0, l1, l2, l4, l5, l6);
        result = half_in + result;

        sfpi::dst_reg[0] = result;

        sfpi::dst_reg++;







    }

    sfpi::l_reg[sfpi::LRegs::LReg0] = l0;
    sfpi::l_reg[sfpi::LRegs::LReg1] = l1;
    sfpi::l_reg[sfpi::LRegs::LReg2] = l2;
    sfpi::l_reg[sfpi::LRegs::LReg4] = l4;
    sfpi::l_reg[sfpi::LRegs::LReg5] = l5;
    sfpi::l_reg[sfpi::LRegs::LReg6] = l6;
}

template <int ITERATIONS>
inline void _calculate_gelu_accurate_()
{
    constexpr bool scaled = true;
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat result = _calculate_cdf_appx_(in, scaled);
        sfpi::dst_reg[0] = result;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_gelu_()
{
    if constexpr (APPROXIMATION_MODE)
    {
        _calculate_gelu_appx_<ITERATIONS>();
    }
    else
    {
        _calculate_gelu_accurate_<ITERATIONS>();
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_gelu_derivative_()
{
    if constexpr (APPROXIMATION_MODE)
    {
        constexpr int lut_mode = 1;

        sfpi::vUInt l0 = sfpi::l_reg[sfpi::LRegs::LReg0];
        sfpi::vUInt l1 = sfpi::l_reg[sfpi::LRegs::LReg1];
        sfpi::vUInt l2 = sfpi::l_reg[sfpi::LRegs::LReg2];
        sfpi::vUInt l4 = sfpi::l_reg[sfpi::LRegs::LReg4];
        sfpi::vUInt l5 = sfpi::l_reg[sfpi::LRegs::LReg5];
        sfpi::vUInt l6 = sfpi::l_reg[sfpi::LRegs::LReg6];


#pragma GCC unroll 0
        for (int d = 0; d < ITERATIONS; d++)
        {
            sfpi::vFloat val = sfpi::dst_reg[0];
            val = lut2(val, l0, l1, l2, l4, l5, l6, lut_mode);
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0F);
            {
                val = val + 1.0f;
            }
            };
            sfpi::dst_reg[0] = val;
            sfpi::dst_reg++;
        }

        sfpi::l_reg[sfpi::LRegs::LReg0] = l0;
        sfpi::l_reg[sfpi::LRegs::LReg1] = l1;
        sfpi::l_reg[sfpi::LRegs::LReg2] = l2;
        sfpi::l_reg[sfpi::LRegs::LReg4] = l4;
        sfpi::l_reg[sfpi::LRegs::LReg5] = l5;
        sfpi::l_reg[sfpi::LRegs::LReg6] = l6;
    }
    else
    {
        constexpr uint imm2 = 0xFF10;

        sfpi::vUInt l0 = sfpi::l_reg[sfpi::LRegs::LReg0];
        sfpi::vUInt l1 = sfpi::l_reg[sfpi::LRegs::LReg1];


#pragma GCC unroll 0
        for (int d = 0; d < ITERATIONS; d++)
        {
            sfpi::vFloat in = sfpi::dst_reg[0];
            sfpi::vFloat neg_half_sq_in = in * in * -0.5f;


            sfpi::vFloat exp = _calculate_exponential_body_<false>(neg_half_sq_in);


            sfpi::vFloat partial = exp * in * sfpi::s2vFloat16b(0.3989423F);

            sfpi::vFloat result = _calculate_gelu_core_<true>(in);

            result = lut(result, l0, l1, imm2);

            sfpi::dst_reg[0] = partial + result + 0.5f;
            sfpi::dst_reg++;
        }

        sfpi::l_reg[sfpi::LRegs::LReg0] = l0;
        sfpi::l_reg[sfpi::LRegs::LReg1] = l1;
    }
}

template <bool APPROXIMATION_MODE>
inline void _init_gelu_()
{
    sfpi::vConstFloatPrgm0 = 0.5f;
    _sfpu_load_imm32_(0, 0x37E7322B);
    _sfpu_load_imm32_(4, 0xB12286D8);

    _sfpu_load_imm32_(1, 0x38E138F3);
    _sfpu_load_imm32_(5, 0xB437B479);

    _sfpu_load_imm32_(2, 0x38003852);
    _sfpu_load_imm32_(6, 0x7c00afa4);
}

template <bool APPROXIMATION_MODE>
inline void _init_gelu_derivative_()
{
    sfpi::vConstFloatPrgm0 = 1.442695f;
    sfpi::vConstFloatPrgm1 = 2.0f;
    sfpi::vConstFloatPrgm2 = 0.863281f;

    uint imm0;
    uint imm1;
    uint imm2;
    uint imm3;
    uint imm4;
    uint imm5;

    if constexpr (APPROXIMATION_MODE)
    {
        imm0 = 0x36663A66;

        imm1 = 0xADC32E66;

        imm2 = 0x7C00ACCD;

        imm3 = 0x399A3800;

        imm4 = 0x3D143BEC;

        imm5 = 0x3C003CF1;
        _sfpu_load_imm32_(0, imm0);
        _sfpu_load_imm32_(1, imm1);
        _sfpu_load_imm32_(2, imm2);
        _sfpu_load_imm32_(4, imm3);
        _sfpu_load_imm32_(5, imm4);
        _sfpu_load_imm32_(6, imm5);
    }
    else
    {
        imm0 = 0x28FF;
        imm1 = 0x3020;
        _sfpu_load_imm16_(0, imm0);
        _sfpu_load_imm16_(1, imm1);
    }
}

}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_hardtanh_(const int iterations, uint param0, uint param1, uint param2)
{





    sfpi::vFloat p0 = sfpi::s2vFloat16(param0);
    sfpi::vFloat p1 = sfpi::s2vFloat16(param1);
    sfpi::vFloat p2 = sfpi::s2vFloat16(param2);

#pragma GCC unroll 0
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];

        val += p0;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0f);
        {
            val = 0.0f;
        }
        };

        val += p1;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val >= 0.0f);
        {
            val = 0.0f;
        }
        };

        val += p2;

        sfpi::dst_reg[0] = val;

        sfpi::dst_reg++;
    }
}

}
}







       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_max_(const int iterations)
{
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat a = sfpi::dst_reg[0];
        sfpi::vFloat b = sfpi::dst_reg[32];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(a < b);
        {
            sfpi::dst_reg[0] = b;
        }
        };

        sfpi::dst_reg++;
    }
}

}
}




       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_max_int32_(const int iterations)
{
    for (int d = 0; d < iterations; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((2) << 20) + ((12) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((12) << 16) + ((3) << 14) + ((64) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((0) << 8) + ((1) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0) << 12) + ((2) << 8) + ((1) << 4) + ((2) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((12) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0x003) << 12) + ((0) << 8) + ((0) << 4) + ((10) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _mul_int_(const uint dst_offset)
{
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        constexpr uint dst_tile_size = 64;

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((LO16) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));

        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((LO16) << 16) + ((ADDR_MOD_3) << 14) + ((dst_offset * dst_tile_size) << 0)));





        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x86 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LREG1) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((6) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((LO16) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));

        sfpi::dst_reg++;
    }
}

}
}




       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_negative_()
{
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];
        sfpi::dst_reg[0] = -val;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_negative_int_()
{
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vInt val = sfpi::dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val != 0);
        {
            sfpi::dst_reg[0] = sfpi::reinterpret<sfpi::vInt>(-sfpi::reinterpret<sfpi::vFloat>(val));
        }
        };
        sfpi::dst_reg++;
    }
}

}
}




       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_power_(const int iterations, uint exponent)
{
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat result = in * in;
        for (uint i = 2; i < exponent; i++)
        {
            result *= in;
        }

        sfpi::dst_reg[0] = result;

        sfpi::dst_reg++;
    }
}

}
}




       





namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS, bool SIGN_MAGNITUDE_FORMAT>
inline void _quant_int32_(const uint dst_offset)
{




#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((3) << 16) + ((3) << 14) + ((0) << 0))))));

        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((1) << 20) + ((3) << 16) + ((3) << 14) + ((dst_offset * 64) << 0)));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x84 << 24) + (((0) << 16) + ((1) << 12) + ((2) << 8) + ((0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((9) << 12) + ((0) << 8) + ((0) << 4) + ((3) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((SIGN_MAGNITUDE_FORMAT ? 4 : 12) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS, bool SIGN_MAGNITUDE_FORMAT>
inline void _requant_int32_(const uint dst_offset)
{




#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((SIGN_MAGNITUDE_FORMAT ? 4 : 12) << 16) + ((3) << 14) + ((0) << 0))))));

        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((1) << 20) + ((3) << 16) + ((3) << 14) + ((dst_offset * 64) << 0)));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((0) << 8) + ((0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x84 << 24) + (((0) << 16) + ((1) << 12) + ((2) << 8) + ((0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((9) << 12) + ((0) << 8) + ((0) << 4) + ((3) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((SIGN_MAGNITUDE_FORMAT ? 4 : 12) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS, bool SIGN_MAGNITUDE_FORMAT>
inline void _dequant_int32_(const uint dst_offset)
{




#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((SIGN_MAGNITUDE_FORMAT ? 4 : 12) << 16) + ((3) << 14) + ((0) << 0))))));

        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((1) << 20) + ((3) << 16) + ((3) << 14) + ((dst_offset * 64) << 0)));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((0) << 8) + ((0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((0) << 16) + ((10) << 12) + ((2) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x86 << 24) + (((0) << 16) + ((1) << 12) + ((9) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((3) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE >
inline void _init_quant_zero_point_(const uint zero_point)
{
    _sfpu_load_imm32_(2, zero_point);
}

}
}






       





namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_reshuffle_rows_(const uint idx_addr)
{
    constexpr uint output_tile_offset = 64;
    volatile __attribute__((rvtt_l1_ptr)) uint8_t *idx_ptr = reinterpret_cast<volatile __attribute__((rvtt_l1_ptr)) uint8_t *>(idx_addr + (1 << 4));
    static constexpr uint input_lreg[4] = {p_sfpu::LREG0, p_sfpu::LREG1, p_sfpu::LREG2, p_sfpu::LREG3};
    static constexpr uint output_lreg[4] = {p_sfpu::LREG4, p_sfpu::LREG5, p_sfpu::LREG6, p_sfpu::LREG7};

    for (uint row = 0; row < 32; row++)
    {
        uint input_row_addr = (row < 16) ? ((row / 4) * 4) : ((row / 4) * 4 + 16);
        uint input_row_lreg = input_lreg[row % 4];

        uint dst_row = (uint)idx_ptr[row];
        if (dst_row >= 32)
        {
            continue;
        }
        uint output_row_addr = (dst_row < 16) ? ((dst_row / 4) * 4) : ((dst_row / 4) * 4 + 16);
        uint output_row_lreg = output_lreg[dst_row % 4];


        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((input_row_addr) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((input_row_addr + 2) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((input_row_addr + 16) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((input_row_addr + 18) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr + 2) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr + 16) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr + 18) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));


        ckernel::instrn_buffer[0] = ((0x85 << 24) + (((input_row_lreg) << 16) + ((p_sfpu::LCONST_1) << 12) + ((output_row_lreg) << 8) + ((output_row_lreg) << 4) + ((0) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG4) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG5) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr + 2) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG6) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr + 16) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG7) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((output_tile_offset + output_row_addr + 18) << 0)));
    }
}

}
}




       


       







namespace ckernel
{
namespace sfpu
{

inline sfpi::vInt _float_to_int32_(sfpi::vFloat in)
{
    sfpi::vInt result;
    sfpi::vInt exp = exexp(in);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0);
    {
        result = 0;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(exp > 30);
    {

        result = std::numeric_limits<int32_t>::max();

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            result = sfpi::reinterpret<sfpi::vInt>(sfpi::setsgn(sfpi::reinterpret<sfpi::vFloat>(result), 1));
        }
        };
    }
    __cc.cc_else();
    {

        sfpi::vInt man = exman8(in);

        sfpi::vInt shift = exp - 23;
        man = shft(sfpi::reinterpret<sfpi::vUInt>(man), shift);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            man = sfpi::reinterpret<sfpi::vInt>(sfpi::setsgn(sfpi::reinterpret<sfpi::vFloat>(man), 1));
        }
        };
        result = man;
    }
    };
    return result;
}

inline sfpi::vInt _float_to_int31_(sfpi::vFloat v)
{
    sfpi::vInt q = float_to_int16(v * 0x1p-15f, 0);
    sfpi::vInt r = float_to_int16(v - int32_to_float(q, 0) * 0x1p15f, 0);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(r < 0);
    {
        r = sfpi::setsgn(r, 0);
        q = (q << 15) - r;
    }
    __cc.cc_else();
    {
        q = (q << 15) + r;
    }
    };
    return q;
}

inline constexpr std::array<float, 84> PRECOMPUTED_POW10_TABLE = {
    1e-45F, 1e-44F, 1e-43F, 1e-42F, 1e-41F, 1e-40F, 1e-39F, 1e-38F, 1e-37F, 1e-36F, 1e-35F, 1e-34F, 1e-33F, 1e-32F, 1e-31F, 1e-30F, 1e-29F,
    1e-28F, 1e-27F, 1e-26F, 1e-25F, 1e-24F, 1e-23F, 1e-22F, 1e-21F, 1e-20F, 1e-19F, 1e-18F, 1e-17F, 1e-16F, 1e-15F, 1e-14F, 1e-13F, 1e-12F,
    1e-11F, 1e-10F, 1e-9F, 1e-8F, 1e-7F, 1e-6F, 1e-5F, 1e-4F, 1e-3F, 1e-2F, 1e-1F, 1e0F, 1e1F, 1e2F, 1e3F, 1e4F, 1e5F,
    1e6F, 1e7F, 1e8F, 1e9F, 1e10F, 1e11F, 1e12F, 1e13F, 1e14F, 1e15F, 1e16F, 1e17F, 1e18F, 1e19F, 1e20F, 1e21F, 1e22F,
    1e23F, 1e24F, 1e25F, 1e26F, 1e27F, 1e28F, 1e29F, 1e30F, 1e31F, 1e32F, 1e33F, 1e34F, 1e35F, 1e36F, 1e37F, 1e38F,
};

template <bool APPROXIMATION_MODE, int ITERATIONS = 8, bool USE_FP32 = false>
inline void _calculate_floor_()
{
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        sfpi::vFloat result = v;
        sfpi::vInt tmp;

        if constexpr (USE_FP32)
        {
            tmp = _float_to_int32_(result);
        }
        else
        {
            tmp = float_to_int16(result, 0);
        }

        result = int32_to_float(tmp, 0);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result > v);
        {
            result = result - 1;
        }
        };

        if constexpr (!USE_FP32)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= 
           (-0x7fff - 1) 
           || v >= 0x7fff);
            {
                result = v;
            }
            };
        }

        sfpi::dst_reg[0] = result;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8, bool USE_FP32 = false>
inline void _calculate_ceil_()
{
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat result = sfpi::dst_reg[0];
        sfpi::vFloat v = result;

        sfpi::vInt tmp;
        if constexpr (USE_FP32)
        {
            tmp = _float_to_int32_(result);
        }
        else
        {
            tmp = float_to_int16(result, 0);
        }

        result = int32_to_float(tmp, 0);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result < v);
        {
            result = result + 1;
        }
        };

        if constexpr (!USE_FP32)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= 
           (-0x7fff - 1) 
           || v >= 0x7fff);
            {
                result = v;
            }
            };
        }

        sfpi::dst_reg[0] = result;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, bool USE_FP32 = false, int ITERATIONS = 8>
inline void _calculate_trunc_()
{
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat result = in;
        sfpi::vInt tmp;

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            result = 0 - result;
        }
        };

        sfpi::vFloat v = result;

        if constexpr (USE_FP32)
        {
            tmp = _float_to_int32_(result);
        }
        else
        {
            tmp = float_to_int16(result, 0);
        }

        result = int32_to_float(tmp, 0);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result > v);
        {
            result = result - 1;
        }
        };

        if constexpr (!USE_FP32)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= 
           (-0x7fff - 1) 
           || v >= 0x7fff);
            {
                result = v;
            }
            };
        }

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            result = 0 - result;
        }
        };

        sfpi::dst_reg[0] = result;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, bool USE_FP32 = false, int ITERATIONS = 8>
inline void _calculate_frac_()
{
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat result = in;
        sfpi::vInt tmp;

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            result = 0 - result;
        }
        };

        sfpi::vFloat v = result;

        if constexpr (USE_FP32)
        {
            tmp = _float_to_int32_(result);
        }
        else
        {
            tmp = float_to_int16(result, 0);
        }

        result = int32_to_float(tmp, 0);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(result > v);
        {
            result = result - 1;
        }
        };

        if constexpr (!USE_FP32)
        {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= 
           (-0x7fff - 1) 
           || v >= 0x7fff);
            {
                result = v;
            }
            };
        }

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
        {
            result = 0 - result;
        }
        };

        sfpi::dst_reg[0] = in - result;
        sfpi::dst_reg++;
    }
}

inline sfpi::vFloat _round_even_(sfpi::vFloat v)
{
    sfpi::vFloat result;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(v) < 0x1p30f);
    {
        result = int32_to_float(_float_to_int31_(v), 0);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(v - result) == 0.5F);
        {
            sfpi::vInt res = float_to_int16(result, 0);
            res = res & 0xFFFE;
            result = sfpi::int32_to_float(res, 0);
        }
        };
    }
    __cc.cc_else();
    {
        result = v;
    }
    };
    return result;
}

template <bool APPROXIMATE, int ITERATIONS = 8>
void _calculate_round_(const int decimals)
{
    const auto exp10i = [](int n)
    {
        if (n > 38)
        {
            return 1.0F / 0.0F;
        }

        if (n < -45)
        {
            return 0.0F;
        }

        return PRECOMPUTED_POW10_TABLE[n + 45];
    };

    const sfpi::vFloat coeff = exp10i(decimals);
    const sfpi::vFloat inverse = exp10i(-decimals);

    for (int d = 0; d < ITERATIONS; ++d)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        sfpi::vFloat result = inverse * _round_even_(sfpi::abs(v) * coeff);
        result = sfpi::setsgn(result, v);
        sfpi::dst_reg[0] = result;
        sfpi::dst_reg++;
    }
}

}
}




       






namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS, InstrModLoadStore INSTRUCTION_MODE, bool SIGN_MAGNITUDE_FORMAT>
inline void _calculate_binary_left_shift_(const uint dst_offset)
{
    static_assert(is_valid_instruction_mode(INSTRUCTION_MODE), "INSTRUCTION_MODE must be one of: INT32_2S_COMP, INT32, LO16.");

    constexpr int sfpload_instr_mod = SIGN_MAGNITUDE_FORMAT ? INT32_2S_COMP : static_cast<std::underlying_type_t<InstrModLoadStore>>(INSTRUCTION_MODE);


    for (int d = 0; d < ITERATIONS; d++)
    {
        constexpr uint dst_tile_size = 64;

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((dst_offset * dst_tile_size) << 0)));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0xFE0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG2) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8b << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7a << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS, InstrModLoadStore INSTRUCTION_MODE, bool SIGN_MAGNITUDE_FORMAT>
inline void _calculate_binary_right_shift_(const uint dst_offset)
{
    static_assert(is_valid_instruction_mode(INSTRUCTION_MODE), "INSTRUCTION_MODE must be one of: INT32_2S_COMP, INT32, LO16.");

    constexpr int sfpload_instr_mod = SIGN_MAGNITUDE_FORMAT ? INT32_2S_COMP : static_cast<std::underlying_type_t<InstrModLoadStore>>(INSTRUCTION_MODE);


    for (int d = 0; d < ITERATIONS; d++)
    {
        constexpr uint dst_tile_size = 64;

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((3) << 14) + ((0) << 0))))));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((dst_offset * dst_tile_size) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG4) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0xFE0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG2) << 4) + ((p_sfpu::LCONST_0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG1) << 4) + ((6) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7a << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((p_sfpu::LREG4) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((2) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0x020) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG2) << 4) + ((5) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x80 << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG3) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7a << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7f << 24) + (((0) << 12) + ((p_sfpu::LREG3) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS, InstrModLoadStore INSTRUCTION_MODE, bool SIGN_MAGNITUDE_FORMAT>
inline void _calculate_logical_right_shift_(const uint dst_offset)
{
    static_assert(is_valid_instruction_mode(INSTRUCTION_MODE), "INSTRUCTION_MODE must be one of: INT32_2S_COMP, INT32, LO16.");

    constexpr int sfpload_instr_mod = SIGN_MAGNITUDE_FORMAT ? INT32_2S_COMP : static_cast<std::underlying_type_t<InstrModLoadStore>>(INSTRUCTION_MODE);


    for (int d = 0; d < ITERATIONS; d++)
    {
        constexpr uint dst_tile_size = 64;

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((dst_offset * dst_tile_size) << 0)));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0xFE0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG2) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8b << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG1) << 4) + ((6) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7a << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_sigmoid_(const int iterations)
{
    constexpr int lut_mode = 0;
    sfpi::vUInt l0 = sfpi::l_reg[sfpi::LRegs::LReg0];
    sfpi::vUInt l1 = sfpi::l_reg[sfpi::LRegs::LReg1];
    sfpi::vUInt l2 = sfpi::l_reg[sfpi::LRegs::LReg2];
    sfpi::vUInt l4 = sfpi::l_reg[sfpi::LRegs::LReg4];
    sfpi::vUInt l5 = sfpi::l_reg[sfpi::LRegs::LReg5];
    sfpi::vUInt l6 = sfpi::l_reg[sfpi::LRegs::LReg6];

#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];

        sfpi::dst_reg[0] = lut2(val, l0, l1, l2, l4, l5, l6, lut_mode) + 0.5f;

        sfpi::dst_reg++;
    }

    sfpi::l_reg[sfpi::LRegs::LReg0] = l0;
    sfpi::l_reg[sfpi::LRegs::LReg1] = l1;
    sfpi::l_reg[sfpi::LRegs::LReg2] = l2;
    sfpi::l_reg[sfpi::LRegs::LReg4] = l4;
    sfpi::l_reg[sfpi::LRegs::LReg5] = l5;
    sfpi::l_reg[sfpi::LRegs::LReg6] = l6;
}

template <bool APPROXIMATION_MODE>
inline void _init_sigmoid_()
{
    _sfpu_load_imm32_(0, 0x32F433D9);

    _sfpu_load_imm32_(4, 0x23C89018);


    _sfpu_load_imm32_(1, 0x300A318A);

    _sfpu_load_imm32_(5, 0x30272BAA);


    _sfpu_load_imm32_(2, 0x7C002A35);

    _sfpu_load_imm32_(6, 0x37ff34CC);
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_sign_(const int iterations, uint exponent_size_8)
{


#pragma GCC unroll 0
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        sfpi::dst_reg[0] = sfpi::vConst1;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0.0F);
        {
            sfpi::dst_reg[0] = sfpi::vConstNeg1;
        }
        };



        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(v, exponent_size_8));
        {
            sfpi::dst_reg[0] = sfpi::vConst0;
        }
        };

        sfpi::dst_reg++;
    }
}

}
}




       




namespace ckernel::sfpu
{

inline sfpi::vFloat _sigmoid_piecewise_linear_positive_(sfpi::vFloat val)
{
    sfpi::vFloat result = 1.0f;
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val <= 1.0f);
    {
        result = 0.229f * val + 0.5f;
    }
    __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(val < 5.0f);
    {
        result = POLYVAL5<sfpi::vFloat>(0.00144462f, -0.01055479f, -0.01203685f, 0.24300185f, 0.50437757f, val);
    }
    };
    return result;
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_silu_()
{

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];
        sfpi::vFloat result = sfpi::abs(val);
        result = _sigmoid_piecewise_linear_positive_(result);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0f);
        {
            result = 1.0f - result;
        }
        };
        sfpi::dst_reg[0] = val * result;
        sfpi::dst_reg++;
    }
}

}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int RECIPROCAL_ITERATIONS>
__attribute__((always_inline)) inline sfpi::vFloat _calculate_sqrt_body_(sfpi::vFloat val)
{
    sfpi::vFloat result;
    if constexpr (APPROXIMATION_MODE)
    {
        sfpi::vUInt magic = sfpi::vConstIntPrgm0;



        sfpi::vUInt val_s = magic + sfpi::reinterpret<sfpi::vUInt>(val);


        val_s >>= 1;
        result = sfpi::reinterpret<sfpi::vFloat>(val_s);
    }
    else
    {



        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val != 0.0f);
        {
            sfpi::vUInt magic = sfpi::vConstIntPrgm0;
            sfpi::vFloat approx = sfpi::reinterpret<sfpi::vFloat>(magic - (sfpi::reinterpret<sfpi::vUInt>(val) >> 1));


            for (int r = 0; r < RECIPROCAL_ITERATIONS; r++)
            {

                approx = ((approx * approx) * (val * -0.5f) + 1.5f) * approx;
            }

            result = approx * val;
        }
        __cc.cc_else();
        {
            result = val;
        }
        };
    }
    return result;
}

template <bool APPROXIMATION_MODE, int ITERATIONS, int RECIPROCAL_ITERATIONS>
inline void _calculate_sqrt_(const int iterations)
{
#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];
        sfpi::dst_reg[0] = _calculate_sqrt_body_<APPROXIMATION_MODE, RECIPROCAL_ITERATIONS>(val);
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void _init_sqrt_()
{
    if (APPROXIMATION_MODE)
    {
        sfpi::vConstFloatPrgm0 = sfpi::s2vFloat16b(127 << 7);
    }
    else
    {
        sfpi::vConstFloatPrgm0 = sfpi::s2vFloat16b(0x5f37);
    }
}

}
}




       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_square_(const int iterations)
{
#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];
        sfpi::vFloat result = in * in;

        sfpi::dst_reg[0] = result;

        sfpi::dst_reg++;
    }
}

}
}




       
namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS, InstrModLoadStore INSTRUCTION_MODE, bool SIGN_MAGNITUDE_FORMAT>
inline void _sub_int_(const uint dst_offset)
{
    static_assert(is_valid_instruction_mode(INSTRUCTION_MODE), "INSTRUCTION_MODE must be one of: INT32_2S_COMP, INT32, LO16.");



    constexpr int sfpload_instr_mod = SIGN_MAGNITUDE_FORMAT ? INT32_2S_COMP : static_cast<std::underlying_type_t<InstrModLoadStore>>(INSTRUCTION_MODE);




#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));

        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((dst_offset * 64) << 0)));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x79 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((6) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((sfpload_instr_mod) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_tanh_(const int iterations)
{

    sfpi::vUInt l0 = sfpi::l_reg[sfpi::LRegs::LReg0];
    sfpi::vUInt l1 = sfpi::l_reg[sfpi::LRegs::LReg1];
    sfpi::vUInt l2 = sfpi::l_reg[sfpi::LRegs::LReg2];

#pragma GCC unroll 8
    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];
        val = lut(val, l0, l1, l2);
        sfpi::dst_reg[0] = val;

        sfpi::dst_reg++;
    }

    sfpi::l_reg[sfpi::LRegs::LReg0] = l0;
    sfpi::l_reg[sfpi::LRegs::LReg1] = l1;
    sfpi::l_reg[sfpi::LRegs::LReg2] = l2;
}

template <bool APPROXIMATION_MODE>
inline void _init_tanh_()
{
    uint imm0;
    uint imm1;
    uint imm2;
    imm0 = 0x1DFF;
    imm1 = 0x481A;
    imm2 = 0xFF00;
    _sfpu_load_imm16_(0, imm0);
    _sfpu_load_imm16_(1, imm1);
    _sfpu_load_imm16_(2, imm2);
}

}
}




       



namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int WITH_PRECOMPUTED_TANH, int ITERATIONS>
inline void _calculate_tanh_derivative_(const int iterations)
{
    sfpi::vUInt l0 = sfpi::l_reg[sfpi::LRegs::LReg0];
    sfpi::vUInt l1 = sfpi::l_reg[sfpi::LRegs::LReg1];
    sfpi::vUInt l2 = sfpi::l_reg[sfpi::LRegs::LReg2];


    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat val = sfpi::dst_reg[0];

        if constexpr (!WITH_PRECOMPUTED_TANH)
        {
            val = lut(val, l0, l1, l2);
        }

        val = val * (-val) + sfpi::vConst1;
        sfpi::dst_reg[0] = val;

        sfpi::dst_reg++;
    }

    sfpi::l_reg[sfpi::LRegs::LReg0] = l0;
    sfpi::l_reg[sfpi::LRegs::LReg1] = l1;
    sfpi::l_reg[sfpi::LRegs::LReg2] = l2;
}

}
}




       
namespace ckernel
{
namespace sfpu
{

static int32_t topk_replay_init = 0;

inline void set_dst_write_addr(uint32_t addr)
{
    uint dst_index = addr + get_dest_buffer_base();
    ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((1) << 16) + ((dst_index) << 0)));
}

template <bool is_fp32_dest_acc_en>
inline void bitonic_topk_load8(uint offset, uint dist)
{
    constexpr uint dst_indices_offset = 128;
    constexpr uint8_t instr_mod_index = is_fp32_dest_acc_en ? InstrModLoadStore::INT32 : InstrModLoadStore::LO16;

    uint face_offset = offset >> 4;
    uint ld_offset = (offset & 0xF) + face_offset * 32;


    ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((ld_offset) << 0)));
    ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((ld_offset + dist) << 0)));


    ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG4) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + ld_offset) << 0)));
    ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG5) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + ld_offset + dist) << 0)));
}

template <bool is_fp32_dest_acc_en>
inline void bitonic_topk_store8(uint offset, uint dist)
{
    constexpr uint dst_indices_offset = 128;
    constexpr uint8_t instr_mod_index = is_fp32_dest_acc_en ? InstrModLoadStore::INT32 : InstrModLoadStore::LO16;

    uint face_offset = offset >> 4;
    uint ld_offset = (offset & 0xF) + face_offset * 32;


    ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((ld_offset) << 0)));
    ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((ld_offset + dist) << 0)));


    ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG4) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + ld_offset + 0) << 0)));
    ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG5) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + ld_offset + dist) << 0)));
}

template <bool is_fp32_dest_acc_en>
inline void bitonic_topk_load16(uint dist0, uint dist1)
{
    constexpr uint dst_indices_offset = 128;
    constexpr uint8_t instr_mod_index = is_fp32_dest_acc_en ? InstrModLoadStore::INT32 : InstrModLoadStore::LO16;


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
    if ((dist0 == 4) && (dist1 == 8))
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12) << 0))))));
    }
    else
    {
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + dist0) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((dist1) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((dist1 + dist0) << 0)));
    }


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG4) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 0) << 0))))));
    if ((dist0 == 4) && (dist1 == 8))
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG5) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG6) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG7) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 12) << 0))))));
    }
    else
    {
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG5) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 0 + dist0) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG6) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + dist1) << 0)));
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((p_sfpu::LREG7) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + dist1 + dist0) << 0)));
    }
}

template <bool is_fp32_dest_acc_en, bool alt_addr_mod = false>
inline void bitonic_topk_store16(uint dist0, uint dist1)
{
    constexpr uint dst_indices_offset = 128;
    constexpr uint8_t instr_mod_index = is_fp32_dest_acc_en ? InstrModLoadStore::INT32 : InstrModLoadStore::LO16;


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
    if ((dist0 == 4) && (dist1 == 8))
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((12) << 0))))));
    }
    else
    {
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0 + dist0) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG2) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((dist1) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG3) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((dist1 + dist0) << 0)));
    }


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG4) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 0) << 0))))));
    if ((dist0 == 4) && (dist1 == 8))
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG5) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG6) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG7) << 20) + ((instr_mod_index) << 16) + ((alt_addr_mod ? ADDR_MOD_2 : ADDR_MOD_3) << 14) + ((dst_indices_offset + 12) << 0))))));
    }
    else
    {
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG5) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + 0 + dist0) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG6) << 20) + ((instr_mod_index) << 16) + ((ADDR_MOD_3) << 14) + ((dst_indices_offset + dist1) << 0)));
        ckernel::instrn_buffer[0] = ((0x72 << 24) + (((p_sfpu::LREG7) << 20) + ((instr_mod_index) << 16) + ((alt_addr_mod ? ADDR_MOD_2 : ADDR_MOD_3) << 14) + ((dst_indices_offset + dist1 + dist0) << 0)));
    }
}

inline void bitonic_topk_ph3_st4_to_1(bool dir, bool &init_replay, int replay_start)
{
    if (dir == (bool)SortDir::ArgMin)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0x104) << 8) + ((0xF) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    }

    if (init_replay)
    {
        lltt::record<lltt::Exec>(replay_start, 5);


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG2) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));

        init_replay = false;
    }
    else
    {
        lltt::replay(replay_start, 5);
    }

    lltt::replay(replay_start, 5);

    if (dir == (bool)SortDir::ArgMin)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x91 << 24) + (((0x004) << 8) + ((0xF) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
    }
}

inline void bitonic_topk_ph2_st3_to_1()
{

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::UNCONDITIONALLY) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG2) << 4) + ((p_sfpswap::ROWS_01_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ROWS_01_MAX) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((p_sfpswap::ROWS_01_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ROWS_01_MAX) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
}

inline void bitonic_topk_ph1_st2_to_1()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG2) << 4) + ((p_sfpswap::ROWS_02_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ROWS_02_MAX) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((p_sfpswap::ROWS_02_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ROWS_02_MAX) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
}

inline void bitonic_topk_ph0_st1_to_1()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::UNCONDITIONALLY) << 0))))));

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8c << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
}

inline void bitonic_topk_step_N(bool dir)
{

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG2) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
    if (dir == (bool)SortDir::ArgMin)
    {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG2) << 4) + ((p_sfpswap::UNCONDITIONALLY) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG3) << 4) + ((p_sfpswap::UNCONDITIONALLY) << 0))))));
    }

}

inline void bitonic_topk_inc_x8_dest(uint inc, bool cr)
{
    uint inc_grp8 = inc >> 3;
    for (uint i = 0; i < inc_grp8; i++)
    {
        if (cr)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0b100) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
        }
    }
}

inline void bitonic_topk_inc_x4_dest(uint inc, bool cr)
{
    uint inc_grp4 = inc >> 2;
    for (uint i = 0; i < inc_grp4; i++)
    {
        if (cr)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0b100) << 18) + ((4) << 14) + ((0) << 10) + ((0) << 6))))));
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((4) << 14) + ((0) << 10) + ((0) << 6))))));
        }
    }
}

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, int ITERATIONS>
inline void _bitonic_topk_phases_steps(const int idir, const int i_end_phase, const int i_start_phase, const int i_end_step, const int i_start_step)
{




    bool init_load = (topk_replay_init >= 0) ? true : false;
    bool init_store = (topk_replay_init >= 0) ? true : false;
    bool init_phase;

    uint dst_addr_offset = 0;
    for (int face = 0; face < 2; face++)
    {
        for (int col = 0; col < 2; col++)
        {
            bool dir = idir;
            for (int ph = i_start_phase; ph < (i_end_phase + 1); ph++)
            {
                init_phase = true;

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                switch (ph)
                {
                    case 0:
                        for (int d = 0; d < 4; d++)
                        {

                            if (init_load)
                            {
                                lltt::record<lltt::Exec>(0, 8);
                                bitonic_topk_load16<is_fp32_dest_acc_en>(4, 8);
                                init_load = false;
                            }
                            else
                            {
                                lltt::replay(0, 8);
                            }
                            if (init_phase)
                            {
                                lltt::record<lltt::Exec>(16, 5);
                                bitonic_topk_ph0_st1_to_1();
                                init_phase = false;
                            }
                            else
                            {
                                lltt::replay(16, 5);
                            }
                            if (init_store)
                            {
                                lltt::record<lltt::Exec>(8, 8);
                                bitonic_topk_store16<is_fp32_dest_acc_en, true>(4, 8);
                                init_store = false;
                            }
                            else
                            {
                                lltt::replay(8, 8);
                            }
                        }
                        break;
                    case 1:
                        for (int d = 0; d < 4; d++)
                        {

                            lltt::replay(0, 8);
                            if (init_phase)
                            {
                                lltt::record<lltt::Exec>(16, 6);
                                bitonic_topk_ph1_st2_to_1();
                                init_phase = false;
                            }
                            else
                            {
                                lltt::replay(16, 6);
                            }
                            lltt::replay(8, 8);
                        }
                        break;
                    case 2:
                        for (int d = 0; d < 4; d++)
                        {
                            lltt::replay(0, 8);
                            if (init_phase)
                            {
                                lltt::record<lltt::Exec>(16, 9);
                                bitonic_topk_ph2_st3_to_1();
                                init_phase = false;
                            }
                            else
                            {
                                lltt::replay(16, 9);
                            }
                            lltt::replay(8, 8);
                        }
                        break;
                    case 3:
                        for (int d = 0; d < 4; d++)
                        {
                            lltt::replay(0, 8);
                            bitonic_topk_ph3_st4_to_1(dir, init_phase, 16);
                            lltt::replay(8, 8);
                            dir = !dir;
                        }
                        break;
                    default:
                        uint num_steps = ph + 1;
                        uint start_step = (i_start_phase == i_end_phase) ? i_start_step : num_steps;
                        uint end_step = (i_start_phase == i_end_phase) ? i_end_step : 4;
                        uint sorted_seq_length = 1 << num_steps;
                        uint datums_compared = 0;
                        uint total_datums_to_compare = 64;
                        for (uint ss = start_step; ss > end_step; ss--)
                        {

                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                            dir = idir;
                            uint dist = (ss == 5) ? 16 : 32;
                            uint inner_d = dist >> 3;
                            datums_compared = 0;
                            uint dst_offset = 0;
                            while (datums_compared < total_datums_to_compare)
                            {
                                for (uint ii = 0; ii < inner_d; ii++)
                                {
                                    bitonic_topk_load16<is_fp32_dest_acc_en>(4, 2 * dist);
                                    bitonic_topk_step_N(dir);
                                    bitonic_topk_store16<is_fp32_dest_acc_en, false>(
                                        4, 2 * dist);
                                    uint dst_inc = 8;
                                    dst_offset += dst_inc;
                                    bool dst_cr = false;
                                    if (ii == (inner_d - 1))
                                    {
                                        dst_cr = true;
                                        dst_inc = 4 * dist;
                                        dst_offset = 2 * dist;
                                    }
                                    else if (dst_offset == 16)
                                    {
                                        dst_cr = true;
                                        dst_inc = 32;
                                    }
                                    bitonic_topk_inc_x8_dest(dst_inc, dst_cr);
                                    datums_compared += 16;
                                }
                                dir = (datums_compared == sorted_seq_length) ? !dir : dir;
                            }
                        }

                        dir = idir;
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                        datums_compared = 0;
                        while (datums_compared < total_datums_to_compare)
                        {
                            lltt::replay(0, 8);
                            bitonic_topk_ph3_st4_to_1(dir, init_phase, 16);
                            lltt::replay(8, 8);
                            datums_compared += 16;
                            dir = (datums_compared == sorted_seq_length) ? !dir : dir;
                        }
                }
            }
            dst_addr_offset += 2;
            set_dst_write_addr(dst_addr_offset);
        }
        dst_addr_offset = 16;
        set_dst_write_addr(dst_addr_offset);
    }
    topk_replay_init = -1;
}

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, bool top_min, int ITERATIONS>
inline void _bitonic_topk_merge(const int m_iter, const int k)
{
    uint dst_addr_offset = 0;
    for (int face = 0; face < 2; face++)
    {
        for (int col = 0; col < 2; col++)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            int k_max = k > 32 ? 32 : k;
            uint inner_d = k_max >> 2;
            uint total_datums_to_compare = ((64 >> m_iter) < 2 * k_max)
                                               ? 2 * k_max
                                               : (64 >> m_iter);
            uint dist = (k_max << m_iter) > 32 ? 32 : (k_max << m_iter);
            uint ld_dist = (dist < 16) ? dist : 2 * dist;
            uint datums_compared = 0;
            uint dst_offset = 0;
            uint dst_cr = 0;

            while (datums_compared < total_datums_to_compare)
            {
                for (uint ii = 0; ii < inner_d; ii++)
                {
                    bitonic_topk_load8<is_fp32_dest_acc_en>(dst_offset, ld_dist);
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((top_min ? p_sfpu::LREG1 : p_sfpu::LREG0) << 8) + ((top_min ? p_sfpu::LREG0 : p_sfpu::LREG1) << 4) + ((p_sfpswap::ALL_ROWS_MAX) << 0))))));
                    bitonic_topk_store8<is_fp32_dest_acc_en>(dst_offset, ld_dist);
                    datums_compared += 8;
                    if (ii == (inner_d - 1))
                    {
                        dst_cr += 2 * dist;
                        dst_offset = dst_cr;
                    }
                    else
                    {
                        dst_offset += 4;
                    }
                }
            }
            dst_addr_offset += 2;
            set_dst_write_addr(dst_addr_offset);
        }
        dst_addr_offset = 16;
        set_dst_write_addr(dst_addr_offset);
    }
}

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, int ITERATIONS>
inline void _bitonic_topk_rebuild(const bool idir, const int m_iter, const int k, const int logk, const int skip_second)
{

    bool init_rebuild = (topk_replay_init != m_iter + 1) ? true : false;

    uint dst_addr_offset = 0;
    for (int face = 0; face < 2; face++)
    {
        for (int col = 0; col < 2; col++)
        {
            uint total_datums_shift = (skip_second & 0x1);
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            uint rebuild_m = m_iter + 1;
            uint total_datums_to_compare =
                ((64 >> rebuild_m) < 2 * k) ? 2 * k : (64 >> rebuild_m);
            total_datums_to_compare = total_datums_to_compare >> total_datums_shift;
            uint dist = (k << rebuild_m) > 32 ? 32 : (k << rebuild_m);
            uint ld_offset = (dist >> 4) * 32 + (dist & 0xF);
            uint ld_dist;
            int ph = logk - 1;
            bool dir = idir;
            uint datums_compared = 0;

            switch (ph)
            {
                case 0:

                    break;
                case 1:
                    if (m_iter >= 2)
                    {
                        while (datums_compared < total_datums_to_compare)
                        {

                            if (init_rebuild)
                            {
                                lltt::record<lltt::Exec>(0, 22);
                                bitonic_topk_load8<is_fp32_dest_acc_en>(0, ld_offset);
                                bitonic_topk_ph1_st2_to_1();
                                bitonic_topk_store8<is_fp32_dest_acc_en>(0, ld_offset);
                                bitonic_topk_inc_x8_dest(64, false);
                                init_rebuild = false;
                            }
                            else
                            {
                                lltt::replay(0, 22);
                            }
                            datums_compared += 16;
                        }
                        break;
                    }
                    else
                    {
                        ld_dist = (ld_offset < 16) ? 4 * ld_offset : 2 * ld_offset;
                        while (datums_compared < total_datums_to_compare)
                        {

                            if (init_rebuild)
                            {
                                lltt::record<lltt::Exec>(0, 26);
                                bitonic_topk_load16<is_fp32_dest_acc_en>(ld_offset, ld_dist);
                                bitonic_topk_ph1_st2_to_1();
                                bitonic_topk_store16<is_fp32_dest_acc_en, true>(ld_offset, ld_dist);
                                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                                init_rebuild = false;
                            }
                            else
                            {
                                lltt::replay(0, 26);
                            }
                            datums_compared += 16;
                        }
                        break;
                    }
                case 2:
                    while (datums_compared < total_datums_to_compare)
                    {

                        if (init_rebuild)
                        {
                            lltt::record<lltt::Exec>(0, 29);
                            bitonic_topk_load16<is_fp32_dest_acc_en>(4, ld_offset);
                            bitonic_topk_ph2_st3_to_1();
                            bitonic_topk_store16<is_fp32_dest_acc_en, true>(4, ld_offset);
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            init_rebuild = false;
                        }
                        else
                        {
                            lltt::replay(0, 29);
                        }
                        datums_compared += 16;
                    }
                    break;
                case 3:
                    while (datums_compared < total_datums_to_compare)
                    {

                        if (init_rebuild)
                        {
                            lltt::record<lltt::Exec>(0, 8);
                            bitonic_topk_load16<is_fp32_dest_acc_en>(4, 8);
                            bitonic_topk_ph3_st4_to_1(dir, init_rebuild, 8);
                            lltt::record<lltt::Exec>(13, 12);
                            bitonic_topk_store16<is_fp32_dest_acc_en, true>(4, 8);
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x38 << 24) + (((0) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6))))));
                        }
                        else
                        {
                            lltt::replay(0, 8);
                            bitonic_topk_ph3_st4_to_1(dir, init_rebuild, 8);
                            lltt::replay(13, 12);
                        }
                        datums_compared += 16;
                        dir = !dir;
                    }
                    break;
                default:
                    uint num_steps = ph + 1;
                    uint start_step = num_steps;
                    uint end_step = 4;
                    uint sorted_seq_length = 1 << num_steps;
                    uint total_datums_to_compare = 64;
                    for (uint ss = start_step; ss > end_step; ss--)
                    {

                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                        dir = idir;
                        datums_compared = 0;
                        uint dist = (ss == 5) ? 16 : 32;
                        uint inner_d = dist >> 3;
                        uint dst_offset = 0;
                        while (datums_compared < total_datums_to_compare)
                        {
                            for (uint ii = 0; ii < inner_d; ii++)
                            {
                                bitonic_topk_load16<is_fp32_dest_acc_en>(4, 2 * dist);
                                bitonic_topk_step_N(dir);
                                bitonic_topk_store16<is_fp32_dest_acc_en, false>(4, 2 * dist);
                                uint dst_inc = 8;
                                dst_offset += dst_inc;
                                bool dst_cr = false;
                                if (ii == (inner_d - 1))
                                {
                                    dst_cr = true;
                                    dst_inc = 4 * dist;
                                    dst_offset = 2 * dist;
                                }
                                else if (dst_offset == 16)
                                {
                                    dst_cr = true;
                                    dst_inc = 32;
                                }
                                bitonic_topk_inc_x8_dest(dst_inc, dst_cr);
                                datums_compared += 16;
                            }
                            dir = (datums_compared == sorted_seq_length) ? !dir : dir;
                        }
                    }

                    dir = idir;
                    datums_compared = 0;
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                    while (datums_compared < total_datums_to_compare)
                    {
                        if (init_rebuild)
                        {
                            lltt::record<lltt::Exec>(0, 8);
                            bitonic_topk_load16<is_fp32_dest_acc_en>(4, 8);
                            bitonic_topk_ph3_st4_to_1(dir, init_rebuild, 8);
                            lltt::record<lltt::Exec>(13, 8);
                            bitonic_topk_store16<is_fp32_dest_acc_en, true>(4, 8);
                        }
                        else
                        {
                            lltt::replay(0, 8);
                            bitonic_topk_ph3_st4_to_1(dir, init_rebuild, 8);
                            lltt::replay(13, 8);
                        }
                        datums_compared += 16;
                        dir = (datums_compared == sorted_seq_length) ? !dir : dir;
                    }
            }

            dst_addr_offset += 2;
            set_dst_write_addr(dst_addr_offset);
        }
        dst_addr_offset = 16;
        set_dst_write_addr(dst_addr_offset);
    }
    topk_replay_init = m_iter + 1;
}

inline void _init_topk()
{
    topk_replay_init = 0;
    _sfpu_load_config32_(0xF, 0x0, 0x4);
}

}
}




       







namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE>
__attribute__((always_inline)) inline sfpi::vFloat _sfpu_sine_maclaurin_series_(sfpi::vFloat val)
{


    sfpi::vFloat tmp = val;

    sfpi::vFloat output = tmp;

    tmp = tmp * val * val;
    output += -0.166666666 * tmp;

    tmp = tmp * val * val;
    output += 0.0083333333 * tmp;

    tmp = tmp * val * val;
    output += -0.0001984126 * tmp;
    if constexpr (not APPROXIMATION_MODE)
    {

        tmp = tmp * val * val;
        output += 0.0000027557 * tmp;

        tmp = tmp * val * val;
        output += -0.00000002505 * tmp;
    }


    return output;
}

template <bool APPROXIMATION_MODE>
__attribute__((always_inline)) inline sfpi::vFloat _sfpu_cosine_maclaurin_series_(sfpi::vFloat val)
{



    sfpi::vFloat output = 1.0f;

    sfpi::vFloat tmp = val * val;
    output += -0.5 * tmp;

    tmp = tmp * val * val;
    output += 0.0416666666 * tmp;

    tmp = tmp * val * val;
    output += -0.0013888888 * tmp;
    if constexpr (not APPROXIMATION_MODE)
    {

        tmp = tmp * val * val;
        output += 0.0000248015 * tmp;

        tmp = tmp * val * val;
        output += -0.0000002755 * tmp;
    }


    return output;
}



template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_sine_(const int iterations)
{

    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        v = 0.318309886183791f * v;
        sfpi::vInt whole_v = float_to_int16(v, 0);
        sfpi::vFloat whole_v_float = int32_to_float(whole_v, 0);
        v = v - whole_v_float;
        v *= 3.141592653589793f;
        v = _sfpu_sine_maclaurin_series_<APPROXIMATION_MODE>(v);
        whole_v = whole_v & 0x1;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(whole_v != 0);
        {

            v *= -1;
        }
        };
        sfpi::dst_reg[0] = v;
        sfpi::dst_reg++;
    }
}



template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_cosine_(const int iterations)
{

    for (int d = 0; d < iterations; d++)
    {
        sfpi::vFloat v = sfpi::dst_reg[0];
        v = 0.318309886183791f * v;
        sfpi::vInt whole_v = float_to_int16(v, 0);
        sfpi::vFloat whole_v_float = int32_to_float(whole_v, 0);
        v = v - whole_v_float;
        v *= 3.141592653589793f;
        v = _sfpu_cosine_maclaurin_series_<APPROXIMATION_MODE>(v);
        whole_v = whole_v & 0x1;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(whole_v != 0);
        {

            v *= -1;
        }
        };
        sfpi::dst_reg[0] = v;
        sfpi::dst_reg++;
    }
}



template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_acosh_()
{

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat inp = sfpi::dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(inp < sfpi::vConst1);
        {
            sfpi::dst_reg[0] = std::numeric_limits<float>::quiet_NaN();
        }
        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(inp == sfpi::vConst1);
        {
            sfpi::dst_reg[0] = sfpi::vConst0;
        }
        __cc.cc_else();
        {
            sfpi::vFloat tmp = inp * inp;
            tmp = tmp - sfpi::vConst1;
            tmp = _calculate_sqrt_body_<APPROXIMATION_MODE, 2>(tmp);
            tmp = tmp + inp;
            sfpi::dst_reg[0] = _calculate_log_body_no_init_(tmp);
        }
        };
        sfpi::dst_reg++;
    }
}


template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_asinh_()
{

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat inp = sfpi::dst_reg[0];
        sfpi::vFloat tmp = inp * inp + sfpi::vConst1;
        tmp = _calculate_sqrt_body_<APPROXIMATION_MODE, 2>(tmp);
        tmp = tmp + sfpi::abs(inp);
        sfpi::dst_reg[0] = _calculate_log_body_no_init_(tmp);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(inp < sfpi::vConst0);
        {
            sfpi::dst_reg[0] = -sfpi::dst_reg[0];
        }
        };
        sfpi::dst_reg++;
    }
}


template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, int ITERATIONS>
inline void _calculate_atanh_()
{

    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat inp = sfpi::dst_reg[0];
        sfpi::vFloat abs_inp = sfpi::abs(inp);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(abs_inp > sfpi::vConst1);
        {
            sfpi::dst_reg[0] = std::numeric_limits<float>::quiet_NaN();
        }
        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(abs_inp == sfpi::vConst1);
        {
            sfpi::vFloat inf = std::numeric_limits<float>::infinity();
            sfpi::dst_reg[0] = sfpi::setsgn(inf, inp);
        }
        __cc.cc_else();
        {
            sfpi::vFloat num = sfpi::vConst1 + inp;
            sfpi::vFloat den = sfpi::vConst1 - inp;
            sfpi::vFloat tmp = _sfpu_reciprocal_<APPROXIMATION_MODE ? 2 : 3>(den);
            tmp = sfpi::setsgn(tmp, den);
            if constexpr (is_fp32_dest_acc_en || APPROXIMATION_MODE)
            {
                den = tmp;
            }
            else
            {
                den = sfpi::reinterpret<sfpi::vFloat>(float_to_fp16b(tmp, 0));
            }
            num = num * den;
            den = _calculate_log_body_no_init_(num);
            sfpi::dst_reg[0] = 0.5f * den;
        }
        };
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
void _init_inverse_hyperbolic_()
{
    _init_sqrt_<APPROXIMATION_MODE>();
}

template <bool APPROXIMATION_MODE>
void _init_atanh_()
{
    _init_reciprocal_<APPROXIMATION_MODE>();
}

}
}




       




namespace ckernel
{
namespace sfpu
{

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_fp16b_to_uint16_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((0) << 16) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((2) << 12) + ((0) << 8) + ((1) << 4) + ((14) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((6) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_uint16_to_fp16b_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((6) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((0) << 8) + ((1) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((3) << 12) + ((1) << 8) + ((2) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((2) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_int32_to_fp16b_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((12) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((0) << 8) + ((1) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((3) << 12) + ((1) << 8) + ((2) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((2) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_fp16b_to_int32_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];


        sfpi::vInt exp = exexp(in);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0);
        {
            sfpi::dst_reg[0] = 0;
        }
        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(exp > 30);
        {

            sfpi::vInt tmp = std::numeric_limits<int32_t>::max();

            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
            {
                tmp = sfpi::reinterpret<sfpi::vInt>(sfpi::setsgn(sfpi::reinterpret<sfpi::vFloat>(tmp), 1));
            }
            } sfpi::dst_reg[0] = tmp;
        }
        __cc.cc_else();
        {

            sfpi::vInt man = exman8(in);

            sfpi::vInt shift = exp - 23;
            man = sfpi::shft(sfpi::reinterpret<sfpi::vUInt>(man), shift);

            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in < 0);
            {
                man = sfpi::reinterpret<sfpi::vInt>(sfpi::setsgn(sfpi::reinterpret<sfpi::vFloat>(man), 1));
            }
            } sfpi::dst_reg[0] = man;
        }
        }

            sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_fp32_to_fp16b_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((2) << 12) + ((0) << 8) + ((1) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((0) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_uint16_to_fp32_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((6) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((0) << 8) + ((1) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((3) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_int32_to_fp32_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((12) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((0) << 8) + ((1) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((1) << 20) + ((3) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_fp16b_to_uint32_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        sfpi::vFloat in = sfpi::dst_reg[0];


        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in <= 0);
        {
            sfpi::dst_reg[0] = 0;
        }
        __cc.cc_else();
        {

            sfpi::vInt exp = exexp(in);

            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0);
            {
                sfpi::dst_reg[0] = 0;
            }
            __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(exp > 31);
            {

                sfpi::vInt tmp = std::numeric_limits<int32_t>::max();
                sfpi::dst_reg[0] = sfpi::setsgn(sfpi::reinterpret<sfpi::vFloat>(tmp), 1);
            }
            __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(exp == 31);
            {

                sfpi::vInt man = exman9(in);

                sfpi::vInt shift = exp - 23;
                man = sfpi::shft(sfpi::reinterpret<sfpi::vUInt>(man), shift);

                sfpi::dst_reg[0] = sfpi::setsgn(sfpi::reinterpret<sfpi::vFloat>(man), 1);
            }
            __cc.cc_else();
            {

                sfpi::vInt man = exman8(in);

                sfpi::vInt shift = exp - 23;
                man = sfpi::shft(sfpi::reinterpret<sfpi::vUInt>(man), shift);
                sfpi::dst_reg[0] = man;
            }
            }
        }
        }

            sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_uint32_to_fp16b_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((4) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x89 << 24) + (((0) << 12) + ((0) << 8) + ((1) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((1) << 8) + ((2) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8e << 24) + (((0) << 21) + ((0) << 16) + ((4) << 12) + ((2) << 8) + ((3) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x75 << 24) + (((0x4f00) << 8) + ((3) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((3) << 20) + ((2) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_uint32_to_fp32_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((4) << 16) + ((3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x89 << 24) + (((0) << 12) + ((0) << 8) + ((1) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x90 << 24) + (((1) << 8) + ((2) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x75 << 24) + (((0x4f00) << 8) + ((2) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((2) << 20) + ((3) << 16) + ((3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_uint16_to_uint32_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::LO16) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_uint32_to_uint16_()
{

#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((p_sfpu::LREG1) << 20) + ((2) << 16) + ((0xFFFF) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7b << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((0) << 4) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8a << 24) + (((0) << 12) + ((0) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((InstrModLoadStore::LO16) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void _calculate_typecast_int32_to_uint16_()
{
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((p_sfpu::LREG1) << 20) + ((2) << 16) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((p_sfpu::LREG2) << 20) + ((2) << 16) + ((0xFFFF) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG0) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::LO16) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        sfpi::dst_reg++;
    }
}

}
}
using namespace ckernel;

namespace ckernel::math
{

constexpr uint DstTileSize[3] = {
    64,
    32,
    16
};
constexpr uint DstTileSizeLog2[3] = {
    6,
    5,
    4
};

constexpr uint replay_buf_offset = 16;


inline void reset_counters(const uint setrwc)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((setrwc) << 0))))));
}

inline void incr_counters(const uint incr_a, const uint incr_b, const uint incr_d, const uint incr_cr)
{
    ckernel::instrn_buffer[0] = ((0x38 << 24) + (((incr_cr) << 18) + ((incr_d) << 14) + ((incr_b) << 10) + ((incr_a) << 6)));
}

inline void move_d2a_fixed_face(const uint8_t addrmod)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::SRCA_VLD) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 0) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_4_ROWS) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 4) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_4_ROWS) << 12) + ((4) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 8) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_4_ROWS) << 12) + ((8) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 12) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_4_ROWS) << 12) + ((12) << 0))))));
}

inline void move_d2b_fixed_face(const uint8_t addrmod)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::SRCB_VLD) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ZERO_OFFSET + 0) << 17) + ((addrmod) << 15) + ((p_movd2b::MOV_4_ROWS) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ZERO_OFFSET + 4) << 17) + ((addrmod) << 15) + ((p_movd2b::MOV_4_ROWS) << 12) + ((4) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ZERO_OFFSET + 8) << 17) + ((addrmod) << 15) + ((p_movd2b::MOV_4_ROWS) << 12) + ((8) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ZERO_OFFSET + 12) << 17) + ((addrmod) << 15) + ((p_movd2b::MOV_4_ROWS) << 12) + ((12) << 0))))));
}

inline void move_d2a_row_broadcast_fixed_face(const uint8_t addrmod)
{

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 0) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 1) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 2) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 3) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 4) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 5) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 6) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 7) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 8) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 9) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 10) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 11) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 12) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 13) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 14) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x08 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS + 15) << 17) + ((addrmod) << 15) + ((p_movd2a::MOV_1_ROW) << 12) + ((0) << 0))))));
}

inline void move_a2d_fixed_face(const uint8_t addrmod)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x12 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS) << 17) + ((addrmod) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x12 << 24) + (((0) << 23) + ((p_mova2d::MATH_HALO_ROWS) << 17) + ((addrmod) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))))));
}

template <uint SrcReg>
inline void wait_bank_valid()
{
    if constexpr (SrcReg == Srcs::SrcA)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::SRCA_VLD) << 0))))));
    }
    else
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::SRCB_VLD) << 0))))));
    }
}

template <uint SrcReg>
inline void clear_bank_valid()
{
    if constexpr (SrcReg == Srcs::SrcA)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_A) << 0))))));
    }
    else
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))))));
    }
}

inline void wait_math_semaphores()
{

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa6 << 24) + (((p_stall::STALL_MATH | p_stall::STALL_SFPU) << 15) + ((semaphore::t6_sem(semaphore::MATH_PACK)) << 2) + ((p_stall::STALL_ON_MAX) << 0))))));
}

inline void set_math_semaphores()
{

    t6_semaphore_post<p_stall::MATH | p_stall::WAIT_SFPU>(semaphore::MATH_PACK);
}

inline void math_unpack_to_dest_math_ready()
{
    t6_semaphore_wait_on_max<p_stall::STALL_SYNC>(semaphore::MATH_DONE);
    t6_semaphore_post<p_stall::MATH | p_stall::WAIT_SFPU>(semaphore::MATH_DONE);
    while (semaphore_read(semaphore::MATH_DONE) == 0)
    {
    }
    semaphore_get(semaphore::MATH_DONE);
}

inline void math_unpack_to_dest_tile_ready()
{
    t6_semaphore_wait_on_zero<p_stall::STALL_SYNC>(semaphore::UNPACK_TO_DEST);
    t6_semaphore_get<p_stall::MATH | p_stall::WAIT_SFPU>(semaphore::UNPACK_TO_DEST);
}

template <DstTileLayout layout, DstTileShape tile_shape, bool unpack_to_dest = false>
inline void set_dst_write_addr(uint32_t tile_index)
{
    if constexpr (layout == DstTileLayout::Default)
    {
        uint dst_index = tile_index << DstTileSizeLog2[tile_shape];
        dst_index = dst_index + get_dest_buffer_base();
        if constexpr (unpack_to_dest)
        {
            mailbox_write(ThreadId::UnpackThreadId, dst_index);
        }
        else
        {
            ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((1) << 16) + ((dst_index) << 0)));
        }
    }
    else
    {

    }
}



inline void clear_dst_reg_addr()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
}

inline void set_addr_mod_base()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((2) << 16) + ((1) << 0))))));
}

inline void clear_addr_mod_base()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((2) << 16) + ((0) << 0))))));
}

template <uint num_rows = 8>
inline void inc_dst_addr()
{
    static_assert(num_rows <= 15, "num_rows must be <= 15");
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((num_rows) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
}

inline void math_dest_wait()
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa6 << 24) + (((p_stall::STALL_MATH | p_stall::STALL_SFPU | p_stall::STALL_SYNC) << 15) + ((semaphore::t6_sem(semaphore::MATH_PACK)) << 2) + ((p_stall::STALL_ON_MAX) << 0))))));
}

inline void dest_section_flip()
{
    update_dest_offset_id();
    uint base_addr = get_dest_buffer_base();
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::MATH | p_stall::SFPU1) << 0))))));
    ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((1) << 16) + ((base_addr) << 0)));
}

template <DstStart Dst>
inline void set_dest_section_base()
{
    uint base_addr;
    if constexpr (Dst == DstStart::StartZero)
    {
        base_addr = 0;
    }
    else
    {
        base_addr = DEST_REGISTER_HALF_SIZE;
    }
    ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((1) << 16) + ((base_addr) << 0)));
}

inline constexpr bool is_32bit_input(const std::uint32_t src_format, const std::uint32_t dst_format)
{
    const uint input_df = src_format & 0xF;
    const uint output_df = dst_format & 0xF;

    return ((input_df == (uint)DataFormat::Int32) || (input_df == (uint)DataFormat::Float32)) &&
           ((output_df == (uint)DataFormat::Int32) || (output_df == (uint)DataFormat::Float32));
}

inline constexpr int get_math_num_fidelity_phases(const int math_fidelity_desc)
{
    return (math_fidelity_desc & 0x7);
}

inline constexpr int get_math_fidelity_increment(const int math_fidelity_desc)
{
    return ((math_fidelity_desc >> 3) & 0x1) + 1;
}

}






       
using namespace ckernel::math;

template <bool untilize_en = false, bool row_pool = false>
inline void _llk_math_hw_configure_(const std::uint32_t srca_data_format, const std::uint32_t srcb_data_format)
{
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::MATH | p_stall::WAIT_SFPU) << 0))))));
    uint exp_width = ((uint)srca_data_format >> 2) & 0x1;
    uint int8_math_enabled = ((uint)(srca_data_format & 0xF) == (uint)DataFormat::Int8) || ((uint)(srcb_data_format & 0xF) == (uint)DataFormat::Int8) ||
                             ((uint)srca_data_format == (uint)DataFormat::Int32) || ((uint)srcb_data_format == (uint)DataFormat::Int32);
    uint srcb_format = (row_pool ? ((uint)DataFormat::Float16 | (exp_width << 2)) : srcb_data_format);
    uint config_data = (srca_data_format << 17) | (srcb_format << 21) |
                       (int8_math_enabled << 31);
    constexpr uint config_mask = 0x1e0000 | 0x1e00000 | 0x80000000;
    cfg_reg_rmw_tensix<1, 0, config_mask>(config_data);
}

template <DstSync Dst>
inline void _llk_math_wait_for_dest_available_()
{


    math_dest_wait();
}

template <DstSync Dst, bool is_fp32_dest_acc_en>
inline void _llk_math_dest_section_done_()
{
    set_math_semaphores();
    if constexpr (Dst == DstSync::SyncHalf)
    {
        math_sync_tile_dst_index = 0;
        dest_section_flip();
    }
}

template <DstSync Dst, bool is_fp32_dest_acc_en>
inline void _llk_math_pack_sync_init_()
{
    tensix_sync();
    while (semaphore_read(semaphore::MATH_PACK) > 0)
    {
    };
    if constexpr (Dst == DstSync::SyncFull)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa3 << 24) + (((1) << 20) + ((0) << 16) + ((p_stall::SEMAPHORE_1) << 2))))));
        reset_dest_offset_id();
        set_dest_section_base<StartZero>();
    }
    else
    {
        static_assert(Dst == DstSync::SyncHalf);
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa3 << 24) + (((2) << 20) + ((0) << 16) + ((p_stall::SEMAPHORE_1) << 2))))));
        reset_dest_offset_id();
        set_dest_section_base<StartZero>();
    }
}

template <bool mail2math = true, bool mail2pack = true>
inline void _llk_math_get_tile_(std::uint32_t tile_index, std::uint32_t* p_tile)
{
    constexpr uint32_t wait_sem = (mail2math && mail2pack) ? (2) : (1);
    while (semaphore_read(semaphore::UNPACK_OPERAND_SYNC) < wait_sem)
        ;
    if constexpr (mail2math)
    {
        *p_tile = mailbox_read(ThreadId::UnpackThreadId);
    }
    else
    {
        *p_tile = 0x0;
    }
}

template <bool mail2math = true, bool mail2pack = true>
inline void _llk_math_release_tile_()
{
    if constexpr (mail2math)
    {
        semaphore_get(semaphore::UNPACK_OPERAND_SYNC);
    }
}

inline void _llk_math_debug_dump_(std::uint8_t* data, std::uint32_t byte_size)
{
    debug_dump(data, byte_size);
}

inline void _llk_math_debug_dump_seek_(std::uint8_t offset)
{
    debug_dump_seek(offset);
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void _llk_math_reconfig_data_format_srca_(const std::uint32_t srca_data_format)
{
    if constexpr (to_from_int8)
    {
        static_assert(is_fp32_dest_acc_en, "Reconfiguring math to/from Int8 formats requires FP32 Dest mode enabled");
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::MATH | p_stall::WAIT_SFPU) << 0))))));
        uint int8_math_enabled = ((uint)(srca_data_format & 0xF) == (uint)DataFormat::Int8) || ((uint)srca_data_format == (uint)DataFormat::Int32);
        uint config_data = (srca_data_format << 17) | (int8_math_enabled << 31);
        constexpr uint config_mask = 0x1e0000 | 0x80000000;
        cfg_reg_rmw_tensix<1, 0, config_mask>(config_data);
    }
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void _llk_math_reconfig_data_format_srcb_(const std::uint32_t srcb_data_format)
{
    if constexpr (to_from_int8)
    {
        static_assert(is_fp32_dest_acc_en, "Reconfiguring math to/from Int8 formats requires FP32 Dest mode enabled");
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::MATH | p_stall::WAIT_SFPU) << 0))))));
        uint int8_math_enabled = ((uint)(srcb_data_format & 0xF) == (uint)DataFormat::Int8) || ((uint)srcb_data_format == (uint)DataFormat::Int32);
        uint config_data = (srcb_data_format << 21) | (int8_math_enabled << 31);
        constexpr uint config_mask = 0x1e00000 | 0x80000000;
        cfg_reg_rmw_tensix<1, 0, config_mask>(config_data);
    }
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void _llk_math_reconfig_data_format_(const std::uint32_t srca_data_format, const std::uint32_t srcb_data_format)
{
    if constexpr (to_from_int8)
    {
        static_assert(is_fp32_dest_acc_en, "Reconfiguring math to/from Int8 formats requires FP32 Dest mode enabled");
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::MATH | p_stall::WAIT_SFPU) << 0))))));
        uint int8_math_enabled = ((uint)(srca_data_format & 0xF) == (uint)DataFormat::Int8) || ((uint)(srcb_data_format & 0xF) == (uint)DataFormat::Int8) ||
                                 ((uint)srca_data_format == (uint)DataFormat::Int32) || ((uint)srcb_data_format == (uint)DataFormat::Int32);
        uint config_data = (srca_data_format << 17) | (srcb_data_format << 21) |
                           (int8_math_enabled << 31);
        constexpr uint config_mask = 0x1e0000 | 0x1e00000 | 0x80000000;
        cfg_reg_rmw_tensix<1, 0, config_mask>(config_data);
    }
}

inline std::uint32_t _llk_math_get_compute_special_value_flags_()
{
    return reg_read((0xFFB12000 | 0x0B4));
}

inline void _llk_math_clear_compute_special_value_flags_()
{
    reg_write((0xFFB12000 | 0x0B4), 0);
}




       

       


       


       

#pragma GCC visibility push(default)




extern "C++" {

namespace std
{
  class exception
  {
  public:
    exception() noexcept { }
    virtual ~exception() noexcept;

    exception(const exception&) = default;
    exception& operator=(const exception&) = default;
    exception(exception&&) = default;
    exception& operator=(exception&&) = default;




    virtual const char*
    what() const noexcept;
  };



}

}

#pragma GCC visibility pop

#pragma GCC visibility push(default)

extern "C++" {

namespace std
{






  class bad_alloc : public exception
  {
  public:
    bad_alloc() throw() { }


    bad_alloc(const bad_alloc&) = default;
    bad_alloc& operator=(const bad_alloc&) = default;




    virtual ~bad_alloc() throw();


    virtual const char* what() const throw();
  };


  class bad_array_new_length : public bad_alloc
  {
  public:
    bad_array_new_length() throw() { }



    virtual ~bad_array_new_length() throw();


    virtual const char* what() const throw();
  };



  enum class align_val_t: size_t {};


  struct nothrow_t
  {

    explicit nothrow_t() = default;

  };

  extern const nothrow_t nothrow;



  typedef void (*new_handler)();



  new_handler set_new_handler(new_handler) throw();



  new_handler get_new_handler() noexcept;

}
[[__nodiscard__]] void* operator new(std::size_t)
  __attribute__((__externally_visible__));
[[__nodiscard__]] void* operator new[](std::size_t)
  __attribute__((__externally_visible__));
void operator delete(void*) noexcept
  __attribute__((__externally_visible__));
void operator delete[](void*) noexcept
  __attribute__((__externally_visible__));

void operator delete(void*, std::size_t) noexcept
  __attribute__((__externally_visible__));
void operator delete[](void*, std::size_t) noexcept
  __attribute__((__externally_visible__));

[[__nodiscard__]] void* operator new(std::size_t, const std::nothrow_t&) noexcept
  __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
[[__nodiscard__]] void* operator new[](std::size_t, const std::nothrow_t&) noexcept
  __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
void operator delete(void*, const std::nothrow_t&) noexcept
  __attribute__((__externally_visible__));
void operator delete[](void*, const std::nothrow_t&) noexcept
  __attribute__((__externally_visible__));

[[__nodiscard__]] void* operator new(std::size_t, std::align_val_t)
  __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
[[__nodiscard__]] void* operator new(std::size_t, std::align_val_t, const std::nothrow_t&)
  noexcept __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
void operator delete(void*, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
void operator delete(void*, std::align_val_t, const std::nothrow_t&)
  noexcept __attribute__((__externally_visible__));
[[__nodiscard__]] void* operator new[](std::size_t, std::align_val_t)
  __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
[[__nodiscard__]] void* operator new[](std::size_t, std::align_val_t, const std::nothrow_t&)
  noexcept __attribute__((__externally_visible__, __alloc_size__ (1), __malloc__));
void operator delete[](void*, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
void operator delete[](void*, std::align_val_t, const std::nothrow_t&)
  noexcept __attribute__((__externally_visible__));

void operator delete(void*, std::size_t, std::align_val_t)
  noexcept __attribute__((__externally_visible__));
void operator delete[](void*, std::size_t, std::align_val_t)
  noexcept __attribute__((__externally_visible__));




[[__nodiscard__]] inline void* operator new(std::size_t, void* __p) noexcept
{ return __p; }
[[__nodiscard__]] inline void* operator new[](std::size_t, void* __p) noexcept
{ return __p; }


inline void operator delete (void*, void*) noexcept { }
inline void operator delete[](void*, void*) noexcept { }

}


namespace std
{



  template<typename _Tp>
    [[nodiscard]] constexpr _Tp*
    launder(_Tp* __p) noexcept
    { return __builtin_launder(__p); }




  template<typename _Ret, typename... _Args , bool _NE>
    void launder(_Ret (*)(_Args...) noexcept (_NE)) = delete;
  template<typename _Ret, typename... _Args , bool _NE>
    void launder(_Ret (*)(_Args......) noexcept (_NE)) = delete;

  void launder(void*) = delete;
  void launder(const void*) = delete;
  void launder(volatile void*) = delete;
  void launder(const volatile void*) = delete;




  inline constexpr size_t hardware_destructive_interference_size = 32;
  inline constexpr size_t hardware_constructive_interference_size = 32;

}
#pragma GCC visibility pop






namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Tp>
    class __new_allocator
    {
    public:
      typedef _Tp value_type;
      typedef std::size_t size_type;
      typedef std::ptrdiff_t difference_type;

      typedef _Tp* pointer;
      typedef const _Tp* const_pointer;
      typedef _Tp& reference;
      typedef const _Tp& const_reference;

      template<typename _Tp1>
 struct rebind
 { typedef __new_allocator<_Tp1> other; };





      typedef std::true_type propagate_on_container_move_assignment;


     
      __new_allocator() noexcept { }

     
      __new_allocator(const __new_allocator&) noexcept { }

      template<typename _Tp1>

 __new_allocator(const __new_allocator<_Tp1>&) noexcept { }


      __new_allocator& operator=(const __new_allocator&) = default;



      ~__new_allocator() noexcept { }

      pointer
      address(reference __x) const noexcept
      { return std::__addressof(__x); }

      const_pointer
      address(const_reference __x) const noexcept
      { return std::__addressof(__x); }
      [[__nodiscard__]] _Tp*
      allocate(size_type __n, const void* = static_cast<const void*>(0))
      {



 static_assert(sizeof(_Tp) != 0, "cannot allocate incomplete types");


 if (__builtin_expect(__n > this->_M_max_size(), false))
   {


     if (__n > (std::size_t(-1) / sizeof(_Tp)))
       std::__throw_bad_array_new_length();
     std::__throw_bad_alloc();
   }


 if (alignof(_Tp) > 16)
   {
     std::align_val_t __al = std::align_val_t(alignof(_Tp));
     return static_cast<_Tp*>(::operator new(__n * sizeof(_Tp),
          __al));
   }

 return static_cast<_Tp*>(::operator new(__n * sizeof(_Tp)));
      }


      void
      deallocate(_Tp* __p, size_type __n __attribute__ ((__unused__)))
      {







 if (alignof(_Tp) > 16)
   {
     ::operator delete((__p), (__n) * sizeof(_Tp),
         std::align_val_t(alignof(_Tp)));
     return;
   }

 ::operator delete((__p), (__n) * sizeof(_Tp));
      }






      size_type
      max_size() const noexcept
      { return _M_max_size(); }


      template<typename _Up, typename... _Args>
 void
 construct(_Up* __p, _Args&&... __args)
 noexcept(std::is_nothrow_constructible<_Up, _Args...>::value)
 { ::new((void *)__p) _Up(std::forward<_Args>(__args)...); }

      template<typename _Up>
 void
 destroy(_Up* __p)
 noexcept(std::is_nothrow_destructible<_Up>::value)
 { __p->~_Up(); }
      template<typename _Up>
 friend bool
 operator==(const __new_allocator&, const __new_allocator<_Up>&)
 noexcept
 { return true; }


      template<typename _Up>
 friend bool
 operator!=(const __new_allocator&, const __new_allocator<_Up>&)
 noexcept
 { return false; }


    private:
      constexpr size_type
      _M_max_size() const noexcept
      {

 return std::size_t(0x7fffffff) / sizeof(_Tp);



      }
    };


}


namespace std
{
  template<typename _Tp>
    using __allocator_base = __new_allocator<_Tp>;
}
       



namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename>
    class allocator;

  template<>
    class allocator<void>;



  template<typename, typename>
    struct uses_allocator;

  template<typename>
    struct allocator_traits;





}






namespace std __attribute__ ((__visibility__ ("default")))
{

  template<>
    class allocator<void>
    {
    public:
      typedef void value_type;
      typedef size_t size_type;
      typedef ptrdiff_t difference_type;



      typedef void* pointer;
      typedef const void* const_pointer;

      template<typename _Tp1>
 struct rebind
 { typedef allocator<_Tp1> other; };





      using propagate_on_container_move_assignment = true_type;

      using is_always_equal

 = true_type;
    };
  template<typename _Tp>
    class allocator : public __allocator_base<_Tp>
    {
    public:
      typedef _Tp value_type;
      typedef size_t size_type;
      typedef ptrdiff_t difference_type;



      typedef _Tp* pointer;
      typedef const _Tp* const_pointer;
      typedef _Tp& reference;
      typedef const _Tp& const_reference;

      template<typename _Tp1>
 struct rebind
 { typedef allocator<_Tp1> other; };





      using propagate_on_container_move_assignment = true_type;

      using is_always_equal

 = true_type;




     
      allocator() noexcept { }

     
      allocator(const allocator& __a) noexcept
      : __allocator_base<_Tp>(__a) { }



      allocator& operator=(const allocator&) = default;


      template<typename _Tp1>

 allocator(const allocator<_Tp1>&) noexcept { }




      ~allocator() noexcept { }
      friend bool
      operator==(const allocator&, const allocator&) noexcept
      { return true; }


      friend bool
      operator!=(const allocator&, const allocator&) noexcept
      { return false; }



    };






  template<typename _T1, typename _T2>
    inline bool
    operator==(const allocator<_T1>&, const allocator<_T2>&)
    noexcept
    { return true; }


  template<typename _T1, typename _T2>
    inline bool
    operator!=(const allocator<_T1>&, const allocator<_T2>&)
    noexcept
    { return false; }






  template<typename _Tp>
    class allocator<const _Tp>
    {
    public:
      typedef _Tp value_type;
      template<typename _Up> allocator(const allocator<_Up>&) { }
    };

  template<typename _Tp>
    class allocator<volatile _Tp>
    {
    public:
      typedef _Tp value_type;
      template<typename _Up> allocator(const allocator<_Up>&) { }
    };

  template<typename _Tp>
    class allocator<const volatile _Tp>
    {
    public:
      typedef _Tp value_type;
      template<typename _Up> allocator(const allocator<_Up>&) { }
    };






  extern template class allocator<char>;
  extern template class allocator<wchar_t>;






  template<typename _Alloc, bool = __is_empty(_Alloc)>
    struct __alloc_swap
    { static void _S_do_it(_Alloc&, _Alloc&) noexcept { } };

  template<typename _Alloc>
    struct __alloc_swap<_Alloc, false>
    {
      static void
      _S_do_it(_Alloc& __one, _Alloc& __two) noexcept
      {

 if (__one != __two)
   swap(__one, __two);
      }
    };


  template<typename _Alloc, bool = __is_empty(_Alloc)>
    struct __alloc_neq
    {
      static bool
      _S_do_it(const _Alloc&, const _Alloc&)
      { return false; }
    };

  template<typename _Alloc>
    struct __alloc_neq<_Alloc, false>
    {
      static bool
      _S_do_it(const _Alloc& __one, const _Alloc& __two)
      { return __one != __two; }
    };


  template<typename _Tp, bool
    = __or_<is_copy_constructible<typename _Tp::value_type>,
            is_nothrow_move_constructible<typename _Tp::value_type>>::value>
    struct __shrink_to_fit_aux
    { static bool _S_do_it(_Tp&) noexcept { return false; } };

  template<typename _Tp>
    struct __shrink_to_fit_aux<_Tp, true>
    {
     
      static bool
      _S_do_it(_Tp& __c) noexcept
      {
 return false;

      }
    };




}
namespace std __attribute__ ((__visibility__ ("default")))
{



  template <typename _Tp>
    inline void
    destroy_at(_Tp* __location)
    {
      if constexpr (201703L > 201703L && is_array_v<_Tp>)
 {
   for (auto& __x : *__location)
     std::destroy_at(std::__addressof(__x));
 }
      else
 __location->~_Tp();
    }
  template<typename _Tp, typename... _Args>
   
    inline void
    _Construct(_Tp* __p, _Args&&... __args)
    {
      ::new((void*)__p) _Tp(std::forward<_Args>(__args)...);
    }
  template<typename _T1>
    inline void
    _Construct_novalue(_T1* __p)
    { ::new((void*)__p) _T1; }

  template<typename _ForwardIterator>
    void
    _Destroy(_ForwardIterator __first, _ForwardIterator __last);




  template<typename _Tp>
    constexpr inline void
    _Destroy(_Tp* __pointer)
    {



      __pointer->~_Tp();

    }

  template<bool>
    struct _Destroy_aux
    {
      template<typename _ForwardIterator>
 static void
 __destroy(_ForwardIterator __first, _ForwardIterator __last)
 {
   for (; __first != __last; ++__first)
     std::_Destroy(std::__addressof(*__first));
 }
    };

  template<>
    struct _Destroy_aux<true>
    {
      template<typename _ForwardIterator>
        static void
        __destroy(_ForwardIterator, _ForwardIterator) { }
    };






  template<typename _ForwardIterator>
    inline void
    _Destroy(_ForwardIterator __first, _ForwardIterator __last)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
                       _Value_type;


      static_assert(is_destructible<_Value_type>::value,
      "value type is destructible");





      std::_Destroy_aux<__has_trivial_destructor(_Value_type)>::
 __destroy(__first, __last);
    }

  template<bool>
    struct _Destroy_n_aux
    {
      template<typename _ForwardIterator, typename _Size>
 static _ForwardIterator
 __destroy_n(_ForwardIterator __first, _Size __count)
 {
   for (; __count > 0; (void)++__first, --__count)
     std::_Destroy(std::__addressof(*__first));
   return __first;
 }
    };

  template<>
    struct _Destroy_n_aux<true>
    {
      template<typename _ForwardIterator, typename _Size>
        static _ForwardIterator
        __destroy_n(_ForwardIterator __first, _Size __count)
 {
   std::advance(__first, __count);
   return __first;
 }
    };






  template<typename _ForwardIterator, typename _Size>
    inline _ForwardIterator
    _Destroy_n(_ForwardIterator __first, _Size __count)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
                       _Value_type;


      static_assert(is_destructible<_Value_type>::value,
      "value type is destructible");





      return std::_Destroy_n_aux<__has_trivial_destructor(_Value_type)>::
 __destroy_n(__first, __count);
    }


  template <typename _ForwardIterator>
    inline void
    destroy(_ForwardIterator __first, _ForwardIterator __last)
    {
      std::_Destroy(__first, __last);
    }

  template <typename _ForwardIterator, typename _Size>
    inline _ForwardIterator
    destroy_n(_ForwardIterator __first, _Size __count)
    {
      return std::_Destroy_n(__first, __count);
    }



}
       

namespace std __attribute__ ((__visibility__ ("default")))
{






  struct __allocator_traits_base
  {
    template<typename _Tp, typename _Up, typename = void>
      struct __rebind : __replace_first_arg<_Tp, _Up> { };

    template<typename _Tp, typename _Up>
      struct __rebind<_Tp, _Up,
        __void_t<typename _Tp::template rebind<_Up>::other>>
      { using type = typename _Tp::template rebind<_Up>::other; };

  protected:
    template<typename _Tp>
      using __pointer = typename _Tp::pointer;
    template<typename _Tp>
      using __c_pointer = typename _Tp::const_pointer;
    template<typename _Tp>
      using __v_pointer = typename _Tp::void_pointer;
    template<typename _Tp>
      using __cv_pointer = typename _Tp::const_void_pointer;
    template<typename _Tp>
      using __pocca = typename _Tp::propagate_on_container_copy_assignment;
    template<typename _Tp>
      using __pocma = typename _Tp::propagate_on_container_move_assignment;
    template<typename _Tp>
      using __pocs = typename _Tp::propagate_on_container_swap;
    template<typename _Tp>
      using __equal = __type_identity<typename _Tp::is_always_equal>;
  };

  template<typename _Alloc, typename _Up>
    using __alloc_rebind
      = typename __allocator_traits_base::template __rebind<_Alloc, _Up>::type;
  template<typename _Alloc>
    struct allocator_traits : __allocator_traits_base
    {

      typedef _Alloc allocator_type;

      typedef typename _Alloc::value_type value_type;






      using pointer = __detected_or_t<value_type*, __pointer, _Alloc>;

    private:

      template<template<typename> class _Func, typename _Tp, typename = void>
 struct _Ptr
 {
   using type = typename pointer_traits<pointer>::template rebind<_Tp>;
 };

      template<template<typename> class _Func, typename _Tp>
 struct _Ptr<_Func, _Tp, __void_t<_Func<_Alloc>>>
 {
   using type = _Func<_Alloc>;
 };


      template<typename _A2, typename _PtrT, typename = void>
 struct _Diff
 { using type = typename pointer_traits<_PtrT>::difference_type; };

      template<typename _A2, typename _PtrT>
 struct _Diff<_A2, _PtrT, __void_t<typename _A2::difference_type>>
 { using type = typename _A2::difference_type; };


      template<typename _A2, typename _DiffT, typename = void>
 struct _Size : make_unsigned<_DiffT> { };

      template<typename _A2, typename _DiffT>
 struct _Size<_A2, _DiffT, __void_t<typename _A2::size_type>>
 { using type = typename _A2::size_type; };

    public:






      using const_pointer = typename _Ptr<__c_pointer, const value_type>::type;







      using void_pointer = typename _Ptr<__v_pointer, void>::type;







      using const_void_pointer = typename _Ptr<__cv_pointer, const void>::type;







      using difference_type = typename _Diff<_Alloc, pointer>::type;







      using size_type = typename _Size<_Alloc, difference_type>::type;







      using propagate_on_container_copy_assignment
 = __detected_or_t<false_type, __pocca, _Alloc>;







      using propagate_on_container_move_assignment
 = __detected_or_t<false_type, __pocma, _Alloc>;







      using propagate_on_container_swap
 = __detected_or_t<false_type, __pocs, _Alloc>;







      using is_always_equal
 = typename __detected_or_t<is_empty<_Alloc>, __equal, _Alloc>::type;

      template<typename _Tp>
 using rebind_alloc = __alloc_rebind<_Alloc, _Tp>;
      template<typename _Tp>
 using rebind_traits = allocator_traits<rebind_alloc<_Tp>>;

    private:
      template<typename _Alloc2>
 static constexpr auto
 _S_allocate(_Alloc2& __a, size_type __n, const_void_pointer __hint, int)
 -> decltype(__a.allocate(__n, __hint))
 { return __a.allocate(__n, __hint); }

      template<typename _Alloc2>
 static constexpr pointer
 _S_allocate(_Alloc2& __a, size_type __n, const_void_pointer, ...)
 { return __a.allocate(__n); }

      template<typename _Tp, typename... _Args>
 struct __construct_helper
 {
   template<typename _Alloc2,
     typename = decltype(std::declval<_Alloc2*>()->construct(
    std::declval<_Tp*>(), std::declval<_Args>()...))>
     static true_type __test(int);

   template<typename>
     static false_type __test(...);

   using type = decltype(__test<_Alloc>(0));
 };

      template<typename _Tp, typename... _Args>
 using __has_construct
   = typename __construct_helper<_Tp, _Args...>::type;

      template<typename _Tp, typename... _Args>
 static constexpr _Require<__has_construct<_Tp, _Args...>>
 _S_construct(_Alloc& __a, _Tp* __p, _Args&&... __args)
 noexcept(noexcept(__a.construct(__p, std::forward<_Args>(__args)...)))
 { __a.construct(__p, std::forward<_Args>(__args)...); }

      template<typename _Tp, typename... _Args>
 static constexpr
 _Require<__and_<__not_<__has_construct<_Tp, _Args...>>,
          is_constructible<_Tp, _Args...>>>
 _S_construct(_Alloc&, _Tp* __p, _Args&&... __args)
 noexcept(std::is_nothrow_constructible<_Tp, _Args...>::value)
 {

   ::new((void*)__p) _Tp(std::forward<_Args>(__args)...);



 }

      template<typename _Alloc2, typename _Tp>
 static constexpr auto
 _S_destroy(_Alloc2& __a, _Tp* __p, int)
 noexcept(noexcept(__a.destroy(__p)))
 -> decltype(__a.destroy(__p))
 { __a.destroy(__p); }

      template<typename _Alloc2, typename _Tp>
 static constexpr void
 _S_destroy(_Alloc2&, _Tp* __p, ...)
 noexcept(std::is_nothrow_destructible<_Tp>::value)
 { std::_Destroy(__p); }

      template<typename _Alloc2>
 static constexpr auto
 _S_max_size(_Alloc2& __a, int)
 -> decltype(__a.max_size())
 { return __a.max_size(); }

      template<typename _Alloc2>
 static constexpr size_type
 _S_max_size(_Alloc2&, ...)
 {


   return __gnu_cxx::__numeric_traits<size_type>::__max
     / sizeof(value_type);
 }

      template<typename _Alloc2>
 static constexpr auto
 _S_select(_Alloc2& __a, int)
 -> decltype(__a.select_on_container_copy_construction())
 { return __a.select_on_container_copy_construction(); }

      template<typename _Alloc2>
 static constexpr _Alloc2
 _S_select(_Alloc2& __a, ...)
 { return __a; }

    public:
      [[__nodiscard__]] static pointer
      allocate(_Alloc& __a, size_type __n)
      { return __a.allocate(__n); }
      [[__nodiscard__]] static pointer
      allocate(_Alloc& __a, size_type __n, const_void_pointer __hint)
      { return _S_allocate(__a, __n, __hint, 0); }
      static void
      deallocate(_Alloc& __a, pointer __p, size_type __n)
      { __a.deallocate(__p, __n); }
      template<typename _Tp, typename... _Args>
 static auto
 construct(_Alloc& __a, _Tp* __p, _Args&&... __args)
 noexcept(noexcept(_S_construct(__a, __p,
           std::forward<_Args>(__args)...)))
 -> decltype(_S_construct(__a, __p, std::forward<_Args>(__args)...))
 { _S_construct(__a, __p, std::forward<_Args>(__args)...); }
      template<typename _Tp>
 static void
 destroy(_Alloc& __a, _Tp* __p)
 noexcept(noexcept(_S_destroy(__a, __p, 0)))
 { _S_destroy(__a, __p, 0); }
      static size_type
      max_size(const _Alloc& __a) noexcept
      { return _S_max_size(__a, 0); }
      static _Alloc
      select_on_container_copy_construction(const _Alloc& __rhs)
      { return _S_select(__rhs, 0); }
    };






  template<typename _Tp>
    struct allocator_traits<allocator<_Tp>>
    {

      using allocator_type = allocator<_Tp>;


      using value_type = _Tp;


      using pointer = _Tp*;


      using const_pointer = const _Tp*;


      using void_pointer = void*;


      using const_void_pointer = const void*;


      using difference_type = std::ptrdiff_t;


      using size_type = std::size_t;


      using propagate_on_container_copy_assignment = false_type;


      using propagate_on_container_move_assignment = true_type;


      using propagate_on_container_swap = false_type;


      using is_always_equal = true_type;

      template<typename _Up>
 using rebind_alloc = allocator<_Up>;

      template<typename _Up>
 using rebind_traits = allocator_traits<allocator<_Up>>;
      [[__nodiscard__]] static pointer
      allocate(allocator_type& __a, size_type __n)
      { return __a.allocate(__n); }
      [[__nodiscard__]] static pointer
      allocate(allocator_type& __a, size_type __n, const_void_pointer __hint)
      {

 return __a.allocate(__n, __hint);



      }
      static void
      deallocate(allocator_type& __a, pointer __p, size_type __n)
      { __a.deallocate(__p, __n); }
      template<typename _Up, typename... _Args>
 static void
 construct(allocator_type& __a __attribute__((__unused__)), _Up* __p,
    _Args&&... __args)
 noexcept(std::is_nothrow_constructible<_Up, _Args...>::value)
 {

   __a.construct(__p, std::forward<_Args>(__args)...);



 }
      template<typename _Up>
 static void
 destroy(allocator_type& __a __attribute__((__unused__)), _Up* __p)
 noexcept(is_nothrow_destructible<_Up>::value)
 {

   __a.destroy(__p);



 }






      static size_type
      max_size(const allocator_type& __a __attribute__((__unused__))) noexcept
      {

 return __a.max_size();



      }






      static allocator_type
      select_on_container_copy_construction(const allocator_type& __rhs)
      { return __rhs; }
    };


  template<>
    struct allocator_traits<allocator<void>>
    {

      using allocator_type = allocator<void>;


      using value_type = void;


      using pointer = void*;


      using const_pointer = const void*;


      using void_pointer = void*;


      using const_void_pointer = const void*;


      using difference_type = std::ptrdiff_t;


      using size_type = std::size_t;


      using propagate_on_container_copy_assignment = false_type;


      using propagate_on_container_move_assignment = true_type;


      using propagate_on_container_swap = false_type;


      using is_always_equal = true_type;

      template<typename _Up>
 using rebind_alloc = allocator<_Up>;

      template<typename _Up>
 using rebind_traits = allocator_traits<allocator<_Up>>;


      static void*
      allocate(allocator_type&, size_type, const void* = nullptr) = delete;


      static void
      deallocate(allocator_type&, void*, size_type) = delete;
      template<typename _Up, typename... _Args>
 static void
 construct(allocator_type&, _Up* __p, _Args&&... __args)
 noexcept(std::is_nothrow_constructible<_Up, _Args...>::value)
 { std::_Construct(__p, std::forward<_Args>(__args)...); }
      template<typename _Up>
 static void
 destroy(allocator_type&, _Up* __p)
 noexcept(is_nothrow_destructible<_Up>::value)
 { std::_Destroy(__p); }


      static size_type
      max_size(const allocator_type&) = delete;






      static allocator_type
      select_on_container_copy_construction(const allocator_type& __rhs)
      { return __rhs; }
    };
  template<typename _Alloc>
    constexpr inline void
    __alloc_on_copy(_Alloc& __one, const _Alloc& __two)
    {
      typedef allocator_traits<_Alloc> __traits;
      typedef typename __traits::propagate_on_container_copy_assignment __pocca;

      if constexpr (__pocca::value)
 __one = __two;



    }

  template<typename _Alloc>
    constexpr _Alloc
    __alloc_on_copy(const _Alloc& __a)
    {
      typedef allocator_traits<_Alloc> __traits;
      return __traits::select_on_container_copy_construction(__a);
    }
  template<typename _Alloc>
    constexpr inline void
    __alloc_on_move(_Alloc& __one, _Alloc& __two)
    {
      typedef allocator_traits<_Alloc> __traits;
      typedef typename __traits::propagate_on_container_move_assignment __pocma;

      if constexpr (__pocma::value)
 __one = std::move(__two);



    }
  template<typename _Alloc>
    constexpr inline void
    __alloc_on_swap(_Alloc& __one, _Alloc& __two)
    {
      typedef allocator_traits<_Alloc> __traits;
      typedef typename __traits::propagate_on_container_swap __pocs;

      if constexpr (__pocs::value)
 {
   using std::swap;
   swap(__one, __two);
 }



    }

  template<typename _Alloc, typename _Tp,
    typename _ValueT = __remove_cvref_t<typename _Alloc::value_type>,
    typename = void>
    struct __is_alloc_insertable_impl
    : false_type
    { };

  template<typename _Alloc, typename _Tp, typename _ValueT>
    struct __is_alloc_insertable_impl<_Alloc, _Tp, _ValueT,
      __void_t<decltype(allocator_traits<_Alloc>::construct(
     std::declval<_Alloc&>(), std::declval<_ValueT*>(),
     std::declval<_Tp>()))>>
    : true_type
    { };




  template<typename _Alloc>
    struct __is_copy_insertable
    : __is_alloc_insertable_impl<_Alloc,
     typename _Alloc::value_type const&>::type
    { };


  template<typename _Tp>
    struct __is_copy_insertable<allocator<_Tp>>
    : is_copy_constructible<_Tp>
    { };




  template<typename _Alloc>
    struct __is_move_insertable
    : __is_alloc_insertable_impl<_Alloc, typename _Alloc::value_type>::type
    { };


  template<typename _Tp>
    struct __is_move_insertable<allocator<_Tp>>
    : is_move_constructible<_Tp>
    { };


  template<typename _Alloc, typename = void>
    struct __is_allocator : false_type { };

  template<typename _Alloc>
    struct __is_allocator<_Alloc,
      __void_t<typename _Alloc::value_type,
        decltype(std::declval<_Alloc&>().allocate(size_t{}))>>
    : true_type { };

  template<typename _Alloc>
    using _RequireAllocator
      = typename enable_if<__is_allocator<_Alloc>::value, _Alloc>::type;

  template<typename _Alloc>
    using _RequireNotAllocator
      = typename enable_if<!__is_allocator<_Alloc>::value, _Alloc>::type;
  template<typename _ForwardIterator, typename _Allocator>
   
    void
    _Destroy(_ForwardIterator __first, _ForwardIterator __last,
      _Allocator& __alloc)
    {
      for (; __first != __last; ++__first)



 allocator_traits<_Allocator>::destroy(__alloc,
           std::__addressof(*__first));

    }

  template<typename _ForwardIterator, typename _Tp>
   
    inline void
    _Destroy(_ForwardIterator __first, _ForwardIterator __last,
      allocator<_Tp>&)
    {
      std::_Destroy(__first, __last);
    }



}




namespace __gnu_cxx __attribute__ ((__visibility__ ("default")))
{






template<typename _Alloc, typename = typename _Alloc::value_type>
  struct __alloc_traits

  : std::allocator_traits<_Alloc>

  {
    typedef _Alloc allocator_type;

    typedef std::allocator_traits<_Alloc> _Base_type;
    typedef typename _Base_type::value_type value_type;
    typedef typename _Base_type::pointer pointer;
    typedef typename _Base_type::const_pointer const_pointer;
    typedef typename _Base_type::size_type size_type;
    typedef typename _Base_type::difference_type difference_type;

    typedef value_type& reference;
    typedef const value_type& const_reference;
    using _Base_type::allocate;
    using _Base_type::deallocate;
    using _Base_type::construct;
    using _Base_type::destroy;
    using _Base_type::max_size;

  private:
    template<typename _Ptr>
      using __is_custom_pointer
 = std::__and_<std::is_same<pointer, _Ptr>,
        std::__not_<std::is_pointer<_Ptr>>>;

  public:

    template<typename _Ptr, typename... _Args>
      static constexpr
      std::__enable_if_t<__is_custom_pointer<_Ptr>::value>
      construct(_Alloc& __a, _Ptr __p, _Args&&... __args)
      noexcept(noexcept(_Base_type::construct(__a, std::__to_address(__p),
           std::forward<_Args>(__args)...)))
      {
 _Base_type::construct(__a, std::__to_address(__p),
         std::forward<_Args>(__args)...);
      }


    template<typename _Ptr>
      static constexpr
      std::__enable_if_t<__is_custom_pointer<_Ptr>::value>
      destroy(_Alloc& __a, _Ptr __p)
      noexcept(noexcept(_Base_type::destroy(__a, std::__to_address(__p))))
      { _Base_type::destroy(__a, std::__to_address(__p)); }

    static constexpr _Alloc _S_select_on_copy(const _Alloc& __a)
    { return _Base_type::select_on_container_copy_construction(__a); }

    static constexpr void _S_on_swap(_Alloc& __a, _Alloc& __b)
    { std::__alloc_on_swap(__a, __b); }

    static constexpr bool _S_propagate_on_copy_assign()
    { return _Base_type::propagate_on_container_copy_assignment::value; }

    static constexpr bool _S_propagate_on_move_assign()
    { return _Base_type::propagate_on_container_move_assignment::value; }

    static constexpr bool _S_propagate_on_swap()
    { return _Base_type::propagate_on_container_swap::value; }

    static constexpr bool _S_always_equal()
    { return _Base_type::is_always_equal::value; }

    static constexpr bool _S_nothrow_move()
    { return _S_propagate_on_move_assign() || _S_always_equal(); }

    template<typename _Tp>
      struct rebind
      { typedef typename _Base_type::template rebind_alloc<_Tp> other; };
  };


}





namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _ValueType, typename _Tp>
    constexpr bool
    __check_constructible()
    {





      static_assert(is_constructible<_ValueType, _Tp>::value,
   "result type must be constructible from input type");

      return true;
    }
  template<typename _InputIterator, typename _ForwardIterator>
   
    _ForwardIterator
    __do_uninit_copy(_InputIterator __first, _InputIterator __last,
       _ForwardIterator __result)
    {
      _ForwardIterator __cur = __result;
      if (true)
 {
   for (; __first != __last; ++__first, (void)++__cur)
     std::_Construct(std::__addressof(*__cur), *__first);
   return __cur;
 }
      if (false)
 {
   std::_Destroy(__result, __cur);
   ;
 }
    }

  template<bool _TrivialValueTypes>
    struct __uninitialized_copy
    {
      template<typename _InputIterator, typename _ForwardIterator>
        static _ForwardIterator
        __uninit_copy(_InputIterator __first, _InputIterator __last,
        _ForwardIterator __result)
 { return std::__do_uninit_copy(__first, __last, __result); }
    };

  template<>
    struct __uninitialized_copy<true>
    {
      template<typename _InputIterator, typename _ForwardIterator>
        static _ForwardIterator
        __uninit_copy(_InputIterator __first, _InputIterator __last,
        _ForwardIterator __result)
        { return std::copy(__first, __last, __result); }
    };
  template<typename _InputIterator, typename _ForwardIterator>
    inline _ForwardIterator
    uninitialized_copy(_InputIterator __first, _InputIterator __last,
         _ForwardIterator __result)
    {
      typedef typename iterator_traits<_InputIterator>::value_type
 _ValueType1;
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType2;




      const bool __can_memmove = __is_trivial(_ValueType1);




      using _From = decltype(*__first);

      const bool __assignable
 = __is_trivial(_ValueType2) && __is_assignable(_ValueType2&, _From) && std::__check_constructible<_ValueType2, _From>();

      return std::__uninitialized_copy<__can_memmove && __assignable>::
 __uninit_copy(__first, __last, __result);
    }



  template<typename _ForwardIterator, typename _Tp>
    void
    __do_uninit_fill(_ForwardIterator __first, _ForwardIterator __last,
       const _Tp& __x)
    {
      _ForwardIterator __cur = __first;
      if (true)
 {
   for (; __cur != __last; ++__cur)
     std::_Construct(std::__addressof(*__cur), __x);
 }
      if (false)
 {
   std::_Destroy(__first, __cur);
   ;
 }
    }

  template<bool _TrivialValueType>
    struct __uninitialized_fill
    {
      template<typename _ForwardIterator, typename _Tp>
        static void
        __uninit_fill(_ForwardIterator __first, _ForwardIterator __last,
        const _Tp& __x)
 { std::__do_uninit_fill(__first, __last, __x); }
    };

  template<>
    struct __uninitialized_fill<true>
    {
      template<typename _ForwardIterator, typename _Tp>
        static void
        __uninit_fill(_ForwardIterator __first, _ForwardIterator __last,
        const _Tp& __x)
        { std::fill(__first, __last, __x); }
    };
  template<typename _ForwardIterator, typename _Tp>
    inline void
    uninitialized_fill(_ForwardIterator __first, _ForwardIterator __last,
         const _Tp& __x)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;



      const bool __can_fill
 = __is_trivial(_ValueType) && __is_assignable(_ValueType&, const _Tp&) && std::__check_constructible<_ValueType, const _Tp&>();

      std::__uninitialized_fill<__can_fill>::
 __uninit_fill(__first, __last, __x);
    }



  template<typename _ForwardIterator, typename _Size, typename _Tp>
   
    _ForwardIterator
    __do_uninit_fill_n(_ForwardIterator __first, _Size __n, const _Tp& __x)
    {
      _ForwardIterator __cur = __first;
      if (true)
 {
   for (; __n > 0; --__n, (void) ++__cur)
     std::_Construct(std::__addressof(*__cur), __x);
   return __cur;
 }
      if (false)
 {
   std::_Destroy(__first, __cur);
   ;
 }
    }

  template<bool _TrivialValueType>
    struct __uninitialized_fill_n
    {
      template<typename _ForwardIterator, typename _Size, typename _Tp>
 static _ForwardIterator
        __uninit_fill_n(_ForwardIterator __first, _Size __n,
   const _Tp& __x)
 { return std::__do_uninit_fill_n(__first, __n, __x); }
    };

  template<>
    struct __uninitialized_fill_n<true>
    {
      template<typename _ForwardIterator, typename _Size, typename _Tp>
 static _ForwardIterator
        __uninit_fill_n(_ForwardIterator __first, _Size __n,
   const _Tp& __x)
        { return std::fill_n(__first, __n, __x); }
    };
  template<typename _ForwardIterator, typename _Size, typename _Tp>
    inline _ForwardIterator
    uninitialized_fill_n(_ForwardIterator __first, _Size __n, const _Tp& __x)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;



      const bool __can_fill
 = __is_trivial(_ValueType) && __is_assignable(_ValueType&, const _Tp&) && std::__check_constructible<_ValueType, const _Tp&>()



 && __is_integer<_Size>::__value;

      return __uninitialized_fill_n<__can_fill>::
 __uninit_fill_n(__first, __n, __x);
    }
  template<typename _InputIterator, typename _ForwardIterator,
    typename _Allocator>
   
    _ForwardIterator
    __uninitialized_copy_a(_InputIterator __first, _InputIterator __last,
      _ForwardIterator __result, _Allocator& __alloc)
    {
      _ForwardIterator __cur = __result;
      if (true)
 {
   typedef __gnu_cxx::__alloc_traits<_Allocator> __traits;
   for (; __first != __last; ++__first, (void)++__cur)
     __traits::construct(__alloc, std::__addressof(*__cur), *__first);
   return __cur;
 }
      if (false)
 {
   std::_Destroy(__result, __cur, __alloc);
   ;
 }
    }

  template<typename _InputIterator, typename _ForwardIterator, typename _Tp>
   
    inline _ForwardIterator
    __uninitialized_copy_a(_InputIterator __first, _InputIterator __last,
      _ForwardIterator __result, allocator<_Tp>&)
    {




      return std::uninitialized_copy(__first, __last, __result);
    }

  template<typename _InputIterator, typename _ForwardIterator,
    typename _Allocator>
   
    inline _ForwardIterator
    __uninitialized_move_a(_InputIterator __first, _InputIterator __last,
      _ForwardIterator __result, _Allocator& __alloc)
    {
      return std::__uninitialized_copy_a(std::make_move_iterator(__first),
      std::make_move_iterator(__last),
      __result, __alloc);
    }

  template<typename _InputIterator, typename _ForwardIterator,
    typename _Allocator>
   
    inline _ForwardIterator
    __uninitialized_move_if_noexcept_a(_InputIterator __first,
           _InputIterator __last,
           _ForwardIterator __result,
           _Allocator& __alloc)
    {
      return std::__uninitialized_copy_a
 (std::__make_move_if_noexcept_iterator(__first),
  std::__make_move_if_noexcept_iterator(__last), __result, __alloc);
    }

  template<typename _ForwardIterator, typename _Tp, typename _Allocator>
   
    void
    __uninitialized_fill_a(_ForwardIterator __first, _ForwardIterator __last,
      const _Tp& __x, _Allocator& __alloc)
    {
      _ForwardIterator __cur = __first;
      if (true)
 {
   typedef __gnu_cxx::__alloc_traits<_Allocator> __traits;
   for (; __cur != __last; ++__cur)
     __traits::construct(__alloc, std::__addressof(*__cur), __x);
 }
      if (false)
 {
   std::_Destroy(__first, __cur, __alloc);
   ;
 }
    }

  template<typename _ForwardIterator, typename _Tp, typename _Tp2>
   
    inline void
    __uninitialized_fill_a(_ForwardIterator __first, _ForwardIterator __last,
      const _Tp& __x, allocator<_Tp2>&)
    {




      std::uninitialized_fill(__first, __last, __x);
    }

  template<typename _ForwardIterator, typename _Size, typename _Tp,
    typename _Allocator>
    
    _ForwardIterator
    __uninitialized_fill_n_a(_ForwardIterator __first, _Size __n,
        const _Tp& __x, _Allocator& __alloc)
    {
      _ForwardIterator __cur = __first;
      if (true)
 {
   typedef __gnu_cxx::__alloc_traits<_Allocator> __traits;
   for (; __n > 0; --__n, (void) ++__cur)
     __traits::construct(__alloc, std::__addressof(*__cur), __x);
   return __cur;
 }
      if (false)
 {
   std::_Destroy(__first, __cur, __alloc);
   ;
 }
    }

  template<typename _ForwardIterator, typename _Size, typename _Tp,
    typename _Tp2>
   
    inline _ForwardIterator
    __uninitialized_fill_n_a(_ForwardIterator __first, _Size __n,
        const _Tp& __x, allocator<_Tp2>&)
    {




      return std::uninitialized_fill_n(__first, __n, __x);
    }
  template<typename _InputIterator1, typename _InputIterator2,
    typename _ForwardIterator, typename _Allocator>
    inline _ForwardIterator
    __uninitialized_copy_move(_InputIterator1 __first1,
         _InputIterator1 __last1,
         _InputIterator2 __first2,
         _InputIterator2 __last2,
         _ForwardIterator __result,
         _Allocator& __alloc)
    {
      _ForwardIterator __mid = std::__uninitialized_copy_a(__first1, __last1,
          __result,
          __alloc);
      if (true)
 {
   return std::__uninitialized_move_a(__first2, __last2, __mid, __alloc);
 }
      if (false)
 {
   std::_Destroy(__result, __mid, __alloc);
   ;
 }
    }





  template<typename _InputIterator1, typename _InputIterator2,
    typename _ForwardIterator, typename _Allocator>
    inline _ForwardIterator
    __uninitialized_move_copy(_InputIterator1 __first1,
         _InputIterator1 __last1,
         _InputIterator2 __first2,
         _InputIterator2 __last2,
         _ForwardIterator __result,
         _Allocator& __alloc)
    {
      _ForwardIterator __mid = std::__uninitialized_move_a(__first1, __last1,
          __result,
          __alloc);
      if (true)
 {
   return std::__uninitialized_copy_a(__first2, __last2, __mid, __alloc);
 }
      if (false)
 {
   std::_Destroy(__result, __mid, __alloc);
   ;
 }
    }




  template<typename _ForwardIterator, typename _Tp, typename _InputIterator,
    typename _Allocator>
    inline _ForwardIterator
    __uninitialized_fill_move(_ForwardIterator __result, _ForwardIterator __mid,
         const _Tp& __x, _InputIterator __first,
         _InputIterator __last, _Allocator& __alloc)
    {
      std::__uninitialized_fill_a(__result, __mid, __x, __alloc);
      if (true)
 {
   return std::__uninitialized_move_a(__first, __last, __mid, __alloc);
 }
      if (false)
 {
   std::_Destroy(__result, __mid, __alloc);
   ;
 }
    }




  template<typename _InputIterator, typename _ForwardIterator, typename _Tp,
    typename _Allocator>
    inline void
    __uninitialized_move_fill(_InputIterator __first1, _InputIterator __last1,
         _ForwardIterator __first2,
         _ForwardIterator __last2, const _Tp& __x,
         _Allocator& __alloc)
    {
      _ForwardIterator __mid2 = std::__uninitialized_move_a(__first1, __last1,
           __first2,
           __alloc);
      if (true)
 {
   std::__uninitialized_fill_a(__mid2, __last2, __x, __alloc);
 }
      if (false)
 {
   std::_Destroy(__first2, __mid2, __alloc);
   ;
 }
    }
  template<bool _TrivialValueType>
    struct __uninitialized_default_1
    {
      template<typename _ForwardIterator>
        static void
        __uninit_default(_ForwardIterator __first, _ForwardIterator __last)
        {
   _ForwardIterator __cur = __first;
   if (true)
     {
       for (; __cur != __last; ++__cur)
  std::_Construct(std::__addressof(*__cur));
     }
   if (false)
     {
       std::_Destroy(__first, __cur);
       ;
     }
 }
    };

  template<>
    struct __uninitialized_default_1<true>
    {
      template<typename _ForwardIterator>
        static void
        __uninit_default(_ForwardIterator __first, _ForwardIterator __last)
        {
   if (__first == __last)
     return;

   typename iterator_traits<_ForwardIterator>::value_type* __val
     = std::__addressof(*__first);
   std::_Construct(__val);
   if (++__first != __last)
     std::fill(__first, __last, *__val);
 }
    };

  template<bool _TrivialValueType>
    struct __uninitialized_default_n_1
    {
      template<typename _ForwardIterator, typename _Size>

        static _ForwardIterator
        __uninit_default_n(_ForwardIterator __first, _Size __n)
        {
   _ForwardIterator __cur = __first;
   if (true)
     {
       for (; __n > 0; --__n, (void) ++__cur)
  std::_Construct(std::__addressof(*__cur));
       return __cur;
     }
   if (false)
     {
       std::_Destroy(__first, __cur);
       ;
     }
 }
    };

  template<>
    struct __uninitialized_default_n_1<true>
    {
      template<typename _ForwardIterator, typename _Size>

        static _ForwardIterator
        __uninit_default_n(_ForwardIterator __first, _Size __n)
        {
   if (__n > 0)
     {
       typename iterator_traits<_ForwardIterator>::value_type* __val
  = std::__addressof(*__first);
       std::_Construct(__val);
       ++__first;
       __first = std::fill_n(__first, __n - 1, *__val);
     }
   return __first;
 }
    };



  template<typename _ForwardIterator>
    inline void
    __uninitialized_default(_ForwardIterator __first,
       _ForwardIterator __last)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;

      const bool __assignable = is_copy_assignable<_ValueType>::value;

      std::__uninitialized_default_1<__is_trivial(_ValueType)
         && __assignable>::
 __uninit_default(__first, __last);
    }



  template<typename _ForwardIterator, typename _Size>
   
    inline _ForwardIterator
    __uninitialized_default_n(_ForwardIterator __first, _Size __n)
    {






      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;

      constexpr bool __can_fill
 = __and_<is_integral<_Size>, is_copy_assignable<_ValueType>>::value;

      return __uninitialized_default_n_1<__is_trivial(_ValueType)
      && __can_fill>::
 __uninit_default_n(__first, __n);
    }





  template<typename _ForwardIterator, typename _Allocator>
    void
    __uninitialized_default_a(_ForwardIterator __first,
         _ForwardIterator __last,
         _Allocator& __alloc)
    {
      _ForwardIterator __cur = __first;
      if (true)
 {
   typedef __gnu_cxx::__alloc_traits<_Allocator> __traits;
   for (; __cur != __last; ++__cur)
     __traits::construct(__alloc, std::__addressof(*__cur));
 }
      if (false)
 {
   std::_Destroy(__first, __cur, __alloc);
   ;
 }
    }

  template<typename _ForwardIterator, typename _Tp>
    inline void
    __uninitialized_default_a(_ForwardIterator __first,
         _ForwardIterator __last,
         allocator<_Tp>&)
    { std::__uninitialized_default(__first, __last); }





  template<typename _ForwardIterator, typename _Size, typename _Allocator>
    _ForwardIterator
    __uninitialized_default_n_a(_ForwardIterator __first, _Size __n,
    _Allocator& __alloc)
    {
      _ForwardIterator __cur = __first;
      if (true)
 {
   typedef __gnu_cxx::__alloc_traits<_Allocator> __traits;
   for (; __n > 0; --__n, (void) ++__cur)
     __traits::construct(__alloc, std::__addressof(*__cur));
   return __cur;
 }
      if (false)
 {
   std::_Destroy(__first, __cur, __alloc);
   ;
 }
    }



  template<typename _ForwardIterator, typename _Size, typename _Tp>
   
    inline _ForwardIterator
    __uninitialized_default_n_a(_ForwardIterator __first, _Size __n,
    allocator<_Tp>&)
    { return std::__uninitialized_default_n(__first, __n); }

  template<bool _TrivialValueType>
    struct __uninitialized_default_novalue_1
    {
      template<typename _ForwardIterator>
 static void
 __uninit_default_novalue(_ForwardIterator __first,
     _ForwardIterator __last)
 {
   _ForwardIterator __cur = __first;
   if (true)
     {
       for (; __cur != __last; ++__cur)
  std::_Construct_novalue(std::__addressof(*__cur));
     }
   if (false)
     {
       std::_Destroy(__first, __cur);
       ;
     }
 }
    };

  template<>
    struct __uninitialized_default_novalue_1<true>
    {
      template<typename _ForwardIterator>
        static void
        __uninit_default_novalue(_ForwardIterator __first,
     _ForwardIterator __last)
 {
 }
    };

  template<bool _TrivialValueType>
    struct __uninitialized_default_novalue_n_1
    {
      template<typename _ForwardIterator, typename _Size>
 static _ForwardIterator
 __uninit_default_novalue_n(_ForwardIterator __first, _Size __n)
 {
   _ForwardIterator __cur = __first;
   if (true)
     {
       for (; __n > 0; --__n, (void) ++__cur)
  std::_Construct_novalue(std::__addressof(*__cur));
       return __cur;
     }
   if (false)
     {
       std::_Destroy(__first, __cur);
       ;
     }
 }
    };

  template<>
    struct __uninitialized_default_novalue_n_1<true>
    {
      template<typename _ForwardIterator, typename _Size>
 static _ForwardIterator
 __uninit_default_novalue_n(_ForwardIterator __first, _Size __n)
 { return std::next(__first, __n); }
    };



  template<typename _ForwardIterator>
    inline void
    __uninitialized_default_novalue(_ForwardIterator __first,
        _ForwardIterator __last)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;

      std::__uninitialized_default_novalue_1<
 is_trivially_default_constructible<_ValueType>::value>::
 __uninit_default_novalue(__first, __last);
    }



  template<typename _ForwardIterator, typename _Size>
    inline _ForwardIterator
    __uninitialized_default_novalue_n(_ForwardIterator __first, _Size __n)
    {
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType;

      return __uninitialized_default_novalue_n_1<
 is_trivially_default_constructible<_ValueType>::value>::
 __uninit_default_novalue_n(__first, __n);
    }

  template<typename _InputIterator, typename _Size,
    typename _ForwardIterator>
    _ForwardIterator
    __uninitialized_copy_n(_InputIterator __first, _Size __n,
      _ForwardIterator __result, input_iterator_tag)
    {
      _ForwardIterator __cur = __result;
      if (true)
 {
   for (; __n > 0; --__n, (void) ++__first, ++__cur)
     std::_Construct(std::__addressof(*__cur), *__first);
   return __cur;
 }
      if (false)
 {
   std::_Destroy(__result, __cur);
   ;
 }
    }

  template<typename _RandomAccessIterator, typename _Size,
    typename _ForwardIterator>
    inline _ForwardIterator
    __uninitialized_copy_n(_RandomAccessIterator __first, _Size __n,
      _ForwardIterator __result,
      random_access_iterator_tag)
    { return std::uninitialized_copy(__first, __first + __n, __result); }

  template<typename _InputIterator, typename _Size,
    typename _ForwardIterator>
    pair<_InputIterator, _ForwardIterator>
    __uninitialized_copy_n_pair(_InputIterator __first, _Size __n,
      _ForwardIterator __result, input_iterator_tag)
    {
      _ForwardIterator __cur = __result;
      if (true)
 {
   for (; __n > 0; --__n, (void) ++__first, ++__cur)
     std::_Construct(std::__addressof(*__cur), *__first);
   return {__first, __cur};
 }
      if (false)
 {
   std::_Destroy(__result, __cur);
   ;
 }
    }

  template<typename _RandomAccessIterator, typename _Size,
    typename _ForwardIterator>
    inline pair<_RandomAccessIterator, _ForwardIterator>
    __uninitialized_copy_n_pair(_RandomAccessIterator __first, _Size __n,
      _ForwardIterator __result,
      random_access_iterator_tag)
    {
      auto __second_res = uninitialized_copy(__first, __first + __n, __result);
      auto __first_res = std::next(__first, __n);
      return {__first_res, __second_res};
    }
  template<typename _InputIterator, typename _Size, typename _ForwardIterator>
    inline _ForwardIterator
    uninitialized_copy_n(_InputIterator __first, _Size __n,
    _ForwardIterator __result)
    { return std::__uninitialized_copy_n(__first, __n, __result,
      std::__iterator_category(__first)); }


  template<typename _InputIterator, typename _Size, typename _ForwardIterator>
    inline pair<_InputIterator, _ForwardIterator>
    __uninitialized_copy_n_pair(_InputIterator __first, _Size __n,
         _ForwardIterator __result)
    {
      return
 std::__uninitialized_copy_n_pair(__first, __n, __result,
      std::__iterator_category(__first));
    }
  template <typename _ForwardIterator>
    inline void
    uninitialized_default_construct(_ForwardIterator __first,
        _ForwardIterator __last)
    {
      __uninitialized_default_novalue(__first, __last);
    }
  template <typename _ForwardIterator, typename _Size>
    inline _ForwardIterator
    uninitialized_default_construct_n(_ForwardIterator __first, _Size __count)
    {
      return __uninitialized_default_novalue_n(__first, __count);
    }







  template <typename _ForwardIterator>
    inline void
    uninitialized_value_construct(_ForwardIterator __first,
      _ForwardIterator __last)
    {
      return __uninitialized_default(__first, __last);
    }
  template <typename _ForwardIterator, typename _Size>
    inline _ForwardIterator
    uninitialized_value_construct_n(_ForwardIterator __first, _Size __count)
    {
      return __uninitialized_default_n(__first, __count);
    }
  template <typename _InputIterator, typename _ForwardIterator>
    inline _ForwardIterator
    uninitialized_move(_InputIterator __first, _InputIterator __last,
         _ForwardIterator __result)
    {
      return std::uninitialized_copy
 (std::make_move_iterator(__first),
  std::make_move_iterator(__last), __result);
    }
  template <typename _InputIterator, typename _Size, typename _ForwardIterator>
    inline pair<_InputIterator, _ForwardIterator>
    uninitialized_move_n(_InputIterator __first, _Size __count,
    _ForwardIterator __result)
    {
      auto __res = std::__uninitialized_copy_n_pair
 (std::make_move_iterator(__first),
  __count, __result);
      return {__res.first.base(), __res.second};
    }





  template<typename _Tp, typename _Up, typename _Allocator>
   
    inline void
    __relocate_object_a(_Tp* __dest, _Up* __orig,
   _Allocator& __alloc)
    noexcept(noexcept(std::allocator_traits<_Allocator>::construct(__alloc,
    __dest, std::move(*__orig)))
      && noexcept(std::allocator_traits<_Allocator>::destroy(
       __alloc, std::__addressof(*__orig))))
    {
      typedef std::allocator_traits<_Allocator> __traits;
      __traits::construct(__alloc, __dest, std::move(*__orig));
      __traits::destroy(__alloc, std::__addressof(*__orig));
    }



  template<typename _Tp, typename = void>
    struct __is_bitwise_relocatable
    : is_trivial<_Tp> { };

  template <typename _InputIterator, typename _ForwardIterator,
     typename _Allocator>
   
    inline _ForwardIterator
    __relocate_a_1(_InputIterator __first, _InputIterator __last,
     _ForwardIterator __result, _Allocator& __alloc)
    noexcept(noexcept(std::__relocate_object_a(std::addressof(*__result),
            std::addressof(*__first),
            __alloc)))
    {
      typedef typename iterator_traits<_InputIterator>::value_type
 _ValueType;
      typedef typename iterator_traits<_ForwardIterator>::value_type
 _ValueType2;
      static_assert(std::is_same<_ValueType, _ValueType2>::value,
   "relocation is only possible for values of the same type");
      _ForwardIterator __cur = __result;
      for (; __first != __last; ++__first, (void)++__cur)
 std::__relocate_object_a(std::__addressof(*__cur),
     std::__addressof(*__first), __alloc);
      return __cur;
    }

  template <typename _Tp, typename _Up>
   
    inline __enable_if_t<std::__is_bitwise_relocatable<_Tp>::value, _Tp*>
    __relocate_a_1(_Tp* __first, _Tp* __last,
     _Tp* __result,
     [[__maybe_unused__]] allocator<_Up>& __alloc) noexcept
    {
      ptrdiff_t __count = __last - __first;
      if (__count > 0)
 {
   __builtin_memmove(__result, __first, __count * sizeof(_Tp));
 }
      return __result + __count;
    }


  template <typename _InputIterator, typename _ForwardIterator,
     typename _Allocator>
   
    inline _ForwardIterator
    __relocate_a(_InputIterator __first, _InputIterator __last,
   _ForwardIterator __result, _Allocator& __alloc)
    noexcept(noexcept(__relocate_a_1(std::__niter_base(__first),
         std::__niter_base(__last),
         std::__niter_base(__result), __alloc)))
    {
      return std::__relocate_a_1(std::__niter_base(__first),
     std::__niter_base(__last),
     std::__niter_base(__result), __alloc);
    }







}
namespace std __attribute__ ((__visibility__ ("default")))
{




  template<typename _Tp, typename _Alloc>
    struct _Vector_base
    {
      typedef typename __gnu_cxx::__alloc_traits<_Alloc>::template
 rebind<_Tp>::other _Tp_alloc_type;
      typedef typename __gnu_cxx::__alloc_traits<_Tp_alloc_type>::pointer
        pointer;

      struct _Vector_impl_data
      {
 pointer _M_start;
 pointer _M_finish;
 pointer _M_end_of_storage;


 _Vector_impl_data() noexcept
 : _M_start(), _M_finish(), _M_end_of_storage()
 { }



 _Vector_impl_data(_Vector_impl_data&& __x) noexcept
 : _M_start(__x._M_start), _M_finish(__x._M_finish),
   _M_end_of_storage(__x._M_end_of_storage)
 { __x._M_start = __x._M_finish = __x._M_end_of_storage = pointer(); }



 void
 _M_copy_data(_Vector_impl_data const& __x) noexcept
 {
   _M_start = __x._M_start;
   _M_finish = __x._M_finish;
   _M_end_of_storage = __x._M_end_of_storage;
 }


 void
 _M_swap_data(_Vector_impl_data& __x) noexcept
 {


   _Vector_impl_data __tmp;
   __tmp._M_copy_data(*this);
   _M_copy_data(__x);
   __x._M_copy_data(__tmp);
 }
      };

      struct _Vector_impl
 : public _Tp_alloc_type, public _Vector_impl_data
      {

 _Vector_impl() noexcept(is_nothrow_default_constructible<_Tp_alloc_type>::value)

 : _Tp_alloc_type()
 { }


 _Vector_impl(_Tp_alloc_type const& __a) noexcept
 : _Tp_alloc_type(__a)
 { }





 _Vector_impl(_Vector_impl&& __x) noexcept
 : _Tp_alloc_type(std::move(__x)), _Vector_impl_data(std::move(__x))
 { }


 _Vector_impl(_Tp_alloc_type&& __a) noexcept
 : _Tp_alloc_type(std::move(__a))
 { }


 _Vector_impl(_Tp_alloc_type&& __a, _Vector_impl&& __rv) noexcept
 : _Tp_alloc_type(std::move(__a)), _Vector_impl_data(std::move(__rv))
 { }
      };

    public:
      typedef _Alloc allocator_type;

     
      _Tp_alloc_type&
      _M_get_Tp_allocator() noexcept
      { return this->_M_impl; }

     
      const _Tp_alloc_type&
      _M_get_Tp_allocator() const noexcept
      { return this->_M_impl; }

     
      allocator_type
      get_allocator() const noexcept
      { return allocator_type(_M_get_Tp_allocator()); }


      _Vector_base() = default;




     
      _Vector_base(const allocator_type& __a) noexcept
      : _M_impl(__a) { }



     
      _Vector_base(size_t __n)
      : _M_impl()
      { _M_create_storage(__n); }


     
      _Vector_base(size_t __n, const allocator_type& __a)
      : _M_impl(__a)
      { _M_create_storage(__n); }


      _Vector_base(_Vector_base&&) = default;



     
      _Vector_base(_Tp_alloc_type&& __a) noexcept
      : _M_impl(std::move(__a)) { }

     
      _Vector_base(_Vector_base&& __x, const allocator_type& __a)
      : _M_impl(__a)
      {
 if (__x.get_allocator() == __a)
   this->_M_impl._M_swap_data(__x._M_impl);
 else
   {
     size_t __n = __x._M_impl._M_finish - __x._M_impl._M_start;
     _M_create_storage(__n);
   }
      }


     
      _Vector_base(const allocator_type& __a, _Vector_base&& __x)
      : _M_impl(_Tp_alloc_type(__a), std::move(__x._M_impl))
      { }


     
      ~_Vector_base() noexcept
      {
 _M_deallocate(_M_impl._M_start,
        _M_impl._M_end_of_storage - _M_impl._M_start);
      }

    public:
      _Vector_impl _M_impl;

     
      pointer
      _M_allocate(size_t __n)
      {
 typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type> _Tr;
 return __n != 0 ? _Tr::allocate(_M_impl, __n) : pointer();
      }

     
      void
      _M_deallocate(pointer __p, size_t __n)
      {
 typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type> _Tr;
 if (__p)
   _Tr::deallocate(_M_impl, __p, __n);
      }

    protected:
     
      void
      _M_create_storage(size_t __n)
      {
 this->_M_impl._M_start = this->_M_allocate(__n);
 this->_M_impl._M_finish = this->_M_impl._M_start;
 this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __n;
      }
    };
  template<typename _Tp, typename _Alloc = std::allocator<_Tp> >
    class vector : protected _Vector_base<_Tp, _Alloc>
    {
      static_assert(is_same<typename remove_cv<_Tp>::type, _Tp>::value,
   "std::vector must have a non-const, non-volatile value_type");

      static_assert(is_same<typename _Alloc::value_type, _Tp>::value,
   "std::vector must have the same value_type as its allocator");



      typedef _Vector_base<_Tp, _Alloc> _Base;
      typedef typename _Base::_Tp_alloc_type _Tp_alloc_type;
      typedef __gnu_cxx::__alloc_traits<_Tp_alloc_type> _Alloc_traits;

    public:
      typedef _Tp value_type;
      typedef typename _Base::pointer pointer;
      typedef typename _Alloc_traits::const_pointer const_pointer;
      typedef typename _Alloc_traits::reference reference;
      typedef typename _Alloc_traits::const_reference const_reference;
      typedef __gnu_cxx::__normal_iterator<pointer, vector> iterator;
      typedef __gnu_cxx::__normal_iterator<const_pointer, vector>
      const_iterator;
      typedef std::reverse_iterator<const_iterator> const_reverse_iterator;
      typedef std::reverse_iterator<iterator> reverse_iterator;
      typedef size_t size_type;
      typedef ptrdiff_t difference_type;
      typedef _Alloc allocator_type;

    private:

      static constexpr bool
      _S_nothrow_relocate(true_type)
      {
 return noexcept(std::__relocate_a(std::declval<pointer>(),
       std::declval<pointer>(),
       std::declval<pointer>(),
       std::declval<_Tp_alloc_type&>()));
      }

      static constexpr bool
      _S_nothrow_relocate(false_type)
      { return false; }

      static constexpr bool
      _S_use_relocate()
      {



 return _S_nothrow_relocate(__is_move_insertable<_Tp_alloc_type>{});
      }

      static pointer
      _S_do_relocate(pointer __first, pointer __last, pointer __result,
       _Tp_alloc_type& __alloc, true_type) noexcept
      {
 return std::__relocate_a(__first, __last, __result, __alloc);
      }

      static pointer
      _S_do_relocate(pointer, pointer, pointer __result,
       _Tp_alloc_type&, false_type) noexcept
      { return __result; }

      static pointer
      _S_relocate(pointer __first, pointer __last, pointer __result,
    _Tp_alloc_type& __alloc) noexcept
      {


 return std::__relocate_a(__first, __last, __result, __alloc);




      }


    protected:
      using _Base::_M_allocate;
      using _Base::_M_deallocate;
      using _Base::_M_impl;
      using _Base::_M_get_Tp_allocator;

    public:







      vector() = default;
      explicit
     
      vector(const allocator_type& __a) noexcept
      : _Base(__a) { }
      explicit
     
      vector(size_type __n, const allocator_type& __a = allocator_type())
      : _Base(_S_check_init_len(__n, __a), __a)
      { _M_default_initialize(__n); }
     
      vector(size_type __n, const value_type& __value,
      const allocator_type& __a = allocator_type())
      : _Base(_S_check_init_len(__n, __a), __a)
      { _M_fill_initialize(__n, __value); }
     
      vector(const vector& __x)
      : _Base(__x.size(),
 _Alloc_traits::_S_select_on_copy(__x._M_get_Tp_allocator()))
      {
 this->_M_impl._M_finish =
   std::__uninitialized_copy_a(__x.begin(), __x.end(),
          this->_M_impl._M_start,
          _M_get_Tp_allocator());
      }
      vector(vector&&) noexcept = default;


     
      vector(const vector& __x, const __type_identity_t<allocator_type>& __a)
      : _Base(__x.size(), __a)
      {
 this->_M_impl._M_finish =
   std::__uninitialized_copy_a(__x.begin(), __x.end(),
          this->_M_impl._M_start,
          _M_get_Tp_allocator());
      }

    private:
     
      vector(vector&& __rv, const allocator_type& __m, true_type) noexcept
      : _Base(__m, std::move(__rv))
      { }

     
      vector(vector&& __rv, const allocator_type& __m, false_type)
      : _Base(__m)
      {
 if (__rv.get_allocator() == __m)
   this->_M_impl._M_swap_data(__rv._M_impl);
 else if (!__rv.empty())
   {
     this->_M_create_storage(__rv.size());
     this->_M_impl._M_finish =
       std::__uninitialized_move_a(__rv.begin(), __rv.end(),
       this->_M_impl._M_start,
       _M_get_Tp_allocator());
     __rv.clear();
   }
      }

    public:

     
      vector(vector&& __rv, const __type_identity_t<allocator_type>& __m)
      noexcept( noexcept(
 vector(std::declval<vector&&>(), std::declval<const allocator_type&>(),
        std::declval<typename _Alloc_traits::is_always_equal>())) )
      : vector(std::move(__rv), __m, typename _Alloc_traits::is_always_equal{})
      { }
     
      vector(initializer_list<value_type> __l,
      const allocator_type& __a = allocator_type())
      : _Base(__a)
      {
 _M_range_initialize(__l.begin(), __l.end(),
       random_access_iterator_tag());
      }
      template<typename _InputIterator,
        typename = std::_RequireInputIter<_InputIterator>>

 vector(_InputIterator __first, _InputIterator __last,
        const allocator_type& __a = allocator_type())
 : _Base(__a)
 {
   _M_range_initialize(__first, __last,
         std::__iterator_category(__first));
 }
     
      ~vector() noexcept
      {
 std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
        _M_get_Tp_allocator());
 ;
      }
     
      vector&
      operator=(const vector& __x);
     
      vector&
      operator=(vector&& __x) noexcept(_Alloc_traits::_S_nothrow_move())
      {
 constexpr bool __move_storage =
   _Alloc_traits::_S_propagate_on_move_assign()
   || _Alloc_traits::_S_always_equal();
 _M_move_assign(std::move(__x), __bool_constant<__move_storage>());
 return *this;
      }
     
      vector&
      operator=(initializer_list<value_type> __l)
      {
 this->_M_assign_aux(__l.begin(), __l.end(),
       random_access_iterator_tag());
 return *this;
      }
     
      void
      assign(size_type __n, const value_type& __val)
      { _M_fill_assign(__n, __val); }
      template<typename _InputIterator,
        typename = std::_RequireInputIter<_InputIterator>>

 void
 assign(_InputIterator __first, _InputIterator __last)
 { _M_assign_dispatch(__first, __last, __false_type()); }
     
      void
      assign(initializer_list<value_type> __l)
      {
 this->_M_assign_aux(__l.begin(), __l.end(),
       random_access_iterator_tag());
      }



      using _Base::get_allocator;







      [[__nodiscard__]]
      iterator
      begin() noexcept
      { return iterator(this->_M_impl._M_start); }






      [[__nodiscard__]]
      const_iterator
      begin() const noexcept
      { return const_iterator(this->_M_impl._M_start); }






      [[__nodiscard__]]
      iterator
      end() noexcept
      { return iterator(this->_M_impl._M_finish); }






      [[__nodiscard__]]
      const_iterator
      end() const noexcept
      { return const_iterator(this->_M_impl._M_finish); }






      [[__nodiscard__]]
      reverse_iterator
      rbegin() noexcept
      { return reverse_iterator(end()); }






      [[__nodiscard__]]
      const_reverse_iterator
      rbegin() const noexcept
      { return const_reverse_iterator(end()); }






      [[__nodiscard__]]
      reverse_iterator
      rend() noexcept
      { return reverse_iterator(begin()); }






      [[__nodiscard__]]
      const_reverse_iterator
      rend() const noexcept
      { return const_reverse_iterator(begin()); }







      [[__nodiscard__]]
      const_iterator
      cbegin() const noexcept
      { return const_iterator(this->_M_impl._M_start); }






      [[__nodiscard__]]
      const_iterator
      cend() const noexcept
      { return const_iterator(this->_M_impl._M_finish); }






      [[__nodiscard__]]
      const_reverse_iterator
      crbegin() const noexcept
      { return const_reverse_iterator(end()); }






      [[__nodiscard__]]
      const_reverse_iterator
      crend() const noexcept
      { return const_reverse_iterator(begin()); }




      [[__nodiscard__]]
      size_type
      size() const noexcept
      { return size_type(this->_M_impl._M_finish - this->_M_impl._M_start); }


      [[__nodiscard__]]
      size_type
      max_size() const noexcept
      { return _S_max_size(_M_get_Tp_allocator()); }
     
      void
      resize(size_type __new_size)
      {
 if (__new_size > size())
   _M_default_append(__new_size - size());
 else if (__new_size < size())
   _M_erase_at_end(this->_M_impl._M_start + __new_size);
      }
     
      void
      resize(size_type __new_size, const value_type& __x)
      {
 if (__new_size > size())
   _M_fill_insert(end(), __new_size - size(), __x);
 else if (__new_size < size())
   _M_erase_at_end(this->_M_impl._M_start + __new_size);
      }
     
      void
      shrink_to_fit()
      { _M_shrink_to_fit(); }






      [[__nodiscard__]]
      size_type
      capacity() const noexcept
      { return size_type(this->_M_impl._M_end_of_storage
    - this->_M_impl._M_start); }





      [[__nodiscard__]]
      bool
      empty() const noexcept
      { return begin() == end(); }
     
      void
      reserve(size_type __n);
      [[__nodiscard__]]
      reference
      operator[](size_type __n) noexcept
      {
 ;
 return *(this->_M_impl._M_start + __n);
      }
      [[__nodiscard__]]
      const_reference
      operator[](size_type __n) const noexcept
      {
 ;
 return *(this->_M_impl._M_start + __n);
      }

    protected:

     
      void
      _M_range_check(size_type __n) const
      {
 if (__n >= this->size())
   __throw_out_of_range_fmt(("vector::_M_range_check: __n " "(which is %zu) >= this->size() " "(which is %zu)")

                            ,
       __n, this->size());
      }

    public:
     
      reference
      at(size_type __n)
      {
 _M_range_check(__n);
 return (*this)[__n];
      }
     
      const_reference
      at(size_type __n) const
      {
 _M_range_check(__n);
 return (*this)[__n];
      }





      [[__nodiscard__]]
      reference
      front() noexcept
      {
 ;
 return *begin();
      }





      [[__nodiscard__]]
      const_reference
      front() const noexcept
      {
 ;
 return *begin();
      }





      [[__nodiscard__]]
      reference
      back() noexcept
      {
 ;
 return *(end() - 1);
      }





      [[__nodiscard__]]
      const_reference
      back() const noexcept
      {
 ;
 return *(end() - 1);
      }
      [[__nodiscard__]]
      _Tp*
      data() noexcept
      { return _M_data_ptr(this->_M_impl._M_start); }

      [[__nodiscard__]]
      const _Tp*
      data() const noexcept
      { return _M_data_ptr(this->_M_impl._M_start); }
     
      void
      push_back(const value_type& __x)
      {
 if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
   {
     ;
     _Alloc_traits::construct(this->_M_impl, this->_M_impl._M_finish,
         __x);
     ++this->_M_impl._M_finish;
     ;
   }
 else
   _M_realloc_insert(end(), __x);
      }


     
      void
      push_back(value_type&& __x)
      { emplace_back(std::move(__x)); }

      template<typename... _Args>


 reference



 emplace_back(_Args&&... __args);
     
      void
      pop_back() noexcept
      {
 ;
 --this->_M_impl._M_finish;
 _Alloc_traits::destroy(this->_M_impl, this->_M_impl._M_finish);
 ;
      }
      template<typename... _Args>

 iterator
 emplace(const_iterator __position, _Args&&... __args)
 { return _M_emplace_aux(__position, std::forward<_Args>(__args)...); }
     
      iterator
      insert(const_iterator __position, const value_type& __x);
     
      iterator
      insert(const_iterator __position, value_type&& __x)
      { return _M_insert_rval(__position, std::move(__x)); }
     
      iterator
      insert(const_iterator __position, initializer_list<value_type> __l)
      {
 auto __offset = __position - cbegin();
 _M_range_insert(begin() + __offset, __l.begin(), __l.end(),
   std::random_access_iterator_tag());
 return begin() + __offset;
      }
     
      iterator
      insert(const_iterator __position, size_type __n, const value_type& __x)
      {
 difference_type __offset = __position - cbegin();
 _M_fill_insert(begin() + __offset, __n, __x);
 return begin() + __offset;
      }
      template<typename _InputIterator,
        typename = std::_RequireInputIter<_InputIterator>>

 iterator
 insert(const_iterator __position, _InputIterator __first,
        _InputIterator __last)
 {
   difference_type __offset = __position - cbegin();
   _M_insert_dispatch(begin() + __offset,
        __first, __last, __false_type());
   return begin() + __offset;
 }
     
      iterator

      erase(const_iterator __position)
      { return _M_erase(begin() + (__position - cbegin())); }
     
      iterator

      erase(const_iterator __first, const_iterator __last)
      {
 const auto __beg = begin();
 const auto __cbeg = cbegin();
 return _M_erase(__beg + (__first - __cbeg), __beg + (__last - __cbeg));
      }
     
      void
      swap(vector& __x) noexcept
      {

 do { if (std::__is_constant_evaluated() && !bool(_Alloc_traits::propagate_on_container_swap::value || _M_get_Tp_allocator() == __x._M_get_Tp_allocator())) __builtin_unreachable(); } while (false)
                                                          ;

 this->_M_impl._M_swap_data(__x._M_impl);
 _Alloc_traits::_S_on_swap(_M_get_Tp_allocator(),
      __x._M_get_Tp_allocator());
      }







     
      void
      clear() noexcept
      { _M_erase_at_end(this->_M_impl._M_start); }

    protected:




      template<typename _ForwardIterator>

 pointer
 _M_allocate_and_copy(size_type __n,
        _ForwardIterator __first, _ForwardIterator __last)
 {
   pointer __result = this->_M_allocate(__n);
   if (true)
     {
       std::__uninitialized_copy_a(__first, __last, __result,
       _M_get_Tp_allocator());
       return __result;
     }
   if (false)
     {
       _M_deallocate(__result, __n);
       ;
     }
 }
      template<typename _InputIterator>

 void
 _M_range_initialize(_InputIterator __first, _InputIterator __last,
       std::input_iterator_tag)
 {
   if (true) {
     for (; __first != __last; ++__first)

       emplace_back(*__first);



   } if (false) {
     clear();
     ;
   }
 }


      template<typename _ForwardIterator>

 void
 _M_range_initialize(_ForwardIterator __first, _ForwardIterator __last,
       std::forward_iterator_tag)
 {
   const size_type __n = std::distance(__first, __last);
   this->_M_impl._M_start
     = this->_M_allocate(_S_check_init_len(__n, _M_get_Tp_allocator()));
   this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __n;
   this->_M_impl._M_finish =
     std::__uninitialized_copy_a(__first, __last,
     this->_M_impl._M_start,
     _M_get_Tp_allocator());
 }



     
      void
      _M_fill_initialize(size_type __n, const value_type& __value)
      {
 this->_M_impl._M_finish =
   std::__uninitialized_fill_n_a(this->_M_impl._M_start, __n, __value,
     _M_get_Tp_allocator());
      }



     
      void
      _M_default_initialize(size_type __n)
      {
 this->_M_impl._M_finish =
   std::__uninitialized_default_n_a(this->_M_impl._M_start, __n,
        _M_get_Tp_allocator());
      }
      template<typename _Integer>

 void
 _M_assign_dispatch(_Integer __n, _Integer __val, __true_type)
 { _M_fill_assign(__n, __val); }


      template<typename _InputIterator>

 void
 _M_assign_dispatch(_InputIterator __first, _InputIterator __last,
      __false_type)
 { _M_assign_aux(__first, __last, std::__iterator_category(__first)); }


      template<typename _InputIterator>

 void
 _M_assign_aux(_InputIterator __first, _InputIterator __last,
        std::input_iterator_tag);


      template<typename _ForwardIterator>

 void
 _M_assign_aux(_ForwardIterator __first, _ForwardIterator __last,
        std::forward_iterator_tag);



     
      void
      _M_fill_assign(size_type __n, const value_type& __val);







      template<typename _Integer>

 void
 _M_insert_dispatch(iterator __pos, _Integer __n, _Integer __val,
      __true_type)
 { _M_fill_insert(__pos, __n, __val); }


      template<typename _InputIterator>

 void
 _M_insert_dispatch(iterator __pos, _InputIterator __first,
      _InputIterator __last, __false_type)
 {
   _M_range_insert(__pos, __first, __last,
     std::__iterator_category(__first));
 }


      template<typename _InputIterator>

 void
 _M_range_insert(iterator __pos, _InputIterator __first,
   _InputIterator __last, std::input_iterator_tag);


      template<typename _ForwardIterator>

 void
 _M_range_insert(iterator __pos, _ForwardIterator __first,
   _ForwardIterator __last, std::forward_iterator_tag);



     
      void
      _M_fill_insert(iterator __pos, size_type __n, const value_type& __x);



     
      void
      _M_default_append(size_type __n);

     
      bool
      _M_shrink_to_fit();
      struct _Temporary_value
      {
 template<typename... _Args>
   explicit
   _Temporary_value(vector* __vec, _Args&&... __args) : _M_this(__vec)
   {
     _Alloc_traits::construct(_M_this->_M_impl, _M_ptr(),
         std::forward<_Args>(__args)...);
   }


 ~_Temporary_value()
 { _Alloc_traits::destroy(_M_this->_M_impl, _M_ptr()); }

 value_type&
 _M_val() noexcept { return _M_storage._M_val; }

      private:
 _Tp*
 _M_ptr() noexcept { return std::__addressof(_M_storage._M_val); }

 union _Storage
 {
   constexpr _Storage() : _M_byte() { }
   ~_Storage() { }
   _Storage& operator=(const _Storage&) = delete;
   unsigned char _M_byte;
   _Tp _M_val;
 };

 vector* _M_this;
 _Storage _M_storage;
      };



      template<typename _Arg>

 void
 _M_insert_aux(iterator __position, _Arg&& __arg);

      template<typename... _Args>

 void
 _M_realloc_insert(iterator __position, _Args&&... __args);


     
      iterator
      _M_insert_rval(const_iterator __position, value_type&& __v);


      template<typename... _Args>

 iterator
 _M_emplace_aux(const_iterator __position, _Args&&... __args);


     
      iterator
      _M_emplace_aux(const_iterator __position, value_type&& __v)
      { return _M_insert_rval(__position, std::move(__v)); }



     
      size_type
      _M_check_len(size_type __n, const char* __s) const
      {
 if (max_size() - size() < __n)
   __throw_length_error((__s));

 const size_type __len = size() + (std::max)(size(), __n);
 return (__len < size() || __len > max_size()) ? max_size() : __len;
      }


      static size_type
      _S_check_init_len(size_type __n, const allocator_type& __a)
      {
 if (__n > _S_max_size(_Tp_alloc_type(__a)))
   __throw_length_error(
       ("cannot create std::vector larger than max_size()"));
 return __n;
      }

      static size_type
      _S_max_size(const _Tp_alloc_type& __a) noexcept
      {



 const size_t __diffmax
   = __gnu_cxx::__numeric_traits<ptrdiff_t>::__max / sizeof(_Tp);
 const size_t __allocmax = _Alloc_traits::max_size(__a);
 return (std::min)(__diffmax, __allocmax);
      }





     
      void
      _M_erase_at_end(pointer __pos) noexcept
      {
 if (size_type __n = this->_M_impl._M_finish - __pos)
   {
     std::_Destroy(__pos, this->_M_impl._M_finish,
     _M_get_Tp_allocator());
     this->_M_impl._M_finish = __pos;
     ;
   }
      }

     
      iterator
      _M_erase(iterator __position);

     
      iterator
      _M_erase(iterator __first, iterator __last);


    private:



     
      void
      _M_move_assign(vector&& __x, true_type) noexcept
      {
 vector __tmp(get_allocator());
 this->_M_impl._M_swap_data(__x._M_impl);
 __tmp._M_impl._M_swap_data(__x._M_impl);
 std::__alloc_on_move(_M_get_Tp_allocator(), __x._M_get_Tp_allocator());
      }



     
      void
      _M_move_assign(vector&& __x, false_type)
      {
 if (__x._M_get_Tp_allocator() == this->_M_get_Tp_allocator())
   _M_move_assign(std::move(__x), true_type());
 else
   {


     this->_M_assign_aux(std::make_move_iterator(__x.begin()),
           std::make_move_iterator(__x.end()),
    std::random_access_iterator_tag());
     __x.clear();
   }
      }


      template<typename _Up>

 _Up*
 _M_data_ptr(_Up* __ptr) const noexcept
 { return __ptr; }


      template<typename _Ptr>

 typename std::pointer_traits<_Ptr>::element_type*
 _M_data_ptr(_Ptr __ptr) const
 { return empty() ? nullptr : std::__to_address(__ptr); }
    };


  template<typename _InputIterator, typename _ValT
      = typename iterator_traits<_InputIterator>::value_type,
    typename _Allocator = allocator<_ValT>,
    typename = _RequireInputIter<_InputIterator>,
    typename = _RequireAllocator<_Allocator>>
    vector(_InputIterator, _InputIterator, _Allocator = _Allocator())
      -> vector<_ValT, _Allocator>;
  template<typename _Tp, typename _Alloc>
   
    inline bool
    operator==(const vector<_Tp, _Alloc>& __x, const vector<_Tp, _Alloc>& __y)
    { return (__x.size() == __y.size()
       && std::equal(__x.begin(), __x.end(), __y.begin())); }
  template<typename _Tp, typename _Alloc>
    inline bool
    operator<(const vector<_Tp, _Alloc>& __x, const vector<_Tp, _Alloc>& __y)
    { return std::lexicographical_compare(__x.begin(), __x.end(),
       __y.begin(), __y.end()); }


  template<typename _Tp, typename _Alloc>
    inline bool
    operator!=(const vector<_Tp, _Alloc>& __x, const vector<_Tp, _Alloc>& __y)
    { return !(__x == __y); }


  template<typename _Tp, typename _Alloc>
    inline bool
    operator>(const vector<_Tp, _Alloc>& __x, const vector<_Tp, _Alloc>& __y)
    { return __y < __x; }


  template<typename _Tp, typename _Alloc>
    inline bool
    operator<=(const vector<_Tp, _Alloc>& __x, const vector<_Tp, _Alloc>& __y)
    { return !(__y < __x); }


  template<typename _Tp, typename _Alloc>
    inline bool
    operator>=(const vector<_Tp, _Alloc>& __x, const vector<_Tp, _Alloc>& __y)
    { return !(__x < __y); }



  template<typename _Tp, typename _Alloc>
   
    inline void
    swap(vector<_Tp, _Alloc>& __x, vector<_Tp, _Alloc>& __y)
    noexcept(noexcept(__x.swap(__y)))
    { __x.swap(__y); }




  namespace __detail::__variant
  {
    template<typename> struct _Never_valueless_alt;



    template<typename _Tp, typename _Alloc>
      struct _Never_valueless_alt<std::vector<_Tp, _Alloc>>
      : std::is_nothrow_move_assignable<std::vector<_Tp, _Alloc>>
      { };
  }



}
       


       



namespace std
{







  size_t
  _Hash_bytes(const void* __ptr, size_t __len, size_t __seed);





  size_t
  _Fnv_hash_bytes(const void* __ptr, size_t __len, size_t __seed);


}

namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Result, typename _Arg>
    struct __hash_base
    {
      typedef _Result result_type [[__deprecated__]];
      typedef _Arg argument_type [[__deprecated__]];
    };


  template<typename _Tp>
    struct hash;

  template<typename _Tp, typename = void>
    struct __poison_hash
    {
      static constexpr bool __enable_hash_call = false;
    private:

      __poison_hash(__poison_hash&&);
      ~__poison_hash();
    };

  template<typename _Tp>
    struct __poison_hash<_Tp, __void_t<decltype(hash<_Tp>()(declval<_Tp>()))>>
    {
      static constexpr bool __enable_hash_call = true;
    };


  template<typename _Tp, bool = is_enum<_Tp>::value>
    struct __hash_enum
    {
    private:

      __hash_enum(__hash_enum&&);
      ~__hash_enum();
    };


  template<typename _Tp>
    struct __hash_enum<_Tp, true> : public __hash_base<size_t, _Tp>
    {
      size_t
      operator()(_Tp __val) const noexcept
      {
       using __type = typename underlying_type<_Tp>::type;
       return hash<__type>{}(static_cast<__type>(__val));
      }
    };



  template<typename _Tp>
    struct hash : __hash_enum<_Tp>
    { };


  template<typename _Tp>
    struct hash<_Tp*> : public __hash_base<size_t, _Tp*>
    {
      size_t
      operator()(_Tp* __p) const noexcept
      { return reinterpret_cast<size_t>(__p); }
    };
  template<> struct hash<bool> : public __hash_base<size_t, bool> { size_t operator()(bool __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<char> : public __hash_base<size_t, char> { size_t operator()(char __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<signed char> : public __hash_base<size_t, signed char> { size_t operator()(signed char __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned char> : public __hash_base<size_t, unsigned char> { size_t operator()(unsigned char __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<wchar_t> : public __hash_base<size_t, wchar_t> { size_t operator()(wchar_t __val) const noexcept { return static_cast<size_t>(__val); } };







  template<> struct hash<char16_t> : public __hash_base<size_t, char16_t> { size_t operator()(char16_t __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<char32_t> : public __hash_base<size_t, char32_t> { size_t operator()(char32_t __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<short> : public __hash_base<size_t, short> { size_t operator()(short __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<int> : public __hash_base<size_t, int> { size_t operator()(int __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<long> : public __hash_base<size_t, long> { size_t operator()(long __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<long long> : public __hash_base<size_t, long long> { size_t operator()(long long __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned short> : public __hash_base<size_t, unsigned short> { size_t operator()(unsigned short __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned int> : public __hash_base<size_t, unsigned int> { size_t operator()(unsigned int __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned long> : public __hash_base<size_t, unsigned long> { size_t operator()(unsigned long __val) const noexcept { return static_cast<size_t>(__val); } };


  template<> struct hash<unsigned long long> : public __hash_base<size_t, unsigned long long> { size_t operator()(unsigned long long __val) const noexcept { return static_cast<size_t>(__val); } };
  struct _Hash_impl
  {
    static size_t
    hash(const void* __ptr, size_t __clength,
  size_t __seed = static_cast<size_t>(0xc70f6907UL))
    { return _Hash_bytes(__ptr, __clength, __seed); }

    template<typename _Tp>
      static size_t
      hash(const _Tp& __val)
      { return hash(&__val, sizeof(__val)); }

    template<typename _Tp>
      static size_t
      __hash_combine(const _Tp& __val, size_t __hash)
      { return hash(&__val, sizeof(__val), __hash); }
  };


  struct _Fnv_hash_impl
  {
    static size_t
    hash(const void* __ptr, size_t __clength,
  size_t __seed = static_cast<size_t>(2166136261UL))
    { return _Fnv_hash_bytes(__ptr, __clength, __seed); }

    template<typename _Tp>
      static size_t
      hash(const _Tp& __val)
      { return hash(&__val, sizeof(__val)); }

    template<typename _Tp>
      static size_t
      __hash_combine(const _Tp& __val, size_t __hash)
      { return hash(&__val, sizeof(__val), __hash); }
  };


  template<>
    struct hash<float> : public __hash_base<size_t, float>
    {
      size_t
      operator()(float __val) const noexcept
      {

 return __val != 0.0f ? std::_Hash_impl::hash(__val) : 0;
      }
    };


  template<>
    struct hash<double> : public __hash_base<size_t, double>
    {
      size_t
      operator()(double __val) const noexcept
      {

 return __val != 0.0 ? std::_Hash_impl::hash(__val) : 0;
      }
    };


  template<>
    struct hash<long double>
    : public __hash_base<size_t, long double>
    {
      __attribute__ ((__pure__)) size_t
      operator()(long double __val) const noexcept;
    };


  template<>
    struct hash<nullptr_t> : public __hash_base<size_t, nullptr_t>
    {
      size_t
      operator()(nullptr_t) const noexcept
      { return 0; }
    };
  template<typename _Hash>
    struct __is_fast_hash : public std::true_type
    { };

  template<>
    struct __is_fast_hash<hash<long double>> : public std::false_type
    { };


}


namespace std __attribute__ ((__visibility__ ("default")))
{


  typedef unsigned long _Bit_type;
  enum { _S_word_bit = int(8 * sizeof(_Bit_type)) };

  __attribute__((__nonnull__))
 
  void
  __fill_bvector_n(_Bit_type*, size_t, bool) noexcept;



  struct _Bit_reference
  {
    _Bit_type * _M_p;
    _Bit_type _M_mask;

   
    _Bit_reference(_Bit_type * __x, _Bit_type __y)
    : _M_p(__x), _M_mask(__y) { }

   
    _Bit_reference() noexcept : _M_p(0), _M_mask(0) { }


    _Bit_reference(const _Bit_reference&) = default;


    [[__nodiscard__]]
    operator bool() const noexcept
    { return !!(*_M_p & _M_mask); }

   
    _Bit_reference&
    operator=(bool __x) noexcept
    {
      if (__x)
 *_M_p |= _M_mask;
      else
 *_M_p &= ~_M_mask;
      return *this;
    }

   
    _Bit_reference&
    operator=(const _Bit_reference& __x) noexcept
    { return *this = bool(__x); }

    [[__nodiscard__]]
    bool
    operator==(const _Bit_reference& __x) const
    { return bool(*this) == bool(__x); }

    [[__nodiscard__]]
    bool
    operator<(const _Bit_reference& __x) const
    { return !bool(*this) && bool(__x); }

   
    void
    flip() noexcept
    { *_M_p ^= _M_mask; }


   
    friend void
    swap(_Bit_reference __x, _Bit_reference __y) noexcept
    {
      bool __tmp = __x;
      __x = __y;
      __y = __tmp;
    }

   
    friend void
    swap(_Bit_reference __x, bool& __y) noexcept
    {
      bool __tmp = __x;
      __x = __y;
      __y = __tmp;
    }

   
    friend void
    swap(bool& __x, _Bit_reference __y) noexcept
    {
      bool __tmp = __x;
      __x = __y;
      __y = __tmp;
    }

  };


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
  struct _Bit_iterator_base
  : public std::iterator<std::random_access_iterator_tag, bool>
  {
    _Bit_type * _M_p;
    unsigned int _M_offset;

   
    _Bit_iterator_base(_Bit_type * __x, unsigned int __y)
    : _M_p(__x), _M_offset(__y) { }

   
    void
    _M_bump_up()
    {
      if (_M_offset++ == int(_S_word_bit) - 1)
 {
   _M_offset = 0;
   ++_M_p;
 }
    }

   
    void
    _M_bump_down()
    {
      if (_M_offset-- == 0)
 {
   _M_offset = int(_S_word_bit) - 1;
   --_M_p;
 }
    }

   
    void
    _M_incr(ptrdiff_t __i)
    {
      difference_type __n = __i + _M_offset;
      _M_p += __n / int(_S_word_bit);
      __n = __n % int(_S_word_bit);
      if (__n < 0)
 {
   __n += int(_S_word_bit);
   --_M_p;
 }
      _M_offset = static_cast<unsigned int>(__n);
    }

    [[__nodiscard__]]
    friend bool
    operator==(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    { return __x._M_p == __y._M_p && __x._M_offset == __y._M_offset; }
    [[__nodiscard__]]
    friend bool
    operator<(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    {
      return __x._M_p < __y._M_p
     || (__x._M_p == __y._M_p && __x._M_offset < __y._M_offset);
    }

    [[__nodiscard__]]
    friend bool
    operator!=(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    { return !(__x == __y); }

    [[__nodiscard__]]
    friend bool
    operator>(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    { return __y < __x; }

    [[__nodiscard__]]
    friend bool
    operator<=(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    { return !(__y < __x); }

    [[__nodiscard__]]
    friend bool
    operator>=(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    { return !(__x < __y); }


    friend ptrdiff_t
    operator-(const _Bit_iterator_base& __x, const _Bit_iterator_base& __y)
    {
      return (int(_S_word_bit) * (__x._M_p - __y._M_p)
       + __x._M_offset - __y._M_offset);
    }
  };
#pragma GCC diagnostic pop

  struct _Bit_iterator : public _Bit_iterator_base
  {
    typedef _Bit_reference reference;



    typedef _Bit_reference* pointer;

    typedef _Bit_iterator iterator;

   
    _Bit_iterator() : _Bit_iterator_base(0, 0) { }

   
    _Bit_iterator(_Bit_type * __x, unsigned int __y)
    : _Bit_iterator_base(__x, __y) { }

   
    iterator
    _M_const_cast() const
    { return *this; }

    [[__nodiscard__]]
    reference
    operator*() const
    { return reference(_M_p, 1UL << _M_offset); }

   
    iterator&
    operator++()
    {
      _M_bump_up();
      return *this;
    }

   
    iterator
    operator++(int)
    {
      iterator __tmp = *this;
      _M_bump_up();
      return __tmp;
    }

   
    iterator&
    operator--()
    {
      _M_bump_down();
      return *this;
    }

   
    iterator
    operator--(int)
    {
      iterator __tmp = *this;
      _M_bump_down();
      return __tmp;
    }

   
    iterator&
    operator+=(difference_type __i)
    {
      _M_incr(__i);
      return *this;
    }

   
    iterator&
    operator-=(difference_type __i)
    {
      *this += -__i;
      return *this;
    }

    [[__nodiscard__]]
    reference
    operator[](difference_type __i) const
    { return *(*this + __i); }

    [[__nodiscard__]]
    friend iterator
    operator+(const iterator& __x, difference_type __n)
    {
      iterator __tmp = __x;
      __tmp += __n;
      return __tmp;
    }

    [[__nodiscard__]]
    friend iterator
    operator+(difference_type __n, const iterator& __x)
    { return __x + __n; }

    [[__nodiscard__]]
    friend iterator
    operator-(const iterator& __x, difference_type __n)
    {
      iterator __tmp = __x;
      __tmp -= __n;
      return __tmp;
    }
  };

  struct _Bit_const_iterator : public _Bit_iterator_base
  {
    typedef bool reference;
    typedef bool const_reference;



    typedef const bool* pointer;

    typedef _Bit_const_iterator const_iterator;

   
    _Bit_const_iterator() : _Bit_iterator_base(0, 0) { }

   
    _Bit_const_iterator(_Bit_type * __x, unsigned int __y)
    : _Bit_iterator_base(__x, __y) { }

   
    _Bit_const_iterator(const _Bit_iterator& __x)
    : _Bit_iterator_base(__x._M_p, __x._M_offset) { }

   
    _Bit_iterator
    _M_const_cast() const
    { return _Bit_iterator(_M_p, _M_offset); }

    [[__nodiscard__]]
    const_reference
    operator*() const
    { return _Bit_reference(_M_p, 1UL << _M_offset); }

   
    const_iterator&
    operator++()
    {
      _M_bump_up();
      return *this;
    }

   
    const_iterator
    operator++(int)
    {
      const_iterator __tmp = *this;
      _M_bump_up();
      return __tmp;
    }

   
    const_iterator&
    operator--()
    {
      _M_bump_down();
      return *this;
    }

   
    const_iterator
    operator--(int)
    {
      const_iterator __tmp = *this;
      _M_bump_down();
      return __tmp;
    }

   
    const_iterator&
    operator+=(difference_type __i)
    {
      _M_incr(__i);
      return *this;
    }

   
    const_iterator&
    operator-=(difference_type __i)
    {
      *this += -__i;
      return *this;
    }

    [[__nodiscard__]]
    const_reference
    operator[](difference_type __i) const
    { return *(*this + __i); }

    [[__nodiscard__]]
    friend const_iterator
    operator+(const const_iterator& __x, difference_type __n)
    {
      const_iterator __tmp = __x;
      __tmp += __n;
      return __tmp;
    }

    [[__nodiscard__]]
    friend const_iterator
    operator-(const const_iterator& __x, difference_type __n)
    {
      const_iterator __tmp = __x;
      __tmp -= __n;
      return __tmp;
    }

    [[__nodiscard__]]
    friend const_iterator
    operator+(difference_type __n, const const_iterator& __x)
    { return __x + __n; }
  };

  template<typename _Alloc>
    struct _Bvector_base
    {
      typedef typename __gnu_cxx::__alloc_traits<_Alloc>::template
        rebind<_Bit_type>::other _Bit_alloc_type;
      typedef typename __gnu_cxx::__alloc_traits<_Bit_alloc_type>
 _Bit_alloc_traits;
      typedef typename _Bit_alloc_traits::pointer _Bit_pointer;

      struct _Bvector_impl_data
      {

 _Bit_iterator _M_start;
 _Bit_iterator _M_finish;
 _Bit_pointer _M_end_of_storage;


 _Bvector_impl_data() noexcept
 : _M_start(), _M_finish(), _M_end_of_storage()
 { }


 _Bvector_impl_data(const _Bvector_impl_data&) = default;

 _Bvector_impl_data&
 operator=(const _Bvector_impl_data&) = default;


 _Bvector_impl_data(_Bvector_impl_data&& __x) noexcept
 : _Bvector_impl_data(__x)
 { __x._M_reset(); }


 void
 _M_move_data(_Bvector_impl_data&& __x) noexcept
 {
   *this = __x;
   __x._M_reset();
 }



 void
 _M_reset() noexcept
 { *this = _Bvector_impl_data(); }


 void
 _M_swap_data(_Bvector_impl_data& __x) noexcept
 {


   std::swap(*this, __x);
 }
      };

      struct _Bvector_impl
 : public _Bit_alloc_type, public _Bvector_impl_data
      {

 _Bvector_impl() noexcept(is_nothrow_default_constructible<_Bit_alloc_type>::value)

 : _Bit_alloc_type()
 { }


 _Bvector_impl(const _Bit_alloc_type& __a) noexcept
 : _Bit_alloc_type(__a)
 { }





 _Bvector_impl(_Bvector_impl&& __x) noexcept
 : _Bit_alloc_type(std::move(__x)), _Bvector_impl_data(std::move(__x))
 { }


 _Bvector_impl(_Bit_alloc_type&& __a, _Bvector_impl&& __x) noexcept
 : _Bit_alloc_type(std::move(__a)), _Bvector_impl_data(std::move(__x))
 { }



 _Bit_type*
 _M_end_addr() const noexcept
 {
   if (this->_M_end_of_storage)
     return std::__addressof(this->_M_end_of_storage[-1]) + 1;
   return 0;
 }
      };

    public:
      typedef _Alloc allocator_type;

     
      _Bit_alloc_type&
      _M_get_Bit_allocator() noexcept
      { return this->_M_impl; }

     
      const _Bit_alloc_type&
      _M_get_Bit_allocator() const noexcept
      { return this->_M_impl; }

     
      allocator_type
      get_allocator() const noexcept
      { return allocator_type(_M_get_Bit_allocator()); }


      _Bvector_base() = default;




     
      _Bvector_base(const allocator_type& __a)
      : _M_impl(__a) { }


      _Bvector_base(_Bvector_base&&) = default;

     
      _Bvector_base(_Bvector_base&& __x, const allocator_type& __a) noexcept
      : _M_impl(_Bit_alloc_type(__a), std::move(__x._M_impl))
      { }


     
      ~_Bvector_base()
      { this->_M_deallocate(); }

    protected:
      _Bvector_impl _M_impl;

     
      _Bit_pointer
      _M_allocate(size_t __n)
      {
 _Bit_pointer __p = _Bit_alloc_traits::allocate(_M_impl, _S_nword(__n));
 return __p;
      }

     
      void
      _M_deallocate()
      {
 if (_M_impl._M_start._M_p)
   {
     const size_t __n = _M_impl._M_end_addr() - _M_impl._M_start._M_p;
     _Bit_alloc_traits::deallocate(_M_impl,
       _M_impl._M_end_of_storage - __n,
       __n);
     _M_impl._M_reset();
   }
      }


     
      void
      _M_move_data(_Bvector_base&& __x) noexcept
      { _M_impl._M_move_data(std::move(__x._M_impl)); }


      constexpr
      static size_t
      _S_nword(size_t __n)
      { return (__n + int(_S_word_bit) - 1) / int(_S_word_bit); }
    };
  template<typename _Alloc>
    class vector<bool, _Alloc> : protected _Bvector_base<_Alloc>
    {
      typedef _Bvector_base<_Alloc> _Base;
      typedef typename _Base::_Bit_pointer _Bit_pointer;
      typedef typename _Base::_Bit_alloc_traits _Bit_alloc_traits;


      friend struct std::hash<vector>;


    public:
      typedef bool value_type;
      typedef size_t size_type;
      typedef ptrdiff_t difference_type;
      typedef _Bit_reference reference;
      typedef bool const_reference;
      typedef _Bit_reference* pointer;
      typedef const bool* const_pointer;
      typedef _Bit_iterator iterator;
      typedef _Bit_const_iterator const_iterator;
      typedef std::reverse_iterator<const_iterator> const_reverse_iterator;
      typedef std::reverse_iterator<iterator> reverse_iterator;
      typedef _Alloc allocator_type;

     
      allocator_type
      get_allocator() const
      { return _Base::get_allocator(); }

    protected:
      using _Base::_M_allocate;
      using _Base::_M_deallocate;
      using _Base::_S_nword;
      using _Base::_M_get_Bit_allocator;

    public:

      vector() = default;




     
      explicit
      vector(const allocator_type& __a)
      : _Base(__a) { }


     
      explicit
      vector(size_type __n, const allocator_type& __a = allocator_type())
      : vector(__n, false, __a)
      { }

     
      vector(size_type __n, const bool& __value,
      const allocator_type& __a = allocator_type())





      : _Base(__a)
      {
 _M_initialize(__n);
 _M_initialize_value(__value);
      }

     
      vector(const vector& __x)
      : _Base(_Bit_alloc_traits::_S_select_on_copy(__x._M_get_Bit_allocator()))
      {
 _M_initialize(__x.size());
 _M_copy_aligned(__x.begin(), __x.end(), begin());
      }


      vector(vector&&) = default;

    private:
     
      vector(vector&& __x, const allocator_type& __a, true_type) noexcept
      : _Base(std::move(__x), __a)
      { }

     
      vector(vector&& __x, const allocator_type& __a, false_type)
      : _Base(__a)
      {
 if (__x.get_allocator() == __a)
   this->_M_move_data(std::move(__x));
 else
   {
     _M_initialize(__x.size());
     _M_copy_aligned(__x.begin(), __x.end(), begin());
     __x.clear();
   }
      }

    public:
     
      vector(vector&& __x, const __type_identity_t<allocator_type>& __a)
      noexcept(_Bit_alloc_traits::_S_always_equal())
      : vector(std::move(__x), __a,
        typename _Bit_alloc_traits::is_always_equal{})
      { }

     
      vector(const vector& __x, const __type_identity_t<allocator_type>& __a)
      : _Base(__a)
      {
 _M_initialize(__x.size());
 _M_copy_aligned(__x.begin(), __x.end(), begin());
      }

     
      vector(initializer_list<bool> __l,
      const allocator_type& __a = allocator_type())
      : _Base(__a)
      {
 _M_initialize_range(__l.begin(), __l.end(),
       random_access_iterator_tag());
      }



      template<typename _InputIterator,
        typename = std::_RequireInputIter<_InputIterator>>

 vector(_InputIterator __first, _InputIterator __last,
        const allocator_type& __a = allocator_type())
 : _Base(__a)
 {
   _M_initialize_range(__first, __last,
         std::__iterator_category(__first));
 }
     
      ~vector() noexcept { }

     
      vector&
      operator=(const vector& __x)
      {
 if (&__x == this)
   return *this;

 if (_Bit_alloc_traits::_S_propagate_on_copy_assign())
   {
     if (this->_M_get_Bit_allocator() != __x._M_get_Bit_allocator())
       {
  this->_M_deallocate();
  std::__alloc_on_copy(_M_get_Bit_allocator(),
         __x._M_get_Bit_allocator());
  _M_initialize(__x.size());
       }
     else
       std::__alloc_on_copy(_M_get_Bit_allocator(),
       __x._M_get_Bit_allocator());
   }

 if (__x.size() > capacity())
   {
     this->_M_deallocate();
     _M_initialize(__x.size());
   }
 this->_M_impl._M_finish = _M_copy_aligned(__x.begin(), __x.end(),
        begin());
 return *this;
      }


     
      vector&
      operator=(vector&& __x) noexcept(_Bit_alloc_traits::_S_nothrow_move())
      {
 if (_Bit_alloc_traits::_S_propagate_on_move_assign()
     || this->_M_get_Bit_allocator() == __x._M_get_Bit_allocator())
   {
     this->_M_deallocate();
     this->_M_move_data(std::move(__x));
     std::__alloc_on_move(_M_get_Bit_allocator(),
     __x._M_get_Bit_allocator());
   }
 else
   {
     if (__x.size() > capacity())
       {
  this->_M_deallocate();
  _M_initialize(__x.size());
       }
     this->_M_impl._M_finish = _M_copy_aligned(__x.begin(), __x.end(),
            begin());
     __x.clear();
   }
 return *this;
      }

     
      vector&
      operator=(initializer_list<bool> __l)
      {
 this->assign(__l.begin(), __l.end());
 return *this;
      }






     
      void
      assign(size_type __n, const bool& __x)
      { _M_fill_assign(__n, __x); }


      template<typename _InputIterator,
        typename = std::_RequireInputIter<_InputIterator>>

 void
 assign(_InputIterator __first, _InputIterator __last)
 { _M_assign_aux(__first, __last, std::__iterator_category(__first)); }
     
      void
      assign(initializer_list<bool> __l)
      { _M_assign_aux(__l.begin(), __l.end(), random_access_iterator_tag()); }


      [[__nodiscard__]]
      iterator
      begin() noexcept
      { return iterator(this->_M_impl._M_start._M_p, 0); }

      [[__nodiscard__]]
      const_iterator
      begin() const noexcept
      { return const_iterator(this->_M_impl._M_start._M_p, 0); }

      [[__nodiscard__]]
      iterator
      end() noexcept
      { return this->_M_impl._M_finish; }

      [[__nodiscard__]]
      const_iterator
      end() const noexcept
      { return this->_M_impl._M_finish; }

      [[__nodiscard__]]
      reverse_iterator
      rbegin() noexcept
      { return reverse_iterator(end()); }

      [[__nodiscard__]]
      const_reverse_iterator
      rbegin() const noexcept
      { return const_reverse_iterator(end()); }

      [[__nodiscard__]]
      reverse_iterator
      rend() noexcept
      { return reverse_iterator(begin()); }

      [[__nodiscard__]]
      const_reverse_iterator
      rend() const noexcept
      { return const_reverse_iterator(begin()); }


      [[__nodiscard__]]
      const_iterator
      cbegin() const noexcept
      { return const_iterator(this->_M_impl._M_start._M_p, 0); }

      [[__nodiscard__]]
      const_iterator
      cend() const noexcept
      { return this->_M_impl._M_finish; }

      [[__nodiscard__]]
      const_reverse_iterator
      crbegin() const noexcept
      { return const_reverse_iterator(end()); }

      [[__nodiscard__]]
      const_reverse_iterator
      crend() const noexcept
      { return const_reverse_iterator(begin()); }


      [[__nodiscard__]]
      size_type
      size() const noexcept
      { return size_type(end() - begin()); }

      [[__nodiscard__]]
      size_type
      max_size() const noexcept
      {
 const size_type __isize =
   __gnu_cxx::__numeric_traits<difference_type>::__max
   - int(_S_word_bit) + 1;
 const size_type __asize
   = _Bit_alloc_traits::max_size(_M_get_Bit_allocator());
 return (__asize <= __isize / int(_S_word_bit)
  ? __asize * int(_S_word_bit) : __isize);
      }

      [[__nodiscard__]]
      size_type
      capacity() const noexcept
      { return size_type(const_iterator(this->_M_impl._M_end_addr(), 0)
    - begin()); }

      [[__nodiscard__]]
      bool
      empty() const noexcept
      { return begin() == end(); }

      [[__nodiscard__]]
      reference
      operator[](size_type __n)
      { return begin()[__n]; }

      [[__nodiscard__]]
      const_reference
      operator[](size_type __n) const
      { return begin()[__n]; }

    protected:
     
      void
      _M_range_check(size_type __n) const
      {
 if (__n >= this->size())
   __throw_out_of_range_fmt(("vector<bool>::_M_range_check: __n " "(which is %zu) >= this->size() " "(which is %zu)")

                            ,
       __n, this->size());
      }

    public:
     
      reference
      at(size_type __n)
      {
 _M_range_check(__n);
 return (*this)[__n];
      }

     
      const_reference
      at(size_type __n) const
      {
 _M_range_check(__n);
 return (*this)[__n];
      }

     
      void
      reserve(size_type __n)
      {
 if (__n > max_size())
   __throw_length_error(("vector::reserve"));
 if (capacity() < __n)
   _M_reallocate(__n);
      }

      [[__nodiscard__]]
      reference
      front()
      { return *begin(); }

      [[__nodiscard__]]
      const_reference
      front() const
      { return *begin(); }

      [[__nodiscard__]]
      reference
      back()
      { return *(end() - 1); }

      [[__nodiscard__]]
      const_reference
      back() const
      { return *(end() - 1); }

     
      void
      push_back(bool __x)
      {
 if (this->_M_impl._M_finish._M_p != this->_M_impl._M_end_addr())
   *this->_M_impl._M_finish++ = __x;
 else
   _M_insert_aux(end(), __x);
      }

     
      void
      swap(vector& __x) noexcept
      {

 do { if (std::__is_constant_evaluated() && !bool(_Bit_alloc_traits::propagate_on_container_swap::value || _M_get_Bit_allocator() == __x._M_get_Bit_allocator())) __builtin_unreachable(); } while (false)
                                                            ;

 this->_M_impl._M_swap_data(__x._M_impl);
 _Bit_alloc_traits::_S_on_swap(_M_get_Bit_allocator(),
          __x._M_get_Bit_allocator());
      }


     
      static void
      swap(reference __x, reference __y) noexcept
      {
 bool __tmp = __x;
 __x = __y;
 __y = __tmp;
      }

     
      iterator

      insert(const_iterator __position, const bool& __x)



      {
 const difference_type __n = __position - begin();
 if (this->_M_impl._M_finish._M_p != this->_M_impl._M_end_addr()
     && __position == end())
   *this->_M_impl._M_finish++ = __x;
 else
   _M_insert_aux(__position._M_const_cast(), __x);
 return begin() + __n;
      }


      __attribute__ ((__deprecated__ ("use '" "insert(position, false)" "' instead")))
      iterator
      insert(const_iterator __position)
      { return this->insert(__position._M_const_cast(), false); }



      template<typename _InputIterator,
        typename = std::_RequireInputIter<_InputIterator>>

 iterator
 insert(const_iterator __position,
        _InputIterator __first, _InputIterator __last)
 {
   difference_type __offset = __position - cbegin();
   _M_insert_range(__position._M_const_cast(),
     __first, __last,
     std::__iterator_category(__first));
   return begin() + __offset;
 }
     
      iterator
      insert(const_iterator __position, size_type __n, const bool& __x)
      {
 difference_type __offset = __position - cbegin();
 _M_fill_insert(__position._M_const_cast(), __n, __x);
 return begin() + __offset;
      }







     
      iterator
      insert(const_iterator __p, initializer_list<bool> __l)
      { return this->insert(__p, __l.begin(), __l.end()); }


     
      void
      pop_back()
      { --this->_M_impl._M_finish; }

     
      iterator

      erase(const_iterator __position)



      { return _M_erase(__position._M_const_cast()); }

     
      iterator

      erase(const_iterator __first, const_iterator __last)



      { return _M_erase(__first._M_const_cast(), __last._M_const_cast()); }

     
      void
      resize(size_type __new_size, bool __x = bool())
      {
 if (__new_size < size())
   _M_erase_at_end(begin() + difference_type(__new_size));
 else
   insert(end(), __new_size - size(), __x);
      }


     
      void
      shrink_to_fit()
      { _M_shrink_to_fit(); }


     
      void
      flip() noexcept
      {
 _Bit_type * const __end = this->_M_impl._M_end_addr();
 for (_Bit_type * __p = this->_M_impl._M_start._M_p; __p != __end; ++__p)
   *__p = ~*__p;
      }

     
      void
      clear() noexcept
      { _M_erase_at_end(begin()); }


      template<typename... _Args>


 reference



 emplace_back(_Args&&... __args)
 {
   push_back(bool(__args...));

   return back();

 }

      template<typename... _Args>

 iterator
 emplace(const_iterator __pos, _Args&&... __args)
 { return insert(__pos, bool(__args...)); }


    protected:

     
      iterator
      _M_copy_aligned(const_iterator __first, const_iterator __last,
        iterator __result)
      {
 _Bit_type* __q = std::copy(__first._M_p, __last._M_p, __result._M_p);
 return std::copy(const_iterator(__last._M_p, 0), __last,
    iterator(__q, 0));
      }

     
      void
      _M_initialize(size_type __n)
      {
 if (__n)
   {
     _Bit_pointer __q = this->_M_allocate(__n);
     this->_M_impl._M_end_of_storage = __q + _S_nword(__n);
     iterator __start = iterator(std::__addressof(*__q), 0);
     this->_M_impl._M_start = __start;
     this->_M_impl._M_finish = __start + difference_type(__n);
   }
      }

     
      void
      _M_initialize_value(bool __x) noexcept
      {
 if (_Bit_type* __p = this->_M_impl._M_start._M_p)
   __fill_bvector_n(__p, this->_M_impl._M_end_addr() - __p, __x);
      }

     
      void
      _M_reallocate(size_type __n);


     
      bool
      _M_shrink_to_fit();
      template<typename _InputIterator>

 void
 _M_initialize_range(_InputIterator __first, _InputIterator __last,
       std::input_iterator_tag)
 {
   for (; __first != __last; ++__first)
     push_back(*__first);
 }

      template<typename _ForwardIterator>

 void
 _M_initialize_range(_ForwardIterator __first, _ForwardIterator __last,
       std::forward_iterator_tag)
 {
   const size_type __n = std::distance(__first, __last);
   _M_initialize(__n);
   std::copy(__first, __last, begin());
 }
     
      void
      _M_fill_assign(size_t __n, bool __x)
      {
 if (__n > size())
   {
     _M_initialize_value(__x);
     insert(end(), __n - size(), __x);
   }
 else
   {
     _M_erase_at_end(begin() + __n);
     _M_initialize_value(__x);
   }
      }

      template<typename _InputIterator>

 void
 _M_assign_aux(_InputIterator __first, _InputIterator __last,
        std::input_iterator_tag)
 {
   iterator __cur = begin();
   for (; __first != __last && __cur != end(); ++__cur, (void)++__first)
     *__cur = *__first;
   if (__first == __last)
     _M_erase_at_end(__cur);
   else
     insert(end(), __first, __last);
 }

      template<typename _ForwardIterator>

 void
 _M_assign_aux(_ForwardIterator __first, _ForwardIterator __last,
        std::forward_iterator_tag)
 {
   const size_type __len = std::distance(__first, __last);
   if (__len < size())
     _M_erase_at_end(std::copy(__first, __last, begin()));
   else
     {
       _ForwardIterator __mid = __first;
       std::advance(__mid, size());
       std::copy(__first, __mid, begin());
       insert(end(), __mid, __last);
     }
 }
     
      void
      _M_fill_insert(iterator __position, size_type __n, bool __x);

      template<typename _InputIterator>

 void
 _M_insert_range(iterator __pos, _InputIterator __first,
   _InputIterator __last, std::input_iterator_tag)
 {
   for (; __first != __last; ++__first)
     {
       __pos = insert(__pos, *__first);
       ++__pos;
     }
 }

      template<typename _ForwardIterator>

 void
 _M_insert_range(iterator __position, _ForwardIterator __first,
   _ForwardIterator __last, std::forward_iterator_tag);

     
      void
      _M_insert_aux(iterator __position, bool __x);

     
      size_type
      _M_check_len(size_type __n, const char* __s) const
      {
 if (max_size() - size() < __n)
   __throw_length_error((__s));

 const size_type __len = size() + std::max(size(), __n);
 return (__len < size() || __len > max_size()) ? max_size() : __len;
      }

     
      void
      _M_erase_at_end(iterator __pos)
      { this->_M_impl._M_finish = __pos; }

     
      iterator
      _M_erase(iterator __pos);

     
      iterator
      _M_erase(iterator __first, iterator __last);

    protected:






      void data() = delete;



    };




 
  inline void
  __fill_bvector(_Bit_type* __v, unsigned int __first, unsigned int __last,
   bool __x) noexcept
  {
    const _Bit_type __fmask = ~0ul << __first;
    const _Bit_type __lmask = ~0ul >> (_S_word_bit - __last);
    const _Bit_type __mask = __fmask & __lmask;

    if (__x)
      *__v |= __mask;
    else
      *__v &= ~__mask;
  }


  __attribute__((__nonnull__))
 
  inline void
  __fill_bvector_n(_Bit_type* __p, size_t __n, bool __x) noexcept
  {
    __builtin_memset(__p, __x ? ~0 : 0, __n * sizeof(_Bit_type));
  }


 
  inline void
  __fill_a1(std::_Bit_iterator __first,
     std::_Bit_iterator __last, const bool& __x)
  {
    if (__first._M_p != __last._M_p)
      {
 _Bit_type* __first_p = __first._M_p;
 if (__first._M_offset != 0)
   __fill_bvector(__first_p++, __first._M_offset, _S_word_bit, __x);

 __fill_bvector_n(__first_p, __last._M_p - __first_p, __x);

 if (__last._M_offset != 0)
   __fill_bvector(__last._M_p, 0, __last._M_offset, __x);
      }
    else if (__first._M_offset != __last._M_offset)
      __fill_bvector(__first._M_p, __first._M_offset, __last._M_offset, __x);
  }




  template<typename _Alloc>
    struct hash<std::vector<bool, _Alloc>>
    : public __hash_base<size_t, std::vector<bool, _Alloc>>
    {
      size_t
      operator()(const std::vector<bool, _Alloc>&) const noexcept;
    };



}
       




       
namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Tp, typename _Up = typename __inv_unwrap<_Tp>::type>
    constexpr _Up&&
    __invfwd(typename remove_reference<_Tp>::type& __t) noexcept
    { return static_cast<_Up&&>(__t); }

  template<typename _Res, typename _Fn, typename... _Args>
    constexpr _Res
    __invoke_impl(__invoke_other, _Fn&& __f, _Args&&... __args)
    { return std::forward<_Fn>(__f)(std::forward<_Args>(__args)...); }

  template<typename _Res, typename _MemFun, typename _Tp, typename... _Args>
    constexpr _Res
    __invoke_impl(__invoke_memfun_ref, _MemFun&& __f, _Tp&& __t,
    _Args&&... __args)
    { return (__invfwd<_Tp>(__t).*__f)(std::forward<_Args>(__args)...); }

  template<typename _Res, typename _MemFun, typename _Tp, typename... _Args>
    constexpr _Res
    __invoke_impl(__invoke_memfun_deref, _MemFun&& __f, _Tp&& __t,
    _Args&&... __args)
    {
      return ((*std::forward<_Tp>(__t)).*__f)(std::forward<_Args>(__args)...);
    }

  template<typename _Res, typename _MemPtr, typename _Tp>
    constexpr _Res
    __invoke_impl(__invoke_memobj_ref, _MemPtr&& __f, _Tp&& __t)
    { return __invfwd<_Tp>(__t).*__f; }

  template<typename _Res, typename _MemPtr, typename _Tp>
    constexpr _Res
    __invoke_impl(__invoke_memobj_deref, _MemPtr&& __f, _Tp&& __t)
    { return (*std::forward<_Tp>(__t)).*__f; }


  template<typename _Callable, typename... _Args>
    constexpr typename __invoke_result<_Callable, _Args...>::type
    __invoke(_Callable&& __fn, _Args&&... __args)
    noexcept(__is_nothrow_invocable<_Callable, _Args...>::value)
    {
      using __result = __invoke_result<_Callable, _Args...>;
      using __type = typename __result::type;
      using __tag = typename __result::__invoke_type;
      return std::__invoke_impl<__type>(__tag{}, std::forward<_Callable>(__fn),
     std::forward<_Args>(__args)...);
    }



  template<typename _Res, typename _Callable, typename... _Args>
    constexpr enable_if_t<is_invocable_r_v<_Res, _Callable, _Args...>, _Res>
    __invoke_r(_Callable&& __fn, _Args&&... __args)
    noexcept(is_nothrow_invocable_r_v<_Res, _Callable, _Args...>)
    {
      using __result = __invoke_result<_Callable, _Args...>;
      using __type = typename __result::type;
      using __tag = typename __result::__invoke_type;
      if constexpr (is_void_v<_Res>)
 std::__invoke_impl<__type>(__tag{}, std::forward<_Callable>(__fn),
     std::forward<_Args>(__args)...);
      else
 return std::__invoke_impl<__type>(__tag{},
       std::forward<_Callable>(__fn),
       std::forward<_Args>(__args)...);
    }

}
namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Arg, typename _Result>
    struct unary_function
    {

      typedef _Arg argument_type;


      typedef _Result result_type;
    } __attribute__ ((__deprecated__));





  template<typename _Arg1, typename _Arg2, typename _Result>
    struct binary_function
    {

      typedef _Arg1 first_argument_type;


      typedef _Arg2 second_argument_type;


      typedef _Result result_type;
    } __attribute__ ((__deprecated__));
  struct __is_transparent;

  template<typename _Tp = void>
    struct plus;

  template<typename _Tp = void>
    struct minus;

  template<typename _Tp = void>
    struct multiplies;

  template<typename _Tp = void>
    struct divides;

  template<typename _Tp = void>
    struct modulus;

  template<typename _Tp = void>
    struct negate;



#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"


  template<typename _Tp>
    struct plus : public binary_function<_Tp, _Tp, _Tp>
    {

      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x + __y; }
    };


  template<typename _Tp>
    struct minus : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x - __y; }
    };


  template<typename _Tp>
    struct multiplies : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x * __y; }
    };


  template<typename _Tp>
    struct divides : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x / __y; }
    };


  template<typename _Tp>
    struct modulus : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x % __y; }
    };


  template<typename _Tp>
    struct negate : public unary_function<_Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x) const
      { return -__x; }
    };
#pragma GCC diagnostic pop





  template<>
    struct plus<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) + std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) + std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) + std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct minus<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) - std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) - std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) - std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct multiplies<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) * std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) * std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) * std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct divides<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) / std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) / std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) / std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct modulus<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) % std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) % std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) % std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct negate<void>
    {
      template <typename _Tp>
 constexpr
 auto
 operator()(_Tp&& __t) const
 noexcept(noexcept(-std::forward<_Tp>(__t)))
 -> decltype(-std::forward<_Tp>(__t))
 { return -std::forward<_Tp>(__t); }

      typedef __is_transparent is_transparent;
    };
  template<typename _Tp = void>
    struct equal_to;

  template<typename _Tp = void>
    struct not_equal_to;

  template<typename _Tp = void>
    struct greater;

  template<typename _Tp = void>
    struct less;

  template<typename _Tp = void>
    struct greater_equal;

  template<typename _Tp = void>
    struct less_equal;


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"


  template<typename _Tp>
    struct equal_to : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x == __y; }
    };


  template<typename _Tp>
    struct not_equal_to : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x != __y; }
    };


  template<typename _Tp>
    struct greater : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x > __y; }
    };


  template<typename _Tp>
    struct less : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x < __y; }
    };


  template<typename _Tp>
    struct greater_equal : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x >= __y; }
    };


  template<typename _Tp>
    struct less_equal : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x <= __y; }
    };


  template<typename _Tp>
    struct greater<_Tp*> : public binary_function<_Tp*, _Tp*, bool>
    {
      constexpr bool
      operator()(_Tp* __x, _Tp* __y) const noexcept
      {

 if (std::__is_constant_evaluated())
   return __x > __y;

 return (unsigned int)__x > (unsigned int)__y;
      }
    };


  template<typename _Tp>
    struct less<_Tp*> : public binary_function<_Tp*, _Tp*, bool>
    {
      constexpr bool
      operator()(_Tp* __x, _Tp* __y) const noexcept
      {

 if (std::__is_constant_evaluated())
   return __x < __y;

 return (unsigned int)__x < (unsigned int)__y;
      }
    };


  template<typename _Tp>
    struct greater_equal<_Tp*> : public binary_function<_Tp*, _Tp*, bool>
    {
      constexpr bool
      operator()(_Tp* __x, _Tp* __y) const noexcept
      {

 if (std::__is_constant_evaluated())
   return __x >= __y;

 return (unsigned int)__x >= (unsigned int)__y;
      }
    };


  template<typename _Tp>
    struct less_equal<_Tp*> : public binary_function<_Tp*, _Tp*, bool>
    {
      constexpr bool
      operator()(_Tp* __x, _Tp* __y) const noexcept
      {

 if (std::__is_constant_evaluated())
   return __x <= __y;

 return (unsigned int)__x <= (unsigned int)__y;
      }
    };
#pragma GCC diagnostic pop



  template<>
    struct equal_to<void>
    {
      template <typename _Tp, typename _Up>
 constexpr auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) == std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) == std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) == std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct not_equal_to<void>
    {
      template <typename _Tp, typename _Up>
 constexpr auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) != std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) != std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) != std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct greater<void>
    {
      template <typename _Tp, typename _Up>
 constexpr auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) > std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) > std::forward<_Up>(__u))
 {
   return _S_cmp(std::forward<_Tp>(__t), std::forward<_Up>(__u),
   __ptr_cmp<_Tp, _Up>{});
 }

      template<typename _Tp, typename _Up>
 constexpr bool
 operator()(_Tp* __t, _Up* __u) const noexcept
 { return greater<common_type_t<_Tp*, _Up*>>{}(__t, __u); }

      typedef __is_transparent is_transparent;

    private:
      template <typename _Tp, typename _Up>
 static constexpr decltype(auto)
 _S_cmp(_Tp&& __t, _Up&& __u, false_type)
 { return std::forward<_Tp>(__t) > std::forward<_Up>(__u); }

      template <typename _Tp, typename _Up>
 static constexpr bool
 _S_cmp(_Tp&& __t, _Up&& __u, true_type) noexcept
 {
   return greater<const volatile void*>{}(
       static_cast<const volatile void*>(std::forward<_Tp>(__t)),
       static_cast<const volatile void*>(std::forward<_Up>(__u)));
 }


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded2 : true_type { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded2<_Tp, _Up, __void_t<
   decltype(std::declval<_Tp>().operator>(std::declval<_Up>()))>>
 : false_type { };


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded : __not_overloaded2<_Tp, _Up> { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded<_Tp, _Up, __void_t<
   decltype(operator>(std::declval<_Tp>(), std::declval<_Up>()))>>
 : false_type { };

      template<typename _Tp, typename _Up>
 using __ptr_cmp = __and_<__not_overloaded<_Tp, _Up>,
       is_convertible<_Tp, const volatile void*>,
       is_convertible<_Up, const volatile void*>>;
    };


  template<>
    struct less<void>
    {
      template <typename _Tp, typename _Up>
 constexpr auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) < std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) < std::forward<_Up>(__u))
 {
   return _S_cmp(std::forward<_Tp>(__t), std::forward<_Up>(__u),
   __ptr_cmp<_Tp, _Up>{});
 }

      template<typename _Tp, typename _Up>
 constexpr bool
 operator()(_Tp* __t, _Up* __u) const noexcept
 { return less<common_type_t<_Tp*, _Up*>>{}(__t, __u); }

      typedef __is_transparent is_transparent;

    private:
      template <typename _Tp, typename _Up>
 static constexpr decltype(auto)
 _S_cmp(_Tp&& __t, _Up&& __u, false_type)
 { return std::forward<_Tp>(__t) < std::forward<_Up>(__u); }

      template <typename _Tp, typename _Up>
 static constexpr bool
 _S_cmp(_Tp&& __t, _Up&& __u, true_type) noexcept
 {
   return less<const volatile void*>{}(
       static_cast<const volatile void*>(std::forward<_Tp>(__t)),
       static_cast<const volatile void*>(std::forward<_Up>(__u)));
 }


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded2 : true_type { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded2<_Tp, _Up, __void_t<
   decltype(std::declval<_Tp>().operator<(std::declval<_Up>()))>>
 : false_type { };


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded : __not_overloaded2<_Tp, _Up> { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded<_Tp, _Up, __void_t<
   decltype(operator<(std::declval<_Tp>(), std::declval<_Up>()))>>
 : false_type { };

      template<typename _Tp, typename _Up>
 using __ptr_cmp = __and_<__not_overloaded<_Tp, _Up>,
       is_convertible<_Tp, const volatile void*>,
       is_convertible<_Up, const volatile void*>>;
    };


  template<>
    struct greater_equal<void>
    {
      template <typename _Tp, typename _Up>
 constexpr auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) >= std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) >= std::forward<_Up>(__u))
 {
   return _S_cmp(std::forward<_Tp>(__t), std::forward<_Up>(__u),
   __ptr_cmp<_Tp, _Up>{});
 }

      template<typename _Tp, typename _Up>
 constexpr bool
 operator()(_Tp* __t, _Up* __u) const noexcept
 { return greater_equal<common_type_t<_Tp*, _Up*>>{}(__t, __u); }

      typedef __is_transparent is_transparent;

    private:
      template <typename _Tp, typename _Up>
 static constexpr decltype(auto)
 _S_cmp(_Tp&& __t, _Up&& __u, false_type)
 { return std::forward<_Tp>(__t) >= std::forward<_Up>(__u); }

      template <typename _Tp, typename _Up>
 static constexpr bool
 _S_cmp(_Tp&& __t, _Up&& __u, true_type) noexcept
 {
   return greater_equal<const volatile void*>{}(
       static_cast<const volatile void*>(std::forward<_Tp>(__t)),
       static_cast<const volatile void*>(std::forward<_Up>(__u)));
 }


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded2 : true_type { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded2<_Tp, _Up, __void_t<
   decltype(std::declval<_Tp>().operator>=(std::declval<_Up>()))>>
 : false_type { };


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded : __not_overloaded2<_Tp, _Up> { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded<_Tp, _Up, __void_t<
   decltype(operator>=(std::declval<_Tp>(), std::declval<_Up>()))>>
 : false_type { };

      template<typename _Tp, typename _Up>
 using __ptr_cmp = __and_<__not_overloaded<_Tp, _Up>,
       is_convertible<_Tp, const volatile void*>,
       is_convertible<_Up, const volatile void*>>;
    };


  template<>
    struct less_equal<void>
    {
      template <typename _Tp, typename _Up>
 constexpr auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) <= std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) <= std::forward<_Up>(__u))
 {
   return _S_cmp(std::forward<_Tp>(__t), std::forward<_Up>(__u),
   __ptr_cmp<_Tp, _Up>{});
 }

      template<typename _Tp, typename _Up>
 constexpr bool
 operator()(_Tp* __t, _Up* __u) const noexcept
 { return less_equal<common_type_t<_Tp*, _Up*>>{}(__t, __u); }

      typedef __is_transparent is_transparent;

    private:
      template <typename _Tp, typename _Up>
 static constexpr decltype(auto)
 _S_cmp(_Tp&& __t, _Up&& __u, false_type)
 { return std::forward<_Tp>(__t) <= std::forward<_Up>(__u); }

      template <typename _Tp, typename _Up>
 static constexpr bool
 _S_cmp(_Tp&& __t, _Up&& __u, true_type) noexcept
 {
   return less_equal<const volatile void*>{}(
       static_cast<const volatile void*>(std::forward<_Tp>(__t)),
       static_cast<const volatile void*>(std::forward<_Up>(__u)));
 }


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded2 : true_type { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded2<_Tp, _Up, __void_t<
   decltype(std::declval<_Tp>().operator<=(std::declval<_Up>()))>>
 : false_type { };


      template<typename _Tp, typename _Up, typename = void>
 struct __not_overloaded : __not_overloaded2<_Tp, _Up> { };


      template<typename _Tp, typename _Up>
 struct __not_overloaded<_Tp, _Up, __void_t<
   decltype(operator<=(std::declval<_Tp>(), std::declval<_Up>()))>>
 : false_type { };

      template<typename _Tp, typename _Up>
 using __ptr_cmp = __and_<__not_overloaded<_Tp, _Up>,
       is_convertible<_Tp, const volatile void*>,
       is_convertible<_Up, const volatile void*>>;
    };
  template<typename _Tp = void>
    struct logical_and;

  template<typename _Tp = void>
    struct logical_or;

  template<typename _Tp = void>
    struct logical_not;


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"


  template<typename _Tp>
    struct logical_and : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x && __y; }
    };


  template<typename _Tp>
    struct logical_or : public binary_function<_Tp, _Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x || __y; }
    };


  template<typename _Tp>
    struct logical_not : public unary_function<_Tp, bool>
    {
      constexpr
      bool
      operator()(const _Tp& __x) const
      { return !__x; }
    };
#pragma GCC diagnostic pop



  template<>
    struct logical_and<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) && std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) && std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) && std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct logical_or<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) || std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) || std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) || std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };


  template<>
    struct logical_not<void>
    {
      template <typename _Tp>
 constexpr
 auto
 operator()(_Tp&& __t) const
 noexcept(noexcept(!std::forward<_Tp>(__t)))
 -> decltype(!std::forward<_Tp>(__t))
 { return !std::forward<_Tp>(__t); }

      typedef __is_transparent is_transparent;
    };




  template<typename _Tp = void>
    struct bit_and;

  template<typename _Tp = void>
    struct bit_or;

  template<typename _Tp = void>
    struct bit_xor;

  template<typename _Tp = void>
    struct bit_not;


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"



  template<typename _Tp>
    struct bit_and : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x & __y; }
    };

  template<typename _Tp>
    struct bit_or : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x | __y; }
    };

  template<typename _Tp>
    struct bit_xor : public binary_function<_Tp, _Tp, _Tp>
    {
      constexpr
      _Tp
      operator()(const _Tp& __x, const _Tp& __y) const
      { return __x ^ __y; }
    };

  template<typename _Tp>
    struct bit_not : public unary_function<_Tp, _Tp>
    {
    constexpr
      _Tp
      operator()(const _Tp& __x) const
      { return ~__x; }
    };
#pragma GCC diagnostic pop


  template <>
    struct bit_and<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) & std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) & std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) & std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };

  template <>
    struct bit_or<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) | std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) | std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) | std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };

  template <>
    struct bit_xor<void>
    {
      template <typename _Tp, typename _Up>
 constexpr
 auto
 operator()(_Tp&& __t, _Up&& __u) const
 noexcept(noexcept(std::forward<_Tp>(__t) ^ std::forward<_Up>(__u)))
 -> decltype(std::forward<_Tp>(__t) ^ std::forward<_Up>(__u))
 { return std::forward<_Tp>(__t) ^ std::forward<_Up>(__u); }

      typedef __is_transparent is_transparent;
    };

  template <>
    struct bit_not<void>
    {
      template <typename _Tp>
 constexpr
 auto
 operator()(_Tp&& __t) const
 noexcept(noexcept(~std::forward<_Tp>(__t)))
 -> decltype(~std::forward<_Tp>(__t))
 { return ~std::forward<_Tp>(__t); }

      typedef __is_transparent is_transparent;
    };


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
  template<typename _Predicate>
    class [[__deprecated__]] unary_negate
    : public unary_function<typename _Predicate::argument_type, bool>
    {
    protected:
      _Predicate _M_pred;

    public:
      constexpr
      explicit
      unary_negate(const _Predicate& __x) : _M_pred(__x) { }

      constexpr
      bool
      operator()(const typename _Predicate::argument_type& __x) const
      { return !_M_pred(__x); }
    };


  template<typename _Predicate>
    __attribute__ ((__deprecated__ ("use '" "std::not_fn" "' instead")))
    constexpr
    inline unary_negate<_Predicate>
    not1(const _Predicate& __pred)
    { return unary_negate<_Predicate>(__pred); }


  template<typename _Predicate>
    class [[__deprecated__]] binary_negate
    : public binary_function<typename _Predicate::first_argument_type,
        typename _Predicate::second_argument_type, bool>
    {
    protected:
      _Predicate _M_pred;

    public:
      constexpr
      explicit
      binary_negate(const _Predicate& __x) : _M_pred(__x) { }

      constexpr
      bool
      operator()(const typename _Predicate::first_argument_type& __x,
   const typename _Predicate::second_argument_type& __y) const
      { return !_M_pred(__x, __y); }
    };


  template<typename _Predicate>
    __attribute__ ((__deprecated__ ("use '" "std::not_fn" "' instead")))
    constexpr
    inline binary_negate<_Predicate>
    not2(const _Predicate& __pred)
    { return binary_negate<_Predicate>(__pred); }
  template<typename _Arg, typename _Result>
    class pointer_to_unary_function : public unary_function<_Arg, _Result>
    {
    protected:
      _Result (*_M_ptr)(_Arg);

    public:
      pointer_to_unary_function() { }

      explicit
      pointer_to_unary_function(_Result (*__x)(_Arg))
      : _M_ptr(__x) { }

      _Result
      operator()(_Arg __x) const
      { return _M_ptr(__x); }
    } __attribute__ ((__deprecated__));


  template<typename _Arg, typename _Result>
    __attribute__ ((__deprecated__ ("use '" "std::function" "' instead")))
    inline pointer_to_unary_function<_Arg, _Result>
    ptr_fun(_Result (*__x)(_Arg))
    { return pointer_to_unary_function<_Arg, _Result>(__x); }


  template<typename _Arg1, typename _Arg2, typename _Result>
    class pointer_to_binary_function
    : public binary_function<_Arg1, _Arg2, _Result>
    {
    protected:
      _Result (*_M_ptr)(_Arg1, _Arg2);

    public:
      pointer_to_binary_function() { }

      explicit
      pointer_to_binary_function(_Result (*__x)(_Arg1, _Arg2))
      : _M_ptr(__x) { }

      _Result
      operator()(_Arg1 __x, _Arg2 __y) const
      { return _M_ptr(__x, __y); }
    } __attribute__ ((__deprecated__));


  template<typename _Arg1, typename _Arg2, typename _Result>
    __attribute__ ((__deprecated__ ("use '" "std::function" "' instead")))
    inline pointer_to_binary_function<_Arg1, _Arg2, _Result>
    ptr_fun(_Result (*__x)(_Arg1, _Arg2))
    { return pointer_to_binary_function<_Arg1, _Arg2, _Result>(__x); }


  template<typename _Tp>
    struct _Identity
    : public unary_function<_Tp, _Tp>
    {
      _Tp&
      operator()(_Tp& __x) const
      { return __x; }

      const _Tp&
      operator()(const _Tp& __x) const
      { return __x; }
    };


  template<typename _Tp> struct _Identity<const _Tp> : _Identity<_Tp> { };

  template<typename _Pair>
    struct _Select1st
    : public unary_function<_Pair, typename _Pair::first_type>
    {
      typename _Pair::first_type&
      operator()(_Pair& __x) const
      { return __x.first; }

      const typename _Pair::first_type&
      operator()(const _Pair& __x) const
      { return __x.first; }


      template<typename _Pair2>
        typename _Pair2::first_type&
        operator()(_Pair2& __x) const
        { return __x.first; }

      template<typename _Pair2>
        const typename _Pair2::first_type&
        operator()(const _Pair2& __x) const
        { return __x.first; }

    };

  template<typename _Pair>
    struct _Select2nd
    : public unary_function<_Pair, typename _Pair::second_type>
    {
      typename _Pair::second_type&
      operator()(_Pair& __x) const
      { return __x.second; }

      const typename _Pair::second_type&
      operator()(const _Pair& __x) const
      { return __x.second; }
    };
  template<typename _Ret, typename _Tp>
    class mem_fun_t : public unary_function<_Tp*, _Ret>
    {
    public:
      explicit
      mem_fun_t(_Ret (_Tp::*__pf)())
      : _M_f(__pf) { }

      _Ret
      operator()(_Tp* __p) const
      { return (__p->*_M_f)(); }

    private:
      _Ret (_Tp::*_M_f)();
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp>
    class const_mem_fun_t : public unary_function<const _Tp*, _Ret>
    {
    public:
      explicit
      const_mem_fun_t(_Ret (_Tp::*__pf)() const)
      : _M_f(__pf) { }

      _Ret
      operator()(const _Tp* __p) const
      { return (__p->*_M_f)(); }

    private:
      _Ret (_Tp::*_M_f)() const;
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp>
    class mem_fun_ref_t : public unary_function<_Tp, _Ret>
    {
    public:
      explicit
      mem_fun_ref_t(_Ret (_Tp::*__pf)())
      : _M_f(__pf) { }

      _Ret
      operator()(_Tp& __r) const
      { return (__r.*_M_f)(); }

    private:
      _Ret (_Tp::*_M_f)();
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp>
    class const_mem_fun_ref_t : public unary_function<_Tp, _Ret>
    {
    public:
      explicit
      const_mem_fun_ref_t(_Ret (_Tp::*__pf)() const)
      : _M_f(__pf) { }

      _Ret
      operator()(const _Tp& __r) const
      { return (__r.*_M_f)(); }

    private:
      _Ret (_Tp::*_M_f)() const;
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp, typename _Arg>
    class mem_fun1_t : public binary_function<_Tp*, _Arg, _Ret>
    {
    public:
      explicit
      mem_fun1_t(_Ret (_Tp::*__pf)(_Arg))
      : _M_f(__pf) { }

      _Ret
      operator()(_Tp* __p, _Arg __x) const
      { return (__p->*_M_f)(__x); }

    private:
      _Ret (_Tp::*_M_f)(_Arg);
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp, typename _Arg>
    class const_mem_fun1_t : public binary_function<const _Tp*, _Arg, _Ret>
    {
    public:
      explicit
      const_mem_fun1_t(_Ret (_Tp::*__pf)(_Arg) const)
      : _M_f(__pf) { }

      _Ret
      operator()(const _Tp* __p, _Arg __x) const
      { return (__p->*_M_f)(__x); }

    private:
      _Ret (_Tp::*_M_f)(_Arg) const;
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp, typename _Arg>
    class mem_fun1_ref_t : public binary_function<_Tp, _Arg, _Ret>
    {
    public:
      explicit
      mem_fun1_ref_t(_Ret (_Tp::*__pf)(_Arg))
      : _M_f(__pf) { }

      _Ret
      operator()(_Tp& __r, _Arg __x) const
      { return (__r.*_M_f)(__x); }

    private:
      _Ret (_Tp::*_M_f)(_Arg);
    } __attribute__ ((__deprecated__));


  template<typename _Ret, typename _Tp, typename _Arg>
    class const_mem_fun1_ref_t : public binary_function<_Tp, _Arg, _Ret>
    {
    public:
      explicit
      const_mem_fun1_ref_t(_Ret (_Tp::*__pf)(_Arg) const)
      : _M_f(__pf) { }

      _Ret
      operator()(const _Tp& __r, _Arg __x) const
      { return (__r.*_M_f)(__x); }

    private:
      _Ret (_Tp::*_M_f)(_Arg) const;
    } __attribute__ ((__deprecated__));



  template<typename _Ret, typename _Tp>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline mem_fun_t<_Ret, _Tp>
    mem_fun(_Ret (_Tp::*__f)())
    { return mem_fun_t<_Ret, _Tp>(__f); }

  template<typename _Ret, typename _Tp>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline const_mem_fun_t<_Ret, _Tp>
    mem_fun(_Ret (_Tp::*__f)() const)
    { return const_mem_fun_t<_Ret, _Tp>(__f); }

  template<typename _Ret, typename _Tp>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline mem_fun_ref_t<_Ret, _Tp>
    mem_fun_ref(_Ret (_Tp::*__f)())
    { return mem_fun_ref_t<_Ret, _Tp>(__f); }

  template<typename _Ret, typename _Tp>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline const_mem_fun_ref_t<_Ret, _Tp>
    mem_fun_ref(_Ret (_Tp::*__f)() const)
    { return const_mem_fun_ref_t<_Ret, _Tp>(__f); }

  template<typename _Ret, typename _Tp, typename _Arg>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline mem_fun1_t<_Ret, _Tp, _Arg>
    mem_fun(_Ret (_Tp::*__f)(_Arg))
    { return mem_fun1_t<_Ret, _Tp, _Arg>(__f); }

  template<typename _Ret, typename _Tp, typename _Arg>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline const_mem_fun1_t<_Ret, _Tp, _Arg>
    mem_fun(_Ret (_Tp::*__f)(_Arg) const)
    { return const_mem_fun1_t<_Ret, _Tp, _Arg>(__f); }

  template<typename _Ret, typename _Tp, typename _Arg>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline mem_fun1_ref_t<_Ret, _Tp, _Arg>
    mem_fun_ref(_Ret (_Tp::*__f)(_Arg))
    { return mem_fun1_ref_t<_Ret, _Tp, _Arg>(__f); }

  template<typename _Ret, typename _Tp, typename _Arg>
    __attribute__ ((__deprecated__ ("use '" "std::mem_fn" "' instead")))
    inline const_mem_fun1_ref_t<_Ret, _Tp, _Arg>
    mem_fun_ref(_Ret (_Tp::*__f)(_Arg) const)
    { return const_mem_fun1_ref_t<_Ret, _Tp, _Arg>(__f); }
#pragma GCC diagnostic pop




  template<typename _Func, typename _SfinaeType, typename = __void_t<>>
    struct __has_is_transparent
    { };

  template<typename _Func, typename _SfinaeType>
    struct __has_is_transparent<_Func, _SfinaeType,
    __void_t<typename _Func::is_transparent>>
    { typedef void type; };

  template<typename _Func, typename _SfinaeType>
    using __has_is_transparent_t
      = typename __has_is_transparent<_Func, _SfinaeType>::type;



}


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"

namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Operation>
    class binder1st
    : public unary_function<typename _Operation::second_argument_type,
       typename _Operation::result_type>
    {
    protected:
      _Operation op;
      typename _Operation::first_argument_type value;

    public:
      binder1st(const _Operation& __x,
  const typename _Operation::first_argument_type& __y)
      : op(__x), value(__y) { }

      typename _Operation::result_type
      operator()(const typename _Operation::second_argument_type& __x) const
      { return op(value, __x); }



      typename _Operation::result_type
      operator()(typename _Operation::second_argument_type& __x) const
      { return op(value, __x); }
    } __attribute__ ((__deprecated__ ("use '" "std::bind" "' instead")));


  template<typename _Operation, typename _Tp>
    __attribute__ ((__deprecated__ ("use '" "std::bind" "' instead")))
    inline binder1st<_Operation>
    bind1st(const _Operation& __fn, const _Tp& __x)
    {
      typedef typename _Operation::first_argument_type _Arg1_type;
      return binder1st<_Operation>(__fn, _Arg1_type(__x));
    }


  template<typename _Operation>
    class binder2nd
    : public unary_function<typename _Operation::first_argument_type,
       typename _Operation::result_type>
    {
    protected:
      _Operation op;
      typename _Operation::second_argument_type value;

    public:
      binder2nd(const _Operation& __x,
  const typename _Operation::second_argument_type& __y)
      : op(__x), value(__y) { }

      typename _Operation::result_type
      operator()(const typename _Operation::first_argument_type& __x) const
      { return op(__x, value); }



      typename _Operation::result_type
      operator()(typename _Operation::first_argument_type& __x) const
      { return op(__x, value); }
    } __attribute__ ((__deprecated__ ("use '" "std::bind" "' instead")));


  template<typename _Operation, typename _Tp>
    __attribute__ ((__deprecated__ ("use '" "std::bind" "' instead")))
    inline binder2nd<_Operation>
    bind2nd(const _Operation& __fn, const _Tp& __x)
    {
      typedef typename _Operation::second_argument_type _Arg2_type;
      return binder2nd<_Operation>(__fn, _Arg2_type(__x));
    }



}

#pragma GCC diagnostic pop

namespace std __attribute__ ((__visibility__ ("default")))
{

  template<typename _Res, typename... _ArgTypes>
    struct _Maybe_unary_or_binary_function { };


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"


  template<typename _Res, typename _T1>
    struct _Maybe_unary_or_binary_function<_Res, _T1>
    : std::unary_function<_T1, _Res> { };


  template<typename _Res, typename _T1, typename _T2>
    struct _Maybe_unary_or_binary_function<_Res, _T1, _T2>
    : std::binary_function<_T1, _T2, _Res> { };

#pragma GCC diagnostic pop

  template<typename _Signature>
    struct _Mem_fn_traits;

  template<typename _Res, typename _Class, typename... _ArgTypes>
    struct _Mem_fn_traits_base
    {
      using __result_type = _Res;
      using __maybe_type
 = _Maybe_unary_or_binary_function<_Res, _Class*, _ArgTypes...>;
      using __arity = integral_constant<size_t, sizeof...(_ArgTypes)>;
    };
template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) > : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) > : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const > : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const > : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile > : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile > : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile > : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile > : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };
template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) &> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) &> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const &> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const &> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile &> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile &> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile &> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile &> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };
template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) &&> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) &&> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const &&> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const &&> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile &&> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile &&> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile &&> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile &&> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };


template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };
template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) & noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const & noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile & noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile & noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };
template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) && noexcept> : _Mem_fn_traits_base<_Res, _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const && noexcept> : _Mem_fn_traits_base<_Res, const _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) volatile && noexcept> : _Mem_fn_traits_base<_Res, volatile _Class, _ArgTypes...> { using __vararg = true_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = false_type; }; template<typename _Res, typename _Class, typename... _ArgTypes> struct _Mem_fn_traits<_Res (_Class::*)(_ArgTypes... ...) const volatile && noexcept> : _Mem_fn_traits_base<_Res, const volatile _Class, _ArgTypes...> { using __vararg = true_type; };






  template<typename _Functor, typename = __void_t<>>
    struct _Maybe_get_result_type
    { };

  template<typename _Functor>
    struct _Maybe_get_result_type<_Functor,
      __void_t<typename _Functor::result_type>>
    { typedef typename _Functor::result_type result_type; };





  template<typename _Functor>
    struct _Weak_result_type_impl
    : _Maybe_get_result_type<_Functor>
    { };


  template<typename _Res, typename... _ArgTypes , bool _NE>
    struct _Weak_result_type_impl<_Res(_ArgTypes...) noexcept (_NE)>
    { typedef _Res result_type; };


  template<typename _Res, typename... _ArgTypes , bool _NE>
    struct _Weak_result_type_impl<_Res(_ArgTypes......) noexcept (_NE)>
    { typedef _Res result_type; };


  template<typename _Res, typename... _ArgTypes , bool _NE>
    struct _Weak_result_type_impl<_Res(*)(_ArgTypes...) noexcept (_NE)>
    { typedef _Res result_type; };


  template<typename _Res, typename... _ArgTypes , bool _NE>
    struct
    _Weak_result_type_impl<_Res(*)(_ArgTypes......) noexcept (_NE)>
    { typedef _Res result_type; };


  template<typename _Functor,
    bool = is_member_function_pointer<_Functor>::value>
    struct _Weak_result_type_memfun
    : _Weak_result_type_impl<_Functor>
    { };


  template<typename _MemFunPtr>
    struct _Weak_result_type_memfun<_MemFunPtr, true>
    {
      using result_type = typename _Mem_fn_traits<_MemFunPtr>::__result_type;
    };


  template<typename _Func, typename _Class>
    struct _Weak_result_type_memfun<_Func _Class::*, false>
    { };





  template<typename _Functor>
    struct _Weak_result_type
    : _Weak_result_type_memfun<typename remove_cv<_Functor>::type>
    { };



  template<typename _Tp, typename = __void_t<>>
    struct _Refwrap_base_arg1
    { };


  template<typename _Tp>
    struct _Refwrap_base_arg1<_Tp,
         __void_t<typename _Tp::argument_type>>
    {
      typedef typename _Tp::argument_type argument_type;
    };


  template<typename _Tp, typename = __void_t<>>
    struct _Refwrap_base_arg2
    { };


  template<typename _Tp>
    struct _Refwrap_base_arg2<_Tp,
         __void_t<typename _Tp::first_argument_type,
           typename _Tp::second_argument_type>>
    {
      typedef typename _Tp::first_argument_type first_argument_type;
      typedef typename _Tp::second_argument_type second_argument_type;
    };







  template<typename _Tp>
    struct _Reference_wrapper_base
    : _Weak_result_type<_Tp>, _Refwrap_base_arg1<_Tp>, _Refwrap_base_arg2<_Tp>
    { };


#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wdeprecated-declarations"


  template<typename _Res, typename _T1 , bool _NE>
    struct _Reference_wrapper_base<_Res(_T1) noexcept (_NE)>
    : unary_function<_T1, _Res>
    { };

  template<typename _Res, typename _T1>
    struct _Reference_wrapper_base<_Res(_T1) const>
    : unary_function<_T1, _Res>
    { };

  template<typename _Res, typename _T1>
    struct _Reference_wrapper_base<_Res(_T1) volatile>
    : unary_function<_T1, _Res>
    { };

  template<typename _Res, typename _T1>
    struct _Reference_wrapper_base<_Res(_T1) const volatile>
    : unary_function<_T1, _Res>
    { };


  template<typename _Res, typename _T1, typename _T2 , bool _NE>
    struct _Reference_wrapper_base<_Res(_T1, _T2) noexcept (_NE)>
    : binary_function<_T1, _T2, _Res>
    { };

  template<typename _Res, typename _T1, typename _T2>
    struct _Reference_wrapper_base<_Res(_T1, _T2) const>
    : binary_function<_T1, _T2, _Res>
    { };

  template<typename _Res, typename _T1, typename _T2>
    struct _Reference_wrapper_base<_Res(_T1, _T2) volatile>
    : binary_function<_T1, _T2, _Res>
    { };

  template<typename _Res, typename _T1, typename _T2>
    struct _Reference_wrapper_base<_Res(_T1, _T2) const volatile>
    : binary_function<_T1, _T2, _Res>
    { };


  template<typename _Res, typename _T1 , bool _NE>
    struct _Reference_wrapper_base<_Res(*)(_T1) noexcept (_NE)>
    : unary_function<_T1, _Res>
    { };


  template<typename _Res, typename _T1, typename _T2 , bool _NE>
    struct _Reference_wrapper_base<_Res(*)(_T1, _T2) noexcept (_NE)>
    : binary_function<_T1, _T2, _Res>
    { };

  template<typename _Tp, bool = is_member_function_pointer<_Tp>::value>
    struct _Reference_wrapper_base_memfun
    : _Reference_wrapper_base<_Tp>
    { };

  template<typename _MemFunPtr>
    struct _Reference_wrapper_base_memfun<_MemFunPtr, true>
    : _Mem_fn_traits<_MemFunPtr>::__maybe_type
    {
      using result_type = typename _Mem_fn_traits<_MemFunPtr>::__result_type;
    };
#pragma GCC diagnostic pop
  template<typename _Tp>
    class reference_wrapper



    : public _Reference_wrapper_base_memfun<typename remove_cv<_Tp>::type>

    {
      _Tp* _M_data;

     
      static _Tp* _S_fun(_Tp& __r) noexcept { return std::__addressof(__r); }

      static void _S_fun(_Tp&&) = delete;

      template<typename _Up, typename _Up2 = __remove_cvref_t<_Up>>
 using __not_same
   = typename enable_if<!is_same<reference_wrapper, _Up2>::value>::type;

    public:
      typedef _Tp type;




      template<typename _Up, typename = __not_same<_Up>, typename
  = decltype(reference_wrapper::_S_fun(std::declval<_Up>()))>

 reference_wrapper(_Up&& __uref)
 noexcept(noexcept(reference_wrapper::_S_fun(std::declval<_Up>())))
 : _M_data(reference_wrapper::_S_fun(std::forward<_Up>(__uref)))
 { }

      reference_wrapper(const reference_wrapper&) = default;

      reference_wrapper&
      operator=(const reference_wrapper&) = default;

     
      operator _Tp&() const noexcept
      { return this->get(); }

     
      _Tp&
      get() const noexcept
      { return *_M_data; }

      template<typename... _Args>

 typename __invoke_result<_Tp&, _Args...>::type
 operator()(_Args&&... __args) const
 noexcept(__is_nothrow_invocable<_Tp&, _Args...>::value)
 {




   return std::__invoke(get(), std::forward<_Args>(__args)...);
 }
    };


  template<typename _Tp>
    reference_wrapper(_Tp&) -> reference_wrapper<_Tp>;





  template<typename _Tp>
   
    inline reference_wrapper<_Tp>
    ref(_Tp& __t) noexcept
    { return reference_wrapper<_Tp>(__t); }


  template<typename _Tp>
   
    inline reference_wrapper<const _Tp>
    cref(const _Tp& __t) noexcept
    { return reference_wrapper<const _Tp>(__t); }

  template<typename _Tp>
    void ref(const _Tp&&) = delete;

  template<typename _Tp>
    void cref(const _Tp&&) = delete;


  template<typename _Tp>
   
    inline reference_wrapper<_Tp>
    ref(reference_wrapper<_Tp> __t) noexcept
    { return __t; }


  template<typename _Tp>
   
    inline reference_wrapper<const _Tp>
    cref(reference_wrapper<_Tp> __t) noexcept
    { return { __t.get() }; }




}



namespace std __attribute__ ((__visibility__ ("default")))
{



  template<typename _Tp, typename _Alloc>
   
    void
    vector<_Tp, _Alloc>::
    reserve(size_type __n)
    {
      if (__n > this->max_size())
 __throw_length_error(("vector::reserve"));
      if (this->capacity() < __n)
 {
   const size_type __old_size = size();
   pointer __tmp;

   if constexpr (_S_use_relocate())
     {
       __tmp = this->_M_allocate(__n);
       _S_relocate(this->_M_impl._M_start, this->_M_impl._M_finish,
     __tmp, _M_get_Tp_allocator());
     }
   else

     {
       __tmp = _M_allocate_and_copy(__n,
  std::__make_move_if_noexcept_iterator(this->_M_impl._M_start),
  std::__make_move_if_noexcept_iterator(this->_M_impl._M_finish));
       std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
       _M_get_Tp_allocator());
     }
   ;
   _M_deallocate(this->_M_impl._M_start,
   this->_M_impl._M_end_of_storage
   - this->_M_impl._M_start);
   this->_M_impl._M_start = __tmp;
   this->_M_impl._M_finish = __tmp + __old_size;
   this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __n;
 }
    }


  template<typename _Tp, typename _Alloc>
    template<typename... _Args>

     
      typename vector<_Tp, _Alloc>::reference



      vector<_Tp, _Alloc>::
      emplace_back(_Args&&... __args)
      {
 if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
   {
     ;
     _Alloc_traits::construct(this->_M_impl, this->_M_impl._M_finish,
         std::forward<_Args>(__args)...);
     ++this->_M_impl._M_finish;
     ;
   }
 else
   _M_realloc_insert(end(), std::forward<_Args>(__args)...);

 return back();

      }


  template<typename _Tp, typename _Alloc>
   
    typename vector<_Tp, _Alloc>::iterator
    vector<_Tp, _Alloc>::

    insert(const_iterator __position, const value_type& __x)



    {
      const size_type __n = __position - begin();
      if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
 if (__position == end())
   {
     ;
     _Alloc_traits::construct(this->_M_impl, this->_M_impl._M_finish,
         __x);
     ++this->_M_impl._M_finish;
     ;
   }
 else
   {

     const auto __pos = begin() + (__position - cbegin());


     _Temporary_value __x_copy(this, __x);
     _M_insert_aux(__pos, std::move(__x_copy._M_val()));



   }
      else

 _M_realloc_insert(begin() + (__position - cbegin()), __x);




      return iterator(this->_M_impl._M_start + __n);
    }

  template<typename _Tp, typename _Alloc>
   
    typename vector<_Tp, _Alloc>::iterator
    vector<_Tp, _Alloc>::
    _M_erase(iterator __position)
    {
      if (__position + 1 != end())
 std::move(__position + 1, end(), __position);
      --this->_M_impl._M_finish;
      _Alloc_traits::destroy(this->_M_impl, this->_M_impl._M_finish);
      ;
      return __position;
    }

  template<typename _Tp, typename _Alloc>
   
    typename vector<_Tp, _Alloc>::iterator
    vector<_Tp, _Alloc>::
    _M_erase(iterator __first, iterator __last)
    {
      if (__first != __last)
 {
   if (__last != end())
     std::move(__last, end(), __first);
   _M_erase_at_end(__first.base() + (end() - __last));
 }
      return __first;
    }

  template<typename _Tp, typename _Alloc>
   
    vector<_Tp, _Alloc>&
    vector<_Tp, _Alloc>::
    operator=(const vector<_Tp, _Alloc>& __x)
    {
      if (std::__addressof(__x) != this)
 {
   ;

   if (_Alloc_traits::_S_propagate_on_copy_assign())
     {
       if (!_Alloc_traits::_S_always_equal()
           && _M_get_Tp_allocator() != __x._M_get_Tp_allocator())
         {

    this->clear();
    _M_deallocate(this->_M_impl._M_start,
    this->_M_impl._M_end_of_storage
    - this->_M_impl._M_start);
    this->_M_impl._M_start = nullptr;
    this->_M_impl._M_finish = nullptr;
    this->_M_impl._M_end_of_storage = nullptr;
  }
       std::__alloc_on_copy(_M_get_Tp_allocator(),
       __x._M_get_Tp_allocator());
     }

   const size_type __xlen = __x.size();
   if (__xlen > capacity())
     {
       pointer __tmp = _M_allocate_and_copy(__xlen, __x.begin(),
         __x.end());
       std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
       _M_get_Tp_allocator());
       _M_deallocate(this->_M_impl._M_start,
       this->_M_impl._M_end_of_storage
       - this->_M_impl._M_start);
       this->_M_impl._M_start = __tmp;
       this->_M_impl._M_end_of_storage = this->_M_impl._M_start + __xlen;
     }
   else if (size() >= __xlen)
     {
       std::_Destroy(std::copy(__x.begin(), __x.end(), begin()),
       end(), _M_get_Tp_allocator());
     }
   else
     {
       std::copy(__x._M_impl._M_start, __x._M_impl._M_start + size(),
   this->_M_impl._M_start);
       std::__uninitialized_copy_a(__x._M_impl._M_start + size(),
       __x._M_impl._M_finish,
       this->_M_impl._M_finish,
       _M_get_Tp_allocator());
     }
   this->_M_impl._M_finish = this->_M_impl._M_start + __xlen;
 }
      return *this;
    }

  template<typename _Tp, typename _Alloc>
   
    void
    vector<_Tp, _Alloc>::
    _M_fill_assign(size_t __n, const value_type& __val)
    {
      if (__n > capacity())
 {
   vector __tmp(__n, __val, _M_get_Tp_allocator());
   __tmp._M_impl._M_swap_data(this->_M_impl);
 }
      else if (__n > size())
 {
   std::fill(begin(), end(), __val);
   const size_type __add = __n - size();
   ;
   this->_M_impl._M_finish =
     std::__uninitialized_fill_n_a(this->_M_impl._M_finish,
       __add, __val, _M_get_Tp_allocator());
   ;
 }
      else
        _M_erase_at_end(std::fill_n(this->_M_impl._M_start, __n, __val));
    }

  template<typename _Tp, typename _Alloc>
    template<typename _InputIterator>
     
      void
      vector<_Tp, _Alloc>::
      _M_assign_aux(_InputIterator __first, _InputIterator __last,
      std::input_iterator_tag)
      {
 pointer __cur(this->_M_impl._M_start);
 for (; __first != __last && __cur != this->_M_impl._M_finish;
      ++__cur, (void)++__first)
   *__cur = *__first;
 if (__first == __last)
   _M_erase_at_end(__cur);
 else
   _M_range_insert(end(), __first, __last,
     std::__iterator_category(__first));
      }

  template<typename _Tp, typename _Alloc>
    template<typename _ForwardIterator>
     
      void
      vector<_Tp, _Alloc>::
      _M_assign_aux(_ForwardIterator __first, _ForwardIterator __last,
      std::forward_iterator_tag)
      {
 const size_type __len = std::distance(__first, __last);

 if (__len > capacity())
   {
     _S_check_init_len(__len, _M_get_Tp_allocator());
     pointer __tmp(_M_allocate_and_copy(__len, __first, __last));
     std::_Destroy(this->_M_impl._M_start, this->_M_impl._M_finish,
     _M_get_Tp_allocator());
     ;
     _M_deallocate(this->_M_impl._M_start,
     this->_M_impl._M_end_of_storage
     - this->_M_impl._M_start);
     this->_M_impl._M_start = __tmp;
     this->_M_impl._M_finish = this->_M_impl._M_start + __len;
     this->_M_impl._M_end_of_storage = this->_M_impl._M_finish;
   }
 else if (size() >= __len)
   _M_erase_at_end(std::copy(__first, __last, this->_M_impl._M_start));
 else
   {
     _ForwardIterator __mid = __first;
     std::advance(__mid, size());
     std::copy(__first, __mid, this->_M_impl._M_start);
     const size_type __attribute__((__unused__)) __n = __len - size();
     ;
     this->_M_impl._M_finish =
       std::__uninitialized_copy_a(__mid, __last,
       this->_M_impl._M_finish,
       _M_get_Tp_allocator());
     ;
   }
      }


  template<typename _Tp, typename _Alloc>
   
    auto
    vector<_Tp, _Alloc>::
    _M_insert_rval(const_iterator __position, value_type&& __v) -> iterator
    {
      const auto __n = __position - cbegin();
      if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
 if (__position == cend())
   {
     ;
     _Alloc_traits::construct(this->_M_impl, this->_M_impl._M_finish,
         std::move(__v));
     ++this->_M_impl._M_finish;
     ;
   }
 else
   _M_insert_aux(begin() + __n, std::move(__v));
      else
 _M_realloc_insert(begin() + __n, std::move(__v));

      return iterator(this->_M_impl._M_start + __n);
    }

  template<typename _Tp, typename _Alloc>
    template<typename... _Args>
     
      auto
      vector<_Tp, _Alloc>::
      _M_emplace_aux(const_iterator __position, _Args&&... __args)
      -> iterator
      {
 const auto __n = __position - cbegin();
 if (this->_M_impl._M_finish != this->_M_impl._M_end_of_storage)
   if (__position == cend())
     {
       ;
       _Alloc_traits::construct(this->_M_impl, this->_M_impl._M_finish,
           std::forward<_Args>(__args)...);
       ++this->_M_impl._M_finish;
       ;
     }
   else
     {



       _Temporary_value __tmp(this, std::forward<_Args>(__args)...);
       _M_insert_aux(begin() + __n, std::move(__tmp._M_val()));
     }
 else
   _M_realloc_insert(begin() + __n, std::forward<_Args>(__args)...);

 return iterator(this->_M_impl._M_start + __n);
      }

  template<typename _Tp, typename _Alloc>
    template<typename _Arg>
     
      void
      vector<_Tp, _Alloc>::
      _M_insert_aux(iterator __position, _Arg&& __arg)






    {
      ;
      _Alloc_traits::construct(this->_M_impl, this->_M_impl._M_finish,
          std::move(*(this->_M_impl._M_finish - 1)));
      ++this->_M_impl._M_finish;
      ;



      std::move_backward(__position.base(), this->_M_impl._M_finish - 2, this->_M_impl._M_finish - 1)

                                     ;



      *__position = std::forward<_Arg>(__arg);

    }


  template<typename _Tp, typename _Alloc>
    template<typename... _Args>
     
      void
      vector<_Tp, _Alloc>::
      _M_realloc_insert(iterator __position, _Args&&... __args)






    {
      const size_type __len =
 _M_check_len(size_type(1), "vector::_M_realloc_insert");
      pointer __old_start = this->_M_impl._M_start;
      pointer __old_finish = this->_M_impl._M_finish;
      const size_type __elems_before = __position - begin();
      pointer __new_start(this->_M_allocate(__len));
      pointer __new_finish(__new_start);
      if (true)
 {





   _Alloc_traits::construct(this->_M_impl,
       __new_start + __elems_before,

       std::forward<_Args>(__args)...);



   __new_finish = pointer();


   if constexpr (_S_use_relocate())
     {
       __new_finish = _S_relocate(__old_start, __position.base(),
      __new_start, _M_get_Tp_allocator());

       ++__new_finish;

       __new_finish = _S_relocate(__position.base(), __old_finish,
      __new_finish, _M_get_Tp_allocator());
     }
   else

     {
       __new_finish
  = std::__uninitialized_move_if_noexcept_a
  (__old_start, __position.base(),
   __new_start, _M_get_Tp_allocator());

       ++__new_finish;

       __new_finish
  = std::__uninitialized_move_if_noexcept_a
  (__position.base(), __old_finish,
   __new_finish, _M_get_Tp_allocator());
     }
 }
      if (false)
 {
   if (!__new_finish)
     _Alloc_traits::destroy(this->_M_impl,
       __new_start + __elems_before);
   else
     std::_Destroy(__new_start, __new_finish, _M_get_Tp_allocator());
   _M_deallocate(__new_start, __len);
   ;
 }

      if constexpr (!_S_use_relocate())

 std::_Destroy(__old_start, __old_finish, _M_get_Tp_allocator());
      ;
      _M_deallocate(__old_start,
      this->_M_impl._M_end_of_storage - __old_start);
      this->_M_impl._M_start = __new_start;
      this->_M_impl._M_finish = __new_finish;
      this->_M_impl._M_end_of_storage = __new_start + __len;
    }

  template<typename _Tp, typename _Alloc>
   
    void
    vector<_Tp, _Alloc>::
    _M_fill_insert(iterator __position, size_type __n, const value_type& __x)
    {
      if (__n != 0)
 {
   if (size_type(this->_M_impl._M_end_of_storage
   - this->_M_impl._M_finish) >= __n)
     {



       _Temporary_value __tmp(this, __x);
       value_type& __x_copy = __tmp._M_val();

       const size_type __elems_after = end() - __position;
       pointer __old_finish(this->_M_impl._M_finish);
       if (__elems_after > __n)
  {
    ;
    std::__uninitialized_move_a(__old_finish - __n,
           __old_finish,
           __old_finish,
           _M_get_Tp_allocator());
    this->_M_impl._M_finish += __n;
    ;
    std::move_backward(__position.base(), __old_finish - __n, __old_finish)
                                        ;
    std::fill(__position.base(), __position.base() + __n,
       __x_copy);
  }
       else
  {
    ;
    this->_M_impl._M_finish =
      std::__uninitialized_fill_n_a(__old_finish,
        __n - __elems_after,
        __x_copy,
        _M_get_Tp_allocator());
    ;
    std::__uninitialized_move_a(__position.base(), __old_finish,
           this->_M_impl._M_finish,
           _M_get_Tp_allocator());
    this->_M_impl._M_finish += __elems_after;
    ;
    std::fill(__position.base(), __old_finish, __x_copy);
  }
     }
   else
     {


       pointer __old_start = this->_M_impl._M_start;
       pointer __old_finish = this->_M_impl._M_finish;
       const pointer __pos = __position.base();

       const size_type __len =
  _M_check_len(__n, "vector::_M_fill_insert");
       const size_type __elems_before = __pos - __old_start;
       pointer __new_start(this->_M_allocate(__len));
       pointer __new_finish(__new_start);
       if (true)
  {

    std::__uninitialized_fill_n_a(__new_start + __elems_before,
      __n, __x,
      _M_get_Tp_allocator());
    __new_finish = pointer();

    __new_finish
      = std::__uninitialized_move_if_noexcept_a
      (__old_start, __pos, __new_start, _M_get_Tp_allocator());

    __new_finish += __n;

    __new_finish
      = std::__uninitialized_move_if_noexcept_a
      (__pos, __old_finish, __new_finish, _M_get_Tp_allocator());
  }
       if (false)
  {
    if (!__new_finish)
      std::_Destroy(__new_start + __elems_before,
      __new_start + __elems_before + __n,
      _M_get_Tp_allocator());
    else
      std::_Destroy(__new_start, __new_finish,
      _M_get_Tp_allocator());
    _M_deallocate(__new_start, __len);
    ;
  }
       std::_Destroy(__old_start, __old_finish, _M_get_Tp_allocator());
       ;
       _M_deallocate(__old_start,
       this->_M_impl._M_end_of_storage - __old_start);
       this->_M_impl._M_start = __new_start;
       this->_M_impl._M_finish = __new_finish;
       this->_M_impl._M_end_of_storage = __new_start + __len;
     }
 }
    }


  template<typename _Tp, typename _Alloc>
   
    void
    vector<_Tp, _Alloc>::
    _M_default_append(size_type __n)
    {
      if (__n != 0)
 {
   const size_type __size = size();
   size_type __navail = size_type(this->_M_impl._M_end_of_storage
      - this->_M_impl._M_finish);

   if (__size > max_size() || __navail > max_size() - __size)
     __builtin_unreachable();

   if (__navail >= __n)
     {
       ;
       this->_M_impl._M_finish =
  std::__uninitialized_default_n_a(this->_M_impl._M_finish,
       __n, _M_get_Tp_allocator());
       ;
     }
   else
     {


       pointer __old_start = this->_M_impl._M_start;
       pointer __old_finish = this->_M_impl._M_finish;

       const size_type __len =
  _M_check_len(__n, "vector::_M_default_append");
       pointer __new_start(this->_M_allocate(__len));
       if constexpr (_S_use_relocate())
  {
    if (true)
      {
        std::__uninitialized_default_n_a(__new_start + __size,
         __n, _M_get_Tp_allocator());
      }
    if (false)
      {
        _M_deallocate(__new_start, __len);
        ;
      }
    _S_relocate(__old_start, __old_finish,
         __new_start, _M_get_Tp_allocator());
  }
       else
  {
    pointer __destroy_from = pointer();
    if (true)
      {
        std::__uninitialized_default_n_a(__new_start + __size,
         __n, _M_get_Tp_allocator());
        __destroy_from = __new_start + __size;
        std::__uninitialized_move_if_noexcept_a(
         __old_start, __old_finish,
         __new_start, _M_get_Tp_allocator());
      }
    if (false)
      {
        if (__destroy_from)
   std::_Destroy(__destroy_from, __destroy_from + __n,
          _M_get_Tp_allocator());
        _M_deallocate(__new_start, __len);
        ;
      }
    std::_Destroy(__old_start, __old_finish,
    _M_get_Tp_allocator());
  }
       ;
       _M_deallocate(__old_start,
       this->_M_impl._M_end_of_storage - __old_start);
       this->_M_impl._M_start = __new_start;
       this->_M_impl._M_finish = __new_start + __size + __n;
       this->_M_impl._M_end_of_storage = __new_start + __len;
     }
 }
    }

  template<typename _Tp, typename _Alloc>
   
    bool
    vector<_Tp, _Alloc>::
    _M_shrink_to_fit()
    {
      if (capacity() == size())
 return false;
      ;
      return std::__shrink_to_fit_aux<vector>::_S_do_it(*this);
    }


  template<typename _Tp, typename _Alloc>
    template<typename _InputIterator>
     
      void
      vector<_Tp, _Alloc>::
      _M_range_insert(iterator __pos, _InputIterator __first,
        _InputIterator __last, std::input_iterator_tag)
      {
 if (__pos == end())
   {
     for (; __first != __last; ++__first)
       insert(end(), *__first);
   }
 else if (__first != __last)
   {
     vector __tmp(__first, __last, _M_get_Tp_allocator());
     insert(__pos,
     std::make_move_iterator(__tmp.begin()),
     std::make_move_iterator(__tmp.end()));
   }
      }

  template<typename _Tp, typename _Alloc>
    template<typename _ForwardIterator>
     
      void
      vector<_Tp, _Alloc>::
      _M_range_insert(iterator __position, _ForwardIterator __first,
        _ForwardIterator __last, std::forward_iterator_tag)
      {
 if (__first != __last)
   {
     const size_type __n = std::distance(__first, __last);
     if (size_type(this->_M_impl._M_end_of_storage
     - this->_M_impl._M_finish) >= __n)
       {
  const size_type __elems_after = end() - __position;
  pointer __old_finish(this->_M_impl._M_finish);
  if (__elems_after > __n)
    {
      ;
      std::__uninitialized_move_a(this->_M_impl._M_finish - __n,
      this->_M_impl._M_finish,
      this->_M_impl._M_finish,
      _M_get_Tp_allocator());
      this->_M_impl._M_finish += __n;
      ;
      std::move_backward(__position.base(), __old_finish - __n, __old_finish)
                                          ;
      std::copy(__first, __last, __position);
    }
  else
    {
      _ForwardIterator __mid = __first;
      std::advance(__mid, __elems_after);
      ;
      std::__uninitialized_copy_a(__mid, __last,
      this->_M_impl._M_finish,
      _M_get_Tp_allocator());
      this->_M_impl._M_finish += __n - __elems_after;
      ;
      std::__uninitialized_move_a(__position.base(),
      __old_finish,
      this->_M_impl._M_finish,
      _M_get_Tp_allocator());
      this->_M_impl._M_finish += __elems_after;
      ;
      std::copy(__first, __mid, __position);
    }
       }
     else
       {



  pointer __old_start = this->_M_impl._M_start;
  pointer __old_finish = this->_M_impl._M_finish;

  const size_type __len =
    _M_check_len(__n, "vector::_M_range_insert");
  pointer __new_start(this->_M_allocate(__len));
  pointer __new_finish(__new_start);
  if (true)
    {
      __new_finish
        = std::__uninitialized_move_if_noexcept_a
        (__old_start, __position.base(),
         __new_start, _M_get_Tp_allocator());
      __new_finish
        = std::__uninitialized_copy_a(__first, __last,
          __new_finish,
          _M_get_Tp_allocator());
      __new_finish
        = std::__uninitialized_move_if_noexcept_a
        (__position.base(), __old_finish,
         __new_finish, _M_get_Tp_allocator());
    }
  if (false)
    {
      std::_Destroy(__new_start, __new_finish,
      _M_get_Tp_allocator());
      _M_deallocate(__new_start, __len);
      ;
    }
  std::_Destroy(__old_start, __old_finish,
         _M_get_Tp_allocator());
  ;
  _M_deallocate(__old_start,
         this->_M_impl._M_end_of_storage - __old_start);
  this->_M_impl._M_start = __new_start;
  this->_M_impl._M_finish = __new_finish;
  this->_M_impl._M_end_of_storage = __new_start + __len;
       }
   }
      }



  template<typename _Alloc>
   
    void
    vector<bool, _Alloc>::
    _M_reallocate(size_type __n)
    {
      _Bit_pointer __q = this->_M_allocate(__n);
      iterator __start(std::__addressof(*__q), 0);
      iterator __finish(_M_copy_aligned(begin(), end(), __start));
      this->_M_deallocate();
      this->_M_impl._M_start = __start;
      this->_M_impl._M_finish = __finish;
      this->_M_impl._M_end_of_storage = __q + _S_nword(__n);
    }

  template<typename _Alloc>
   
    void
    vector<bool, _Alloc>::
    _M_fill_insert(iterator __position, size_type __n, bool __x)
    {
      if (__n == 0)
 return;
      if (capacity() - size() >= __n)
 {
   std::copy_backward(__position, end(),
        this->_M_impl._M_finish + difference_type(__n));
   std::fill(__position, __position + difference_type(__n), __x);
   this->_M_impl._M_finish += difference_type(__n);
 }
      else
 {
   const size_type __len =
     _M_check_len(__n, "vector<bool>::_M_fill_insert");
   _Bit_pointer __q = this->_M_allocate(__len);
   iterator __start(std::__addressof(*__q), 0);
   iterator __i = _M_copy_aligned(begin(), __position, __start);
   std::fill(__i, __i + difference_type(__n), __x);
   iterator __finish = std::copy(__position, end(),
     __i + difference_type(__n));
   this->_M_deallocate();
   this->_M_impl._M_end_of_storage = __q + _S_nword(__len);
   this->_M_impl._M_start = __start;
   this->_M_impl._M_finish = __finish;
 }
    }

  template<typename _Alloc>
    template<typename _ForwardIterator>
     
      void
      vector<bool, _Alloc>::
      _M_insert_range(iterator __position, _ForwardIterator __first,
        _ForwardIterator __last, std::forward_iterator_tag)
      {
 if (__first != __last)
   {
     size_type __n = std::distance(__first, __last);
     if (capacity() - size() >= __n)
       {
  std::copy_backward(__position, end(),
       this->_M_impl._M_finish
       + difference_type(__n));
  std::copy(__first, __last, __position);
  this->_M_impl._M_finish += difference_type(__n);
       }
     else
       {
  const size_type __len =
    _M_check_len(__n, "vector<bool>::_M_insert_range");
  _Bit_pointer __q = this->_M_allocate(__len);
  iterator __start(std::__addressof(*__q), 0);
  iterator __i = _M_copy_aligned(begin(), __position, __start);
  __i = std::copy(__first, __last, __i);
  iterator __finish = std::copy(__position, end(), __i);
  this->_M_deallocate();
  this->_M_impl._M_end_of_storage = __q + _S_nword(__len);
  this->_M_impl._M_start = __start;
  this->_M_impl._M_finish = __finish;
       }
   }
      }

  template<typename _Alloc>
   
    void
    vector<bool, _Alloc>::
    _M_insert_aux(iterator __position, bool __x)
    {
      if (this->_M_impl._M_finish._M_p != this->_M_impl._M_end_addr())
 {
   std::copy_backward(__position, this->_M_impl._M_finish,
        this->_M_impl._M_finish + 1);
   *__position = __x;
   ++this->_M_impl._M_finish;
 }
      else
 {
   const size_type __len =
     _M_check_len(size_type(1), "vector<bool>::_M_insert_aux");
   _Bit_pointer __q = this->_M_allocate(__len);
   iterator __start(std::__addressof(*__q), 0);
   iterator __i = _M_copy_aligned(begin(), __position, __start);
   *__i++ = __x;
   iterator __finish = std::copy(__position, end(), __i);
   this->_M_deallocate();
   this->_M_impl._M_end_of_storage = __q + _S_nword(__len);
   this->_M_impl._M_start = __start;
   this->_M_impl._M_finish = __finish;
 }
    }

  template<typename _Alloc>
   
    typename vector<bool, _Alloc>::iterator
    vector<bool, _Alloc>::
    _M_erase(iterator __position)
    {
      if (__position + 1 != end())
        std::copy(__position + 1, end(), __position);
      --this->_M_impl._M_finish;
      return __position;
    }

  template<typename _Alloc>
   
    typename vector<bool, _Alloc>::iterator
    vector<bool, _Alloc>::
    _M_erase(iterator __first, iterator __last)
    {
      if (__first != __last)
 _M_erase_at_end(std::copy(__last, end(), __first));
      return __first;
    }


  template<typename _Alloc>
   
    bool
    vector<bool, _Alloc>::
    _M_shrink_to_fit()
    {
      if (capacity() - size() < int(_S_word_bit))
 return false;
      if (true)
 {
   if (size_type __n = size())
     _M_reallocate(__n);
   else
     {
       this->_M_deallocate();
       this->_M_impl._M_reset();
     }
   return true;
 }
      if (false)
 { return false; }
    }




}



namespace std __attribute__ ((__visibility__ ("default")))
{


  template<typename _Alloc>
    size_t
    hash<std::vector<bool, _Alloc>>::
    operator()(const std::vector<bool, _Alloc>& __b) const noexcept
    {
      size_t __hash = 0;
      const size_t __words = __b.size() / _S_word_bit;
      if (__words)
 {
   const size_t __clength = __words * sizeof(_Bit_type);
   __hash = std::_Hash_impl::hash(__b._M_impl._M_start._M_p, __clength);
 }

      const size_t __extrabits = __b.size() % _S_word_bit;
      if (__extrabits)
 {
   _Bit_type __hiword = *__b._M_impl._M_finish._M_p;
   __hiword &= ~((~static_cast<_Bit_type>(0)) << __extrabits);

   const size_t __clength
     = (__extrabits + 8 - 1) / 8;
   if (__words)
     __hash = std::_Hash_impl::hash(&__hiword, __clength, __hash);
   else
     __hash = std::_Hash_impl::hash(&__hiword, __clength);
 }

      return __hash;
    }


}







namespace std __attribute__ ((__visibility__ ("default")))
{

  namespace pmr {
    template<typename _Tp> class polymorphic_allocator;
    template<typename _Tp>
      using vector = std::vector<_Tp, polymorphic_allocator<_Tp>>;
  }








}


inline uint32_t get_operand_id(uint32_t operand) { return (operand); }

inline const uint32_t get_operand_src_format(const std::uint32_t operand_id) { return unpack_src_format[operand_id]; }

inline const uint32_t get_operand_dst_format(const std::uint32_t operand_id) { return unpack_dst_format[operand_id]; }

inline const uint32_t get_operand_num_faces(const std::uint32_t operand_id) {
    return (uint32_t)unpack_tile_num_faces[operand_id];
}

inline const uint32_t get_operand_partial_face(const std::uint32_t operand_id) {
    return (uint32_t)unpack_partial_face[operand_id];
}

inline const uint32_t get_operand_face_r_dim(const std::uint32_t operand_id) {
    return (uint32_t)unpack_tile_face_r_dim[operand_id];
}

inline const uint32_t get_operand_narrow_tile(const std::uint32_t operand_id) {
    return (uint32_t)unpack_narrow_tile[operand_id];
}

inline const uint32_t get_operand_tile_r_dim(const std::uint32_t operand_id) {
    return (uint32_t)unpack_tile_r_dim[operand_id];
}

inline const uint32_t get_operand_tile_c_dim(const std::uint32_t operand_id) {
    return (uint32_t)unpack_tile_c_dim[operand_id];
}
template <bool untilize_en = false, bool skip_inputs = false>
inline void llk_math_hw_configure_disaggregated(const std::uint32_t srca_operand, const std::uint32_t srcb_operand) {
    if constexpr (skip_inputs == false) {
        std::uint32_t srca_operand_id = get_operand_id(srca_operand);
        std::uint32_t srcb_operand_id = get_operand_id(srcb_operand);
        _llk_math_hw_configure_<untilize_en>(unpack_dst_format[srca_operand_id], unpack_dst_format[srcb_operand_id]);
    }
}

inline void llk_math_wait_for_dest_available() {
    ;
    _llk_math_wait_for_dest_available_<DstSync::SyncHalf>();
    ;
}

template <bool is_fp32_dest_acc_en>
inline void llk_math_dest_section_done() {
    _llk_math_dest_section_done_<DstSync::SyncHalf, is_fp32_dest_acc_en>();
}

template <bool is_fp32_dest_acc_en>
inline void llk_math_pack_sync_init() {
    _llk_math_pack_sync_init_<DstSync::SyncHalf, is_fp32_dest_acc_en>();
}

template <bool mail2math = true, bool mail2pack = true>
inline void llk_math_get_tile(std::uint32_t operand, std::uint32_t tile_index, std::uint32_t* p_tile) {
    _llk_math_get_tile_<mail2math, mail2pack>(tile_index, p_tile);
}

template <bool mail2math = true, bool mail2pack = true>
inline void llk_math_release_tile(std::uint32_t operand) {
    _llk_math_release_tile_<mail2math, mail2pack>();
}

inline void llk_math_debug_dump(std::uint8_t* data, std::uint32_t byte_size) { _llk_math_debug_dump_(data, byte_size); }

inline void llk_math_debug_dump_seek(std::uint8_t offset) { _llk_math_debug_dump_seek_(offset); }

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void llk_math_reconfig_data_format_srca(const std::uint32_t srca_new_operand) {
    std::uint32_t new_srca_operand_id = get_operand_id(srca_new_operand);
    _llk_math_reconfig_data_format_srca_<is_fp32_dest_acc_en, to_from_int8>(unpack_dst_format[new_srca_operand_id]);
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void llk_math_reconfig_data_format_srcb(const std::uint32_t srcb_new_operand) {
    std::uint32_t new_srcb_operand_id = get_operand_id(srcb_new_operand);
    _llk_math_reconfig_data_format_srcb_<is_fp32_dest_acc_en, to_from_int8>(unpack_dst_format[new_srcb_operand_id]);
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void llk_math_reconfig_data_format(const std::uint32_t srca_new_operand, const std::uint32_t srcb_new_operand) {
    std::uint32_t new_srca_operand_id = get_operand_id(srca_new_operand);
    std::uint32_t new_srcb_operand_id = get_operand_id(srcb_new_operand);

    _llk_math_reconfig_data_format_<is_fp32_dest_acc_en, to_from_int8>(
        unpack_dst_format[new_srca_operand_id], unpack_dst_format[new_srcb_operand_id]);
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void llk_math_reconfig_data_format(
    const std::uint32_t srca_old_operand,
    const std::uint32_t srca_new_operand,
    const std::uint32_t srcb_old_operand,
    const std::uint32_t srcb_new_operand) {
    std::uint32_t old_srca_operand_id = get_operand_id(srca_old_operand);
    std::uint32_t new_srca_operand_id = get_operand_id(srca_new_operand);
    std::uint32_t old_srcb_operand_id = get_operand_id(srcb_old_operand);
    std::uint32_t new_srcb_operand_id = get_operand_id(srcb_new_operand);

    if ((unpack_dst_format[old_srca_operand_id] != unpack_dst_format[new_srca_operand_id]) &&
        (unpack_dst_format[old_srcb_operand_id] != unpack_dst_format[new_srcb_operand_id])) {
        llk_math_reconfig_data_format<is_fp32_dest_acc_en, to_from_int8>(srca_new_operand, srcb_new_operand);
    } else if ((unpack_dst_format[old_srca_operand_id] != unpack_dst_format[new_srca_operand_id])) {
        llk_math_reconfig_data_format_srca<is_fp32_dest_acc_en, to_from_int8>(srca_new_operand);
    } else if ((unpack_dst_format[old_srcb_operand_id] != unpack_dst_format[new_srcb_operand_id])) {
        llk_math_reconfig_data_format_srcb<is_fp32_dest_acc_en, to_from_int8>(srcb_new_operand);
    }
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void llk_math_reconfig_data_format_srca(
    const std::uint32_t srca_old_operand, const std::uint32_t srca_new_operand) {
    std::uint32_t old_srca_operand_id = get_operand_id(srca_old_operand);
    std::uint32_t new_srca_operand_id = get_operand_id(srca_new_operand);

    if ((unpack_dst_format[old_srca_operand_id] != unpack_dst_format[new_srca_operand_id])) {
        llk_math_reconfig_data_format_srca<is_fp32_dest_acc_en, to_from_int8>(srca_new_operand);
    }
}

template <bool is_fp32_dest_acc_en, bool to_from_int8 = false>
inline void llk_math_reconfig_data_format_srcb(
    const std::uint32_t srcb_old_operand, const std::uint32_t srcb_new_operand) {
    std::uint32_t old_srcb_operand_id = get_operand_id(srcb_old_operand);
    std::uint32_t new_srcb_operand_id = get_operand_id(srcb_new_operand);

    if ((unpack_dst_format[old_srcb_operand_id] != unpack_dst_format[new_srcb_operand_id])) {
        llk_math_reconfig_data_format_srcb<is_fp32_dest_acc_en, to_from_int8>(srcb_new_operand);
    }
}

inline std::uint32_t llk_math_get_compute_special_value_flags() { return _llk_math_get_compute_special_value_flags_(); }

inline std::uint32_t llk_math_get_compute_special_value_flags_fpu(std::uint32_t special_value_flags_reg) {
    constexpr std::uint32_t special_value_flags_fpu_mask = 0x7;
    constexpr std::uint32_t special_value_flags_fpu_shift = 4;
    return (special_value_flags_reg & special_value_flags_fpu_mask) >> special_value_flags_fpu_shift;
}

inline std::uint32_t llk_math_get_compute_special_value_flags_sfpu(std::uint32_t special_value_flags_reg) {
    constexpr std::uint32_t special_value_flags_sfpu_mask = 0xf;
    constexpr std::uint32_t special_value_flags_sfpu_shift = 0;
    return (special_value_flags_reg & special_value_flags_sfpu_mask) >> special_value_flags_sfpu_shift;
}

inline void llk_math_clear_compute_special_value_flags() { _llk_math_clear_compute_special_value_flags_(); }

inline void llk_math_store_compute_special_value_flags_to_l1(std::uint32_t l1_addr) {
    volatile __attribute__((rvtt_l1_ptr)) std::uint32_t* l1_addr_ptr = reinterpret_cast<volatile __attribute__((rvtt_l1_ptr)) std::uint32_t*>(l1_addr);
    l1_addr_ptr[0] = _llk_math_get_compute_special_value_flags_();
}




       





       
using namespace ckernel;

template <int MATH_FIDELITY_DESC, DstTileFaceLayout FaceLayout = DstTileFaceLayout::ColMajor, int THROTTLE_LEVEL>
inline void matmul_configure_addrmod(
    const bool transpose,
    const std::uint32_t ct_dim,
    const std::uint32_t rt_dim,
    const std::uint32_t kt_dim,
    const std::uint32_t in0_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in0_tile_c_dim = TILE_C_DIM,
    const std::uint32_t in1_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in1_tile_c_dim = TILE_C_DIM,
    const bool partial_face = false)
{
    constexpr int NUM_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    constexpr bool high_fidelity = (NUM_FIDELITY_PHASES > 0);
    constexpr int FIDELITY_INCREMENT = high_fidelity ? get_math_fidelity_increment(MATH_FIDELITY_DESC) : 0;

    const bool is_in0_16x32 = (in0_tile_r_dim <= FACE_R_DIM) && (in0_tile_c_dim > FACE_C_DIM);
    const bool is_in0_32x16 = (in0_tile_r_dim > FACE_R_DIM) && (in0_tile_c_dim <= FACE_C_DIM);
    const bool is_in1_32x16 = (in1_tile_r_dim > FACE_R_DIM) && (in1_tile_c_dim <= FACE_C_DIM);

    static_assert(FaceLayout == DstTileFaceLayout::RowMajor, "FaceLayout must be RowMajor");
    addr_mod_t {
        .srca = {.incr = 0, .clr = 0, .cr = 0},
        .srcb = {.incr = 8, .clr = 0, .cr = 0},
        .dest = {.incr = 8, .clr = 0, .cr = 0},
    }
        .set(ADDR_MOD_0);


    addr_mod_t {
        .srca = {.incr = 0, .clr = 0, .cr = 0},
        .srcb = {.incr = 8, .clr = 0, .cr = 0},
        .dest = {.incr = 8, .clr = 0, .cr = 0},
        .bias = {.incr = 1},
    }
        .set(ADDR_MOD_3);


    addr_mod_t {
        .srca = {.incr = 0, .clr = 1, .cr = 1},
        .srcb = {.incr = 0, .clr = 1, .cr = 1},
        .dest = {.incr = 0, .clr = 1, .cr = 1},
        .fidelity = {.incr = FIDELITY_INCREMENT, .clr = 0},
        .bias = {.incr = 1},
    }
        .set(ADDR_MOD_5);

    if constexpr (THROTTLE_LEVEL)
    {

        addr_mod_t {
            .srca = {.incr = 0, .clr = 1, .cr = 1},
            .srcb = {.incr = 0, .clr = 1, .cr = 1},
            .dest = {.incr = 0, .clr = 1, .cr = 1},
            .fidelity = {.incr = 0, .clr = 1},
            .bias = {.incr = 1},
        }
            .set(ADDR_MOD_6);
    }

    const uint8_t srca_increment = transpose == false ? 16 : 32;
    const uint8_t srca_set = transpose == false ? 32 : 16;
    const uint8_t dest_increment = transpose == false ? 8 : 24;

    if ((is_in0_16x32 && (!is_in1_32x16)) || is_in0_32x16)
    {
        if (transpose)
        {
            addr_mod_t {
                .srca = {.incr = 32, .clr = 0, .cr = 0},
                .srcb = {.incr = 0, .clr = 0, .cr = 1},
                .dest = {.incr = 8, .clr = 0, .cr = 0},
            }
                .set(ADDR_MOD_1);
        }
        else
        {
            addr_mod_t {
                .srca = {.incr = 16, .clr = 0, .cr = 0},
                .srcb = {.incr = 0, .clr = 0, .cr = 1},
                .dest = {.incr = 8, .clr = 0, .cr = 0},
            }
                .set(ADDR_MOD_1);
        }
    }
    else
    {
        if (is_in1_32x16)
        {
            addr_mod_t {
                .srca = {.incr = 16, .clr = 0, .cr = 0},
                .srcb = {.incr = 8, .clr = 0, .cr = 0},
                .dest = {.incr = 0, .clr = 0, .cr = 1},
            }
                .set(ADDR_MOD_1);
        }
        else
        {
            if (transpose)
            {
                addr_mod_t {
                    .srca = {.incr = 32, .clr = 0, .cr = 0},
                    .srcb = {.incr = 0, .clr = 0, .cr = 1},
                    .dest = {.incr = 8, .clr = 0, .cr = 0},
                }
                    .set(ADDR_MOD_1);
            }
            else
            {
                addr_mod_t {

                    .srca = {.incr = 16, .clr = 0, .cr = 0},
                    .srcb = {.incr = 0, .clr = 0, .cr = 1},
                    .dest = {.incr = 8, .clr = 0, .cr = 0},
                }
                    .set(ADDR_MOD_1);
            }
        }
    }

    if (is_in1_32x16)
    {
        addr_mod_t {
            .srca = {.incr = 16, .clr = 0, .cr = 0}, .srcb = {.incr = 8, .clr = 0, .cr = 0}, .dest = {.incr = 0, .clr = 0, .cr = 1},
        }
            .set(ADDR_MOD_2);
    }
    else if (is_in0_16x32 || is_in0_32x16)
    {
        if (partial_face)
        {
            if (transpose)
            {
                addr_mod_t {
                    .srca = {.incr = 32, .clr = 0, .cr = 0},
                    .srcb = {.incr = 0, .clr = 0, .cr = 0},
                    .dest = {.incr = 16, .clr = 0, .cr = 0},
                    .bias = {.incr = 1},
                }
                    .set(ADDR_MOD_2);
            }
            else
            {
                addr_mod_t {
                    .srca = {.incr = 16, .clr = 0, .cr = 0},
                    .srcb = {.incr = 0, .clr = 0, .cr = 0},
                    .dest = {.incr = 16, .clr = 0, .cr = 0},
                    .bias = {.incr = 1},
                }
                    .set(ADDR_MOD_2);
            }
        }
        else
        {
            if (transpose)
            {
                addr_mod_t {
                    .srca = {.incr = 32, .clr = 0, .cr = 0},
                    .srcb = {.incr = 0, .clr = 0, .cr = 1},
                    .dest = {.incr = 8, .clr = 0, .cr = 0},
                }
                    .set(ADDR_MOD_2);
            }
            else
            {
                addr_mod_t {
                    .srca = {.incr = 16, .clr = 0, .cr = 0},
                    .srcb = {.incr = 0, .clr = 0, .cr = 1},
                    .dest = {.incr = 8, .clr = 0, .cr = 0},
                }
                    .set(ADDR_MOD_2);
            }
        }
    }
    else
    {
        addr_mod_t {
            .srca = {.incr = 0, .clr = 0, .cr = 1},
            .srcb = {.incr = 32, .clr = 0, .cr = 1},
            .dest = {.incr = 8, .clr = 0, .cr = 0},
        }
            .set(ADDR_MOD_2);
    }

    if (is_in0_16x32)
    {
        if (partial_face)
        {
            if (transpose)
            {
                addr_mod_t {
                    .srca = {.incr = 16, .clr = 0, .cr = 1},
                    .srcb = {.incr = 16, .clr = 0, .cr = 0},
                    .dest = {.incr = 0, .clr = 1, .cr = 0},
                    .bias = {.incr = 1},
                }
                    .set(ADDR_MOD_4);
            }
            else
            {
                addr_mod_t {
                    .srca = {.incr = 16, .clr = 0, .cr = 0},
                    .srcb = {.incr = 16, .clr = 0, .cr = 0},
                    .dest = {.incr = 0, .clr = 1, .cr = 0},
                    .bias = {.incr = 1},
                }
                    .set(ADDR_MOD_4);
            }
        }
        else
        {
            if (transpose)
            {
                addr_mod_t {
                    .srca = {.incr = 16, .clr = 0, .cr = 1},
                    .srcb = {.incr = 16, .clr = 0, .cr = 1},
                    .dest = {.incr = 0, .clr = 0, .cr = 1},
                    .bias = {.incr = 1},
                }
                    .set(ADDR_MOD_4);
            }
            else
            {
                addr_mod_t {
                    .srca = {.incr = 16, .clr = 0, .cr = 0},
                    .srcb = {.incr = 16, .clr = 0, .cr = 1},
                    .dest = {.incr = 0, .clr = 0, .cr = 1},
                    .bias = {.incr = 1},
                }
                    .set(ADDR_MOD_4);
            }
        }
    }
    else if (is_in0_32x16)
    {
        addr_mod_t {
            .srca = {.incr = 0, .clr = 0, .cr = 1},
            .srcb = {.incr = 16, .clr = 0, .cr = 1},
            .dest = {.incr = 8, .clr = 0, .cr = 0},
            .bias = {.incr = 1},
        }
            .set(ADDR_MOD_4);
    }
    else if (is_in1_32x16)
    {
        addr_mod_t {
            .srca = {.incr = 0, .clr = 0, .cr = 1},
            .srcb = {.incr = 8, .clr = 0, .cr = 0},
            .dest = {.incr = 16, .clr = 0, .cr = 1},
            .bias = {.incr = 1},
        }
            .set(ADDR_MOD_4);
    }
    else
    {
        if (transpose)
        {
            addr_mod_t {
                .srca = {.incr = 16, .clr = 0, .cr = 1},
                .srcb = {.incr = 48, .clr = 0, .cr = 1},
                .dest = {.incr = 0, .clr = 0, .cr = 1},
                .bias = {.incr = 1},
            }
                .set(ADDR_MOD_4);
        }
        else
        {
            addr_mod_t {
                .srca = {.incr = 32, .clr = 0, .cr = 1},

                .srcb = {.incr = 48, .clr = 0, .cr = 1},
                .dest = {.incr = 0, .clr = 0, .cr = 1},
                .bias = {.incr = 1},
            }
                .set(ADDR_MOD_4);
        }
    }
}

template <int NUM_FIDELITY_PHASES, DstTileFaceLayout FaceLayout = DstTileFaceLayout::ColMajor>
inline void matmul_configure_mop(
    bool transpose,
    const std::uint32_t ct_dim,
    const std::uint32_t rt_dim,
    const std::uint32_t kt_dim,
    const std::uint32_t in0_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in0_tile_c_dim = TILE_C_DIM,
    const std::uint32_t in1_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in1_tile_c_dim = TILE_C_DIM,
    const bool partial_face = false)
{
    constexpr bool high_fidelity = NUM_FIDELITY_PHASES > 0;

    const bool reuse_a = ct_dim >= rt_dim;
    const std::uint32_t t_dim = reuse_a ? rt_dim : ct_dim;

    const bool is_in0_16x32 = (in0_tile_r_dim <= FACE_R_DIM) && (in0_tile_c_dim > FACE_C_DIM);
    const bool is_in1_32x16 = (in1_tile_r_dim > FACE_R_DIM) && (in1_tile_c_dim <= FACE_C_DIM);
    const bool is_in0_32x16 = (in0_tile_r_dim > FACE_R_DIM) && (in0_tile_c_dim <= FACE_C_DIM);
    const bool is_in1_16x32 = (in1_tile_r_dim <= FACE_R_DIM) && (in1_tile_c_dim > FACE_C_DIM);

    const std::uint32_t replay_buf_len =
        (is_in0_16x32 && is_in1_32x16) ? 4 : ((is_in0_16x32 || is_in1_32x16 || is_in0_32x16 || is_in1_16x32) ? (partial_face ? 4 : 8) : 16);

    lltt::record(ckernel::math::replay_buf_offset, replay_buf_len);

    if (is_in1_32x16)
    {
        if (is_in0_16x32)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        }
    }
    else if (is_in0_16x32 || is_in0_32x16)
    {
        if (partial_face)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))))



                  ;

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        }
    }
    else
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        if (!is_in1_16x32)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        }
    }

    if constexpr (high_fidelity)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
    }
    else
    {
        if (reuse_a)
        {
            if (t_dim > 1)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
        }
        else
        {
            if (t_dim > 1)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
        }
    }


    constexpr uint inner_loops = high_fidelity ? NUM_FIDELITY_PHASES : 1;
    ckernel_template tmp(1 , inner_loops, lltt::replay_insn(ckernel::math::replay_buf_offset, replay_buf_len));

    if constexpr (high_fidelity)
    {
        if (t_dim > 1)
        {
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_F) << 0))));
        }
        else
        {
            if (reuse_a)
            {
                tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))));
            }
            else
            {
                tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))));
            }
        }
    }
    tmp.program(instrn_buffer);
}

template <int THROTTLE_LEVEL, bool HIGH_FIDELITY>
void run_throttled_sequence(const std::uint32_t t_dim, const bool reuse_a)
{
    if constexpr (THROTTLE_LEVEL == 1)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
    }
    else if constexpr (THROTTLE_LEVEL == 2)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
    }
    else if constexpr (THROTTLE_LEVEL == 3)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
    }
    else if constexpr (THROTTLE_LEVEL == 4)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        if constexpr (HIGH_FIDELITY)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        }
        else
        {
            if (t_dim > 1)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
            else if (reuse_a)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
        }
    }
    else if constexpr (THROTTLE_LEVEL == 5)
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        if constexpr (HIGH_FIDELITY)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
        }
        else
        {
            if (t_dim > 1)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
            else if (reuse_a)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x26 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))))));
            }
        }
    }
}
template <int NUM_FIDELITY_PHASES, DstTileFaceLayout FaceLayout = DstTileFaceLayout::ColMajor, int THROTTLE_LEVEL>
inline void matmul_configure_mop_throttled(
    bool transpose,
    const std::uint32_t ct_dim,
    const std::uint32_t rt_dim,
    const std::uint32_t kt_dim,
    const std::uint32_t in0_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in0_tile_c_dim = TILE_C_DIM,
    const std::uint32_t in1_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in1_tile_c_dim = TILE_C_DIM,
    const bool partial_face = false)
{
    constexpr bool high_fidelity = NUM_FIDELITY_PHASES > 0;
    static_assert((THROTTLE_LEVEL > 0) && (THROTTLE_LEVEL <= 5), "MM throttling only enabled for THROTTLE_LEVEL={1,2,3,4,5}");

    const bool reuse_a = ct_dim >= rt_dim;
    const std::uint32_t t_dim = reuse_a ? rt_dim : ct_dim;

    const bool is_in0_16x32 = (in0_tile_r_dim <= FACE_R_DIM) && (in0_tile_c_dim > FACE_C_DIM);
    const bool is_in1_32x16 = (in1_tile_r_dim > FACE_R_DIM) && (in1_tile_c_dim <= FACE_C_DIM);
    const bool is_in0_32x16 = (in0_tile_r_dim > FACE_R_DIM) && (in0_tile_c_dim <= FACE_C_DIM);
    const bool is_in1_16x32 = (in1_tile_r_dim <= FACE_R_DIM) && (in1_tile_c_dim > FACE_C_DIM);

    constexpr std::uint32_t replay_buff_len_throttle = (THROTTLE_LEVEL > 3) ? (16) : ((THROTTLE_LEVEL > 1) ? (3 + THROTTLE_LEVEL * 4) : 10);
    const std::uint32_t replay_buf_len =
        (is_in0_16x32 && is_in1_32x16) ? 4
                                       : ((is_in0_16x32 || is_in1_32x16 || is_in0_32x16 || is_in1_16x32) ? (partial_face ? 4 : 8) : replay_buff_len_throttle);

    lltt::record(ckernel::math::replay_buf_offset, replay_buf_len);
    if (!is_in1_32x16 && !is_in1_16x32 && !is_in0_32x16 && !is_in0_16x32)
    {
        run_throttled_sequence<THROTTLE_LEVEL, high_fidelity>(t_dim, reuse_a);
    }

    constexpr uint outer_loops = (THROTTLE_LEVEL > 3) ? 2 : (high_fidelity ? NUM_FIDELITY_PHASES : 1);
    const uint inner_loops = (!is_in1_16x32) ? 2 : 1;
    constexpr uint loop_instruction_0 = (THROTTLE_LEVEL == 5) ? lltt::replay_insn(ckernel::math::replay_buf_offset + 1, 8)
                                        : (THROTTLE_LEVEL == 4) ? lltt::replay_insn(ckernel::math::replay_buf_offset + 2, 6)
                                                                : lltt::replay_insn(ckernel::math::replay_buf_offset, replay_buff_len_throttle);
    constexpr uint loop_instruction_1 = (THROTTLE_LEVEL == 5) ? lltt::replay_insn(ckernel::math::replay_buf_offset + 9, 4)
                                        : (THROTTLE_LEVEL == 4) ? lltt::replay_insn(ckernel::math::replay_buf_offset + 8, 4)
                                                                : ((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_0) << 15) + ((0) << 0)));
    ckernel_template tmp(outer_loops, inner_loops, loop_instruction_0, loop_instruction_1);

    if constexpr (THROTTLE_LEVEL == 5)
    {
        tmp.set_last_inner_loop_instr(lltt::replay_insn(ckernel::math::replay_buf_offset, 4));
        tmp.set_last_outer_loop_instr(lltt::replay_insn(ckernel::math::replay_buf_offset + 13, 3));
    }
    else if constexpr (THROTTLE_LEVEL == 4)
    {
        tmp.set_last_inner_loop_instr(lltt::replay_insn(ckernel::math::replay_buf_offset, 4));
        tmp.set_last_outer_loop_instr(lltt::replay_insn(ckernel::math::replay_buf_offset + 12, 4));
    }
    else
    {
        if constexpr (high_fidelity)
        {
            tmp.set_last_inner_loop_instr(((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((ADDR_MOD_1) << 15) + ((0) << 0))));
        }

        if (t_dim > 1)
        {
            tmp.set_last_outer_loop_instr(((0x26 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 19) + ((high_fidelity ? ADDR_MOD_2 : ADDR_MOD_1) << 15) + ((0) << 0))));
        }
        else if (reuse_a)
        {
            tmp.set_last_outer_loop_instr(((0x26 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 19) + ((high_fidelity ? ADDR_MOD_2 : ADDR_MOD_1) << 15) + ((0) << 0))));
        }
        else
        {
            tmp.set_last_outer_loop_instr(((0x26 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 19) + ((high_fidelity ? ADDR_MOD_2 : ADDR_MOD_1) << 15) + ((0) << 0))));
        }
    }

    tmp.program(instrn_buffer);
}

template <int MATH_FIDELITY_DESC, DstTileFaceLayout FaceLayout = DstTileFaceLayout::ColMajor, int THROTTLE_LEVEL = 0>
inline void _llk_math_matmul_init_(
    const std::uint32_t in0_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in0_tile_c_dim = TILE_C_DIM,
    const std::uint32_t in1_tile_r_dim = TILE_R_DIM,
    const std::uint32_t in1_tile_c_dim = TILE_C_DIM,
    const bool partial_face = false,
    const std::uint32_t transpose = 0,
    const std::uint32_t ct_dim = 1,
    const std::uint32_t rt_dim = 1,
    const std::uint32_t kt_dim = 1)
{
    matmul_configure_addrmod<MATH_FIDELITY_DESC, FaceLayout, THROTTLE_LEVEL>(
        transpose, ct_dim, rt_dim, kt_dim, in0_tile_r_dim, in0_tile_c_dim, in1_tile_r_dim, in1_tile_c_dim, partial_face);
    const bool reuse_a = ct_dim >= rt_dim;
    const std::uint32_t t_dim = reuse_a ? rt_dim : ct_dim;
    if (t_dim > 1)
    {
        if (reuse_a)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0x2) << 0))))));
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0x1) << 0))))));
        }
    }
    else
    {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0) << 0))))));
    }

    constexpr int MATH_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    if constexpr (THROTTLE_LEVEL > 0)
    {
        matmul_configure_mop_throttled<MATH_FIDELITY_PHASES, FaceLayout, THROTTLE_LEVEL>(
            transpose > 0, ct_dim, rt_dim, kt_dim, in0_tile_r_dim, in0_tile_c_dim, in1_tile_r_dim, in1_tile_c_dim, partial_face);
    }
    else
    {
        matmul_configure_mop<MATH_FIDELITY_PHASES, FaceLayout>(
            transpose > 0, ct_dim, rt_dim, kt_dim, in0_tile_r_dim, in0_tile_c_dim, in1_tile_r_dim, in1_tile_c_dim, partial_face);
    }
    math::reset_counters(p_setrwc::SET_ABD_F);
}

template <int MATH_FIDELITY_DESC, DstTileFaceLayout FaceLayout = DstTileFaceLayout::ColMajor, int THROTTLE_LEVEL = 0>
inline void _llk_math_matmul_(
    uint dst_index, const bool transpose = false, const std::uint32_t ct_dim = 1, const std::uint32_t rt_dim = 1, const std::uint32_t kt_dim = 1)
{
    const bool reuse_a = ct_dim >= rt_dim;
    const std::uint32_t t_dim = reuse_a ? rt_dim : ct_dim;
    const std::uint32_t rut_dim = reuse_a ? ct_dim : rt_dim;
    constexpr int NUM_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    constexpr bool high_fidelity = NUM_FIDELITY_PHASES > 0;

    for (uint t = 0; t < t_dim; t++)
    {
        for (uint rut = 0; rut < rut_dim; rut++)
        {
            math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(dst_index + (reuse_a ? ct_dim * t + rut : t + rut * ct_dim));

            if (t_dim == 1)
            {
                if constexpr (THROTTLE_LEVEL > 3 && high_fidelity)
                {
                    for (uint phase = 0; phase < NUM_FIDELITY_PHASES; phase++)
                    {
                        ckernel_template::run(instrn_buffer);
                    }
                    if (reuse_a)
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))))));
                    }
                    else
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))))));
                    }
                }
                else
                {
                    ckernel_template::run(instrn_buffer);
                }


                if (rut == (rut_dim - 1))
                {
                    if (reuse_a)
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                    }
                    else
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                    }
                }
            }
            else
            {
                if constexpr (THROTTLE_LEVEL > 3 && high_fidelity)
                {
                    for (uint phase = 0; phase < NUM_FIDELITY_PHASES; phase++)
                    {
                        ckernel_template::run(instrn_buffer);
                    }
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))))));
                }
                else
                {
                    ckernel_template::run(instrn_buffer);
                }

                if ((t + 1) < t_dim)
                {

                    if (reuse_a)
                    {
                        if (rut == (rut_dim - 1))
                        {

                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 0))))));
                        }
                        else
                        {

                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                        }
                    }
                    else
                    {
                        if (rut == (rut_dim - 1))
                        {

                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 0))))));
                        }
                        else
                        {

                            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                        }
                    }

                    math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(
                        dst_index + (reuse_a ? ct_dim * (t + 1) + rut : t + 1 + rut * ct_dim));
                    if constexpr (THROTTLE_LEVEL > 3 && high_fidelity)
                    {
                        for (uint phase = 0; phase < NUM_FIDELITY_PHASES; phase++)
                        {
                            ckernel_template::run(instrn_buffer);
                        }
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD_F) << 0))))));
                    }
                    else
                    {
                        ckernel_template::run(instrn_buffer);
                    }
                }

                if (reuse_a)
                {

                    if (rut == (rut_dim - 1))
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 0))))));
                    }
                    else
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                    }
                }
                else
                {

                    if (rut == (rut_dim - 1))
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 0))))));
                    }
                    else
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));
                    }
                }
            }
        }
        t++;
    }
}





template <int NUM_FIDELITY_PHASES, int THROTTLE_LEVEL = 0>
inline void llk_math_matmul_init(
    const std::uint32_t operandA,
    const std::uint32_t operandB,
    const std::uint32_t transpose = 0,
    const std::uint32_t ct_dim = 1,
    const std::uint32_t rt_dim = 1,
    const std::uint32_t kt_dim = 1) {
    const std::uint32_t in0_id = get_operand_id(operandA);
    const std::uint32_t in1_id = get_operand_id(operandB);



    const bool partial_face = 0;

    const std::uint32_t in0_tile_r_dim = get_operand_tile_r_dim(in0_id);
    const std::uint32_t in0_tile_c_dim = get_operand_tile_c_dim(in0_id);
    const std::uint32_t in1_tile_r_dim = get_operand_tile_r_dim(in1_id);
    const std::uint32_t in1_tile_c_dim = get_operand_tile_c_dim(in1_id);

    _llk_math_matmul_init_<NUM_FIDELITY_PHASES, DstTileFaceLayout::RowMajor, THROTTLE_LEVEL>(
        in0_tile_r_dim,
        in0_tile_c_dim,
        in1_tile_r_dim,
        in1_tile_c_dim,
        partial_face,
        transpose,
        ct_dim,
        rt_dim,
        kt_dim);
}

template <int NUM_FIDELITY_PHASES, int THROTTLE_LEVEL = 0, uint32_t num_faces = 4 >
inline void llk_math_matmul(
    const uint dst_index,
    const bool transpose = false,
    const std::uint32_t ct_dim = 1,
    const std::uint32_t rt_dim = 1,
    const std::uint32_t kt_dim = 1) {
    _llk_math_matmul_<NUM_FIDELITY_PHASES, DstTileFaceLayout::RowMajor, THROTTLE_LEVEL>(
        dst_index, transpose, ct_dim, rt_dim, kt_dim);
}




       






       
using namespace ckernel;


inline void eltwise_unary_configure_addrmod();

template <DataCopyType type, DstSync Dst, bool is_fp32_dest_acc_en, BroadcastType src_b_bcast_type = BroadcastType::NONE, bool unpack_to_dest = false>
inline void _llk_math_eltwise_unary_datacopy_(const std::uint32_t dst_index, const std::uint32_t src_format, const std::uint32_t dst_format)
{
    if (unpack_to_dest && is_32bit_input(src_format, dst_format))
    {
        math_unpack_to_dest_math_ready();
        math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32, true>(dst_index);
        math::math_unpack_to_dest_tile_ready();
    }
    else
    {
        math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(dst_index);

        if constexpr (type == A2D)
        {
            ckernel_template::run(instrn_buffer);
        }
        else if constexpr (type == B2D)
        {
            if constexpr (src_b_bcast_type == BroadcastType::COL)
            {

                ckernel_template::run(instrn_buffer);
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))))));
                ckernel_template::run(instrn_buffer);
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))))));
            }
            else
            {
                ckernel_template::run(instrn_buffer);
            }
        }

        math::clear_dst_reg_addr();
    }
}

template <DataCopyType type, BroadcastType bcast_type = BroadcastType::NONE>
inline void eltwise_unary_configure_addrmod()
{

    if constexpr (type == A2D)
    {
        addr_mod_t {
            .srca = {.incr = 1},
            .srcb = {.incr = 0},
            .dest = {.incr = 1},
        }
            .set(ADDR_MOD_0);


        addr_mod_t {
            .srca = {.incr = 8},
            .srcb = {.incr = 0},
            .dest = {.incr = 8},
        }
            .set(ADDR_MOD_2);
    }
    else
    {
        if constexpr (bcast_type == BroadcastType::ROW || bcast_type == BroadcastType::SCALAR)
        {
            addr_mod_t {
                .srca = {.incr = 0},
                .srcb = {.incr = 0},
                .dest = {.incr = 1},
            }
                .set(ADDR_MOD_0);


            addr_mod_t {
                .srca = {.incr = 0},
                .srcb = {.incr = 0},
                .dest = {.incr = 8},
            }
                .set(ADDR_MOD_2);
        }
        else
        {
            addr_mod_t {
                .srca = {.incr = 0},
                .srcb = {.incr = 1},
                .dest = {.incr = 1},
            }
                .set(ADDR_MOD_0);


            addr_mod_t {
                .srca = {.incr = 0},
                .srcb = {.incr = 8},
                .dest = {.incr = 8},
            }
                .set(ADDR_MOD_2);
        }
    }
}

template <DataCopyType type, bool is_fp32_dest_acc_en, BroadcastType bcast_type = BroadcastType::NONE, bool is_int_fpu_en = false>
inline void eltwise_unary_configure_mop(uint rows_per_inst, uint total_rows, const uint num_faces, const uint dst_format)
{


    if constexpr (type == A2D)
    {
        uint addr_mod = (rows_per_inst == p_mova2d::MOV_1_ROW) ? ADDR_MOD_0 : ADDR_MOD_2;
        uint innerloop = (rows_per_inst == p_mova2d::MOV_1_ROW) ? total_rows : (total_rows >> 3);
        uint outerloop = num_faces;

        if (((is_fp32_dest_acc_en || is_int_fpu_en) && !(dst_format == (uint)DataFormat::UInt16)) || (dst_format == (uint)DataFormat::UInt8))
        {

            ckernel_template tmp(outerloop, innerloop, ((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((p_elwise::SRCB_NO_BCAST) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            tmp.program(instrn_buffer);
        }
        else
        {
            ckernel_template tmp(outerloop, innerloop, ((0x12 << 24) + (((0) << 23) + ((0) << 17) + ((ADDR_MOD_2) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            tmp.program(instrn_buffer);
        }
    }
    else if constexpr (type == B2D)
    {
        uint addr_mod = (rows_per_inst == p_movb2d::MOV_1_ROW) ? ADDR_MOD_0 : ADDR_MOD_2;
        uint innerloop = (rows_per_inst == p_movb2d::MOV_1_ROW) ? total_rows : (total_rows >> 2);
        uint outerloop = 4;
        auto broadcast_type = p_movb2d::MOV_1_ROW;

        if constexpr (bcast_type == BroadcastType::COL)
        {
            innerloop = 16 >> 3;

            outerloop = 2;




            broadcast_type = p_elwise::SRCB_BCAST_COL;
        }
        else if constexpr (bcast_type == BroadcastType::ROW)
        {
            innerloop = (total_rows >> 3);
            broadcast_type = p_movb2d::MOV_8_ROW_BRCST;
        }
        else if constexpr (bcast_type == BroadcastType::SCALAR)
        {

            outerloop = 1;
            innerloop = num_faces * (total_rows >> 3);
            broadcast_type = p_elwise::SRCB_BCAST_ALL;
        }

        if constexpr (bcast_type == BroadcastType::SCALAR)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))));
            tmp.program(instrn_buffer);
        }
        else if constexpr (bcast_type == BroadcastType::COL)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((0) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))));
            tmp.program(instrn_buffer);
        }
        else if constexpr (bcast_type == BroadcastType::ROW)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x13 << 24) + (((0) << 23) + ((0) << 17) + ((addr_mod) << 15) + ((broadcast_type) << 12) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))));
            tmp.program(instrn_buffer);
        }
        else
        {
            ckernel_template tmp(outerloop, innerloop, ((0x13 << 24) + (((0) << 23) + ((0) << 17) + ((addr_mod) << 15) + ((rows_per_inst) << 12) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))));
            tmp.program(instrn_buffer);
        }
    }
}

template <DataCopyType type, bool is_fp32_dest_acc_en, BroadcastType src_b_bcast_type = BroadcastType::NONE, bool is_int_fpu_en = false>

inline void _llk_math_eltwise_unary_datacopy_init_(
    const std::uint32_t transpose_of_faces = 0 ,
    const std::uint32_t within_face_16x16_transpose = 0 ,
    const std::uint32_t num_faces = 4,
    const std::uint32_t dst_format = 255)
{
    eltwise_unary_configure_addrmod<type, src_b_bcast_type>();

    if constexpr (type == A2D)
    {
        eltwise_unary_configure_mop<type, is_fp32_dest_acc_en, src_b_bcast_type, is_int_fpu_en>(p_mova2d::MOV_8_ROWS, 16, num_faces, dst_format);
    }
    else if constexpr (type == B2D)
    {
        eltwise_unary_configure_mop<type, false, src_b_bcast_type>(p_movb2d::MOV_4_ROWS, 16, num_faces, dst_format);
    }

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0) << 0))))));

    math::reset_counters(p_setrwc::SET_ABD_F);
}
inline void _llk_math_fast_tilize_addrmod_config_(const std::uint32_t unpack_dst_format, const std::uint32_t unit_dim)
{

    addr_mod_t {
        .srcb = {.incr = 4},
        .dest = {.incr = 4},
    }
        .set(ADDR_MOD_1);


    addr_mod_t {
        .srca = {.incr = 8},
        .dest = {.incr = 8},
    }
        .set(ADDR_MOD_2);



    uint32_t bottom_face_offset = (unpack_dst_format == (uint)DataFormat::Tf32 ? 256 : 512) / 2;




    uint8_t unit_dim_1_forward_jump = bottom_face_offset - (1 * (TILE_NUM_FACES / 2) * FACE_R_DIM - 8);
    uint8_t unit_dim_2_forward_jump = bottom_face_offset - (2 * (TILE_NUM_FACES / 2) * FACE_R_DIM - 8);



    int16_t unit_dim_1_backward_jump = -bottom_face_offset + 8;
    int16_t unit_dim_2_backward_jump = -bottom_face_offset + 4;


    addr_mod_t {
        .srca = {.incr = 8},
        .dest = {.incr = unit_dim == 1 ? unit_dim_1_forward_jump : unit_dim_2_forward_jump},
    }
        .set(ADDR_MOD_3);


    addr_mod_t {
        .dest = {.incr = unit_dim == 1 ? unit_dim_1_backward_jump : unit_dim_2_backward_jump},
    }
        .set(ADDR_MOD_0);
}

inline void _llk_math_fast_tilize_mop_config_()
{
    ckernel_unpack_template tmp = ckernel_unpack_template(
        false,
        false,
        ((0x12 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_2) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))),
        ((0x02 << 24) + 0),
        ((0x02 << 24) + 0),
        ((0x02 << 24) + 0),
        ((0x13 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_1) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))),
        ((0x02 << 24) + 0),
        ((0x02 << 24) + 0));

    tmp.program(instrn_buffer);
}

inline void _llk_math_fast_tilize_init_(const std::uint32_t unpack_dst_format, const std::uint32_t unit_dim)
{




    if (unpack_dst_format != (uint)DataFormat::Tf32)
    {
        ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((0) << 16) + ((1) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        cfg_reg_rmw_tensix<1, 29, 0x20000000>(0);
    }


    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0) << 0))))));

    math::reset_counters(p_setrwc::SET_ABD_F);

    _llk_math_fast_tilize_addrmod_config_(unpack_dst_format, unit_dim);

    _llk_math_fast_tilize_mop_config_();
}

template <bool is_fp32_dest_acc_en>
inline void _llk_math_fast_tilize_uninit_(const std::uint32_t unpack_dst_format)
{


    if (unpack_dst_format != (uint)DataFormat::Tf32)
    {
        cfg_reg_rmw_tensix<1, 29, 0x20000000>(is_fp32_dest_acc_en);
        ckernel::instrn_buffer[0] = ((0xb2 << 24) + (((0) << 16) + ((0) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
    }
}

inline void _llk_math_fast_tilize_block_(
    const std::uint32_t dst_index, const std::uint32_t unpack_dst_format, const std::uint32_t unit_dim, const std::uint32_t num_units)
{


    math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x16>(dst_index);

    for (uint i = 0; i < num_units; i++)
    {
        if (unit_dim == 1)
        {






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((3 - 1) << 16) + ((0x0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x12 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_3) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))))));






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((3 - 1) << 16) + ((0x0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x12 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_0) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))))));
        }
        else if (unit_dim == 2)
        {






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((7 - 1) << 16) + ((0x0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x12 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_3) << 15) + ((p_mova2d::MOV_8_ROWS) << 12) + ((0) << 0))))));






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((15 - 1) << 16) + ((0xFFFF) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))))));
        }
        else if (unit_dim == 3)
        {






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((6 - 1) << 16) + ((0x0) << 0))))));






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((12 - 1) << 16) + ((0xFFFF) << 0))))));


            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_ABD) << 0))))));

            uint32_t top_face_offset = dst_index + i * 3;


            uint32_t bottom_face_offset = top_face_offset + (unpack_dst_format == (uint)DataFormat::Tf32 ? 4 : 8);
            math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x16>(bottom_face_offset);






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((6 - 1) << 16) + ((0x0) << 0))))));






            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x01 << 24) + (((p_mop::MASK_LOOP) << 23) + ((11 - 1) << 16) + ((0xFFFF) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((p_mov::DEST_NORM) << 23) + ((0) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))))));
        }
    }

    math::clear_dst_reg_addr();
}





template <
    DataCopyType type,
    bool is_fp32_dest_acc_en,
    BroadcastType src_b_bcast_type = BroadcastType::NONE,
    bool unpack_to_dest = false>
inline void llk_math_eltwise_unary_datacopy(uint dst_index, uint operand = 0) {
    const std::uint32_t operand_id = get_operand_id(operand);
    _llk_math_eltwise_unary_datacopy_<type, DstSync::SyncHalf, is_fp32_dest_acc_en, src_b_bcast_type, unpack_to_dest>(
        dst_index, unpack_src_format[operand_id], unpack_dst_format[operand_id]);
}

template <
    DataCopyType type,
    bool is_fp32_dest_acc_en,
    BroadcastType src_b_bcast_type = BroadcastType::NONE,
    bool unpack_to_dest = false>
inline void llk_math_eltwise_unary_datacopy_block(uint start_dst_index, uint ntiles, uint operand = 0) {
    const std::uint32_t operand_id = get_operand_id(operand);

    for (uint32_t dst_index = start_dst_index; dst_index < start_dst_index + ntiles; dst_index++) {
        _llk_math_eltwise_unary_datacopy_<type, DstSync::SyncHalf, is_fp32_dest_acc_en, src_b_bcast_type, unpack_to_dest>(
            dst_index, unpack_src_format[operand_id], unpack_dst_format[operand_id]);
    }
}

template <
    DataCopyType type,
    bool is_fp32_dest_acc_en,
    BroadcastType src_b_bcast_type = BroadcastType::NONE,
    bool is_int_fpu_en = false,
    bool tilize = false >

inline void llk_math_eltwise_unary_datacopy_init(
    const std::uint32_t transpose_of_faces = 0 ,
    const std::uint32_t within_face_16x16_transpose = 0 ,
    const std::uint32_t operand = 0) {
    const std::uint32_t operand_id = get_operand_id(operand);
    const std::uint32_t num_faces = get_operand_num_faces(operand_id);
    const std::uint32_t dst_format = get_operand_dst_format(operand_id);
    _llk_math_eltwise_unary_datacopy_init_<type, is_fp32_dest_acc_en, src_b_bcast_type, is_int_fpu_en>(
        transpose_of_faces, within_face_16x16_transpose, num_faces, dst_format);
}





inline void llk_math_fast_tilize_init(const std::uint32_t operand, const std::uint32_t unit_dim) {
    const std::uint32_t operand_id = get_operand_id(operand);
    _llk_math_fast_tilize_init_(unpack_dst_format[operand_id], unit_dim);
}

template <bool is_fp32_dest_acc_en>
inline void llk_math_fast_tilize_uninit(const std::uint32_t operand) {
    const std::uint32_t operand_id = get_operand_id(operand);
    _llk_math_fast_tilize_uninit_<is_fp32_dest_acc_en>(unpack_dst_format[operand_id]);
}

inline void llk_math_fast_tilize_block_(
    const std::uint32_t dst_index,
    const std::uint32_t operand,
    const std::uint32_t unit_dim,
    const std::uint32_t num_units) {
    const std::uint32_t operand_id = get_operand_id(operand);
    _llk_math_fast_tilize_block_(dst_index, unpack_dst_format[operand_id], unit_dim, num_units);
}




       





       
using namespace ckernel;


inline void eltwise_binary_configure_addrmod();

template <EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void eltwise_binary_reuse_dest_as_src()
{
    if constexpr (binary_reuse_dest == EltwiseBinaryReuseDestType::DEST_TO_SRCA)
    {
        move_d2a_fixed_face(ADDR_MOD_1);
    }
    else if constexpr (binary_reuse_dest == EltwiseBinaryReuseDestType::DEST_TO_SRCB)
    {
        move_d2b_fixed_face(ADDR_MOD_1);
    }
}

template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType src_b_bcast_type,
    DstSync Dst,
    bool is_fp32_dest_acc_en,
    int NUM_FIDELITY_PHASES = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void _llk_math_eltwise_binary_(const std::uint32_t num_faces, uint dst_index, const bool clear_fp32_dst_acc)
{
    constexpr bool high_fidelity = (NUM_FIDELITY_PHASES > 0);
    constexpr uint32_t ZERO_ACC_MODE = p_zeroacc::CLR_16;

    math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(dst_index);

    if constexpr ((eltwise_binary_type == ELWADD) || (eltwise_binary_type == ELWSUB))
    {
        if constexpr (src_b_bcast_type == BroadcastType::COL)
        {

            constexpr uint32_t outerloop = (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE) ? 2 : 1;
#pragma GCC unroll 0
            for (std::uint32_t n = 0; n < outerloop; n++)
            {
                eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                ckernel_template::run(instrn_buffer);
            }
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))))));
            if (num_faces == 4)
            {
#pragma GCC unroll 0
                for (std::uint32_t n = 0; n < outerloop; n++)
                {
                    eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                    ckernel_template::run(instrn_buffer);
                }
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))))));
            }
        }
        else
        {
            constexpr uint32_t outerloop = (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE) ? 4 : 1;
#pragma GCC unroll 0
            for (std::uint32_t n = 0; n < outerloop; n++)
            {
                eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                ckernel_template::run(instrn_buffer);
            }

            if constexpr (src_b_bcast_type == BroadcastType::SCALAR)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            }
        }
    }
    else if constexpr (eltwise_binary_type == ELWMUL)
    {
        if constexpr (src_b_bcast_type == BroadcastType::COL)
        {

            constexpr uint32_t outerloop = (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE) ? 2 : 1;
            if constexpr (high_fidelity)
            {
#pragma GCC unroll 0
                for (std::uint32_t n = 0; n < 2; n++)
                {
                    eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                    auto base_address = (get_dest_buffer_base() >> 4) + (dst_index << (is_fp32_dest_acc_en && clear_fp32_dst_acc ? 3 : 2));

                    if (is_fp32_dest_acc_en && clear_fp32_dst_acc)
                    {
                        ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (0 + n * 2)) << 0)));
                        ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (0 + ((n * 2) + 1))) << 0)));
                    }
                    else
                    {
                        ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (0 + n)) << 0)));
                    }
                    ckernel_template::run(instrn_buffer);
                }
            }
            else
            {
#pragma GCC unroll 0
                for (std::uint32_t n = 0; n < outerloop; n++)
                {
                    eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                    if constexpr (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE)
                    {
                        auto base_address = (get_dest_buffer_base() >> 4) + (dst_index << (is_fp32_dest_acc_en && clear_fp32_dst_acc ? 3 : 2));

                        if (is_fp32_dest_acc_en && clear_fp32_dst_acc)
                        {
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (0 + n * 2)) << 0)));
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (0 + ((n * 2) + 1))) << 0)));
                        }
                        else
                        {
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (0 + n)) << 0)));
                        }
                    }
                    ckernel_template::run(instrn_buffer);
                }
            }
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))))));
            if (num_faces == 4)
            {
                if constexpr (high_fidelity)
                {
#pragma GCC unroll 0
                    for (std::uint32_t n = 0; n < 2; n++)
                    {
                        eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                        if constexpr (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE)
                        {
                            auto base_address = (get_dest_buffer_base() >> 4) + (dst_index << (is_fp32_dest_acc_en && clear_fp32_dst_acc ? 3 : 2));

                            if (is_fp32_dest_acc_en && clear_fp32_dst_acc)
                            {
                                ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (4 + n * 2)) << 0)));
                                ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (4 + ((n * 2) + 1))) << 0)));
                            }
                            else
                            {
                                ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (2 + n)) << 0)));
                            }
                        }
                        ckernel_template::run(instrn_buffer);
                    }
                }
                else
                {
#pragma GCC unroll 0
                    for (std::uint32_t n = 0; n < outerloop; n++)
                    {
                        eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                        if constexpr (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE)
                        {
                            auto base_address = (get_dest_buffer_base() >> 4) + (dst_index << (is_fp32_dest_acc_en && clear_fp32_dst_acc ? 3 : 2));

                            if (is_fp32_dest_acc_en && clear_fp32_dst_acc)
                            {
                                ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (4 + n * 2)) << 0)));
                                ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (4 + ((n * 2) + 1))) << 0)));
                            }
                            else
                            {
                                ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (2 + n)) << 0)));
                            }
                        }
                        ckernel_template::run(instrn_buffer);
                    }
                }
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((0) << 0))))));
            }
        }
        else
        {

            const uint32_t outerloop = (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE) ? num_faces : 1;
            if constexpr (high_fidelity)
            {
#pragma GCC unroll 0
                for (std::uint32_t n = 0; n < num_faces; n++)
                {
                    eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                    if constexpr (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE)
                    {
                        auto base_address = (get_dest_buffer_base() >> 4) + (dst_index << (is_fp32_dest_acc_en && clear_fp32_dst_acc ? 3 : 2));

                        if (is_fp32_dest_acc_en && clear_fp32_dst_acc)
                        {
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (n * 2)) << 0)));
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + ((n * 2) + 1)) << 0)));
                        }
                        else
                        {
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + n) << 0)));
                        }
                    }
                    ckernel_template::run(instrn_buffer);
                }
            }
            else
            {
#pragma GCC unroll 0
                for (std::uint32_t n = 0; n < outerloop; n++)
                {
                    eltwise_binary_reuse_dest_as_src<binary_reuse_dest>();
                    if constexpr (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE)
                    {
                        auto base_address = (get_dest_buffer_base() >> 4) + (dst_index << (is_fp32_dest_acc_en && clear_fp32_dst_acc ? 3 : 2));

                        if (is_fp32_dest_acc_en && clear_fp32_dst_acc)
                        {
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + (n * 2)) << 0)));
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + ((n * 2) + 1)) << 0)));
                        }
                        else
                        {
                            ckernel::instrn_buffer[0] = ((0x10 << 24) + (((ZERO_ACC_MODE) << 19) + ((ADDR_MOD_1) << 15) + ((base_address + n) << 0)));
                        }
                    }
                    ckernel_template::run(instrn_buffer);
                }
            }
            if constexpr (src_b_bcast_type == BroadcastType::SCALAR)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_B) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            }
        }
    }
    math::clear_dst_reg_addr();
}

template <EltwiseBinaryType eltwise_binary_type, BroadcastType bcast_type, std::uint32_t FIDELITY_INCREMENT>
inline void eltwise_binary_configure_addrmod()
{

    if constexpr ((eltwise_binary_type == ELWADD) || (eltwise_binary_type == ELWSUB) || (eltwise_binary_type == ELWMUL))
    {
        if constexpr (bcast_type == BroadcastType::NONE || bcast_type == BroadcastType::COL)
        {
            addr_mod_t {
                .srca = {.incr = 8},
                .srcb = {.incr = 8},
                .dest = {.incr = 8},
            }
                .set(ADDR_MOD_0);
        }
        else if constexpr (bcast_type == BroadcastType::ROW || bcast_type == BroadcastType::SCALAR)
        {
            addr_mod_t {
                .srca = {.incr = 8},
                .srcb = {.incr = 0},
                .dest = {.incr = 8},
            }
                .set(ADDR_MOD_0);
        }
        addr_mod_t {
            .srca = {.incr = 0},
            .srcb = {.incr = 0},
            .dest = {.incr = 0},
        }
            .set(ADDR_MOD_1);

        addr_mod_t {
            .srca = {.incr = 0, .clr = 1}, .srcb = {.incr = 0, .clr = 1}, .dest = {.incr = 0, .clr = 0, .cr = 1}, .fidelity = {.incr = FIDELITY_INCREMENT}}
            .set(ADDR_MOD_2);

        addr_mod_t {
            .srca = {.incr = 0, .clr = 1},
            .srcb = {.incr = 0, .clr = 1},
            .dest = {.incr = 8, .clr = 0, .cr = 0, .c_to_cr = 1},
            .fidelity = {.incr = 0, .clr = 1}}
            .set(ADDR_MOD_3);
    }
}

template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType bcast_type,
    int NUM_FIDELITY_PHASES = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void eltwise_binary_configure_mop(const std::uint32_t acc_to_dest = 0, const std::uint32_t num_faces = 4)
{
    constexpr bool high_fidelity = (NUM_FIDELITY_PHASES > 0);
    const uint addr_mod = ADDR_MOD_0;
    constexpr uint innerloop = 16 >> 3;
    uint outerloop = num_faces;
    auto broadcast_type = p_elwise::SRCB_NO_BCAST;
    if constexpr (bcast_type == BroadcastType::COL)
    {

        outerloop = 2;
        broadcast_type = p_elwise::SRCB_BCAST_COL;
    }
    else if constexpr (bcast_type == BroadcastType::ROW)
    {
        broadcast_type = p_elwise::SRCB_BCAST_ROW;
    }
    else if constexpr (bcast_type == BroadcastType::SCALAR)
    {
        broadcast_type = p_elwise::SRCB_BCAST_ALL;
    }

    if constexpr (binary_reuse_dest != EltwiseBinaryReuseDestType::NONE)
    {
        outerloop = 1;
    }


    if constexpr (bcast_type == BroadcastType::COL || bcast_type == BroadcastType::SCALAR)
    {
        if constexpr (eltwise_binary_type == ELWADD)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x28 << 24) + (((0) << 22) + ((acc_to_dest) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((p_setrwc::CR_AB) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            tmp.program(instrn_buffer);
        }
        else if constexpr (eltwise_binary_type == ELWSUB)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x30 << 24) + (((0) << 22) + ((acc_to_dest) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((p_setrwc::CR_AB) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            tmp.program(instrn_buffer);
        }
        else if constexpr (eltwise_binary_type == ELWMUL)
        {
            ckernel_template tmp(high_fidelity ? NUM_FIDELITY_PHASES : outerloop, innerloop, ((0x27 << 24) + (((0) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            if constexpr (high_fidelity)
            {
                tmp.set_last_inner_loop_instr(((0x27 << 24) + (((0) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))));
                tmp.set_last_outer_loop_instr(((0x27 << 24) + (((p_setrwc::CLR_A) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))));
            }
            else
            {
                tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_A) << 22) + ((p_setrwc::CR_AB) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            }
            tmp.program(instrn_buffer);
        }
    }
    else
    {
        if constexpr (eltwise_binary_type == ELWADD)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x28 << 24) + (((0) << 22) + ((acc_to_dest) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_setrwc::CR_AB) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            tmp.program(instrn_buffer);
        }
        else if constexpr (eltwise_binary_type == ELWSUB)
        {
            ckernel_template tmp(outerloop, innerloop, ((0x30 << 24) + (((0) << 22) + ((acc_to_dest) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_setrwc::CR_AB) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            tmp.program(instrn_buffer);
        }
        else if constexpr (eltwise_binary_type == ELWMUL)
        {
            ckernel_template tmp(high_fidelity ? NUM_FIDELITY_PHASES : outerloop, innerloop, ((0x27 << 24) + (((0) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((addr_mod) << 15) + ((0) << 0))));
            if constexpr (high_fidelity)
            {
                tmp.set_last_inner_loop_instr(((0x27 << 24) + (((0) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))));
                tmp.set_last_outer_loop_instr(((0x27 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 21) + ((broadcast_type) << 19) + ((ADDR_MOD_3) << 15) + ((0) << 0))));
            }
            else
            {
                tmp.set_end_op(((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_setrwc::CR_AB) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))));
            }
            tmp.program(instrn_buffer);
        }
    }
}

template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType src_b_bcast_type,
    int MATH_FIDELITY_DESC = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void _llk_math_eltwise_binary_init_(const std::uint32_t num_faces, const std::uint32_t transpose, const std::uint32_t acc_to_dest)
{
    constexpr int MATH_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    constexpr int MATH_FIDELITY_INCREMENT = get_math_fidelity_increment(MATH_FIDELITY_DESC);

    eltwise_binary_configure_addrmod<eltwise_binary_type, src_b_bcast_type, MATH_FIDELITY_INCREMENT>();

    if constexpr ((eltwise_binary_type == ELWADD) || (eltwise_binary_type == ELWSUB) || (eltwise_binary_type == ELWMUL))
    {
        eltwise_binary_configure_mop<eltwise_binary_type, src_b_bcast_type, MATH_FIDELITY_PHASES, binary_reuse_dest>(acc_to_dest, num_faces);
    }

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0) << 0))))));

    math::reset_counters(p_setrwc::SET_ABD_F);
}






template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType src_b_bcast_type,
    int NUM_FIDELITY_PHASES = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void llk_math_eltwise_binary_init(const std::uint32_t transpose = 0, const std::uint32_t acc_to_dest = 0) {
    const std::uint32_t num_faces = 4;

    _llk_math_eltwise_binary_init_<eltwise_binary_type, src_b_bcast_type, NUM_FIDELITY_PHASES, binary_reuse_dest>(
        num_faces, transpose, acc_to_dest);
}


template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType src_b_bcast_type,
    int NUM_FIDELITY_PHASES = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void llk_math_eltwise_binary_init_with_operands(
    const std::uint32_t operand_A,
    const std::uint32_t operand_B,
    const std::uint32_t transpose = 0,
    const std::uint32_t acc_to_dest = 0) {
    const std::uint32_t operand_id =
        get_operand_id(operand_A);
    const std::uint32_t num_faces = get_operand_num_faces(operand_id);

    _llk_math_eltwise_binary_init_<eltwise_binary_type, src_b_bcast_type, NUM_FIDELITY_PHASES, binary_reuse_dest>(
        num_faces, transpose, acc_to_dest);
}

template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType src_b_bcast_type,
    bool is_fp32_dest_acc_en,
    int NUM_FIDELITY_PHASES = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void llk_math_eltwise_binary(uint dst_index, const bool clear_fp32_dst_acc = true) {
    const std::uint32_t num_faces = 4;

    _llk_math_eltwise_binary_<
        eltwise_binary_type,
        src_b_bcast_type,
        DstSync::SyncHalf,
        is_fp32_dest_acc_en,
        NUM_FIDELITY_PHASES,
        binary_reuse_dest>(num_faces, dst_index, clear_fp32_dst_acc);
}

template <
    EltwiseBinaryType eltwise_binary_type,
    BroadcastType src_b_bcast_type,
    bool is_fp32_dest_acc_en,
    int NUM_FIDELITY_PHASES = 0,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline void llk_math_eltwise_binary(
    const std::uint32_t operand_A,
    const std::uint32_t operand_B,
    uint dst_index,
    const bool clear_fp32_dst_acc = true) {
    const std::uint32_t operand_id = get_operand_id(operand_A);
    const std::uint32_t num_faces = get_operand_num_faces(operand_id);

    _llk_math_eltwise_binary_<
        eltwise_binary_type,
        src_b_bcast_type,
        DstSync::SyncHalf,
        is_fp32_dest_acc_en,
        NUM_FIDELITY_PHASES,
        binary_reuse_dest>(num_faces, dst_index, clear_fp32_dst_acc);
}




       





       






       
using namespace ckernel;


template <SfpuType sfpu_op>
inline void eltwise_unary_sfpu_configure_addrmod()
{




    addr_mod_t {
        .srca = {.incr = 0},
        .srcb = {.incr = 0},
        .dest = {.incr = 0},
    }
        .set(ADDR_MOD_7);

    if (sfpu_op == SfpuType::topk_local_sort)
    {
        addr_mod_t {
            .srca = {.incr = 0},
            .srcb = {.incr = 0},
            .dest = {.incr = 32},
        }
            .set(ADDR_MOD_6);
    }
}

inline void eltwise_unary_sfpu_configure_mop();

template <DstSync Dst>
inline void _llk_math_eltwise_unary_sfpu_start_(const uint dst_index)
{
    math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(dst_index);
    math::set_addr_mod_base();
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_SFPU) << 15) + ((p_stall::MATH) << 0))))));
}

inline void _llk_math_eltwise_unary_sfpu_done_()
{
    math::clear_dst_reg_addr();

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::WAIT_SFPU) << 0))))));
    math::clear_addr_mod_base();
}

inline void _llk_math_eltwise_unary_sfpu_inc_dst_face_addr_()
{
    math::inc_dst_addr<8>();
    math::inc_dst_addr<8>();
}

template <SfpuType sfpu_op>
inline void _llk_math_eltwise_unary_sfpu_init_()
{
    sfpu::_init_sfpu_config_reg();
    eltwise_unary_sfpu_configure_addrmod<sfpu_op>();
    math::reset_counters(p_setrwc::SET_ABD_F);
}

namespace ckernel {

template <SfpuType sfpu_op, bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_init() {
    _llk_math_eltwise_unary_sfpu_init_<sfpu_op>();
}

template <SfpuType sfpu_op, bool APPROXIMATE, class F, class... ARGS>
inline void llk_math_eltwise_unary_sfpu_init(F&& init_func, ARGS&&... args) {
    _llk_math_eltwise_unary_sfpu_init_<sfpu_op>();
    init_func(static_cast<ARGS&&>(args)...);
}
}




       






       





template <bool APPROXIMATE, typename Callable, typename... Args>
inline void _llk_math_eltwise_unary_sfpu_params_(Callable&& sfpu_func, uint dst_index, int vector_mode = (int)VectorMode::RC, Args&&... args)
{
    math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(dst_index);
    math::set_addr_mod_base();

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_SFPU) << 15) + ((p_stall::MATH) << 0))))));
    VectorMode mode = static_cast<VectorMode>(vector_mode);

    if (mode == VectorMode::R)
    {

#pragma GCC unroll 0
        for (int face = 0; face < 2; face++)
        {
            std::forward<Callable>(sfpu_func)(std::forward<Args>(args)...);
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
        }

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
    }
    else if (mode == VectorMode::C)
    {

#pragma GCC unroll 0
        for (int face = 0; face < 2; face++)
        {
            std::forward<Callable>(sfpu_func)(std::forward<Args>(args)...);
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
        }
    }
    else if (mode == VectorMode::RC)
    {

#pragma GCC unroll 0
        for (int face = 0; face < 4; face++)
        {
            std::forward<Callable>(sfpu_func)(std::forward<Args>(args)...);
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
        }
    }
    else
    {
        std::forward<Callable>(sfpu_func)(std::forward<Args>(args)...);
    }
    math::clear_dst_reg_addr();

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_CFG) << 15) + ((p_stall::WAIT_SFPU) << 0))))));
    math::clear_addr_mod_base();
}




       







       
constexpr std::underlying_type_t<TensixProcessorTypes> proc_type =
    static_cast<std::underlying_type_t<TensixProcessorTypes>>(TensixProcessorTypes::DM1);
constexpr uint32_t DYNAMIC_NOC_NCRISC_WR_CMD_BUF = 2;
constexpr uint32_t DYNAMIC_NOC_NCRISC_WR_REG_CMD_BUF = 2;
constexpr uint32_t DYNAMIC_NOC_NCRISC_AT_CMD_BUF = 3;
constexpr uint32_t DYNAMIC_NOC_NCRISC_RD_CMD_BUF = 3;

constexpr uint32_t DYNAMIC_NOC_BRISC_WR_CMD_BUF = 0;
constexpr uint32_t DYNAMIC_NOC_BRISC_WR_REG_CMD_BUF = 0;
constexpr uint32_t DYNAMIC_NOC_BRISC_AT_CMD_BUF = 1;
constexpr uint32_t DYNAMIC_NOC_BRISC_RD_CMD_BUF = 1;

constexpr uint32_t NCRISC_WR_CMD_BUF = 0;
constexpr uint32_t NCRISC_RD_CMD_BUF = 1;
constexpr uint32_t NCRISC_WR_REG_CMD_BUF = 2;
constexpr uint32_t NCRISC_AT_CMD_BUF = 3;

constexpr uint32_t BRISC_WR_CMD_BUF = 0;
constexpr uint32_t BRISC_RD_CMD_BUF = 1;
constexpr uint32_t BRISC_WR_REG_CMD_BUF = 2;
constexpr uint32_t BRISC_AT_CMD_BUF = 3;



constexpr uint32_t NOC_ADDR_COORD_SHIFT =
    32;
const uint32_t NOC_TARG_ADDR_COORDINATE = (0xFFB20000 + 0x4);
const uint32_t NOC_RET_ADDR_COORDINATE = (0xFFB20000 + 0x10);
const uint32_t NOC_COORDINATE_MASK = 0xFFFFFFFF;

extern uint32_t noc_reads_num_issued[2];
extern uint32_t noc_nonposted_writes_num_issued[2];
extern uint32_t noc_nonposted_writes_acked[2];
extern uint32_t noc_nonposted_atomics_acked[2];
extern uint32_t noc_posted_writes_num_issued[2];

enum class NocBarrierType : uint8_t {
    READS_NUM_ISSUED,
    NONPOSTED_WRITES_NUM_ISSUED,
    NONPOSTED_WRITES_ACKED,
    NONPOSTED_ATOMICS_ACKED,
    POSTED_WRITES_NUM_ISSUED,
    COUNT
};

static constexpr uint8_t NUM_BARRIER_TYPES = static_cast<uint32_t>(NocBarrierType::COUNT);

template <uint8_t proc_t, NocBarrierType barrier_type>
inline __attribute__((always_inline)) uint32_t get_noc_counter_address(uint32_t noc) {
    static_assert(proc_t < MaxDMProcessorsPerCoreType);
    static_assert(static_cast<std::underlying_type_t<NocBarrierType>>(barrier_type) < NUM_BARRIER_TYPES);
    constexpr uint32_t offset =
        ((((((((((16 + 12640) + 31) & ~31) + 512) + 1024) + (5 * 1024 + 512)) + 2048) + 1536) + 1536) + 1536) +
        (proc_t * NUM_BARRIER_TYPES + static_cast<std::underlying_type_t<NocBarrierType>>(barrier_type)) * 2 *
            4;
    return offset + noc * 4;
}


template <uint8_t proc_t, NocBarrierType barrier_type>
inline __attribute__((always_inline)) uint32_t get_noc_counter_val(uint32_t noc) {
    uint32_t counter_addr = get_noc_counter_address<proc_t, barrier_type>(noc);
    return *reinterpret_cast<volatile __attribute__((rvtt_l1_ptr)) uint32_t*>(counter_addr);
}

template <uint8_t proc_t, NocBarrierType barrier_type>
inline __attribute__((always_inline)) void inc_noc_counter_val(uint32_t noc, uint32_t inc = 1) {
    uint32_t counter_addr = get_noc_counter_address<proc_t, barrier_type>(noc);
    *reinterpret_cast<volatile __attribute__((rvtt_l1_ptr)) uint32_t*>(counter_addr) += inc;
}

template <uint8_t proc_t, NocBarrierType barrier_type>
inline __attribute__((always_inline)) void set_noc_counter_val(uint32_t noc, uint32_t val) {
    uint32_t counter_addr = get_noc_counter_address<proc_t, barrier_type>(noc);
    *reinterpret_cast<volatile __attribute__((rvtt_l1_ptr)) uint32_t*>(counter_addr) = val;
}

inline __attribute__((always_inline)) void NOC_CMD_BUF_WRITE_REG(
    uint32_t noc, uint32_t buf, uint32_t addr, uint32_t val) {
    uint32_t offset = (buf << 10) + (noc << 16) + addr;
    volatile uint32_t* ptr = (volatile uint32_t*)offset;
    *ptr = val;
}

inline __attribute__((always_inline)) uint32_t NOC_CMD_BUF_READ_REG(uint32_t noc, uint32_t buf, uint32_t addr) {
    uint32_t offset = (buf << 10) + (noc << 16) + addr;
    volatile uint32_t* ptr = (volatile uint32_t*)offset;
    return *ptr;
}

inline __attribute__((always_inline)) uint32_t NOC_STATUS_READ_REG(uint32_t noc, uint32_t reg_id) {
    uint32_t offset = (noc << 16) + (0xFFB20000 + 0x200 + ((reg_id) * 4));
    volatile uint32_t* ptr = (volatile uint32_t*)offset;
    return *ptr;
}

inline __attribute__((always_inline)) uint32_t NOC_CFG_READ_REG(uint32_t noc, uint32_t reg_id) {
    uint32_t offset = (noc << 16) + (0xFFB20000 + 0x100 + ((reg_id) * 4));
    volatile uint32_t* ptr = (volatile uint32_t*)offset;
    return *ptr;
}

inline __attribute__((always_inline)) bool noc_cmd_buf_ready(uint32_t noc, uint32_t cmd_buf) {
    return (NOC_CMD_BUF_READ_REG(noc, cmd_buf, (0xFFB20000 + 0x28)) == 0x0);
}

template <uint8_t noc_mode = DM_DEDICATED_NOC>
inline __attribute__((always_inline)) void ncrisc_noc_fast_read(
    uint32_t noc, uint32_t cmd_buf, uint64_t src_addr, uint32_t dest_addr, uint32_t len_bytes) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        inc_noc_counter_val<proc_type, NocBarrierType::READS_NUM_ISSUED>(noc, 1);
    }
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        uint32_t noc_rd_cmd_field =
            (0x0 << 0) | (0x0 << 1) | (0x1 << 4) | (0x1 << 7) | (((uint32_t)(1)) << 13);
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_rd_cmd_field);
    }
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0xC), dest_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), (uint32_t)src_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, NOC_TARG_ADDR_COORDINATE, (uint32_t)(src_addr >> NOC_ADDR_COORD_SHIFT));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), len_bytes);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), (0x1 << 0));
    if constexpr (noc_mode == DM_DEDICATED_NOC) {
        noc_reads_num_issued[noc] += 1;
    }
}

inline __attribute__((always_inline)) bool ncrisc_dynamic_noc_reads_flushed(uint32_t noc) {
    uint32_t status_reg_val = NOC_STATUS_READ_REG(noc, 0x2);
    uint32_t self_risc_acked = get_noc_counter_val<proc_type, NocBarrierType::READS_NUM_ISSUED>(noc);
    uint32_t other_risc_acked = get_noc_counter_val<1 - proc_type, NocBarrierType::READS_NUM_ISSUED>(noc);
    return (status_reg_val == (self_risc_acked + other_risc_acked));
}

inline __attribute__((always_inline)) bool ncrisc_noc_reads_flushed(uint32_t noc) {
    return (NOC_STATUS_READ_REG(noc, 0x2) == noc_reads_num_issued[noc]);
}

inline __attribute__((always_inline)) bool ncrisc_noc_read_with_transaction_id_flushed(
    uint32_t noc, uint32_t transcation_id) {
    return (NOC_STATUS_READ_REG(noc, (0x10 + (transcation_id))) == 0);
}

template <uint8_t noc_mode = DM_DEDICATED_NOC, bool use_trid = false>
inline __attribute__((always_inline)) void ncrisc_noc_fast_write(
    uint32_t noc,
    uint32_t cmd_buf,
    uint32_t src_addr,
    uint64_t dest_addr,
    uint32_t len_bytes,
    uint32_t vc,
    bool mcast,
    bool linked,
    uint32_t num_dests,
    bool multicast_path_reserve,
    bool posted = false,
    uint32_t trid = 0) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        if (posted) {
            inc_noc_counter_val<proc_type, NocBarrierType::POSTED_WRITES_NUM_ISSUED>(noc, 1);
        } else {
            inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED>(noc, 1);
            inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_ACKED>(noc, num_dests);
        }
    }
    uint32_t noc_cmd_field =
        (0x0 << 0) | (0x1 << 1) | (0x1 << 7) | (((uint32_t)(vc)) << 13) | (linked ? (0x1 << 6) : 0x0) |
        (mcast ? ((multicast_path_reserve ? (0x1 << 8) : 0) | (0x1 << 5)) : 0x0) |
        (posted ? 0 : (0x1 << 4));

    if constexpr (use_trid) {
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x18), ((trid) << 10));
    }

    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_cmd_field);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), src_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0xC), (uint32_t)dest_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, NOC_RET_ADDR_COORDINATE, (uint32_t)(dest_addr >> NOC_ADDR_COORD_SHIFT));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), len_bytes);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), (0x1 << 0));

    if constexpr (noc_mode == DM_DEDICATED_NOC) {
        if (posted) {
            noc_posted_writes_num_issued[noc] += 1;
        } else {
            noc_nonposted_writes_num_issued[noc] += 1;
            noc_nonposted_writes_acked[noc] += num_dests;
        }
    }
}

template <uint8_t noc_mode = DM_DEDICATED_NOC>
inline __attribute__((always_inline)) void ncrisc_noc_fast_write_loopback_src(
    uint32_t noc,
    uint32_t cmd_buf,
    uint32_t src_addr,
    uint64_t dest_addr,
    uint32_t len_bytes,
    uint32_t vc,
    bool mcast,
    bool linked,
    uint32_t num_dests,
    bool multicast_path_reserve) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED>(noc, 1);
        inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_ACKED>(noc, num_dests);
    }
    uint32_t noc_cmd_field =
        (0x0 << 0) | (0x1 << 1) | (0x1 << 7) | (((uint32_t)(vc)) << 13) | (linked ? (0x1 << 6) : 0x0) |
        (mcast ? ((multicast_path_reserve ? (0x1 << 8) : 0) | (0x1 << 5)) : 0x0) |
        (0x1 << 17) | (0x1 << 4);

    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_cmd_field);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), src_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0xC), (uint32_t)dest_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, NOC_RET_ADDR_COORDINATE, (uint32_t)(dest_addr >> NOC_ADDR_COORD_SHIFT));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), len_bytes);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), (0x1 << 0));
    if constexpr (noc_mode == DM_DEDICATED_NOC) {
        noc_nonposted_writes_num_issued[noc] += 1;
        noc_nonposted_writes_acked[noc] += num_dests;
    }
}

template <uint8_t noc_mode = DM_DEDICATED_NOC>
inline __attribute__((always_inline)) void ncrisc_noc_blitz_write_setup(
    uint32_t noc, uint32_t cmd_buf, uint64_t dest_addr, uint32_t len_bytes, uint32_t vc, uint32_t num_times_to_write) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED>(noc, num_times_to_write);
        inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_ACKED>(noc, num_times_to_write);
    }
    uint32_t noc_cmd_field = (0x0 << 0) | (0x1 << 1) | (0x1 << 7) | (((uint32_t)(vc)) << 13) | (0x1 << 4);

    while (!noc_cmd_buf_ready(noc, cmd_buf));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_cmd_field);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), len_bytes);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, NOC_RET_ADDR_COORDINATE, (uint32_t)(dest_addr >> NOC_ADDR_COORD_SHIFT));
    if constexpr (noc_mode == DM_DEDICATED_NOC) {
        noc_nonposted_writes_num_issued[noc] += num_times_to_write;
        noc_nonposted_writes_acked[noc] += num_times_to_write;
    }
}

inline __attribute__((always_inline)) bool ncrisc_dynamic_noc_nonposted_writes_sent(uint32_t noc) {
    uint32_t status_reg_val = NOC_STATUS_READ_REG(noc, 0xA);
    uint32_t self_risc_acked = get_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED>(noc);
    uint32_t other_risc_acked = get_noc_counter_val<1 - proc_type, NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED>(noc);
    return (status_reg_val == (self_risc_acked + other_risc_acked));
}

inline __attribute__((always_inline)) bool ncrisc_noc_nonposted_writes_sent(uint32_t noc) {
    return (NOC_STATUS_READ_REG(noc, 0xA) == noc_nonposted_writes_num_issued[noc]);
}

inline __attribute__((always_inline)) bool ncrisc_dynamic_noc_posted_writes_sent(uint32_t noc) {
    uint32_t status_reg_val = NOC_STATUS_READ_REG(noc, 0xB);
    uint32_t self_risc_acked = get_noc_counter_val<proc_type, NocBarrierType::POSTED_WRITES_NUM_ISSUED>(noc);
    uint32_t other_risc_acked = get_noc_counter_val<1 - proc_type, NocBarrierType::POSTED_WRITES_NUM_ISSUED>(noc);
    return (status_reg_val == (self_risc_acked + other_risc_acked));
}

inline __attribute__((always_inline)) bool ncrisc_noc_posted_writes_sent(uint32_t noc) {
    return (NOC_STATUS_READ_REG(noc, 0xB) == noc_posted_writes_num_issued[noc]);
}

inline __attribute__((always_inline)) bool ncrisc_dynamic_noc_nonposted_writes_flushed(uint32_t noc) {
    uint32_t status_reg_val = NOC_STATUS_READ_REG(noc, 0x1);
    uint32_t self_risc_acked = get_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_ACKED>(noc);
    uint32_t other_risc_acked = get_noc_counter_val<1 - proc_type, NocBarrierType::NONPOSTED_WRITES_ACKED>(noc);
    return (status_reg_val == (self_risc_acked + other_risc_acked));
}

inline __attribute__((always_inline)) bool ncrisc_noc_nonposted_writes_flushed(uint32_t noc) {
    return (NOC_STATUS_READ_REG(noc, 0x1) == noc_nonposted_writes_acked[noc]);
}

inline __attribute__((always_inline)) bool ncrisc_noc_nonposted_write_with_transaction_id_sent(
    uint32_t noc, uint32_t transcation_id) {
    return (NOC_STATUS_READ_REG(noc, (0x20 + (transcation_id))) == 0);
}

inline __attribute__((always_inline)) bool ncrisc_noc_nonposted_write_with_transaction_id_flushed(
    uint32_t noc, uint32_t transcation_id) {
    return (NOC_STATUS_READ_REG(noc, (0x10 + (transcation_id))) == 0);
}

inline __attribute__((always_inline)) bool ncrisc_dynamic_noc_nonposted_atomics_flushed(uint32_t noc) {
    uint32_t status_reg_val = NOC_STATUS_READ_REG(noc, 0x0);
    uint32_t self_risc_acked = get_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_ATOMICS_ACKED>(noc);
    uint32_t other_risc_acked = get_noc_counter_val<1 - proc_type, NocBarrierType::NONPOSTED_ATOMICS_ACKED>(noc);
    return (status_reg_val == (self_risc_acked + other_risc_acked));
}

inline __attribute__((always_inline)) bool ncrisc_noc_nonposted_atomics_flushed(uint32_t noc) {
    return (NOC_STATUS_READ_REG(noc, 0x0) == noc_nonposted_atomics_acked[noc]);
}

inline __attribute__((always_inline)) void noc_init(uint32_t atomic_ret_val) {
#pragma GCC unroll 0
    for (int noc = 0; noc < 2; noc++) {
        uint32_t noc_id_reg = NOC_CMD_BUF_READ_REG(noc, 0, (0xFFB20000 + 0x2C));
        uint32_t my_x = noc_id_reg & ((((uint64_t)0x1) << 6) - 1);
        uint32_t my_y = (noc_id_reg >> 6) & ((((uint64_t)0x1) << 6) - 1);
        uint64_t xy_local_addr = ((((uint64_t)(my_y)) << (36 + 6)) | (((uint64_t)(my_x)) << 36) | ((uint64_t)(0)));

        NOC_CMD_BUF_WRITE_REG(
            noc, NCRISC_WR_CMD_BUF, NOC_TARG_ADDR_COORDINATE, (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));
        NOC_CMD_BUF_WRITE_REG(
            noc, NCRISC_WR_REG_CMD_BUF, NOC_TARG_ADDR_COORDINATE, (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));

        uint64_t atomic_ret_addr = ((((uint64_t)(my_y)) << (36 + 6)) | (((uint64_t)(my_x)) << 36) | ((uint64_t)(atomic_ret_val)));
        NOC_CMD_BUF_WRITE_REG(noc, NCRISC_AT_CMD_BUF, (0xFFB20000 + 0xC), (uint32_t)(atomic_ret_addr & 0xFFFFFFFF));
        NOC_CMD_BUF_WRITE_REG(
            noc, NCRISC_AT_CMD_BUF, NOC_RET_ADDR_COORDINATE, (uint32_t)(atomic_ret_addr >> NOC_ADDR_COORD_SHIFT));

        uint32_t noc_rd_cmd_field =
            (0x0 << 0) | (0x0 << 1) | (0x1 << 4) | (0x1 << 7) | (((uint32_t)(1)) << 13);
        NOC_CMD_BUF_WRITE_REG(noc, NCRISC_RD_CMD_BUF, (0xFFB20000 + 0x1C), noc_rd_cmd_field);
        NOC_CMD_BUF_WRITE_REG(
            noc, NCRISC_RD_CMD_BUF, NOC_RET_ADDR_COORDINATE, (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));
    }
}

inline __attribute__((always_inline)) void dynamic_noc_init() {
#pragma GCC unroll 0
    for (int noc = 0; noc < 2; noc++) {
        uint32_t noc_id_reg = NOC_CMD_BUF_READ_REG(noc, 0, (0xFFB20000 + 0x2C));
        uint32_t my_x = noc_id_reg & ((((uint64_t)0x1) << 6) - 1);
        uint32_t my_y = (noc_id_reg >> 6) & ((((uint64_t)0x1) << 6) - 1);
        uint64_t xy_local_addr = ((((uint64_t)(my_y)) << (36 + 6)) | (((uint64_t)(my_x)) << 36) | ((uint64_t)(0)));


        NOC_CMD_BUF_WRITE_REG(
            noc,
            DYNAMIC_NOC_BRISC_RD_CMD_BUF,
            NOC_RET_ADDR_COORDINATE,
            (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));


        NOC_CMD_BUF_WRITE_REG(
            noc,
            DYNAMIC_NOC_BRISC_WR_CMD_BUF,
            NOC_TARG_ADDR_COORDINATE,
            (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));


        NOC_CMD_BUF_WRITE_REG(
            noc,
            DYNAMIC_NOC_NCRISC_RD_CMD_BUF,
            NOC_RET_ADDR_COORDINATE,
            (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));


        NOC_CMD_BUF_WRITE_REG(
            noc,
            DYNAMIC_NOC_NCRISC_WR_CMD_BUF,
            NOC_TARG_ADDR_COORDINATE,
            (uint32_t)(xy_local_addr >> NOC_ADDR_COORD_SHIFT));
    }
}


inline __attribute__((always_inline)) void noc_local_state_init(int noc) {

    uint32_t reads_num_issued = NOC_STATUS_READ_REG(noc, 0x2);
    uint32_t nonposted_writes_num_issued = NOC_STATUS_READ_REG(noc, 0xA);
    uint32_t nonposted_writes_acked = NOC_STATUS_READ_REG(noc, 0x1);
    uint32_t nonposted_atomics_acked = NOC_STATUS_READ_REG(noc, 0x0);
    uint32_t posted_writes_num_issued = NOC_STATUS_READ_REG(noc, 0xB);

    noc_reads_num_issued[noc] = reads_num_issued;
    noc_nonposted_writes_num_issued[noc] = nonposted_writes_num_issued;
    noc_nonposted_writes_acked[noc] = nonposted_writes_acked;
    noc_nonposted_atomics_acked[noc] = nonposted_atomics_acked;
    noc_posted_writes_num_issued[noc] = posted_writes_num_issued;
}

template <NocBarrierType barrier_type, uint32_t status_register>
inline __attribute__((always_inline)) void dynamic_noc_local_barrier_init(
    uint32_t noc0_status_reg, uint32_t noc1_status_reg) {
    using underlying_tensix_processor_types_t = std::underlying_type_t<TensixProcessorTypes>;
    constexpr underlying_tensix_processor_types_t dm0 =
        static_cast<underlying_tensix_processor_types_t>(TensixProcessorTypes::DM0);
    constexpr underlying_tensix_processor_types_t dm1 =
        static_cast<underlying_tensix_processor_types_t>(TensixProcessorTypes::DM1);

    set_noc_counter_val<dm0, barrier_type>(NOC_0, noc0_status_reg);
    set_noc_counter_val<dm0, barrier_type>(NOC_1, 0);
    set_noc_counter_val<dm1, barrier_type>(NOC_0, 0);
    set_noc_counter_val<dm1, barrier_type>(NOC_1, noc1_status_reg);
}

inline __attribute__((always_inline)) void dynamic_noc_local_state_init() {

    uint32_t noc0_reads_num_issued = NOC_STATUS_READ_REG(NOC_0, 0x2);
    uint32_t noc1_reads_num_issued = NOC_STATUS_READ_REG(NOC_1, 0x2);
    uint32_t noc0_nonposted_writes_num_issued = NOC_STATUS_READ_REG(NOC_0, 0xA);
    uint32_t noc1_nonposted_writes_num_issued = NOC_STATUS_READ_REG(NOC_1, 0xA);
    uint32_t noc0_nonposted_writes_acked = NOC_STATUS_READ_REG(NOC_0, 0x1);
    uint32_t noc1_nonposted_writes_acked = NOC_STATUS_READ_REG(NOC_1, 0x1);
    uint32_t noc0_nonposted_atomics_acked = NOC_STATUS_READ_REG(NOC_0, 0x0);
    uint32_t noc1_nonposted_atomics_acked = NOC_STATUS_READ_REG(NOC_1, 0x0);
    uint32_t noc0_posted_writes_num_issued = NOC_STATUS_READ_REG(NOC_0, 0xB);
    uint32_t noc1_posted_writes_num_issued = NOC_STATUS_READ_REG(NOC_1, 0xB);
    dynamic_noc_local_barrier_init<NocBarrierType::READS_NUM_ISSUED, 0x2>(
        noc0_reads_num_issued, noc1_reads_num_issued);
    dynamic_noc_local_barrier_init<NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED, 0xA>(
        noc0_nonposted_writes_num_issued, noc1_nonposted_writes_num_issued);
    dynamic_noc_local_barrier_init<NocBarrierType::NONPOSTED_WRITES_ACKED, 0x1>(
        noc0_nonposted_writes_acked, noc1_nonposted_writes_acked);
    dynamic_noc_local_barrier_init<NocBarrierType::NONPOSTED_ATOMICS_ACKED, 0x0>(
        noc0_nonposted_atomics_acked, noc1_nonposted_atomics_acked);
    dynamic_noc_local_barrier_init<NocBarrierType::POSTED_WRITES_NUM_ISSUED, 0xB>(
        noc0_posted_writes_num_issued, noc1_posted_writes_num_issued);
}

inline __attribute__((always_inline)) void ncrisc_noc_counters_init() {
    for (int noc = 0; noc < 2; noc++) {

        uint32_t reads_num_issued = NOC_STATUS_READ_REG(noc, 0x2);
        uint32_t nonposted_writes_num_issued = NOC_STATUS_READ_REG(noc, 0xA);
        uint32_t nonposted_writes_acked = NOC_STATUS_READ_REG(noc, 0x1);
        uint32_t nonposted_atomics_acked = NOC_STATUS_READ_REG(noc, 0x0);
        uint32_t posted_writes_num_issued = NOC_STATUS_READ_REG(noc, 0xB);

        noc_reads_num_issued[noc] = reads_num_issued;
        noc_nonposted_writes_num_issued[noc] = nonposted_writes_num_issued;
        noc_nonposted_writes_acked[noc] = nonposted_writes_acked;
        noc_nonposted_atomics_acked[noc] = nonposted_atomics_acked;
        noc_posted_writes_num_issued[noc] = posted_writes_num_issued;
    }
}

inline __attribute__((always_inline)) void ncrisc_noc_full_sync() {
    for (uint32_t n = 0; n < 2; n++) {
        while (!ncrisc_noc_reads_flushed(n));
        while (!ncrisc_noc_nonposted_writes_sent(n));
        while (!ncrisc_noc_nonposted_writes_flushed(n));
        while (!ncrisc_noc_nonposted_atomics_flushed(n));
        while (!ncrisc_noc_posted_writes_sent(n));
    }
}

template <uint8_t noc_mode = DM_DEDICATED_NOC>
inline __attribute__((always_inline)) void ncrisc_noc_fast_read_any_len(
    uint32_t noc, uint32_t cmd_buf, uint64_t src_addr, uint32_t dest_addr, uint32_t len_bytes) {
    while (len_bytes > (256 * (256 / 8))) {
        while (!noc_cmd_buf_ready(noc, cmd_buf));
        ncrisc_noc_fast_read<noc_mode>(noc, cmd_buf, src_addr, dest_addr, (256 * (256 / 8)));
        src_addr += (256 * (256 / 8));
        dest_addr += (256 * (256 / 8));
        len_bytes -= (256 * (256 / 8));
    }
    while (!noc_cmd_buf_ready(noc, cmd_buf));
    ncrisc_noc_fast_read<noc_mode>(noc, cmd_buf, src_addr, dest_addr, len_bytes);
}

template <uint8_t noc_mode = DM_DEDICATED_NOC, bool use_trid = false, bool one_packet = false>
inline __attribute__((always_inline)) void ncrisc_noc_fast_write_any_len(
    uint32_t noc,
    uint32_t cmd_buf,
    uint32_t src_addr,
    uint64_t dest_addr,
    uint32_t len_bytes,
    uint32_t vc,
    bool mcast,
    bool linked,
    uint32_t num_dests,
    bool multicast_path_reserve,
    bool posted = false,
    uint32_t trid = 0) {
    if constexpr (!one_packet) {
        while (len_bytes > (256 * (256 / 8))) {
            while (!noc_cmd_buf_ready(noc, cmd_buf));
            ncrisc_noc_fast_write<noc_mode, use_trid>(
                noc,
                cmd_buf,
                src_addr,
                dest_addr,
                (256 * (256 / 8)),
                vc,
                mcast,
                linked,
                num_dests,
                multicast_path_reserve,
                posted,
                trid);
            src_addr += (256 * (256 / 8));
            dest_addr += (256 * (256 / 8));
            len_bytes -= (256 * (256 / 8));
        }
    }
    while (!noc_cmd_buf_ready(noc, cmd_buf));
    ncrisc_noc_fast_write<noc_mode, use_trid>(
        noc,
        cmd_buf,
        src_addr,
        dest_addr,
        len_bytes,
        vc,
        mcast,
        linked,
        num_dests,
        multicast_path_reserve,
        posted,
        trid);
}

template <uint8_t noc_mode = DM_DEDICATED_NOC>
inline __attribute__((always_inline)) void ncrisc_noc_fast_write_any_len_loopback_src(
    uint32_t noc,
    uint32_t cmd_buf,
    uint32_t src_addr,
    uint64_t dest_addr,
    uint32_t len_bytes,
    uint32_t vc,
    bool mcast,
    bool linked,
    uint32_t num_dests,
    bool multicast_path_reserve) {
    while (len_bytes > (256 * (256 / 8))) {
        while (!noc_cmd_buf_ready(noc, cmd_buf));
        ncrisc_noc_fast_write_loopback_src<noc_mode>(
            noc,
            cmd_buf,
            src_addr,
            dest_addr,
            (256 * (256 / 8)),
            vc,
            mcast,
            linked,
            num_dests,
            multicast_path_reserve);
        src_addr += (256 * (256 / 8));
        dest_addr += (256 * (256 / 8));
        len_bytes -= (256 * (256 / 8));
    }
    while (!noc_cmd_buf_ready(noc, cmd_buf));
    ncrisc_noc_fast_write_loopback_src<noc_mode>(
        noc, cmd_buf, src_addr, dest_addr, len_bytes, vc, mcast, linked, num_dests, multicast_path_reserve);
}

template <uint8_t noc_mode = DM_DEDICATED_NOC>
inline __attribute__((always_inline)) void noc_fast_write_dw_inline(
    uint32_t noc,
    uint32_t cmd_buf,
    uint32_t val,
    uint64_t dest_addr,
    uint32_t be,
    uint32_t static_vc,
    bool mcast,
    bool posted = false) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        if (posted) {
            inc_noc_counter_val<proc_type, NocBarrierType::POSTED_WRITES_NUM_ISSUED>(noc, 1);
        } else {
            inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_NUM_ISSUED>(noc, 1);
            inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_WRITES_ACKED>(noc, 1);
        }
    }
    bool static_vc_alloc = true;
    uint32_t noc_cmd_field = (static_vc_alloc ? (0x1 << 7) : 0x0) | (((uint32_t)(static_vc)) << 13) | (0x0 << 0) |
                             (0x1 << 1) | (0x1 << 3) |
                             (mcast ? ((0x1 << 8) | (0x1 << 5)) : 0x0) |
                             (posted ? 0x0 : (0x1 << 4));

    uint32_t be32 = be;
    uint32_t be_shift = (dest_addr & ((256 / 8) - 1));

    be32 = (be32 << be_shift);

    while (!noc_cmd_buf_ready(noc, cmd_buf));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x24), val);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_cmd_field);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), dest_addr & 0xFFFFFFFF);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, NOC_TARG_ADDR_COORDINATE, (uint32_t)(dest_addr >> NOC_ADDR_COORD_SHIFT));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), be32);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), (0x1 << 0));

    if constexpr (noc_mode == DM_DEDICATED_NOC) {
        if (posted) {
            noc_posted_writes_num_issued[noc] += 1;
        } else {
            noc_nonposted_writes_num_issued[noc] += 1;
            noc_nonposted_writes_acked[noc] += 1;
        }
    }
}

template <uint8_t noc_mode = DM_DEDICATED_NOC, bool program_ret_addr = false>
inline __attribute__((always_inline)) void noc_fast_atomic_increment(
    uint32_t noc,
    uint32_t cmd_buf,
    uint64_t addr,
    uint32_t vc,
    uint32_t incr,
    uint32_t wrap,
    bool linked,
    bool posted = false,
    uint32_t atomic_ret_val = 0) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        if (!posted) {
            inc_noc_counter_val<proc_type, NocBarrierType::NONPOSTED_ATOMICS_ACKED>(noc, 1);
        }
    }
    while (!noc_cmd_buf_ready(noc, cmd_buf));
    if constexpr (noc_mode == DM_DYNAMIC_NOC || program_ret_addr == true) {
        uint32_t noc_id_reg = NOC_CMD_BUF_READ_REG(noc, 0, (0xFFB20000 + 0x2C));
        uint32_t my_x = noc_id_reg & ((((uint64_t)0x1) << 6) - 1);
        uint32_t my_y = (noc_id_reg >> 6) & ((((uint64_t)0x1) << 6) - 1);
        uint64_t atomic_ret_addr = ((((uint64_t)(my_y)) << (36 + 6)) | (((uint64_t)(my_x)) << 36) | ((uint64_t)(atomic_ret_val)));
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0xC), (uint32_t)(atomic_ret_addr & 0xFFFFFFFF));
    }
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), (uint32_t)(addr & 0xFFFFFFFF));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, NOC_TARG_ADDR_COORDINATE, (uint32_t)(addr >> NOC_ADDR_COORD_SHIFT));
    NOC_CMD_BUF_WRITE_REG(
        noc,
        cmd_buf,
        (0xFFB20000 + 0x1C),
        (0x1 << 7) | (((uint32_t)(vc)) << 13) | (linked ? (0x1 << 6) : 0x0) |
            (posted ? 0 : (0x1 << 4)) | (0x1 << 0));
    NOC_CMD_BUF_WRITE_REG(
        noc,
        cmd_buf,
        (0xFFB20000 + 0x20),
        ((0x1) << 12) | ((wrap) << 2) | (((addr >> 2) & 0x3) << 0) | ((0) << 10));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x24), incr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), 0x1);
    if constexpr (noc_mode == DM_DEDICATED_NOC) {
        if (!posted) {
            noc_nonposted_atomics_acked[noc] += 1;
        }
    }
}


template <uint8_t noc_mode = DM_DEDICATED_NOC, bool skip_ptr_update = false>
inline __attribute__((always_inline)) void ncrisc_noc_fast_read_with_transaction_id(
    uint32_t noc, uint32_t cmd_buf, uint32_t src_base_addr, uint32_t src_addr, uint32_t dest_addr, uint32_t trid) {
    if constexpr (noc_mode == DM_DYNAMIC_NOC && !skip_ptr_update) {
        inc_noc_counter_val<proc_type, NocBarrierType::READS_NUM_ISSUED>(noc, 1);
    }
    uint32_t src_addr_;
    src_addr_ = src_base_addr + src_addr;

    while (!noc_cmd_buf_ready(noc, cmd_buf));
    while (NOC_STATUS_READ_REG(noc, (0x10 + (trid))) > ((255 + 1) / 2));

    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0xC), dest_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), src_addr_);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), (0x1 << 0));
    if constexpr (noc_mode == DM_DEDICATED_NOC && !skip_ptr_update) {
        noc_reads_num_issued[noc] += 1;
    }
}


inline __attribute__((always_inline)) void ncrisc_noc_set_transaction_id(
    uint32_t noc, uint32_t cmd_buf, uint32_t trid) {
    while (!noc_cmd_buf_ready(noc, cmd_buf));
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x18), ((trid) << 10));
}
template <uint8_t noc_mode = DM_DEDICATED_NOC, bool one_packet = false, bool use_vc = false>
inline __attribute__((always_inline)) void ncrisc_noc_read_set_state(
    uint32_t noc, uint32_t cmd_buf, uint64_t src_noc_addr, uint32_t len_bytes = 0, const uint32_t vc = 0) {
    while (!noc_cmd_buf_ready(noc, cmd_buf));

    if constexpr (noc_mode == DM_DYNAMIC_NOC) {
        uint32_t noc_rd_cmd_field =
            (0x0 << 0) | (0x0 << 1) | (0x1 << 4) | (0x1 << 7) | (((uint32_t)(1)) << 13);
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_rd_cmd_field);
    }
    if constexpr (use_vc) {
        uint32_t noc_rd_cmd_field =
            (0x0 << 0) | (0x0 << 1) | (0x1 << 4) | (0x1 << 7) | (((uint32_t)(vc)) << 13);
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x1C), noc_rd_cmd_field);
    }
    NOC_CMD_BUF_WRITE_REG(
        noc, cmd_buf, NOC_TARG_ADDR_COORDINATE, (uint32_t)(src_noc_addr >> NOC_ADDR_COORD_SHIFT) & NOC_COORDINATE_MASK);


    if constexpr (one_packet) {
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), len_bytes);
    }
}
template <uint8_t noc_mode = DM_DEDICATED_NOC, bool inc_num_issued = true, bool one_packet = false>
inline __attribute__((always_inline)) void ncrisc_noc_read_with_state(
    uint32_t noc, uint32_t cmd_buf, uint32_t src_local_addr, uint32_t dst_local_addr, uint32_t len_bytes = 0) {
    if constexpr (inc_num_issued && noc_mode == DM_DYNAMIC_NOC) {
        inc_noc_counter_val<proc_type, NocBarrierType::READS_NUM_ISSUED>(noc, 1);
    }

    while (!noc_cmd_buf_ready(noc, cmd_buf));

    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0xC), dst_local_addr);
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x0), src_local_addr);
    if constexpr (!one_packet) {
        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), len_bytes);
    }
    NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x28), (0x1 << 0));

    if constexpr (inc_num_issued && noc_mode == DM_DEDICATED_NOC) {
        noc_reads_num_issued[noc] += 1;
    }
}
template <uint8_t noc_mode = DM_DEDICATED_NOC, bool inc_num_issued = true>
inline __attribute__((always_inline)) void ncrisc_noc_read_any_len_with_state(
    uint32_t noc, uint32_t cmd_buf, uint32_t src_local_addr, uint32_t dst_local_addr, uint32_t len_bytes) {
    if (len_bytes > (256 * (256 / 8))) {

        NOC_CMD_BUF_WRITE_REG(noc, cmd_buf, (0xFFB20000 + 0x20), (256 * (256 / 8)));

        while (len_bytes > (256 * (256 / 8))) {
            ncrisc_noc_read_with_state<noc_mode, inc_num_issued, true >(
                noc, cmd_buf, src_local_addr, dst_local_addr);

            len_bytes -= (256 * (256 / 8));
            src_local_addr += (256 * (256 / 8));
            dst_local_addr += (256 * (256 / 8));
        }
    }


    ncrisc_noc_read_with_state<noc_mode, inc_num_issued>(noc, cmd_buf, src_local_addr, dst_local_addr, len_bytes);
}

using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_abs() {

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        dst_reg[0] = sfpi::abs(v);
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_abs_int32() {

    for (int d = 0; d < ITERATIONS; d++) {
        ckernel::instrn_buffer[0] = ((0x70 << 24) + (((1) << 20) + ((4) << 16) + ((3) << 14) + ((0) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7d << 24) + (((0) << 12) + ((1) << 8) + ((0) << 4) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((4) << 16) + ((3) << 14) + ((0) << 0))))));
        dst_reg++;
    }
}
}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_abs_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::abs, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_abs(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_abs<APPROXIMATE>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_abs_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_abs_int32<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       




using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void calculate_comp(uint exponent_size_8) {
    const vFloat zero = 0.0f;
    const vFloat one = 1.0f;
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];


        if constexpr (COMP_MODE == SfpuType::equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(v, exponent_size_8)); { v = one; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::not_equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(v, exponent_size_8)); { v = zero; }
            __cc.cc_else(); { v = one; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::less_than_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0.0f); { v = zero; }
            __cc.cc_else(); { v = one; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::greater_than_equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0.0f); { v = one; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::greater_than_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > 0.0f); { v = one; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::less_than_equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > 0.0f); { v = zero; }
            __cc.cc_else(); { v = one; }
            };
        }

        dst_reg[0] = v;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void calculate_comp_int() {
    for (int d = 0; d < ITERATIONS; d++) {
        vInt v = dst_reg[0];
        vInt zero = 0;


        if constexpr (COMP_MODE == SfpuType::equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == zero); { v = 1; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::not_equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == zero); { v = zero; }
            __cc.cc_else(); { v = 1; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::less_than_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < zero); { v = 1; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::greater_than_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > zero); { v = 1; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::less_than_equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v <= zero); { v = 1; }
            __cc.cc_else(); { v = zero; }
            };
        }


        if constexpr (COMP_MODE == SfpuType::greater_than_equal_zero) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= zero); { v = 1; }
            __cc.cc_else(); { v = zero; }
            };
        }

        dst_reg[0] = v;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, SfpuType COMP_MODE, int ITERATIONS = 8>
inline void calculate_comp_unary_int(int scalar) {
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vInt v = dst_reg[0];
        vInt val = 0;
        vInt s = scalar;


        if constexpr (COMP_MODE == SfpuType::unary_ne) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0); {
                { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v != scalar); { val = 1; }
                };
            }
            __cc.cc_else(); {
                { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0); {
                    vInt xor_val = reinterpret<vInt>(sfpi::abs(reinterpret<vFloat>(v))) ^ -s;
                    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(xor_val != 0); { val = 1; }
                    };
                }
                __cc.cc_else(); { val = 1; }
                };
            }
            };
        }

        else if constexpr (COMP_MODE == SfpuType::unary_eq) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= 0); {
                { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == scalar); { val = 1; }
                };
            }
            __cc.cc_else(); {
                { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s < 0); {
                    vInt xor_val = reinterpret<vInt>(sfpi::abs(reinterpret<vFloat>(v))) ^ -s;
                    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(xor_val == 0); { val = 1; }
                    };
                }
                __cc.cc_else(); { val = 0; }
                };
            }
            };
        }
        dst_reg[0] = val;
        dst_reg++;
    }
}

}
}

namespace ckernel {




template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_eqz(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp<APPROXIMATE, SfpuType::equal_zero>, dst_index, vector_mode, 8);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_eqz_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_int<APPROXIMATE, SfpuType::equal_zero>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_eqz_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::equal_zero, APPROXIMATE>();
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_nez(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp<APPROXIMATE, SfpuType::not_equal_zero>, dst_index, vector_mode, 8);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_nez_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_int<APPROXIMATE, SfpuType::not_equal_zero>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_nez_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::not_equal_zero, APPROXIMATE>();
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_ltz(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp<APPROXIMATE, SfpuType::less_than_zero>, dst_index, vector_mode, 8);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_ltz_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_int<APPROXIMATE, SfpuType::less_than_zero>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_ltz_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::less_than_zero, APPROXIMATE>();
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_gtz(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp<APPROXIMATE, SfpuType::greater_than_zero>, dst_index, vector_mode, 8);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_gtz_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_int<APPROXIMATE, SfpuType::greater_than_zero>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_gtz_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::greater_than_zero, APPROXIMATE>();
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_lez(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp<APPROXIMATE, SfpuType::less_than_equal_zero>, dst_index, vector_mode, 8);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_lez_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_int<APPROXIMATE, SfpuType::less_than_equal_zero>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_lez_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::less_than_equal_zero, APPROXIMATE>();
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_gez(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp<APPROXIMATE, SfpuType::greater_than_equal_zero>, dst_index, vector_mode, 8);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_gez_int32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_int<APPROXIMATE, SfpuType::greater_than_equal_zero>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_gez_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::greater_than_equal_zero, APPROXIMATE>();
}

}




       







       




namespace ckernel {
namespace sfpu {

template <bool IS_MAX_OP = true, bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_unary_max_min(uint value) {


    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG2) << 20) + ((10) << 16) + ((value & 0xFFFF) << 0)));
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG2) << 20) + ((8) << 16) + ((value >> 16) << 0)));

#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((1) << 0))))));

        if constexpr (IS_MAX_OP) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        } else {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        }
        dst_reg++;
    }
}

template <bool IS_MAX_OP = true, bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_unary_max_min_int32(uint value) {
    int scalar = value;
    if (scalar < 0) {
        scalar = -scalar;
        int res = 0x80000000 | (scalar & 0x7FFFFFFF);
        scalar = res;
    }


    _sfpu_load_imm32_(p_sfpu::LREG2, scalar);

#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32_2S_COMP) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LREG2) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x92 << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG0) << 4) + ((1) << 0))))));


        if constexpr (IS_MAX_OP) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((InstrModLoadStore::INT32_2S_COMP) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        } else {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32_2S_COMP) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        }
        dst_reg++;
    }
}

}
}

namespace ckernel {




template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_max_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_max, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_max(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_max_min<true, APPROXIMATE>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_max_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_max_min_int32<true, APPROXIMATE>, dst_index, vector_mode, param0);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_min_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_min, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_min(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_max_min<false, APPROXIMATE>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_min_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_max_min_int32<false, APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       







       



namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_exp2() {
    _calculate_exp2_<APPROXIMATION_MODE, ITERATIONS>();
}

template <bool APPROXIMATION_MODE>
inline void exp2_init() {
    _init_exp2_<APPROXIMATION_MODE>();
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_exp2_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::exp2, APPROXIMATE>(sfpu::exp2_init<APPROXIMATE>);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_exp2(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_exp2<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       



namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_expm1() {
    const bool SCALE_EN = false;
    const bool SKIP_POSITIVE_CHECK = false;
    const uint16_t exp_base_scale_factor = p_sfpu::kCONST_1_FP16B;


    for (int d = 0; d < ITERATIONS; d++) {
        sfpi::vFloat v = sfpi::dst_reg[0];
        v = _calculate_exponential_piecewise_<APPROXIMATION_MODE, SCALE_EN, SKIP_POSITIVE_CHECK>(
            v, exp_base_scale_factor);
        sfpi::dst_reg[0] = v - 1.0f;
        sfpi::dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
void expm1_init() {
    const uint32_t EXP_BASE_SCALE_FACTOR = 0x3F800000;
    _init_exponential_<APPROXIMATION_MODE, false , EXP_BASE_SCALE_FACTOR>();
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_expm1_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::expm1, APPROXIMATE>(sfpu::expm1_init<APPROXIMATE>);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_expm1(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_expm1<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       






using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_heaviside(uint value) {

    vFloat s = Converter::as_float(value);

#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < 0.0f); { v = 0.0f; }
        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(v > 0.0f); { v = 1.0f; }
        __cc.cc_else(); { v = s; }
        };

        dst_reg[0] = v;

        dst_reg++;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_heaviside_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::heaviside, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_heaviside(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_heaviside<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool HAS_BASE_SCALING>
__attribute__((always_inline)) inline void calculate_log_body(const uint log_base_scale_factor) {



    vFloat in = dst_reg[0];
    vFloat x = setexp(in, 127);
    vFloat a = vConstFloatPrgm1;
    vFloat b = vConstFloatPrgm2;

    vFloat series_result = x * (x * (x * a + b) + 2.0871) + -1.4753f;




    vInt exp = exexp(in);
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0); { exp = setsgn(~exp + 1, 1); }
    };

    vFloat expf = int32_to_float(exp, 0);
    vFloat vConstLn2 = vConstFloatPrgm0;
    vFloat result = expf * vConstLn2 + series_result;

    if constexpr (HAS_BASE_SCALING) {
        result *= s2vFloat16a(log_base_scale_factor);
    }




    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in == 0.0F); {
        result = -std::numeric_limits<float>::infinity();
    }
    };

    dst_reg[0] = result;
}

template <bool APPROXIMATION_MODE, bool HAS_BASE_SCALING, int ITERATIONS = 8>
inline void calculate_log(uint log_base_scale_factor) {
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        calculate_log_body<HAS_BASE_SCALING>(log_base_scale_factor);
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void log_init() {
    vConstFloatPrgm0 = 0.692871f;


    vConstFloatPrgm1 = 0.1058f;
    vConstFloatPrgm2 = -0.7166f;
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_log_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::log, APPROXIMATE>(sfpu::log_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_log(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_log<APPROXIMATE, false>, dst_index, vector_mode, 0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_log_with_base_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::log_with_base, APPROXIMATE>(sfpu::log_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_log_with_base(
    uint dst_index, uint base_scale, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_log<APPROXIMATE, true>, dst_index, vector_mode, base_scale);
}

}




       







       




using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_log1p() {
    vFloat a = vConstFloatPrgm1;
    vFloat b = vConstFloatPrgm2;
    vFloat vConstLn2 = vConstFloatPrgm0;

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat in = dst_reg[0];
        in = in + 1.0f;
        vFloat x = setexp(in, 127);


        vFloat series_result = x * (x * (x * a + b) + 2.0871) + -1.4753f;

        vInt exp = exexp(in);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0); { exp = setsgn(~exp + 1, 1); }
        };

        vFloat expf = int32_to_float(exp, 0);
        vFloat result = expf * vConstLn2 + series_result;

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(in == 0.0F); { result = -std::numeric_limits<float>::infinity(); }
        };

        dst_reg[0] = result;
        ++dst_reg;
    }
}

template <bool APPROXIMATION_MODE>
inline void log1p_init() {
    vConstFloatPrgm0 = 0.692871f;
    vConstFloatPrgm1 = 0.1058f;
    vConstFloatPrgm2 = -0.7166f;
}

}
}

namespace ckernel {

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_log1p_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::log1p, APPROXIMATE>(sfpu::log1p_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_log1p(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_log1p<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_max() {
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat a = dst_reg[0];
        vFloat b = dst_reg[32];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(a < b); { dst_reg[0] = b; }
        };

        dst_reg++;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_max_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::max, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_max(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_max<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_power_iterative(const uint exponent) {
#pragma GCC unroll 8
    for (int d = 0; d < 8; d++) {
        uint exp = exponent;
        vFloat in = dst_reg[0];
        vFloat result = 1.0f;
        while (exp > 0) {
            if (exp & 1){
                result *= in;
            }
            in *= in;
            exp >>= 1;
        }
        dst_reg[0] = result;
        dst_reg++;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_power_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::power, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_power(uint dst_index, int pow = 0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_power_iterative<APPROXIMATE>, dst_index, vector_mode, pow);
}

}




       







       








       







using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <int max_iter = 3, bool save_reg = true >
__attribute__((always_inline)) inline vFloat sfpu_reciprocal(const vFloat in) {
    return _sfpu_reciprocal_<max_iter>(in);
}

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, int ITERATIONS = 8>
inline void calculate_reciprocal() {
    _calculate_reciprocal_<APPROXIMATION_MODE, ITERATIONS, is_fp32_dest_acc_en>(ITERATIONS);
}

template <bool APPROXIMATION_MODE>
void recip_init() {
    _init_reciprocal_<APPROXIMATION_MODE>();
}

}
}


using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS, int RECIPROCAL_ITERATIONS>
inline void calculate_rsqrt() {
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat in = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(dst_reg[0] == 0.0f); { dst_reg[0] = std::numeric_limits<float>::infinity(); }
        __cc.cc_else(); {
            vFloat result = 1.0f;
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(dst_reg[0] > 1.0f); { result = sfpu_reciprocal(in); }
            };

            for (int r = 0; r < RECIPROCAL_ITERATIONS; r++) {

                result = result * (1.5F - 0.5F * dst_reg[0] * result * result);
            }
            dst_reg[0] = result;
        }
        };

        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
inline void rsqrt_init() {
    vConstFloatPrgm0 = 1.442695f;
    vConstFloatPrgm1 = 2.0f;
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_rsqrt_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::rsqrt, APPROXIMATE>(sfpu::rsqrt_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_rsqrt(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_rsqrt<APPROXIMATE, 8, 25>, dst_index, vector_mode);

}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_tiled_prod() {
    vFloat result = 1.0f;
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        result *= v;
        dst_reg[0] = result;
        dst_reg++;
    }
    vFloat v = dst_reg[0];
    result *= v;
    dst_reg[0] = result;
    dst_reg++;
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_tiled_prod_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::tiled_prod, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_tiled_prod(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_tiled_prod<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       








       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <int ITERATIONS = 8>
inline void calculate_sigmoid_appx() {
    vUInt l0 = l_reg[LRegs::LReg0];
    vUInt l1 = l_reg[LRegs::LReg1];
    vUInt l2 = l_reg[LRegs::LReg2];

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];

        dst_reg[0] = lut(val, l0, l1, l2) + 0.5f;

        dst_reg++;
    }

    l_reg[LRegs::LReg0] = l0;
    l_reg[LRegs::LReg1] = l1;
    l_reg[LRegs::LReg2] = l2;
}

inline void sigmoid_appx_init() {
    uint imm0;
    uint imm1;
    uint imm2;
    imm0 = 0x3DFF;
    imm1 = 0x21D8;
    imm2 = 0xFF10;
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((0) << 20) + ((2) << 16) + ((imm0) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((1) << 20) + ((2) << 16) + ((imm1) << 0))))));
    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x71 << 24) + (((2) << 20) + ((2) << 16) + ((imm2) << 0))))));
}

}
}

using namespace sfpi;

namespace ckernel {
namespace sfpu {



template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_sigmoid() {
    if constexpr (APPROXIMATION_MODE == false) {
        for (int d = 0; d < ITERATIONS; d++) {
            vFloat val = dst_reg[0];
            vFloat result = 0.0f;

            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0f); { val = -val; }
            };

            result = _sigmoid_piecewise_linear_positive_(val);

            val = dst_reg[0];
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0f); { result = 1.0f - result; }
            };

            dst_reg[0] = result;
            dst_reg++;
        }
    } else {
        calculate_sigmoid_appx<ITERATIONS>();
    }
}

template <bool APPROXIMATION_MODE>
inline void sigmoid_init() {
    if constexpr (APPROXIMATION_MODE == false) {
        _sfpu_load_imm32_(0, 0x32F433D9);

        _sfpu_load_imm32_(4, 0x23C89018);


        _sfpu_load_imm32_(1, 0x300A318A);

        _sfpu_load_imm32_(5, 0x30272BAA);


        _sfpu_load_imm32_(2, 0x7C002A35);

        _sfpu_load_imm32_(6, 0x37ff34CC);
    } else {
        sigmoid_appx_init();
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sigmoid_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::sigmoid, APPROXIMATE>(sfpu::sigmoid_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sigmoid(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_sigmoid<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_sign(const uint exponent_size_8) {
    _calculate_sign_<APPROXIMATION_MODE, ITERATIONS>(ITERATIONS, exponent_size_8);
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sign_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::sign, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sign(
    uint dst_index, int vector_mode = (int)VectorMode::RC, uint exponent_size_8 = 1) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_sign<APPROXIMATE>, dst_index, vector_mode, exponent_size_8);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {


template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_signbit() {
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0.0f); { val = 1.0f; }
        __cc.cc_else(); { val = 0.0f; }
        };
        dst_reg[0] = val;

        dst_reg++;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_signbit_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::signbit, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_signbit(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_signbit<APPROXIMATE>, dst_index, vector_mode);
}

}




       




namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_rounding_op_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unused, APPROXIMATE>();
}

template <bool APPROXIMATE, int ITERATIONS = 8, bool USE_FP32 = false>
inline void llk_math_eltwise_unary_sfpu_floor(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_floor_<APPROXIMATE, ITERATIONS, USE_FP32>, dst_index, vector_mode);
}

template <bool APPROXIMATE, int ITERATIONS = 8, bool USE_FP32 = true>
inline void llk_math_eltwise_unary_sfpu_floor_float32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_floor_<APPROXIMATE, ITERATIONS, USE_FP32>, dst_index, vector_mode);
}

template <bool APPROXIMATE, int ITERATIONS = 8, bool USE_FP32 = false>
inline void llk_math_eltwise_unary_sfpu_ceil(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_ceil_<APPROXIMATE, ITERATIONS, USE_FP32>, dst_index, vector_mode);
}

template <bool APPROXIMATE, int ITERATIONS = 8, bool USE_FP32 = true>
inline void llk_math_eltwise_unary_sfpu_ceil_float32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_ceil_<APPROXIMATE, ITERATIONS, USE_FP32>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_trunc(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_trunc_<APPROXIMATE>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_trunc_float32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_trunc_<APPROXIMATE, true>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_round(uint dst_index, int decimals, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_round_<APPROXIMATE>, dst_index, vector_mode, decimals);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_frac(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_frac_<APPROXIMATE>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_frac_float32(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_frac_<APPROXIMATE, true>, dst_index, vector_mode);
}

}




       




namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_silu_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::silu, APPROXIMATE>();
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_silu(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_silu_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_square() {
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat in = dst_reg[0];
        vFloat result = in * in;

        dst_reg[0] = result;

        dst_reg++;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_square_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::square, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_square(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_square<APPROXIMATE>, dst_index, vector_mode);
}

}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_tanh() {

    vUInt l0 = l_reg[LRegs::LReg0];
    vUInt l1 = l_reg[LRegs::LReg1];
    vUInt l2 = l_reg[LRegs::LReg2];

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        val = lut(val, l0, l1, l2);
        dst_reg[0] = val;

        dst_reg++;
    }

    l_reg[LRegs::LReg0] = l0;
    l_reg[LRegs::LReg1] = l1;
    l_reg[LRegs::LReg2] = l2;
}

template <bool APPROXIMATION_MODE>
inline void tanh_init() {
    uint imm0;
    uint imm1;
    uint imm2;
    imm0 = 0x1DFF;
    imm1 = 0x481A;
    imm2 = 0xFF00;
    _sfpu_load_imm16_(0, imm0);
    _sfpu_load_imm16_(1, imm1);
    _sfpu_load_imm16_(2, imm2);
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_tanh_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::tanh, APPROXIMATE>(sfpu::tanh_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_tanh(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_tanh<APPROXIMATE>, dst_index, vector_mode);
}

}




       








       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, int ITERATIONS = 8>
inline void calculate_bitonic_topk_phases_steps(
    uint idir, uint i_end_phase, uint i_start_phase, uint i_end_step, uint i_start_step) {
    _bitonic_topk_phases_steps<APPROXIMATION_MODE, is_fp32_dest_acc_en, ITERATIONS>(
        idir, i_end_phase, i_start_phase, i_end_step, i_start_step);
}

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, bool idir = false, int ITERATIONS = 8>
inline void calculate_bitonic_topk_merge(uint m_iter, uint k) {
    _bitonic_topk_merge<APPROXIMATION_MODE, is_fp32_dest_acc_en, idir, ITERATIONS>(m_iter, k);
}

template <bool APPROXIMATION_MODE, bool is_fp32_dest_acc_en, int ITERATIONS = 8>
inline void calculate_bitonic_topk_rebuild(uint idir, uint m_iter, uint k, uint logk, uint skip_second) {
    _bitonic_topk_rebuild<APPROXIMATION_MODE, is_fp32_dest_acc_en, ITERATIONS>(idir, m_iter, k, logk, skip_second);
}

template <bool APPROXIMATION_MODE>
inline void topk_init() {
    _init_topk();
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_topk_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::topk_local_sort, APPROXIMATE>(sfpu::topk_init<APPROXIMATE>);
}

template <bool APPROXIMATE, bool is_fp32_dest_acc_en>
inline void llk_math_eltwise_unary_sfpu_topk_local_sort(
    uint dst_index,
    int idir,
    int i_end_phase,
    int i_start_phase,
    int i_end_step,
    int i_start_step,
    int vector_mode = (int)VectorMode::RC_custom) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitonic_topk_phases_steps<APPROXIMATE, is_fp32_dest_acc_en>,
        dst_index,
        vector_mode,
        idir,
        i_end_phase,
        i_start_phase,
        i_end_step,
        i_start_step);
}

template <bool APPROXIMATE, bool is_fp32_dest_acc_en, bool idir = false>
inline void llk_math_eltwise_unary_sfpu_topk_merge(
    uint dst_index, int m_iter, int k, int vector_mode = (int)VectorMode::RC_custom) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitonic_topk_merge<APPROXIMATE, is_fp32_dest_acc_en, idir>,
        dst_index,
        vector_mode,
        m_iter,
        k);
}

template <bool APPROXIMATE, bool is_fp32_dest_acc_en>
inline void llk_math_eltwise_unary_sfpu_topk_rebuild(
    uint dst_index,
    bool idir,
    int m_iter,
    int k,
    int logk,
    int skip_second,
    int vector_mode = (int)VectorMode::RC_custom) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitonic_topk_rebuild<APPROXIMATE, is_fp32_dest_acc_en>,
        dst_index,
        vector_mode,
        idir,
        m_iter,
        k,
        logk,
        skip_second);
}

}




       







       






using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_unary_ne(uint value) {

    vFloat s = Converter::as_float(value);

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == s); { v = 0.0f; }
        __cc.cc_else(); { v = 1.0f; }
        };

        dst_reg[0] = v;

        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_unary_eq(uint value) {

    vFloat s = Converter::as_float(value);

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v == s); { v = 1.0f; }
        __cc.cc_else(); { v = 0.0f; }
        };

        dst_reg[0] = v;

        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_unary_gt(uint value) {

    vFloat s = Converter::as_float(value);

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v > s); { v = 1.0f; }
        __cc.cc_else(); { v = 0.0f; }
        };

        dst_reg[0] = v;

        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_unary_lt(uint value) {

    vFloat s = Converter::as_float(value);

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v < s); { v = 1.0f; }
        __cc.cc_else(); { v = 0.0f; }
        };

        dst_reg[0] = v;

        dst_reg++;
    }
}

}
}

namespace ckernel {




template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_ne_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_unary_int<APPROXIMATE, SfpuType::unary_ne>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_ne_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_ne, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_ne(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_ne<APPROXIMATE>, dst_index, vector_mode, param0);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_eq_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_comp_unary_int<APPROXIMATE, SfpuType::unary_eq>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_eq_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_eq, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_eq(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_eq<APPROXIMATE>, dst_index, vector_mode, param0);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_gt_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_comp_unary_int_<APPROXIMATE, SfpuType::unary_gt>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_gt_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_gt, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_gt(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_gt<APPROXIMATE>, dst_index, vector_mode, param0);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_lt_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_comp_unary_int_<APPROXIMATE, SfpuType::unary_lt>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_lt_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_lt, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_lt(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_unary_lt<APPROXIMATE>, dst_index, vector_mode, param0);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_ge_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_comp_unary_int_<APPROXIMATE, SfpuType::unary_ge>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_ge_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_ge, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_ge(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_comp_unary_<APPROXIMATE, SfpuType::unary_ge>, dst_index, vector_mode, param0);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_le_int32(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_comp_unary_int_<APPROXIMATE, SfpuType::unary_le>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_le_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unary_le, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_unary_le(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_comp_unary_<APPROXIMATE, SfpuType::unary_le>, dst_index, vector_mode, param0);
}
}




       







       







using namespace sfpi;

namespace ckernel {

namespace sfpu {

static const float PI = 3.1415927f;
static const float PI_2 = 1.5707964f;
static const float PI_4 = 0.7853982f;
static const float FRAC_1_PI = 0.31830987f;

static __attribute__((always_inline)) inline vFloat sfpu_tan_large(vFloat x) {
    const vFloat r = 4.0f * sfpi::abs(x) - 5.0f;
    const vFloat y =
        ((((((((((((2.1457846f * r + 2.815174f) * r - 3.9035487f) * r - 5.2096696f) * r + 3.658698f) * r + 4.9457364f) *
                   r -
               0.7137798f) *
                  r -
              1.0665413f) *
                 r +
             1.1057009f) *
                r +
            1.462757f) *
               r +
           1.4643353f) *
              r +
          1.8716435f) *
             r +
         2.514385f) *
            r +
        3.0097759f;
    return setsgn(y, x);
}

template <bool APPROXIMATION_MODE>
static vFloat sfpu_tan(vFloat x);

template <>
__attribute__((always_inline)) inline vFloat sfpu_tan<true>(vFloat x) {
    const vFloat xx = x * x;

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(x) <= 1.0f); {
        x *= (((0.07407404f * xx - 0.0031158808f) * xx + 0.1559396f) * xx + 0.33035427) * xx + 1.0000609f;
    }
    __cc.cc_else(); { x = sfpu_tan_large(x); }
    };

    return x;
}

template <>
__attribute__((always_inline)) inline vFloat sfpu_tan<false>(vFloat x) {
    const vFloat xx = x * x;

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(x) <= 1.0f); {
        x *= ((((((0.010222361f * xx - 0.015764693f) * xx + 0.02789032f) * xx + 0.012122508f) * xx + 0.05659461f) * xx +
               0.1329926f) *
                  xx +
              0.33334994f) *
                 xx +
             0.9999999f;
    }
    __cc.cc_else(); { x = sfpu_tan_large(x); }
    };

    return x;
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void calculate_tangent() {

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0] * FRAC_1_PI;
        v -= int32_to_float(float_to_int16(v, 0), 0);
        dst_reg[0] = sfpu_tan<APPROXIMATION_MODE>(PI * v);
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
static vFloat sfpu_sinpi(vFloat x);

template <>
__attribute__((always_inline)) inline vFloat sfpu_sinpi<true>(vFloat x) {
    vFloat xx = x * x;

    return x * ((0x1.29cf02p+1f * xx - 0x1.4954d4p+2f) * xx + 0x1.92149p+1f);
}

template <>
__attribute__((always_inline)) inline vFloat sfpu_sinpi<false>(vFloat x) {
    vFloat xx = x * x;

    return x *
           ((((0x1.406628p-4f * xx - 0x9.93f86p-4f) * xx + 0x2.8cd64p+0f) * xx - 0x5.2aef6p+0f) * xx + 0x3.243f6cp+0f);
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void calculate_sine() {

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0] * FRAC_1_PI;
        vInt whole_v = float_to_int16(v, 0);
        v -= int32_to_float(whole_v, 0);
        v = sfpu_sinpi<APPROXIMATION_MODE>(v);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(whole_v & 1); { v = -v; }
        };
        dst_reg[0] = v;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS>
inline void calculate_cosine() {

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0] * FRAC_1_PI + 0.5f;
        vInt whole_v = float_to_int16(v, 0);
        v -= int32_to_float(whole_v, 0);
        v = sfpu_sinpi<APPROXIMATION_MODE>(v);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(whole_v & 1); { v = -v; }
        };
        dst_reg[0] = v;
        dst_reg++;
    }
}

template <SfpuType operation, bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_sfpu_trig() {
    if constexpr (operation == SfpuType::sine) {
        calculate_sine<APPROXIMATION_MODE, ITERATIONS>();
    } else if constexpr (operation == SfpuType::cosine) {
        calculate_cosine<APPROXIMATION_MODE, ITERATIONS>();
    } else if constexpr (operation == SfpuType::tan) {
        calculate_tangent<APPROXIMATION_MODE, ITERATIONS>();
    }
}




template <bool APPROXIMATION_MODE>
__attribute__((always_inline)) inline vFloat sfpu_atan_maclaurin_series(vFloat val) {
    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(1 > sfpi::abs(val)); { dst_reg[0] = sfpi::abs(val); }
    __cc.cc_else(); { dst_reg[0] = sfpu_reciprocal(sfpi::abs(val)); }
    };

    vFloat t1 = dst_reg[0] * dst_reg[0];

    t1 = (t1 * (t1 * (t1 * (t1 * (-0.013480470f * t1 + 0.057477314f) + -0.121239071f) + 0.195635925f) + -0.332994597f) + 0.999995630f);

    t1 = t1 * dst_reg[0];

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(val) > 1); { t1 = 1.570796327f - t1; }
    };

    { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0); { t1 = -t1; }
    };

    return t1;
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_atan() {

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        val = sfpu_atan_maclaurin_series<APPROXIMATION_MODE>(val);
        dst_reg[0] = val;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
__attribute__((always_inline)) inline vFloat sfpu_asine_maclaurin_series(vFloat val) {





    vFloat tmp = val;
    vFloat val_square = val * val;

    vFloat output = tmp;

    tmp = tmp * val_square;
    output += 0.166666666 * tmp;

    tmp = tmp * val_square;
    output += 0.075 * tmp;


    tmp = tmp * val_square;
    output += 0.044642857 * tmp;


    tmp = tmp * val_square;
    output += 0.03038194 * tmp;


    tmp = tmp * val_square;
    output += 0.02237216 * tmp;


    return output;
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_asin() {

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        v = sfpu_asine_maclaurin_series<APPROXIMATION_MODE>(v);
        dst_reg[0] = v;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_acos() {


    for (int d = 0; d < ITERATIONS; d++) {
        vFloat v = dst_reg[0];
        v = sfpu_asine_maclaurin_series<APPROXIMATION_MODE>(v);
        v = PI_2 - v;
        dst_reg[0] = v;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE>
void atan_init() {
    vConstFloatPrgm0 = 1.442695f;
    vConstFloatPrgm1 = 2.0f;
}

}
}

namespace ckernel {




template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sine_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::sine, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sine_op(uint dst_index) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_sfpu_trig<SfpuType::sine, APPROXIMATE>, dst_index, (int)VectorMode::RC);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_cosine_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::cosine, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_cosine_op(uint dst_index) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_sfpu_trig<SfpuType::cosine, APPROXIMATE>, dst_index, (int)VectorMode::RC);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_tan_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::tan, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_tan_op(uint dst_index) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_sfpu_trig<SfpuType::tan, APPROXIMATE>, dst_index, (int)VectorMode::RC);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_asin_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::asin, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_asin(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_asin<APPROXIMATE>, dst_index, vector_mode);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_acos_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::acos, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_acos(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_acos<APPROXIMATE>, dst_index, vector_mode);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_acosh_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::acosh, APPROXIMATE>(
        ckernel::sfpu::_init_inverse_hyperbolic_<APPROXIMATE>);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_acosh(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_acosh_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_atan_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::atan, APPROXIMATE>(sfpu::atan_init<APPROXIMATE>);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_atan(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_atan<APPROXIMATE>, dst_index, vector_mode);
}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_asinh_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::asinh, APPROXIMATE>(
        ckernel::sfpu::_init_inverse_hyperbolic_<APPROXIMATE>);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_asinh(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_asinh_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode);

}


template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_atanh_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::atanh, APPROXIMATE>(ckernel::sfpu::_init_atanh_<APPROXIMATE>);
}

template <bool APPROXIMATE, bool is_fp32_dest_acc_en, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_atanh(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_atanh_<APPROXIMATE, is_fp32_dest_acc_en, ITERATIONS>, dst_index, vector_mode);
}

}





       





       






using namespace sfpi;
namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE>
inline void init_remainder(const uint value, const uint recip) {

    _sfpu_load_config32_(0xC, (value >> 16) & 0xFFFF, value & 0xFFFF);

    _sfpu_load_config32_(0xD, (recip >> 16) & 0xFFFF, recip & 0xFFFF);
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_remainder(const uint value, const uint recip) {

    vFloat s = vConstFloatPrgm0;
    vFloat recip_val = vConstFloatPrgm1;
    vFloat value_tmp = s;
    s = sfpi::abs(s);
    recip_val = sfpi::abs(recip_val);

#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        vFloat v = sfpi::abs(val);

        vFloat quotient;
        vInt exp = exexp(v * recip_val);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0); { quotient = vConst0; }



        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(exp < 23); {
            quotient =
                reinterpret<vFloat>(shft((shft(reinterpret<vUInt>(v * recip_val), (exp - 23))), (0 - (exp - 23))));
        }
        __cc.cc_else(); { quotient = v * recip_val; }
        }

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(quotient > v * recip_val); {
            quotient = quotient - 1;
        }
        };
        v = v - quotient * s;

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(val < 0 && v != 0); { v = s - v; }
        };

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(value_tmp < 0 && v != 0); { v = v + value_tmp; }
        };
        v = setsgn(v, value_tmp);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s == 0); { v = std::numeric_limits<float>::quiet_NaN(); }
        };

        constexpr auto iter = 10;
        for (int l = 0; l < iter; l++) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= s); { v = s - v; }
            };
        }
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(v) - s == 0.0f); { v = 0.0f; }
        };
        dst_reg[0] = v;
        dst_reg++;
    }
}

}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_remainder_init(uint param0, uint param1) {
    llk_math_eltwise_unary_sfpu_init<SfpuType::remainder, APPROXIMATE>(
        sfpu::init_remainder<APPROXIMATE>, param0, param1);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_remainder(
    uint dst_index, uint param0, uint param1, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_remainder<APPROXIMATE>, dst_index, vector_mode, param0, param1);
}

}




       





       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_bitwise_xor(const uint value) {
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vInt input = dst_reg[0];
        vInt v = value;
        vInt res = input ^ v;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(res > 
       (-0x7fffffff - 1) 
       && res < 0); {
            res = 0 - res;
            res = setsgn(res, v);
        }
        } dst_reg[0] = res;
        dst_reg++;
    }
}
}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_xor_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::bitwise_xor, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_xor(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitwise_xor<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       





       






using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_bitwise_not() {
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((p_sfpu::LREG4) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x80 << 24) + (((0) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG0) << 4) + ((1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((p_sfpu::LREG4) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        dst_reg++;
    }
}

}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_not_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::bitwise_not, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_not(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitwise_not<APPROXIMATE>, dst_index, vector_mode);
}
}




       





       






using namespace sfpi;
namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE>
inline void init_fmod(const uint value, const uint recip) {

    _sfpu_load_config32_(0xC, (value >> 16) & 0xFFFF, value & 0xFFFF);

    _sfpu_load_config32_(0xD, (recip >> 16) & 0xFFFF, recip & 0xFFFF);
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_fmod(const uint value, const uint recip) {

    vFloat s = vConstFloatPrgm0;
    vFloat recip_val = vConstFloatPrgm1;
    s = sfpi::abs(s);
    recip_val = sfpi::abs(recip_val);

#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        vFloat v = sfpi::abs(val);

        vFloat quotient;
        vInt exp = exexp(v * recip_val);
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(exp < 0); { quotient = vConst0; }



        __cc.cc_else(); __cc.push(); __cc.mark_top(); __cc.cc_elseif(exp < 23); {
            quotient =
                reinterpret<vFloat>(shft((shft(reinterpret<vUInt>(v * recip_val), (exp - 23))), (0 - (exp - 23))));
        }
        __cc.cc_else(); { quotient = v * recip_val; }
        }

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(quotient > v * recip_val); {
            quotient = quotient - 1;
        }
        };
        v = v - quotient * s;

        v = setsgn(v, val);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(s == 0); { v = std::numeric_limits<float>::quiet_NaN(); }
        };

        constexpr auto iter = 10;
        for (int l = 0; l < iter; l++) {
            { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(v >= s); { v = s - v; }
            };
        }
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(sfpi::abs(v) - s == 0.0f); { v = 0.0f; }
        };
        dst_reg[0] = v;
        dst_reg++;
    }
}

}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_fmod_init(uint param0, uint param1) {
    llk_math_eltwise_unary_sfpu_init<SfpuType::fmod, APPROXIMATE>(sfpu::init_fmod<APPROXIMATE>, param0, param1);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_fmod(
    uint dst_index, uint param0, uint param1, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_fmod<APPROXIMATE>, dst_index, vector_mode, param0, param1);
}

}




       





       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_bitwise_and(const uint value) {
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vInt input = dst_reg[0];
        vInt res = input & value;
        dst_reg[0] = res;
        dst_reg++;
    }
}
}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_and_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::bitwise_and, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_and(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitwise_and<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       




       



using namespace sfpi;
namespace ckernel {
namespace sfpu {
template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_bitwise_or(const uint value) {
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vInt input = dst_reg[0];
        vInt scalar_value = value;
        vInt res = input | scalar_value;
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(res > 
       (-0x7fffffff - 1) 
       && res < 0); {
            res = 0 - res;
            res = setsgn(res, scalar_value);
        }
        } dst_reg[0] = res;
        dst_reg++;
    }
}
}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_or_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::bitwise_or, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_bitwise_or(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_bitwise_or<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       





       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_right_shift(const uint shift_amt) {
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        vInt input = dst_reg[0];
        vUInt val = reinterpret<vUInt>(input);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(input < 0); { val = setsgn(val - 1, 0); }
        };
        vInt res = reinterpret<vInt>(val >> shift_amt);

        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(input < 0); { res = setsgn(res + 1, input); }
        };

        dst_reg[0] = res;
        dst_reg++;
    }
}
}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_right_shift_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::right_shift, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_right_shift(
    uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_right_shift<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       





       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_left_shift(const uint shift_amt) {
#pragma GCC unroll 0
    for (int d = 0; d < ITERATIONS; d++) {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((0) << 20) + ((4) << 16) + ((3) << 14) + ((0) << 0))))));
        ckernel::instrn_buffer[0] = ((0x7a << 24) + (((shift_amt) << 12) + ((0) << 8) + ((0) << 4) + ((1) << 0)));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((0) << 20) + ((4) << 16) + ((3) << 14) + ((0) << 0))))));
        dst_reg++;
    }
}

}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_left_shift_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::left_shift, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_left_shift(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_left_shift<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       




namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_fill_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::fill, APPROXIMATE>();
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_fill(uint dst_index, float param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_fill_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_fill_int(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_fill_int_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode, param0);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_fill_bitcast(
    uint dst_index, uint32_t param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_fill_bitcast_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode, param0);
}

}




       





       






using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_prelu(uint value) {

    vFloat init = Converter::as_float(value);

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat a = dst_reg[0];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(a < 0.0f); { a = a * init; }
        };
        dst_reg[0] = a;
        dst_reg++;
    }
}
}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_prelu_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::prelu, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_prelu(uint dst_index, uint param0, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_prelu<APPROXIMATE>, dst_index, vector_mode, param0);
}

}




       







       





using namespace sfpi;

namespace ckernel {

namespace sfpu {
template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_i1() {
#pragma GCC unroll 0

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat result = 0.0f;
        vFloat input = dst_reg[0];
        vFloat x = input * input;

        vFloat derivative = input * ((0.125f + (0.00520833f + (0.000108507f + (1.35634e-06f + (1.13028e-08f + (6.72786e-11f + (3.00351e-13f + (1.04289e-15f + (2.8969e-18f + (6.58387e-21f + 1.24695e-23f * x) * x) * x) * x) * x) * x) * x) * x) * x) * x) * x)
                                          ;
        result = input * 0.5f + derivative;
        dst_reg[0] = result;
        dst_reg++;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_i1_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::i1, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_i1_op(uint dst_index) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_i1<APPROXIMATE>, dst_index, (int)VectorMode::RC);
}
}




       







       





using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 4>
inline void calculate_alt_complex_rotate90() {
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        dst_reg[0] = -dst_reg[1];
        dst_reg[1] = val;
        dst_reg += 2;
    }
}

}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_alt_complex_rotate90_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::alt_complex_rotate90, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_alt_complex_rotate90(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_alt_complex_rotate90<APPROXIMATE>, dst_index, vector_mode);
}

}




       





       
using namespace ckernel;


inline void reduce_configure_addrmod();

template <ReduceDim dim, int num_fidelity_phases>
inline void reduce_configure_mop();

template <PoolType type, ReduceDim dim, bool is_fp32_dest_acc_en, int MATH_FIDELITY_DESC = 0, bool is_int_fpu_en = false, bool fp32_transpose = false>
inline void _llk_math_reduce_(const uint dst_index, bool narrow_tile = false, const uint num_faces = 4)
{
    constexpr int MATH_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    constexpr bool HIGH_FIDELITY = MATH_FIDELITY_PHASES > 0;

    math::set_dst_write_addr<DstTileLayout::Default, DstTileShape::Tile32x32>(dst_index);
    if constexpr (dim == ReduceDim::REDUCE_ROW)
    {

        if constexpr (type == PoolType::MAX)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
        }
        else if constexpr (HIGH_FIDELITY)
        {
            ckernel_template::run(instrn_buffer);
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 0))))));
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
        }

        if constexpr (type == PoolType::MAX)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
        }
        else if constexpr (HIGH_FIDELITY)
        {
            ckernel_template::run(instrn_buffer);
        }
        else
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
        }

        if constexpr (fp32_transpose)
        {

            constexpr int dest_32b_hi = 0;
            constexpr int dest_32b_lo = 1;



            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_hi) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_hi) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));


            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 4) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((4) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 8) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((8) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 12) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((12) << 0))))));


            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_lo) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_lo) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));


            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 4) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((4) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 8) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((8) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 12) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((12) << 0))))));
        }
        else
        {




            if constexpr (is_int_fpu_en)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_SFPU) << 15) + ((p_stall::MATH) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_0) << 14) + ((0) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT8) << 16) + ((ADDR_MOD_0) << 14) + ((0) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_0) << 14) + ((2) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT8) << 16) + ((ADDR_MOD_0) << 14) + ((2) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::WAIT_SFPU) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((56) << 16) + ((0x1) << 0))))));
            }



            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));
            if constexpr (is_int_fpu_en)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((56) << 16) + ((0x0) << 0))))));
            }

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((8) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((8) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x11 << 24) + (((0) << 4) + ((1) << 3) + ((0) << 2) + ((1) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((p_elwise::SRCB_NO_BCAST) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((p_elwise::SRCB_NO_BCAST) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
        }

        if (num_faces == 2 && !narrow_tile)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_BD) << 0))))));
        }
        else
        {

            if (!narrow_tile)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            }
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_BD) << 0))))));






            if constexpr (type == PoolType::MAX)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
            }
            else if constexpr (HIGH_FIDELITY)
            {
                ckernel_template::run(instrn_buffer);
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 0))))));
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
            }

            if constexpr (type == PoolType::MAX)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
            }
            else if constexpr (HIGH_FIDELITY)
            {
                ckernel_template::run(instrn_buffer);
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
            }

            if constexpr (fp32_transpose)
            {

                constexpr int dest_32b_hi = 0;
                constexpr int dest_32b_lo = 1;



                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_hi) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_hi) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));


                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 4) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((4) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 8) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((8) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_hi) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 12) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((12) << 0))))));


                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_lo) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((dest_32b_lo) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));


                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((0) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 4) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((4) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 8) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((8) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x13 << 24) + (((dest_32b_lo) << 23) + ((p_movb2d::SRC_ROW16_OFFSET + 12) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2d::MOV_4_ROWS) << 12) + ((12) << 0))))));
            }
            else
            {




                if constexpr (is_int_fpu_en)
                {
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_SFPU) << 15) + ((p_stall::MATH) << 0))))));
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_0) << 14) + ((0) << 0))))));
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT8) << 16) + ((ADDR_MOD_0) << 14) + ((0) << 0))))));
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT32) << 16) + ((ADDR_MOD_0) << 14) + ((2) << 0))))));
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG0) << 20) + ((InstrModLoadStore::INT8) << 16) + ((ADDR_MOD_0) << 14) + ((2) << 0))))));
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xa2 << 24) + (((p_stall::STALL_MATH) << 15) + ((p_stall::WAIT_SFPU) << 0))))));
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((56) << 16) + ((0x1) << 0))))));
                }


                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((0) << 0))))));
                if constexpr (is_int_fpu_en)
                {
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((56) << 16) + ((0x0) << 0))))));
                }

                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((8) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_B) << 18) + ((0) << 14) + ((8) << 10) + ((0) << 6) + ((p_setrwc::SET_B) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x11 << 24) + (((0) << 4) + ((1) << 3) + ((0) << 2) + ((1) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((p_elwise::SRCB_NO_BCAST) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x28 << 24) + (((0) << 22) + ((0) << 21) + ((p_elwise::SRCB_NO_BCAST) << 19) + ((ADDR_MOD_2) << 15) + ((0) << 0))))));
            }


            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_BD) << 0))))));
        }
    }
    else if constexpr (dim == ReduceDim::REDUCE_COL)
    {
        const uint num_row_tiles = narrow_tile ? 2 : ((num_faces > 1) ? num_faces / 2 : 1);
        for (uint row_tile = 0; row_tile < num_row_tiles; row_tile++)
        {

            if constexpr (type == PoolType::MAX)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
            }
            else
            {
                if constexpr (HIGH_FIDELITY)
                {
                    ckernel_template::run(instrn_buffer);
                }
                else
                {
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
                }
            }
            if ((!narrow_tile) && (num_faces > 1))
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_setrwc::CR_D) << 18) + ((8) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_D) << 0))))));

                if constexpr (type == PoolType::MAX)
                {
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
                }
                else
                {
                    if constexpr (HIGH_FIDELITY)
                    {
                        ckernel_template::run(instrn_buffer);
                    }
                    else
                    {
                        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
                    }
                }
            }

            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AD) << 0))))));
        }
    }
    else if constexpr (dim == ReduceDim::REDUCE_SCALAR)
    {
        for (int tile = 0; tile < 3; tile++)
        {

            if constexpr (type == PoolType::MAX)
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))))));
            }
            else
            {
                if constexpr (HIGH_FIDELITY)
                {
                    ckernel_template::run(instrn_buffer);
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x36 << 24) + (((p_setrwc::CLR_AB) << 22) + ((0) << 0))))));
                }
                else
                {
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))))));
                }
            }
        }

        if constexpr (type == PoolType::MAX)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))))));
        }
        else
        {
            if constexpr (HIGH_FIDELITY)
            {
                ckernel_template::run(instrn_buffer);
            }
            else
            {
                __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))))));
            }
        }


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x37 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_setrwc::CR_D) << 18) + ((0) << 14) + ((0) << 10) + ((0) << 6) + ((p_setrwc::SET_AB) << 0))))));


        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0a << 24) + (((0) << 23) + ((p_movd2b::SRC_ROW16_OFFSET) << 17) + ((ADDR_MOD_0) << 15) + ((p_movd2b::MOV_1_ROW) << 12) + ((4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x35 << 24) + (((0b1) << 1) + ((0b1) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x16 << 24) + 0))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x35 << 24) + (((0b1) << 1) + ((0b1) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0b << 24) + (((p_movb2a::SRCA_ZERO_OFFSET + 0) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2a::MOV_4_ROWS) << 12) + ((p_movb2a::SRCB_ROW16_OFFSET + 0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0b << 24) + (((p_movb2a::SRCA_ZERO_OFFSET + 4) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2a::MOV_4_ROWS) << 12) + ((p_movb2a::SRCB_ROW16_OFFSET + 4) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0b << 24) + (((p_movb2a::SRCA_ZERO_OFFSET + 8) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2a::MOV_4_ROWS) << 12) + ((p_movb2a::SRCB_ROW16_OFFSET + 8) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x0b << 24) + (((p_movb2a::SRCA_ZERO_OFFSET + 12) << 17) + ((ADDR_MOD_0) << 15) + ((p_movb2a::MOV_4_ROWS) << 12) + ((p_movb2a::SRCB_ROW16_OFFSET + 12) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x35 << 24) + (((0b1) << 1) + ((0b1) << 0))))));

        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x10 << 24) + (((p_zeroacc::CLR_SPECIFIC) << 19) + ((ADDR_MOD_0) << 15) + ((4) << 0))))));

        if constexpr (type == PoolType::MAX)
        {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x33 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
        }
        else
        {
            if constexpr (HIGH_FIDELITY)
            {
                for (int i = 0; i < MATH_FIDELITY_PHASES - 1; i++)
                {
                    __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_3) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
                }
            }
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x34 << 24) + (((p_setrwc::CLR_AB) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))))));
        }
    }
}

template <PoolType type, int MATH_FIDELITY_DESC>
inline void reduce_configure_addrmod()
{
    constexpr int NUM_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    constexpr int FIDELITY_INCREMENT = get_math_fidelity_increment(MATH_FIDELITY_DESC);
    constexpr bool HIGH_FIDELITY = NUM_FIDELITY_PHASES > 0;

    addr_mod_t {.srca = {.incr = 0}, .srcb = {.incr = 0}, .dest = {.incr = 0}, .fidelity = {.incr = 0, .clr = 1}}.set(ADDR_MOD_0);

    addr_mod_t {
        .srca = {.incr = 0},
        .srcb = {.incr = 1},
        .dest = {.incr = 1},
    }
        .set(ADDR_MOD_1);

    addr_mod_t {
        .srca = {.incr = 0},
        .srcb = {.incr = 8},
        .dest = {.incr = 8},
    }
        .set(ADDR_MOD_2);

    if constexpr (HIGH_FIDELITY)
    {
        addr_mod_t {.srca = {.incr = 0}, .srcb = {.incr = 0}, .dest = {.incr = 0}, .fidelity = {.incr = FIDELITY_INCREMENT}}.set(ADDR_MOD_3);
    }
}

template <ReduceDim dim, int num_fidelity_phases>
inline void reduce_configure_mop()
{
    if constexpr (dim == ReduceDim::REDUCE_SCALAR)
    {
        ckernel_template tmp(1, num_fidelity_phases, ((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_3) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))));
        tmp.set_last_inner_loop_instr(((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))));
        tmp.set_last_outer_loop_instr(((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((4) << 0))));
        tmp.program(instrn_buffer);
    }
    else
    {
        ckernel_template tmp(1, num_fidelity_phases, ((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_3) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))));
        tmp.set_last_inner_loop_instr(((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))));
        tmp.set_last_outer_loop_instr(((0x34 << 24) + (((p_setrwc::CLR_NONE) << 22) + ((p_gpool::DIM_16X16) << 19) + ((ADDR_MOD_0) << 15) + ((p_gpool::INDEX_DIS) << 14) + ((0) << 0))));
        tmp.program(instrn_buffer);
    }
}

template <PoolType type, ReduceDim dim, int MATH_FIDELITY_DESC = 0>
inline void _llk_math_reduce_init_(const std::uint32_t within_face_16x16_transpose = 0)
{

    constexpr int MATH_FIDELITY_PHASES = get_math_num_fidelity_phases(MATH_FIDELITY_DESC);
    constexpr bool HIGH_FIDELITY = MATH_FIDELITY_PHASES > 0;

    reduce_configure_addrmod<type, MATH_FIDELITY_DESC>();
    if constexpr (HIGH_FIDELITY)
    {
        reduce_configure_mop<dim, MATH_FIDELITY_PHASES>();
    }

    __asm__ __volatile__(".ttinsn %0" : : "i"((((0xb2 << 24) + (((5) << 16) + ((0) << 0))))));

    math::reset_counters(p_setrwc::SET_ABD_F);
}





template <
    PoolType type,
    ReduceDim dim,
    bool is_fp32_dest_acc_en,
    int num_fidelity_phases = 0,
    bool is_int_fpu_en = false,
    bool fp32_transpose = false>
inline void llk_math_reduce(const uint dst_index, const uint num_faces = 4) {
    _llk_math_reduce_<type, dim, is_fp32_dest_acc_en, num_fidelity_phases, is_int_fpu_en, fp32_transpose>(
        dst_index, false, num_faces);
}

template <
    PoolType type,
    ReduceDim dim,
    bool is_fp32_dest_acc_en,
    int num_fidelity_phases = 0,
    bool is_int_fpu_en = false,
    bool fp32_transpose = false>
inline void llk_math_reduce(const std::uint32_t operandA, const std::uint32_t operandB, const std::uint32_t dst_index) {
    const std::uint32_t operand_id = get_operand_id(operandA);
    const std::uint32_t num_faces = get_operand_num_faces(operand_id);
    _llk_math_reduce_<type, dim, is_fp32_dest_acc_en, num_fidelity_phases, is_int_fpu_en, fp32_transpose>(
        dst_index, false, num_faces);
}

template <PoolType type, ReduceDim dim, int num_fidelity_phases = 0>
inline void llk_math_reduce_init(
    const std::uint32_t within_face_16x16_transpose =
        0) {
    _llk_math_reduce_init_<type, dim, num_fidelity_phases>(within_face_16x16_transpose);
}
namespace ckernel {




template <bool fast_and_approx = true>
inline __attribute__((always_inline)) void rsqrt_tile_init() {
    (llk_math_eltwise_unary_sfpu_rsqrt_init<fast_and_approx>());
}
template <bool fast_and_approx = true>
inline __attribute__((always_inline)) void rsqrt_tile(uint32_t idst) {
    (llk_math_eltwise_unary_sfpu_rsqrt<fast_and_approx>(idst));
}





template <bool fast_and_approx = false>
inline __attribute__((always_inline)) void sigmoid_tile_init() {
    (llk_math_eltwise_unary_sfpu_sigmoid_init<fast_and_approx>());
}
template <int vec_mode = VectorMode::RC, bool fast_and_approx = false>
inline __attribute__((always_inline)) void sigmoid_tile(uint32_t idst) {
    (llk_math_eltwise_unary_sfpu_sigmoid<fast_and_approx>(idst, vec_mode));
}




inline __attribute__((always_inline)) void log_tile_init() {
    (llk_math_eltwise_unary_sfpu_log_init<APPROX>());
}
inline __attribute__((always_inline)) void log_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_log<APPROX>(idst)); }




inline __attribute__((always_inline)) void log_with_base_tile_init() {
    (llk_math_eltwise_unary_sfpu_log_with_base_init<APPROX>());
}
inline __attribute__((always_inline)) void log_with_base_tile(uint32_t idst, uint32_t base_scale) {
    (llk_math_eltwise_unary_sfpu_log_with_base<APPROX>(idst, base_scale));
}





inline __attribute__((always_inline)) void tanh_tile_init() {
    (llk_math_eltwise_unary_sfpu_tanh_init<APPROX>());
}
inline __attribute__((always_inline)) void tanh_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_tanh<APPROX>(idst)); }




inline __attribute__((always_inline)) void signbit_tile_init() { (llk_math_eltwise_unary_sfpu_signbit_init<APPROX>()); }
inline __attribute__((always_inline)) void signbit_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_signbit<APPROX>(idst)); }
inline __attribute__((always_inline)) void abs_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_abs<APPROX>(idst)); }




inline __attribute__((always_inline)) void abs_tile_init() { (llk_math_eltwise_unary_sfpu_abs_init<APPROX>()); }
inline __attribute__((always_inline)) void abs_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_abs_int32<APPROX>(idst)); }
inline __attribute__((always_inline)) void sign_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_sign<APPROX>(idst)); }




inline __attribute__((always_inline)) void sign_tile_init() { (llk_math_eltwise_unary_sfpu_sign_init<APPROX>()); }
inline __attribute__((always_inline)) void square_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_square<APPROX>(idst)); }




inline __attribute__((always_inline)) void square_tile_init() { (llk_math_eltwise_unary_sfpu_square_init<APPROX>()); }
inline __attribute__((always_inline)) void tiled_prod_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_tiled_prod<APPROX>(idst)); }




inline __attribute__((always_inline)) void tiled_prod_tile_init() { (llk_math_eltwise_unary_sfpu_tiled_prod_init<APPROX>()); }
inline __attribute__((always_inline)) void power_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_power<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void power_tile_init() { (llk_math_eltwise_unary_sfpu_power_init<APPROX>()); }
inline __attribute__((always_inline)) void max_tile(uint32_t idst0, uint32_t idst1, int vector_mode = (int)VectorMode::RC) {
    (llk_math_eltwise_unary_sfpu_max<APPROX>(idst0, vector_mode));
}




inline __attribute__((always_inline)) void max_tile_init() { (llk_math_eltwise_unary_sfpu_max_init<APPROX>()); }
inline __attribute__((always_inline)) void exp2_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_exp2<true>(idst)); }




inline __attribute__((always_inline)) void exp2_tile_init() { (llk_math_eltwise_unary_sfpu_exp2_init<true>()); }
inline __attribute__((always_inline)) void heaviside_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_heaviside<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void heaviside_tile_init() { (llk_math_eltwise_unary_sfpu_heaviside_init<APPROX>()); }
inline __attribute__((always_inline)) void expm1_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_expm1<true>(idst)); }




inline __attribute__((always_inline)) void expm1_tile_init() { (llk_math_eltwise_unary_sfpu_expm1_init<true>()); }
inline __attribute__((always_inline)) void asin_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_asin<true>(idst)); }





inline __attribute__((always_inline)) void asin_tile_init() { (llk_math_eltwise_unary_sfpu_asin_init<true>()); }
inline __attribute__((always_inline)) void atan_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_atan<true>(idst)); }





inline __attribute__((always_inline)) void atan_tile_init() { (llk_math_eltwise_unary_sfpu_atan_init<true>()); }
inline __attribute__((always_inline)) void acos_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_acos<true>(idst)); }





inline __attribute__((always_inline)) void acos_tile_init() { (llk_math_eltwise_unary_sfpu_acos_init<true>()); }





inline __attribute__((always_inline)) void silu_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_silu<APPROX>(idst)); }

inline __attribute__((always_inline)) void silu_tile_init() { (llk_math_eltwise_unary_sfpu_silu_init<APPROX>()); }
inline __attribute__((always_inline)) void topk_local_sort(
    uint32_t idst, int idir, int i_end_phase, int i_start_phase = 0, int i_end_step = 0, int i_start_step = 0) {
    (llk_math_eltwise_unary_sfpu_topk_local_sort<true, DST_ACCUM_MODE>( idst, idir, i_end_phase, i_start_phase, i_end_step, i_start_step))
                                                                           ;
}
template <bool idir = false>
inline __attribute__((always_inline)) void topk_merge(uint32_t idst, int m_iter, int k) {
    (llk_math_eltwise_unary_sfpu_topk_merge<true, DST_ACCUM_MODE, idir>(idst, m_iter, k));
}
inline __attribute__((always_inline)) void topk_rebuild(uint32_t idst, bool idir, int m_iter, int k, int logk, int skip_second) {
    (llk_math_eltwise_unary_sfpu_topk_rebuild<true, DST_ACCUM_MODE>(idst, idir, m_iter, k, logk, skip_second));
}




inline __attribute__((always_inline)) void topk_tile_init() { (llk_math_eltwise_unary_sfpu_topk_init<true>()); }






inline __attribute__((always_inline)) void dbg_halt() {
    ;
    ;
    dbg_thread_halt<MathThreadId>();
}






inline __attribute__((always_inline)) void dbg_unhalt() {
    ;
    ;
    dbg_thread_unhalt<MathThreadId>();
}
inline __attribute__((always_inline)) void dbg_read_dest_acc_row(int row_addr, uint32_t* rd_data) {
    (dbg_get_array_row(dbg_array_id::DEST, row_addr, rd_data));
}
inline __attribute__((always_inline)) void unary_max_int32_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_max_int32<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_max_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_max<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_max_tile_init() { (llk_math_eltwise_unary_sfpu_unary_max_init<APPROX>()); }
inline __attribute__((always_inline)) void alt_complex_rotate90_tile(uint32_t idst) {
    (llk_math_eltwise_unary_sfpu_alt_complex_rotate90<APPROX>(idst));
}




inline __attribute__((always_inline)) void alt_complex_rotate90_tile_init() { (llk_math_eltwise_unary_sfpu_alt_complex_rotate90_init<APPROX>()); }
inline __attribute__((always_inline)) void unary_min_int32_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_min_int32<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_min_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_min<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_min_tile_init() { (llk_math_eltwise_unary_sfpu_unary_min_init<APPROX>()); }

inline __attribute__((always_inline)) uint32_t get_compute_special_value_flags() {
    uint32_t ret_val = 0;
    (ret_val = llk_math_get_compute_special_value_flags());
    return ret_val;
}

inline __attribute__((always_inline)) uint32_t get_compute_special_value_flags_fpu(uint32_t special_value_flags_reg) {
    uint32_t ret_val = 0;
    (ret_val = llk_math_get_compute_special_value_flags_fpu(special_value_flags_reg));
    return ret_val;
}

inline __attribute__((always_inline)) uint32_t get_compute_special_value_flags_sfpu(uint32_t special_value_flags_reg) {
    uint32_t ret_val = 0;
    (ret_val = llk_math_get_compute_special_value_flags_sfpu(special_value_flags_reg));
    return ret_val;
}

inline __attribute__((always_inline)) void clear_compute_special_value_flags() { (llk_math_clear_compute_special_value_flags()); }

inline __attribute__((always_inline)) void store_compute_special_value_flags_to_l1(uint32_t l1_addr) {
    (llk_math_store_compute_special_value_flags_to_l1(l1_addr));
}

}




       





       





       




       



namespace ckernel {
inline __attribute__((always_inline)) void acquire_dst() {
    (llk_math_wait_for_dest_available());

    ;
}
inline __attribute__((always_inline)) void tile_regs_acquire() { (llk_math_wait_for_dest_available()); }






inline __attribute__((always_inline)) void tile_regs_wait() { ; }

inline __attribute__((always_inline)) void release_dst() {
    (llk_math_dest_section_done<DST_ACCUM_MODE>());
    ;
}






inline __attribute__((always_inline)) void tile_regs_commit() { (llk_math_dest_section_done<DST_ACCUM_MODE>()); }




inline __attribute__((always_inline)) void tile_regs_release() { ; }

}




       



namespace ckernel {
template <bool out_of_order_output = false>
inline __attribute__((always_inline)) void pack_tile(uint32_t ifrom_dst, uint32_t icb, std::uint32_t output_tile_index = 0) {
    ;
}
inline __attribute__((always_inline)) void pack_tile_block(uint32_t ifrom_dst, uint32_t icb, uint32_t ntiles) {
    ;
}
inline __attribute__((always_inline)) void pack_reconfig_data_format(const uint32_t new_cb_id) {
    ;
}
inline __attribute__((always_inline)) void pack_reconfig_data_format(const uint32_t old_cb_id, const uint32_t new_cb_id) {
    ;
}
inline __attribute__((always_inline)) void pack_reconfig_l1_acc(const uint32_t l1_acc_en) { ; }

}




       



namespace ckernel {




template <bool to_from_int8 = false>
inline __attribute__((always_inline)) void reconfig_data_format(const uint32_t srca_new_operand, const uint32_t srcb_new_operand) {
    ;
    (llk_math_reconfig_data_format<DST_ACCUM_MODE, to_from_int8>(srca_new_operand, srcb_new_operand));
}




template <bool to_from_int8 = false>
inline __attribute__((always_inline)) void reconfig_data_format(
    const uint32_t srca_old_operand,
    const uint32_t srca_new_operand,
    const uint32_t srcb_old_operand,
    const uint32_t srcb_new_operand) {
   
                                                                                 ;
    (llk_math_reconfig_data_format<DST_ACCUM_MODE, to_from_int8>( srca_old_operand, srca_new_operand, srcb_old_operand, srcb_new_operand))
                                                                                 ;
}




template <bool to_from_int8 = false>
inline __attribute__((always_inline)) void reconfig_data_format_srca(const uint32_t srca_new_operand) {
    ;
    (llk_math_reconfig_data_format_srca<DST_ACCUM_MODE, to_from_int8>(srca_new_operand));
}




template <bool to_from_int8 = false>
inline __attribute__((always_inline)) void reconfig_data_format_srca(const uint32_t srca_old_operand, const uint32_t srca_new_operand) {
    ;
    (llk_math_reconfig_data_format_srca<DST_ACCUM_MODE, to_from_int8>(srca_old_operand, srca_new_operand));
}




template <bool to_from_int8 = false>
inline __attribute__((always_inline)) void reconfig_data_format_srcb(const uint32_t srcb_new_operand) {
    ;
    (llk_math_reconfig_data_format_srcb<DST_ACCUM_MODE, to_from_int8>(srcb_new_operand));
}




template <bool to_from_int8 = false>
inline __attribute__((always_inline)) void reconfig_data_format_srcb(const uint32_t srcb_old_operand, const uint32_t srcb_new_operand) {
    ;
    (llk_math_reconfig_data_format_srcb<DST_ACCUM_MODE, to_from_int8>(srcb_old_operand, srcb_new_operand));
}

}




       
namespace ckernel {
inline __attribute__((always_inline)) void cb_wait_front(uint32_t cbid, uint32_t ntiles) { ; }
inline __attribute__((always_inline)) void cb_pop_front(uint32_t cbid, uint32_t ntiles) { ; }
inline __attribute__((always_inline)) void cb_reserve_back(uint32_t cbid, uint32_t ntiles) {
    ;
}
inline __attribute__((always_inline)) void cb_push_back(uint32_t cbid, uint32_t ntiles) { ; }
inline __attribute__((always_inline)) void cb_get_tile(uint32_t cb_id, uint32_t index, volatile void* p_tile) {
    ;

    llk_math_get_tile(cb_id, index, (uint32_t*)p_tile);

    ;
}
inline __attribute__((always_inline)) void cb_release_tile(uint32_t cb_id) {
    ;

    llk_math_release_tile(cb_id);

    ;
}

}




       







namespace ckernel {
inline __attribute__((always_inline)) void compute_kernel_hw_startup(uint32_t icb0, uint32_t icb1, uint32_t ocb) {
    ;

    (llk_math_pack_sync_init<DST_ACCUM_MODE>());
    (llk_math_hw_configure_disaggregated<false , false >(icb0, icb1));

    ;
   




                                  ;
    ;
}
inline __attribute__((always_inline)) void compute_kernel_hw_startup(uint32_t icb0, uint32_t ocb) { compute_kernel_hw_startup(icb0, icb0, ocb); }

}

extern uint32_t __attribute__((rvtt_l1_ptr))* rta_l1_base;
extern uint32_t __attribute__((rvtt_l1_ptr))* crta_l1_base;
static inline __attribute__((always_inline)) uint32_t get_arg_addr(int arg_idx) { return (uint32_t)&rta_l1_base[arg_idx]; }
static inline __attribute__((always_inline)) uint32_t get_common_arg_addr(int arg_idx) { return (uint32_t)&crta_l1_base[arg_idx]; }
template <typename T>
inline __attribute__((always_inline)) T get_arg_val(int arg_idx) {

    static_assert("Error: only 4B args are supported" && sizeof(T) == 4);
    return *((__attribute__((rvtt_l1_ptr)) T*)(get_arg_addr(arg_idx)));
}
template <typename T>
inline __attribute__((always_inline)) T get_common_arg_val(int arg_idx) {

    static_assert("Error: only 4B args are supported" && sizeof(T) == 4);
    return *((__attribute__((rvtt_l1_ptr)) T*)(get_common_arg_addr(arg_idx)));
}
inline uint8_t get_absolute_logical_x() {
    extern uint8_t my_logical_x_;
    return my_logical_x_;
}
inline uint8_t get_absolute_logical_y() {
    extern uint8_t my_logical_y_;
    return my_logical_y_;
}
inline uint8_t get_relative_logical_x() {
    extern uint8_t my_relative_x_;
    return my_relative_x_;
}
inline uint8_t get_relative_logical_y() {
    extern uint8_t my_relative_y_;
    return my_relative_y_;
}
namespace ckernel {
inline __attribute__((always_inline)) void binary_op_init_common(uint32_t icb0, uint32_t icb1, uint32_t ocb) {
    ;
    ;

    (llk_math_pack_sync_init<DST_ACCUM_MODE>());
    (llk_math_hw_configure_disaggregated(icb0, icb1));

    ;
    ;
    ;
}
template <bool full_init, EltwiseBinaryType eltwise_binary_type>
inline __attribute__((always_inline)) void binary_tiles_init(uint32_t icb0, uint32_t icb1, bool acc_to_dest = false) {
    (llk_math_eltwise_binary_init_with_operands<eltwise_binary_type, NONE, MATH_FIDELITY>( icb0, icb1, 0 , acc_to_dest))
                                                   ;

    if constexpr (full_init) {
        ;
    }
}
inline __attribute__((always_inline)) void mul_tiles_init(uint32_t icb0, uint32_t icb1) { binary_tiles_init<true, ELWMUL>(icb0, icb1); }
inline __attribute__((always_inline)) void add_tiles_init(uint32_t icb0, uint32_t icb1, bool acc_to_dest = false) {
    binary_tiles_init<true, ELWADD>(icb0, icb1, acc_to_dest);
}
inline __attribute__((always_inline)) void sub_tiles_init(uint32_t icb0, uint32_t icb1, bool acc_to_dest = false) {
    binary_tiles_init<true, ELWSUB>(icb0, icb1, acc_to_dest);
}
inline __attribute__((always_inline)) void mul_tiles(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    ;
    (llk_math_eltwise_binary<ELWMUL, NONE, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>( icb0, icb1, idst, true))
                                 ;
}
inline __attribute__((always_inline)) void add_tiles(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    ;
    (llk_math_eltwise_binary<ELWADD, NONE, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>( icb0, icb1, idst, true))
                                 ;
}
inline __attribute__((always_inline)) void sub_tiles(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    ;
    (llk_math_eltwise_binary<ELWSUB, NONE, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>( icb0, icb1, idst, true))
                                 ;
}




template <
    EltwiseBinaryType eltwise_binary_type = ELWADD,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline __attribute__((always_inline)) void binary_dest_reuse_tiles_init(uint32_t icb0) {
    ;
    (llk_math_eltwise_binary_init<eltwise_binary_type, NONE, MATH_FIDELITY, binary_reuse_dest>(false, false));
}
template <
    EltwiseBinaryType eltwise_binary_type = ELWADD,
    EltwiseBinaryReuseDestType binary_reuse_dest = EltwiseBinaryReuseDestType::NONE>
inline __attribute__((always_inline)) void binary_dest_reuse_tiles(uint32_t in_cb_id, uint32_t in_tile_index, uint32_t dst_tile_index) {
    ;
    (llk_math_eltwise_binary<eltwise_binary_type, NONE, DST_ACCUM_MODE, MATH_FIDELITY, binary_reuse_dest>( in_tile_index, in_tile_index, dst_tile_index, true))
                                                             ;
}

}




       
namespace ckernel {

inline __attribute__((always_inline)) void unary_op_init_common(uint32_t icb, uint32_t ocb) {
    ;
   
                                                                                   ;

    ;
    ;
    ;

    (llk_math_eltwise_unary_datacopy_init<A2D, DST_ACCUM_MODE, BroadcastType::NONE>( false , false , icb))
                                                                                   ;
    (llk_math_pack_sync_init<DST_ACCUM_MODE>());
    (llk_math_hw_configure_disaggregated(icb, icb));
}

inline __attribute__((always_inline)) void init_sfpu(uint32_t icb, uint32_t ocb) { unary_op_init_common(icb, ocb); }

}




       







       





       
using namespace sfpi;

namespace ckernel {
namespace sfpu {

enum {
    ADD = 0,
    SUB = 1,
    MUL = 2,
    DIV = 3,
    RSUB = 4,
};

template <bool APPROXIMATION_MODE, int BINOP_MODE, int ITERATIONS = 8>
void calculate_binop_with_scalar(uint32_t param) {
    const vFloat parameter = Converter::as_float(param);

    for (int d = 0; d < ITERATIONS; d++) {
        vFloat val = dst_reg[0];
        vFloat result = 0.0f;

        if constexpr (BINOP_MODE == ADD) {
            result = val + parameter;
        } else if constexpr (BINOP_MODE == SUB) {
            result = val - parameter;
        } else if constexpr (BINOP_MODE == MUL) {
            result = val * parameter;
        } else if constexpr (BINOP_MODE == DIV) {

            result = val * parameter;
        } else if constexpr (BINOP_MODE == RSUB) {
            result = parameter - val;
        }

        dst_reg[0] = result;
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
void calculate_add(uint32_t param) {
    calculate_binop_with_scalar<APPROXIMATION_MODE, ADD, ITERATIONS>(param);
    return;
}
template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
void calculate_sub(uint32_t param) {
    calculate_binop_with_scalar<APPROXIMATION_MODE, SUB, ITERATIONS>(param);
    return;
}
template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
void calculate_mul(uint32_t param) {
    calculate_binop_with_scalar<APPROXIMATION_MODE, MUL, ITERATIONS>(param);
    return;
}
template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
void calculate_div(uint32_t param) {
    calculate_binop_with_scalar<APPROXIMATION_MODE, DIV, ITERATIONS>(param);
    return;
}
template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
void calculate_rsub(uint32_t param) {
    calculate_binop_with_scalar<APPROXIMATION_MODE, RSUB, ITERATIONS>(param);
    return;
}

}
}



namespace ckernel {



template <bool APPROXIMATE, int binop_mode>
inline void llk_math_eltwise_unary_sfpu_binop_with_scalar(
    uint dst_index, uint32_t param1, int vector_mode = VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_binop_with_scalar<APPROXIMATE, binop_mode, 8>, dst_index, vector_mode, param1);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_binop_with_scalar_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::unused, APPROXIMATE>();
}

}






namespace ckernel {
enum { ADD_UNARY = 0, SUB_UNARY = 1, MUL_UNARY = 2, DIV_UNARY = 3, RSUB_UNARY = 4 };
inline __attribute__((always_inline)) void add_unary_tile(uint32_t idst, uint32_t param1) {
    (llk_math_eltwise_unary_sfpu_binop_with_scalar<APPROX, ADD_UNARY>(idst, param1));
}

inline __attribute__((always_inline)) void sub_unary_tile(uint32_t idst, uint32_t param1) {
    (llk_math_eltwise_unary_sfpu_binop_with_scalar<APPROX, SUB_UNARY>(idst, param1));
}

inline __attribute__((always_inline)) void mul_unary_tile(uint32_t idst, uint32_t param1) {
    (llk_math_eltwise_unary_sfpu_binop_with_scalar<APPROX, MUL_UNARY>(idst, param1));
}

inline __attribute__((always_inline)) void div_unary_tile(uint32_t idst, uint32_t param1) {
    (llk_math_eltwise_unary_sfpu_binop_with_scalar<APPROX, DIV_UNARY>(idst, param1));
}

inline __attribute__((always_inline)) void rsub_unary_tile(uint32_t idst, uint32_t param1) {
    (llk_math_eltwise_unary_sfpu_binop_with_scalar<APPROX, RSUB_UNARY>(idst, param1));
}




inline __attribute__((always_inline)) void binop_with_scalar_tile_init() { (llk_math_eltwise_unary_sfpu_binop_with_scalar_init<APPROX>()); }

}




       







       





namespace ckernel {



template <bool APPROXIMATE, bool is_fp32_dest_acc_en>
inline void llk_math_eltwise_unary_sfpu_reciprocal(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_reciprocal<APPROXIMATE, is_fp32_dest_acc_en, 8>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_reciprocal_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::reciprocal, APPROXIMATE>(sfpu::recip_init<APPROXIMATE>);
}

}






namespace ckernel {




inline __attribute__((always_inline)) void recip_tile_init() { (llk_math_eltwise_unary_sfpu_reciprocal_init<APPROX>()); }
inline __attribute__((always_inline)) void recip_tile(uint32_t idst, int vector_mode = (int)VectorMode::RC) {
    (llk_math_eltwise_unary_sfpu_reciprocal<APPROX, DST_ACCUM_MODE>(idst, vector_mode));
}

}




       







       







       






using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8, int RECIPROCAL_ITERATIONS = 2>
inline void calculate_sqrt() {
    _calculate_sqrt_<APPROXIMATION_MODE, ITERATIONS, RECIPROCAL_ITERATIONS>(ITERATIONS);
}

template <bool APPROXIMATION_MODE>
void sqrt_init() {
    _init_sqrt_<APPROXIMATION_MODE>();
}
}
}

namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sqrt(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_sqrt<APPROXIMATE>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_sqrt_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::sqrt, APPROXIMATE>(sfpu::sqrt_init<APPROXIMATE>);
}

}






namespace ckernel {




inline __attribute__((always_inline)) void sqrt_tile_init() { (llk_math_eltwise_unary_sfpu_sqrt_init<APPROX>()); }
inline __attribute__((always_inline)) void sqrt_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_sqrt<APPROX>(idst)); }

}




       
namespace ckernel {
inline __attribute__((always_inline)) void copy_tile_to_dst_init_short(uint32_t cbid, uint32_t transpose = 0) {
   
                                                                 ;
    (llk_math_eltwise_unary_datacopy_init<A2D, DST_ACCUM_MODE, BroadcastType::NONE>( false , false , cbid))
                                                                                    ;
}




inline __attribute__((always_inline)) void copy_tile_init(uint32_t cbid) { copy_tile_to_dst_init_short(cbid); }
inline __attribute__((always_inline)) void copy_tile_to_dst_init_short_with_dt(uint32_t old_cbid, uint32_t new_cbid, uint32_t transpose = 0) {


    ;
    (llk_math_reconfig_data_format_srca<DST_ACCUM_MODE>(old_cbid, new_cbid));
    copy_tile_to_dst_init_short(new_cbid, transpose);
}
inline __attribute__((always_inline)) void copy_tile(uint32_t in_cb_id, uint32_t in_tile_index, uint32_t dst_tile_index) {
   
                                  ;
    (llk_math_eltwise_unary_datacopy<A2D, DST_ACCUM_MODE, BroadcastType::NONE, UnpackToDestEn>( dst_tile_index, in_cb_id))
                                   ;
}

inline __attribute__((always_inline)) void copy_block_matmul_partials(
    uint32_t in_cb_id, uint32_t start_in_tile_index, uint32_t start_dst_tile_index, uint32_t ntiles) {
   
                                                       ;
    (llk_math_eltwise_unary_datacopy_block<A2D, DST_ACCUM_MODE, BroadcastType::NONE, UnpackToDestEn>( start_dst_tile_index, ntiles, in_cb_id))
                                                 ;
}

}






       




       
namespace ckernel {

template <BroadcastType bcast_type>
inline __attribute__((always_inline)) void unary_bcast_init(uint32_t icb, uint32_t ocb) {

    const auto data_copy_type = (bcast_type == BroadcastType::NONE) ? A2D : B2D;
    const bool enable_unpack_to_dest = data_copy_type == A2D;


    ;
   
                                                            ;

    (llk_math_eltwise_unary_datacopy_init<data_copy_type, DST_ACCUM_MODE, bcast_type>( false , false , icb))
                                                                                   ;
    (llk_math_pack_sync_init<DST_ACCUM_MODE>());
    (llk_math_hw_configure_disaggregated(icb, icb));

    ;
    ;
    ;
}

template <BroadcastType bcast_type>
inline __attribute__((always_inline)) void unary_bcast(uint32_t icb, uint32_t in_tile_index, uint32_t dst_tile_index) {

    const auto data_copy_type = (bcast_type == BroadcastType::NONE) ? A2D : B2D;
    const bool enable_unpack_to_dest = data_copy_type == A2D;

   
                                                                                                                       ;
    (llk_math_eltwise_unary_datacopy<data_copy_type, DST_ACCUM_MODE, bcast_type, enable_unpack_to_dest>( dst_tile_index, icb))
                              ;
}

template <BroadcastType old_bcast_type, BroadcastType new_bcast_type>
void reconfigure_unary_bcast(uint32_t old_icb, uint32_t new_icb, uint32_t old_ocb, uint32_t new_ocb) {


    const auto data_copy_type = (new_bcast_type == BroadcastType::NONE) ? A2D : B2D;
    const bool enable_unpack_to_dest = data_copy_type == A2D;
    const std::uint32_t new_operand_id = get_operand_id(new_icb);
    const std::uint32_t old_operand_id = get_operand_id(old_icb);
    bool unpacker_src_format_change = unpack_src_format[new_operand_id] != unpack_src_format[old_operand_id];
    bool unpacker_dst_format_change = unpack_dst_format[new_operand_id] != unpack_dst_format[old_operand_id];
    bool bcast_type_change = (old_bcast_type != new_bcast_type);

    if (unpacker_src_format_change || unpacker_dst_format_change) {

        ;
    }

    if (unpacker_src_format_change || unpacker_dst_format_change || bcast_type_change) {
       
                                                                    ;
    }

    if (unpacker_dst_format_change) {
        (llk_math_hw_configure_disaggregated(new_icb, new_icb));
    }

    if (unpacker_dst_format_change || bcast_type_change) {
        (llk_math_eltwise_unary_datacopy_init<data_copy_type, DST_ACCUM_MODE, new_bcast_type>( false , false , new_icb))
                                                                                           ;
    }


    ;
}




inline __attribute__((always_inline)) void sub_tiles_bcast_cols(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWSUB, BroadcastType::COL, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}




inline __attribute__((always_inline)) void sub_tiles_bcast_scalar(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWSUB, BroadcastType::SCALAR, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}




inline __attribute__((always_inline)) void mul_tiles_bcast_cols(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWMUL, BroadcastType::COL, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}




inline __attribute__((always_inline)) void mul_tiles_bcast_rows(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWMUL, BroadcastType::ROW, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}




inline __attribute__((always_inline)) void add_tiles_bcast_rows(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWADD, BroadcastType::ROW, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}




inline __attribute__((always_inline)) void add_tiles_bcast_cols(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWADD, BroadcastType::COL, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}




inline __attribute__((always_inline)) void add_tiles_bcast_scalar(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< EltwiseBinaryType::ELWADD, BroadcastType::SCALAR, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}
template <EltwiseBinaryType tBcastOp, BroadcastType tBcastDim>
void init_bcast(uint32_t icb0, uint32_t icb1, uint32_t ocb) {
    if constexpr (tBcastOp == ELWMUL) {
        (llk_math_eltwise_binary_init<tBcastOp, tBcastDim, MATH_FIDELITY>());
    } else {
        (llk_math_eltwise_binary_init<tBcastOp, tBcastDim>());
    }

    ;
    ;






    ;
    ;
    ;

    (llk_math_pack_sync_init<DST_ACCUM_MODE>());
    (llk_math_hw_configure_disaggregated(icb0, icb1));
}




template <EltwiseBinaryType tBcastOp, BroadcastType tBcastDim>
inline __attribute__((always_inline)) void any_tiles_bcast(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary<tBcastOp, tBcastDim, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>( icb0, icb1, idst, true))
                                 ;
    ;
}
template <BroadcastType tBcastDim>
inline __attribute__((always_inline)) void add_tiles_bcast(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    any_tiles_bcast<EltwiseBinaryType::ELWADD, tBcastDim>(icb0, icb1, itile0, itile1, idst);
}




template <BroadcastType tBcastDim>
inline __attribute__((always_inline)) void sub_tiles_bcast(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    any_tiles_bcast<EltwiseBinaryType::ELWSUB, tBcastDim>(icb0, icb1, itile0, itile1, idst);
}




template <BroadcastType tBcastDim>
inline __attribute__((always_inline)) void mul_tiles_bcast(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    any_tiles_bcast<EltwiseBinaryType::ELWMUL, tBcastDim>(icb0, icb1, itile0, itile1, idst);
}





inline __attribute__((always_inline)) void add_bcast_rows_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init_with_operands<ELWADD, BroadcastType::ROW, MATH_FIDELITY>(icb0, icb1));
    ;
}





inline __attribute__((always_inline)) void add_bcast_cols_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init<ELWADD, BroadcastType::COL>());

    ;
}





inline __attribute__((always_inline)) void add_bcast_scalar_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init<ELWADD, BroadcastType::SCALAR, MATH_FIDELITY>());

    ;
}





inline __attribute__((always_inline)) void mul_tiles_bcast_scalar_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init_with_operands<ELWMUL, BroadcastType::SCALAR, MATH_FIDELITY>(icb0, icb1));

    ;
}




inline __attribute__((always_inline)) void mul_tiles_bcast_scalar(uint32_t icb0, uint32_t icb1, uint32_t itile0, uint32_t itile1, uint32_t idst) {
    (llk_math_eltwise_binary< ELWMUL, BroadcastType::SCALAR, DST_ACCUM_MODE, MATH_FIDELITY, EltwiseBinaryReuseDestType::NONE>(icb0, icb1, idst, true))




                                                                     ;
    ;
}





inline __attribute__((always_inline)) void mul_bcast_cols_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init<ELWMUL, BroadcastType::COL, MATH_FIDELITY>());

    ;
}




inline __attribute__((always_inline)) void mul_bcast_rows_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init<ELWMUL, BroadcastType::ROW, MATH_FIDELITY>());

    ;
}





inline __attribute__((always_inline)) void sub_bcast_cols_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init_with_operands<ELWSUB, BroadcastType::COL, MATH_FIDELITY>(icb0, icb1));

    ;
}





inline __attribute__((always_inline)) void sub_tiles_bcast_scalar_init_short(uint32_t icb0, uint32_t icb1) {
    (llk_math_eltwise_binary_init<ELWSUB, BroadcastType::SCALAR, MATH_FIDELITY>());

    ;
}

}






       
namespace ckernel {
inline __attribute__((always_inline)) void unary_ne_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_ne<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_ne_tile_init() { (llk_math_eltwise_unary_sfpu_unary_ne_init<APPROX>()); }
inline __attribute__((always_inline)) void unary_ne_tile_int32(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_ne_int32<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_eq_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_eq<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_eq_tile_init() { (llk_math_eltwise_unary_sfpu_unary_eq_init<APPROX>()); }
inline __attribute__((always_inline)) void unary_eq_tile_int32(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_eq_int32<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_gt_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_gt<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_gt_tile_init() { (llk_math_eltwise_unary_sfpu_unary_gt_init<APPROX>()); }
inline __attribute__((always_inline)) void unary_gt_tile_int32(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_gt_int32<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_ge_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_ge<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_ge_tile_init() { (llk_math_eltwise_unary_sfpu_unary_ge_init<APPROX>()); }
inline __attribute__((always_inline)) void unary_ge_tile_int32(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_ge_int32<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_lt_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_lt<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_lt_tile_int32(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_lt_int32<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_lt_tile_init() { (llk_math_eltwise_unary_sfpu_unary_lt_init<APPROX>()); }
inline __attribute__((always_inline)) void unary_le_tile(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_le<APPROX>(idst, param0));
}
inline __attribute__((always_inline)) void unary_le_tile_int32(uint32_t idst, uint32_t param0) {
    (llk_math_eltwise_unary_sfpu_unary_le_int32<APPROX>(idst, param0));
}




inline __attribute__((always_inline)) void unary_le_tile_init() { (llk_math_eltwise_unary_sfpu_unary_le_init<APPROX>()); }
inline __attribute__((always_inline)) void gtz_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_gtz<APPROX>(idst)); }
inline __attribute__((always_inline)) void gtz_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_gtz_int32<APPROX>(idst)); }




inline __attribute__((always_inline)) void gtz_tile_init() { (llk_math_eltwise_unary_sfpu_gtz_init<APPROX>()); }
inline __attribute__((always_inline)) void nez_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_nez<APPROX>(idst)); }
inline __attribute__((always_inline)) void nez_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_nez_int32<APPROX>(idst)); }




inline __attribute__((always_inline)) void nez_tile_init() { (llk_math_eltwise_unary_sfpu_nez_init<APPROX>()); }
inline __attribute__((always_inline)) void gez_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_gez<APPROX>(idst)); }
inline __attribute__((always_inline)) void gez_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_gez_int32<APPROX>(idst)); }




inline __attribute__((always_inline)) void gez_tile_init() { (llk_math_eltwise_unary_sfpu_gez_init<APPROX>()); }
inline __attribute__((always_inline)) void ltz_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_ltz<APPROX>(idst)); }
inline __attribute__((always_inline)) void ltz_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_ltz_int32<APPROX>(idst)); }




inline __attribute__((always_inline)) void ltz_tile_init() { (llk_math_eltwise_unary_sfpu_ltz_init<APPROX>()); }
inline __attribute__((always_inline)) void eqz_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_eqz<APPROX>(idst)); }
inline __attribute__((always_inline)) void eqz_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_eqz_int32<APPROX>(idst)); }




inline __attribute__((always_inline)) void eqz_tile_init() { (llk_math_eltwise_unary_sfpu_eqz_init<APPROX>()); }
inline __attribute__((always_inline)) void lez_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_lez<APPROX>(idst)); }
inline __attribute__((always_inline)) void lez_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_lez_int32<APPROX>(idst)); }




inline __attribute__((always_inline)) void lez_tile_init() { (llk_math_eltwise_unary_sfpu_lez_init<APPROX>()); }

}






       







       




namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_negative_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::negative, APPROXIMATE>();
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_negative(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_negative_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode);
}

template <bool APPROXIMATE, int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_negative_int(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::_calculate_negative_int_<APPROXIMATE, ITERATIONS>, dst_index, vector_mode);
}

}






namespace ckernel {

inline __attribute__((always_inline)) void negative_tile_init() { (llk_math_eltwise_unary_sfpu_negative_init<APPROX>()); }
inline __attribute__((always_inline)) void negative_tile(uint32_t idst) { (llk_math_eltwise_unary_sfpu_negative<APPROX>(idst)); }

inline __attribute__((always_inline)) void negative_tile_int32(uint32_t idst) { (llk_math_eltwise_unary_sfpu_negative_int<APPROX>(idst)); }

}




       







       







       





namespace ckernel {
namespace sfpu {

__attribute__((always_inline)) inline sfpi::vFloat sfpu_exp(sfpi::vFloat val) { return _sfpu_exp_(val); }

template <
    bool APPROXIMATION_MODE,
    bool FAST_APPROX,
    bool SCALE_EN = false,
    int ITERATIONS = 8,
    bool SKIP_POSITIVE_CHECK = false>
void calculate_exponential(const uint exp_base_scale_factor = p_sfpu::kCONST_1_FP16B) {
    _calculate_exponential_<APPROXIMATION_MODE, SCALE_EN, ITERATIONS, FAST_APPROX, SKIP_POSITIVE_CHECK>(
        exp_base_scale_factor);
}

template <bool APPROXIMATION_MODE, bool FAST_APPROX, uint32_t scale = 0x3F800000>
void exp_init() {
    _init_exponential_<APPROXIMATION_MODE, FAST_APPROX, scale>();
}

}
}

namespace ckernel {



template <
    bool APPROXIMATE,
    bool FAST_APPROX,
    bool SCALE_EN = false,
    bool SKIP_POSITIVE_CHECK = false,
    int ITERATIONS = 8>
inline void llk_math_eltwise_unary_sfpu_exponential(
    uint dst_index,
    int vector_mode = (int)VectorMode::RC,
    int param0 = p_sfpu::kCONST_1_FP16B ) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_exponential<APPROXIMATE, FAST_APPROX, SCALE_EN, ITERATIONS, SKIP_POSITIVE_CHECK>,
        dst_index,
        vector_mode,
        param0);
}

template <bool APPROXIMATE, bool FAST_APPROX, uint32_t scale = p_sfpu::kCONST_1_FP16B>
inline void llk_math_eltwise_unary_sfpu_exponential_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::exponential, APPROXIMATE>(
        sfpu::exp_init<APPROXIMATE, FAST_APPROX, scale>);
}

}






namespace ckernel {
template <bool approx = false, bool fast_and_approx = true, uint32_t scale = 0x3F800000>
inline __attribute__((always_inline)) void exp_tile_init() {
    (llk_math_eltwise_unary_sfpu_exponential_init<approx, fast_and_approx, scale>());
}
template <
    bool approx = false,
    bool fast_and_approx = true,
    bool scale_en = false,
    bool skip_positive_check = false,
    int iterations = 8>
inline __attribute__((always_inline)) void exp_tile(uint32_t idst, int vector_mode = (int)VectorMode::RC, uint16_t scale = p_sfpu::kCONST_1_FP16B) {
    (llk_math_eltwise_unary_sfpu_exponential<approx, fast_and_approx, scale_en, skip_positive_check, iterations>( idst, vector_mode, scale))
                                   ;
}

}







       







       





       






using namespace sfpi;

namespace ckernel {
namespace sfpu {

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_mask() {
    const bool exponent_size_8 = true;
    const int mask_val_idx = 32;
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat mask = dst_reg[mask_val_idx];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(mask, exponent_size_8)); { dst_reg[0] = vConst0; }
        };
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_int_mask() {
    const int mask_idx = 32;
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vInt mask = dst_reg[mask_idx];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(mask == 0); { dst_reg[0] = vConst0; }
        };
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int ITERATIONS = 8>
inline void calculate_mask_posinf() {
    const bool exponent_size_8 = true;
    const int mask_val_idx = 32;
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        vFloat mask = dst_reg[mask_val_idx];
        { sfpi::__vCCCtrl __cc; __cc.mark_top(); __cc.cc_if(_sfpu_is_fp16_zero_(mask, exponent_size_8)); { dst_reg[0] = std::numeric_limits<float>::infinity(); }
        };
        dst_reg++;
    }
}

}
}



namespace ckernel {



template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_mask_init() {
    llk_math_eltwise_unary_sfpu_init<SfpuType::mask, APPROXIMATE>();
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_mask_posinf(uint dst_index, int vector_mode = (int)VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        ckernel::sfpu::calculate_mask_posinf<APPROXIMATE>, dst_index, vector_mode);
}

template <bool APPROXIMATE>
inline void llk_math_eltwise_unary_sfpu_mask(
    uint dst_index, DataFormat data_format, int vector_mode = (int)VectorMode::RC) {
    if (data_format == DataFormat::Float16_b || data_format == DataFormat::Float16) {
        _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
            ckernel::sfpu::calculate_mask<APPROXIMATE>, dst_index, vector_mode);
    } else if (data_format == DataFormat::Int32) {
        _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
            ckernel::sfpu::calculate_int_mask<APPROXIMATE>, dst_index, vector_mode);
    }
}

}






namespace ckernel {

inline __attribute__((always_inline)) void mask_tile_init() {
    (llk_math_eltwise_unary_sfpu_mask_init<true>());
}
inline __attribute__((always_inline)) void mask_tile(uint32_t idst_data, uint32_t idst2_mask, DataFormat data_format = DataFormat::Float16_b) {
    (llk_math_eltwise_unary_sfpu_mask<true>(idst_data, data_format));
}

inline __attribute__((always_inline)) void mask_posinf_tile(uint32_t idst_data, uint32_t idst2_mask) {
    (llk_math_eltwise_unary_sfpu_mask_posinf<true>(idst_data));
}

}




       
namespace ckernel {
template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW, bool fp32_transpose = false>
inline __attribute__((always_inline)) void reduce_init(uint32_t icb, uint32_t icb_scaler, uint32_t ocb) {
    ;
    (llk_math_reduce_init<reduce_type, reduce_dim, MATH_FIDELITY>());
    ;
}
inline __attribute__((always_inline)) void reduce_uninit() { ; }
template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW, bool fp32_transpose = false>
inline __attribute__((always_inline)) void reduce_tile(uint32_t icb, uint32_t icb_scaler, uint32_t itile, uint32_t itile_sclaer, uint32_t idst) {
    (llk_math_reduce<reduce_type, reduce_dim, DST_ACCUM_MODE, MATH_FIDELITY, false, fp32_transpose>( icb, icb_scaler, idst))
                                ;
    ;
}
template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW, bool fp32_transpose = false>
inline __attribute__((always_inline)) void reduce_tile_math(uint32_t idst, uint32_t num_faces = 4) {
    (llk_math_reduce<reduce_type, reduce_dim, DST_ACCUM_MODE, MATH_FIDELITY, false, fp32_transpose>( idst, num_faces))
                          ;
}

}



inline __attribute__((always_inline)) void ACQ() { acquire_dst(); }
inline __attribute__((always_inline)) void REL() { release_dst(); }

namespace ckernel {

inline __attribute__((always_inline)) void pack_tile_with_dt(uint32_t ifrom_dst, uint32_t icb) {



    pack_tile(ifrom_dst, icb);
}

inline __attribute__((always_inline)) void copy_tile_init_with_dt(uint32_t icb, uint32_t transpose = 0) {



    copy_tile_to_dst_init_short(icb, transpose);
}

inline __attribute__((always_inline)) void add_tiles_init_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    add_tiles_init(icb0, icb1);
}

inline __attribute__((always_inline)) void add_bcast_rows_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    add_bcast_rows_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void add_bcast_cols_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    add_bcast_cols_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void add_bcast_scalar_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    add_bcast_scalar_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void sub_tiles_init_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    sub_tiles_init(icb0, icb1);
}

inline __attribute__((always_inline)) void sub_bcast_rows_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    (llk_math_eltwise_binary_init<ELWSUB, BroadcastType::ROW, MATH_FIDELITY>());

    ;
}

inline __attribute__((always_inline)) void sub_bcast_cols_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    sub_bcast_cols_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void sub_tiles_bcast_scalar_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    sub_tiles_bcast_scalar_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void mul_tiles_init_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    mul_tiles_init(icb0, icb1);
}

inline __attribute__((always_inline)) void mul_bcast_rows_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    mul_bcast_rows_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void mul_bcast_cols_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    mul_bcast_cols_init_short(icb0, icb1);
}

inline __attribute__((always_inline)) void mul_tiles_bcast_scalar_init_short_with_dt(uint32_t icb0 = 0, uint32_t icb1 = 1) {



    mul_tiles_bcast_scalar_init_short(icb0, icb1);
}

template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW>
inline __attribute__((always_inline)) void reduce_init_delta_with_dt(uint32_t ocb = 16, uint32_t icb0 = 0, uint32_t icb1 = 1) {



    reduce_init<reduce_type, reduce_dim>(icb0, icb1, ocb);
}

class ArgFetcher {
private:
    int arg_idx = 0;

public:
    template <typename T>
    T get_next_arg_val() {
        return get_arg_val<T>(arg_idx++);
    }
};

inline __attribute__((always_inline)) void mul_tiles_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();
    mul_tiles_init_with_dt(icb0, icb1);
    mul_tiles(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_and_negative_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();
    mul_tiles_init_with_dt(icb0, icb1);
    mul_tiles(icb0, icb1, itile0, itile1, dst0);

    negative_tile_init();
    negative_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_and_mask_tile_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t maskcb,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t mtile = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1,
    uint32_t popm = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);
    cb_wait_front(maskcb, mtile + 1);

    tile_regs_acquire();
    mul_tiles_init_with_dt(icb0, icb1);
    mul_tiles(icb0, icb1, itile0, itile1, dst0);

    constexpr int dst_mask = 1;
    copy_tile_init_with_dt(maskcb);
    copy_tile(maskcb, mtile, dst_mask);

    mask_tile_init();
    mask_tile(dst0, dst_mask);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }
    if (popm) {
        cb_pop_front(maskcb, popm);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_log_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();
    mul_tiles_init_with_dt(icb0, icb1);
    mul_tiles(icb0, icb1, itile0, itile1, dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_bcast_rows_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();



    mul_bcast_rows_init_short(icb0, icb1);
    mul_tiles_bcast_rows(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_bcast_rows_log_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();



    mul_bcast_rows_init_short(icb0, icb1);
    mul_tiles_bcast_rows(icb0, icb1, itile0, itile1, dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_bcast_cols_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();



    mul_bcast_cols_init_short(icb0, icb1);
    mul_tiles_bcast_cols(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mul_tiles_bcast_cols_log_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();



    mul_bcast_cols_init_short(icb0, icb1);
    mul_tiles_bcast_cols(icb0, icb1, itile0, itile1, dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void copy_tile_to_cb(uint32_t icb, uint32_t ocb, uint32_t itile = 0, uint32_t pop = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void sign_tile_to_cb(uint32_t icb, uint32_t ocb, uint32_t itile = 0, uint32_t pop = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst0);

    sign_tile_init();
    sign_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void add_tiles_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();
    add_tiles_init_with_dt(icb0, icb1);
    add_tiles(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void mask_tile_to_cb(
    uint32_t icb,
    uint32_t maskcb,
    uint32_t ocb,
    uint32_t itile = 0,
    uint32_t mtile = 0,
    uint32_t pop = 1,
    uint32_t popm = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;
    constexpr int dst_mask = 1;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);
    cb_wait_front(maskcb, mtile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst0);

    copy_tile_init_with_dt(maskcb);
    copy_tile(maskcb, mtile, dst_mask);

    mask_tile_init();
    mask_tile(dst0, dst_mask);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    if (popm) {
        cb_pop_front(maskcb, popm);
    }

    cb_push_back(ocb, onetile);
}

template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW>
inline __attribute__((always_inline)) void reduce_tile_to_cb(
    uint32_t icb0, uint32_t icb1, uint32_t ocb, uint32_t size, uint32_t pop0 = 1, uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    tile_regs_acquire();
    cb_wait_front(icb1, onetile);

    reduce_init_delta_with_dt<reduce_type, reduce_dim>(ocb, icb0, icb1);
    for (uint32_t x = 0; x < size; ++x) {
        cb_wait_front(icb0, x + 1);

        constexpr uint32_t bcast_scaler0 = 0;
        reduce_tile<reduce_type, reduce_dim>(icb0, icb1, x, bcast_scaler0, dst0);
    }
    reduce_uninit();
    tile_regs_commit();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void sub_tiles_bcast_cols_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();



    sub_bcast_cols_init_short(icb0, icb1);
    sub_tiles_bcast<BroadcastType::COL>(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void sub_tiles_bcast_rows_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);

    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();




    {
        (llk_math_eltwise_binary_init<ELWSUB, BroadcastType::ROW, MATH_FIDELITY>());
        ;
    }
    sub_tiles_bcast<BroadcastType::ROW>(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void sub_tiles_to_cb(
    uint32_t icb0,
    uint32_t icb1,
    uint32_t ocb,
    uint32_t itile0 = 0,
    uint32_t itile1 = 0,
    uint32_t pop0 = 1,
    uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb0, itile0 + 1);
    cb_wait_front(icb1, itile1 + 1);

    tile_regs_acquire();
    sub_tiles_init_with_dt(icb0, icb1);
    sub_tiles(icb0, icb1, itile0, itile1, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void exp_tile_to_cb(uint32_t icb, uint32_t ocb, uint32_t itile = 0, uint32_t dst = 0, uint32_t pop = 1) {
    constexpr uint32_t onetile = 1;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst);

    exp_tile_init();
    exp_tile(dst);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void rexp_tile_to_cb(uint32_t icb, uint32_t ocb, uint32_t itile = 0, uint32_t dst = 0, uint32_t pop = 1) {
    constexpr uint32_t onetile = 1;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst);

    negative_tile_init();
    negative_tile(dst);

    exp_tile_init();
    exp_tile(dst);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void exp_tile_and_mask_tile_to_cb(
    uint32_t icb,
    uint32_t maskcb,
    uint32_t ocb,
    uint32_t itile = 0,
    uint32_t mtile = 0,
    uint32_t pop = 1,
    uint32_t popm = 1,
    uint32_t dst = 0,
    uint32_t dst_mask = 1) {
    constexpr uint32_t onetile = 1;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);
    cb_wait_front(maskcb, mtile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst);

    if (pop) {
        cb_pop_front(icb, pop);
    }

    exp_tile_init();
    exp_tile(dst);

    copy_tile_init_with_dt(maskcb);
    copy_tile(maskcb, mtile, dst_mask);

    mask_tile_init();
    mask_tile(dst, dst_mask);
    tile_regs_commit();

    if (popm) {
        cb_pop_front(maskcb, popm);
    }

    tile_regs_wait();
    pack_tile_with_dt(dst, ocb);
    tile_regs_release();

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void rexp_tile_and_mask_tile_to_cb(
    uint32_t icb,
    uint32_t maskcb,
    uint32_t ocb,
    uint32_t itile = 0,
    uint32_t mtile = 0,
    uint32_t pop = 1,
    uint32_t popm = 1,
    uint32_t dst = 0,
    uint32_t dst_mask = 1) {
    constexpr uint32_t onetile = 1;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);
    cb_wait_front(maskcb, mtile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst);

    if (pop) {
        cb_pop_front(icb, pop);
    }

    negative_tile_init();
    negative_tile(dst);

    exp_tile_init();
    exp_tile(dst);

    copy_tile_init_with_dt(maskcb);
    copy_tile(maskcb, mtile, dst_mask);

    mask_tile_init();
    mask_tile(dst, dst_mask);
    tile_regs_commit();

    if (popm) {
        cb_pop_front(maskcb, popm);
    }

    tile_regs_wait();
    pack_tile_with_dt(dst, ocb);
    tile_regs_release();

    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void recip_tile_to_cb(uint32_t icb, uint32_t ocb, uint32_t itile = 0, uint32_t pop = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst0);

    recip_tile_init();
    recip_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    cb_push_back(ocb, onetile);
}

inline __attribute__((always_inline)) void log_tile_to_cb(uint32_t icb, uint32_t ocb, uint32_t itile = 0, uint32_t pop = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb, itile + 1);

    tile_regs_acquire();
    copy_tile_init_with_dt(icb);
    copy_tile(icb, itile, dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    if (pop) {
        cb_pop_front(icb, pop);
    }
    cb_push_back(ocb, onetile);
}

template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW>
inline __attribute__((always_inline)) void reduce_and_recip_tile_to_cb(
    uint32_t icb0, uint32_t icb1, uint32_t ocb, uint32_t size, uint32_t pop0 = 1, uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb1, onetile);

    tile_regs_acquire();
    reduce_init_delta_with_dt<reduce_type, reduce_dim>(ocb, icb0, icb1);
    for (uint32_t x = 0; x < size; ++x) {
        cb_wait_front(icb0, x + 1);

        constexpr uint32_t bcast_scaler0 = 0;
        reduce_tile<reduce_type, reduce_dim>(icb0, icb1, x, bcast_scaler0, dst0);
    }
    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    reduce_uninit();

    recip_tile_init();
    recip_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    cb_push_back(ocb, onetile);
}

template <PoolType reduce_type = PoolType::SUM, ReduceDim reduce_dim = ReduceDim::REDUCE_ROW>
inline __attribute__((always_inline)) void reduce_and_log_tile_to_cb(
    uint32_t icb0, uint32_t icb1, uint32_t ocb, uint32_t size, uint32_t pop0 = 1, uint32_t pop1 = 1) {
    constexpr uint32_t onetile = 1;
    constexpr int dst0 = 0;

    cb_reserve_back(ocb, onetile);
    cb_wait_front(icb1, onetile);

    tile_regs_acquire();
    reduce_init_delta_with_dt<reduce_type, reduce_dim>(ocb, icb0, icb1);
    for (uint32_t x = 0; x < size; ++x) {
        cb_wait_front(icb0, x + 1);

        constexpr uint32_t bcast_scaler0 = 0;
        reduce_tile<reduce_type, reduce_dim>(icb0, icb1, x, bcast_scaler0, dst0);
    }
    if (pop0) {
        cb_pop_front(icb0, pop0);
    }
    if (pop1) {
        cb_pop_front(icb1, pop1);
    }

    reduce_uninit();

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, ocb);
    tile_regs_release();

    cb_push_back(ocb, onetile);
}


inline __attribute__((always_inline)) void power_tile_to_cb(
    std::uint8_t cb_x,
    std::uint8_t cb_xpow,
    std::uint8_t cb_logx,
    std::uint8_t cb_decimal,
    std::uint8_t cb_exp_lxmd,
    std::uint8_t cb_correct_xpow,
    uint32_t p,
    bool p_is_negative) {
    constexpr uint32_t onetile = 1;
    constexpr uint32_t dst0 = 0;


    tile_regs_acquire();
    cb_wait_front(cb_x, onetile);
    cb_reserve_back(cb_xpow, onetile);

    copy_tile_init_with_dt(cb_x);
    copy_tile(cb_x, 0, dst0);

    power_tile_init();
    power_tile(dst0, p);

    if (p_is_negative) {
        recip_tile_init();
        recip_tile(dst0);
    }
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_xpow);
    tile_regs_release();

    cb_push_back(cb_xpow, onetile);



    tile_regs_acquire();
    cb_reserve_back(cb_logx, onetile);

    copy_tile_init_with_dt(cb_x);
    copy_tile(cb_x, 0, dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_logx);
    tile_regs_release();

    cb_pop_front(cb_x, onetile);
    cb_push_back(cb_logx, onetile);


    tile_regs_acquire();
    cb_wait_front(cb_logx, onetile);
    cb_reserve_back(cb_exp_lxmd, onetile);

    mul_tiles_init_with_dt(cb_logx, cb_decimal);
    mul_tiles(cb_logx, cb_decimal, 0, 0, dst0);

    exp_tile_init();
    exp_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_exp_lxmd);
    tile_regs_release();

    cb_pop_front(cb_logx, onetile);
    cb_push_back(cb_exp_lxmd, onetile);


    tile_regs_acquire();
    cb_wait_front(cb_xpow, onetile);
    cb_wait_front(cb_exp_lxmd, onetile);
    cb_reserve_back(cb_correct_xpow, onetile);

    mul_tiles_init_with_dt(cb_xpow, cb_exp_lxmd);
    mul_tiles(cb_xpow, cb_exp_lxmd, 0, 0, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_correct_xpow);
    tile_regs_release();

    cb_pop_front(cb_xpow, onetile);
    cb_pop_front(cb_exp_lxmd, onetile);
    cb_push_back(cb_correct_xpow, onetile);
}

inline __attribute__((always_inline)) void power_tile_with_abs_x_to_cb(
    std::uint8_t cb_x,
    std::uint8_t cb_xpow,
    std::uint8_t cb_logx,
    std::uint8_t cb_decimal,
    std::uint8_t cb_exp_lxmd,
    std::uint8_t cb_correct_xpow,
    uint32_t p,
    bool p_is_negative) {
    constexpr uint32_t onetile = 1;
    constexpr uint32_t dst0 = 0;


    tile_regs_acquire();
    cb_wait_front(cb_x, onetile);
    cb_reserve_back(cb_xpow, onetile);

    copy_tile_init_with_dt(cb_x);
    copy_tile(cb_x, 0, dst0);

    abs_tile_init();
    abs_tile(dst0);

    power_tile_init();
    power_tile(dst0, p);

    if (p_is_negative) {
        recip_tile_init();
        recip_tile(dst0);
    }
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_xpow);
    tile_regs_release();

    cb_push_back(cb_xpow, onetile);



    tile_regs_acquire();
    cb_reserve_back(cb_logx, onetile);

    copy_tile_init_with_dt(cb_x);
    copy_tile(cb_x, 0, dst0);

    abs_tile_init();
    abs_tile(dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_logx);
    tile_regs_release();

    cb_pop_front(cb_x, onetile);
    cb_push_back(cb_logx, onetile);


    tile_regs_acquire();
    cb_wait_front(cb_logx, onetile);
    cb_reserve_back(cb_exp_lxmd, onetile);

    mul_tiles_init_with_dt(cb_logx, cb_decimal);
    mul_tiles(cb_logx, cb_decimal, 0, 0, dst0);

    exp_tile_init();
    exp_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_exp_lxmd);
    tile_regs_release();

    cb_pop_front(cb_logx, onetile);
    cb_push_back(cb_exp_lxmd, onetile);


    tile_regs_acquire();
    cb_wait_front(cb_xpow, onetile);
    cb_wait_front(cb_exp_lxmd, onetile);
    cb_reserve_back(cb_correct_xpow, onetile);

    mul_tiles_init_with_dt(cb_xpow, cb_exp_lxmd);
    mul_tiles(cb_xpow, cb_exp_lxmd, 0, 0, dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_correct_xpow);
    tile_regs_release();

    cb_pop_front(cb_xpow, onetile);
    cb_pop_front(cb_exp_lxmd, onetile);
    cb_push_back(cb_correct_xpow, onetile);
}

inline __attribute__((always_inline)) void power_and_recip_tile_to_cb(
    std::uint8_t cb_x,
    std::uint8_t cb_xpow,
    std::uint8_t cb_logx,
    std::uint8_t cb_decimal,
    std::uint8_t cb_exp_lxmd,
    std::uint8_t cb_recip_xpow,
    uint32_t p,
    bool p_is_negative) {
    constexpr uint32_t onetile = 1;
    constexpr uint32_t dst0 = 0;


    cb_wait_front(cb_x, onetile);
    cb_reserve_back(cb_xpow, onetile);

    tile_regs_acquire();
    copy_tile_init_with_dt(cb_x);
    copy_tile(cb_x, 0, dst0);

    power_tile_init();
    power_tile(dst0, p);

    if (p_is_negative) {
        recip_tile_init();
        recip_tile(dst0);
    }
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_xpow);
    tile_regs_release();

    cb_push_back(cb_xpow, onetile);



    cb_reserve_back(cb_logx, onetile);

    tile_regs_acquire();
    copy_tile_init_with_dt(cb_x);
    copy_tile(cb_x, 0, dst0);

    log_tile_init();
    log_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_logx);
    tile_regs_release();

    cb_pop_front(cb_x, onetile);
    cb_push_back(cb_logx, onetile);


    cb_wait_front(cb_logx, onetile);
    cb_reserve_back(cb_exp_lxmd, onetile);

    tile_regs_acquire();
    mul_tiles_init_with_dt(cb_logx, cb_decimal);
    mul_tiles(cb_logx, cb_decimal, 0, 0, dst0);

    exp_tile_init();
    exp_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_exp_lxmd);
    tile_regs_release();

    cb_pop_front(cb_logx, onetile);
    cb_push_back(cb_exp_lxmd, onetile);


    cb_wait_front(cb_xpow, onetile);
    cb_wait_front(cb_exp_lxmd, onetile);
    cb_reserve_back(cb_recip_xpow, onetile);

    tile_regs_acquire();
    mul_tiles_init_with_dt(cb_xpow, cb_exp_lxmd);
    mul_tiles(cb_xpow, cb_exp_lxmd, 0, 0, dst0);

    recip_tile_init();
    recip_tile(dst0);
    tile_regs_commit();

    tile_regs_wait();
    pack_tile_with_dt(dst0, cb_recip_xpow);
    tile_regs_release();

    cb_pop_front(cb_xpow, onetile);
    cb_pop_front(cb_exp_lxmd, onetile);
    cb_push_back(cb_recip_xpow, onetile);
}

inline __attribute__((always_inline)) void copy_tile_to_dst(uint32_t icb, uint32_t itile = 0, uint32_t dst = 0, bool cb_wait_and_pop = true) {
    constexpr uint32_t onetile = 1;
    if (cb_wait_and_pop) {
        cb_wait_front(icb, onetile);
    }
    reconfig_data_format_srca(icb);
    copy_tile_to_dst_init_short(icb);
    copy_tile(icb, itile, dst);
    if (cb_wait_and_pop) {
        cb_pop_front(icb, onetile);
    }
}

inline __attribute__((always_inline)) void pack_tile_from_dst(uint32_t ocb, uint32_t dst = 0) {
    constexpr uint32_t onetile = 1;
    cb_reserve_back(ocb, onetile);
    pack_reconfig_data_format(ocb);
    pack_tile(dst, ocb);
    cb_push_back(ocb, onetile);
}

}



       



namespace cb_adam {
using namespace tt;
inline constexpr auto param_in = CBIndex::c_0;
inline constexpr auto grad = CBIndex::c_1;
inline constexpr auto exp_avg_in = CBIndex::c_2;
inline constexpr auto exp_avg_sq_in = CBIndex::c_3;
inline constexpr auto max_exp_avg_sq_in = CBIndex::c_4;
inline constexpr auto param_out = CBIndex::c_5;
inline constexpr auto exp_avg_out = CBIndex::c_6;
inline constexpr auto exp_avg_sq_out = CBIndex::c_7;
inline constexpr auto max_exp_avg_sq_out = CBIndex::c_8;
inline constexpr auto mask_w = CBIndex::c_9;
inline constexpr auto grad_i = CBIndex::c_10;
inline constexpr auto exp_avg_i = CBIndex::c_11;
inline constexpr auto exp_avg_sq_i = CBIndex::c_12;
inline constexpr auto max_exp_avg_sq_i = CBIndex::c_13;
}

union Scalar {
    float f;
    uint32_t u;
};

inline __attribute__((always_inline)) float to_float(uint32_t bits) {
    Scalar u2f{.u = bits};
    return u2f.f;
}

inline __attribute__((always_inline)) uint32_t to_bits(float f) {
    Scalar f2u{.f = f};
    return f2u.u;
}

using namespace sfpi;

enum {
    ADD = 0,
    SUB = 1,
    MUL = 2,
    RSUB = 3,
};

inline __attribute__((always_inline)) void pack_onetile_to_cb(uint32_t icb = 16, uint32_t ifrom_dst = 0) {
    tile_regs_wait();
    cb_reserve_back(icb, 1);
    pack_tile_with_dt(ifrom_dst, icb);
    cb_push_back(icb, 1);
    tile_regs_release();
}

template <bool APPROXIMATION_MODE, int BINOP_MODE, int ITERATIONS = 8>
inline void calculate_binop_fp32() {
#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG0) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((64) << 0))))));
        if constexpr (BINOP_MODE == ADD) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LCONST_1) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))))




                  ;
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        } else if constexpr (BINOP_MODE == SUB) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x7c << 24) + (((0) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG1) << 4) + ((1) << 0))))));
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LCONST_1) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))))




                  ;
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        } else if constexpr (BINOP_MODE == MUL) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x86 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LREG1) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))))




                  ;
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x8f << 24) + 0))));
        }
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        dst_reg++;
    }
}

template <bool APPROXIMATION_MODE, int UNARY_MODE, int ITERATIONS = 8>
inline void calculate_binop_with_scalar_fp32(uint param) {
    if constexpr (UNARY_MODE == SUB) {
        param ^= 0x80000000u;
    }
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG0) << 20) + ((10) << 16) + ((param & 0xFFFF) << 0)));
    ckernel::instrn_buffer[0] = ((0x71 << 24) + (((p_sfpu::LREG0) << 20) + ((8) << 16) + ((param >> 16) << 0)));

#pragma GCC unroll 8
    for (int d = 0; d < ITERATIONS; d++) {
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x70 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        if constexpr (UNARY_MODE == ADD || UNARY_MODE == SUB) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LCONST_1) << 12) + ((p_sfpu::LREG1) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))))




                  ;
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        } else if constexpr (UNARY_MODE == RSUB) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x85 << 24) + (((p_sfpu::LREG1) << 16) + ((p_sfpu::LCONST_neg1) << 12) + ((p_sfpu::LREG0) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))))




                  ;
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        } else if constexpr (UNARY_MODE == MUL) {
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x86 << 24) + (((p_sfpu::LREG0) << 16) + ((p_sfpu::LREG1) << 12) + ((p_sfpu::LCONST_0) << 8) + ((p_sfpu::LREG1) << 4) + ((0) << 0))))))




                  ;
            __asm__ __volatile__(".ttinsn %0" : : "i"((((0x02 << 24) + 0))));
        }
        __asm__ __volatile__(".ttinsn %0" : : "i"((((0x72 << 24) + (((p_sfpu::LREG1) << 20) + ((0) << 16) + ((ADDR_MOD_3) << 14) + ((0) << 0))))));
        dst_reg++;
    }
}

inline void init_sfpu_default() { llk_math_eltwise_unary_sfpu_init<SfpuType::unused, false>(); }

template <bool APPROXIMATE, int BINOP_MODE>
inline void binary_fp32(uint dst_index, int vector_mode = VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        calculate_binop_fp32<APPROXIMATE, BINOP_MODE>, dst_index, vector_mode);
}

template <bool APPROXIMATE, int UNARY_MODE>
inline void unary_fp32(uint dst_index, uint32_t param1, int vector_mode = VectorMode::RC) {
    _llk_math_eltwise_unary_sfpu_params_<APPROXIMATE>(
        calculate_binop_with_scalar_fp32<APPROXIMATE, UNARY_MODE>, dst_index, vector_mode, param1);
}

namespace chlkc_math {
void math_main() {
    namespace cb = cb_adam;


    constexpr bool amsgrad = get_ct_arg<0>() == 1;


    uint32_t num_tiles = 0;
    const auto upcg1 = get_common_arg_val<uint32_t>(0);
    const auto upcg2 = get_common_arg_val<uint32_t>(1);
    const auto g1_cores = get_common_arg_val<uint32_t>(2);
    const auto g2_cores = get_common_arg_val<uint32_t>(3);
    const auto grid_y = get_common_arg_val<uint32_t>(4);

    uint32_t x = get_relative_logical_x();
    uint32_t y = get_relative_logical_y();
    uint32_t core_linear_id = x * grid_y + y;
    uint32_t total_cores = g1_cores + g2_cores;

    if (core_linear_id >= total_cores) {
        return;
    }

    if (core_linear_id < g1_cores) {
        num_tiles = upcg1;
    } else {
        num_tiles = upcg2;
    }

    const auto step = get_common_arg_val<uint32_t>(5);
    const auto lr_bits = get_common_arg_val<uint32_t>(6);
    const auto beta1_bits = get_common_arg_val<uint32_t>(7);
    const auto beta2_bits = get_common_arg_val<uint32_t>(8);
    const auto eps_bits = get_common_arg_val<uint32_t>(9);
    const auto weight_decay_bits = get_common_arg_val<uint32_t>(10);
    const auto bias_correction1_bits = get_common_arg_val<uint32_t>(11);
    const auto bias_correction2_bits = get_common_arg_val<uint32_t>(12);

    const float lr = to_float(lr_bits);
    const float beta1 = to_float(beta1_bits);
    const float beta2 = to_float(beta2_bits);
    const float eps = to_float(eps_bits);
    const float weight_decay = to_float(weight_decay_bits);
    const float bias_correction1 = to_float(bias_correction1_bits);
    const float bias_correction2 = to_float(bias_correction2_bits);

    constexpr uint32_t onetile = 1;


    constexpr uint32_t dst0 = 0;
    constexpr uint32_t dst1 = 1;
    constexpr uint32_t dst2 = 2;

    binary_op_init_common(cb::param_in, cb::grad_i, cb::param_out);

    for (uint32_t i = 0; i < num_tiles; i++) {
        cb_wait_front(cb::param_in, onetile);
        cb_wait_front(cb::grad, onetile);
        cb_wait_front(cb::exp_avg_in, onetile);
        cb_wait_front(cb::exp_avg_sq_in, onetile);
        if constexpr (amsgrad) {
            cb_wait_front(cb::max_exp_avg_sq_in, onetile);
        }


        tile_regs_acquire();

        copy_tile_init_with_dt(cb::grad);
        copy_tile(cb::grad, 0, dst0);
        copy_tile_init_with_dt(cb::param_in);
        copy_tile(cb::param_in, 0, dst1);
        binop_with_scalar_tile_init();
        mul_unary_tile(dst1, weight_decay_bits);
        init_sfpu_default();
        binary_fp32<false, ADD>(dst0);
        tile_regs_commit();

        pack_onetile_to_cb(cb::grad_i, dst0);


        tile_regs_acquire();
        cb_wait_front(cb::grad_i, onetile);
        cb_reserve_back(cb::exp_avg_i, onetile);
        cb_reserve_back(cb::exp_avg_out, onetile);
        copy_tile_init_with_dt(cb::exp_avg_in);
        copy_tile(cb::exp_avg_in, 0, dst0);
        copy_tile_init_with_dt(cb::grad_i);
        copy_tile(cb::grad_i, 0, dst1);
        binop_with_scalar_tile_init();
        mul_unary_tile(dst0, beta1_bits);
        binop_with_scalar_tile_init();
        mul_unary_tile(dst1, to_bits(1 - beta1));
        init_sfpu_default();
        binary_fp32<false, ADD>(dst0);
        tile_regs_commit();

        tile_regs_wait();
        pack_tile_with_dt(dst0, cb::exp_avg_i);
        pack_tile_with_dt(dst0, cb::exp_avg_out);
        cb_push_back(cb::exp_avg_i, onetile);
        cb_push_back(cb::exp_avg_out, onetile);
        tile_regs_release();



        tile_regs_acquire();
        cb_reserve_back(cb::exp_avg_sq_i, onetile);
        cb_reserve_back(cb::exp_avg_sq_out, onetile);
        copy_tile_init_with_dt(cb::exp_avg_sq_in);
        copy_tile(cb::exp_avg_sq_in, 0, dst0);
        copy_tile_init_with_dt(cb::grad_i);
        copy_tile(cb::grad_i, 0, dst1);
        copy_tile_init_with_dt(cb::grad_i);
        copy_tile(cb::grad_i, 0, dst2);
        binop_with_scalar_tile_init();
        mul_unary_tile(dst0, beta2_bits);
        init_sfpu_default();
        binary_fp32<false, MUL>(dst1);
        binop_with_scalar_tile_init();
        mul_unary_tile(dst1, to_bits(1.0f - beta2));
        init_sfpu_default();
        binary_fp32<false, ADD>(dst0);
        tile_regs_commit();

        tile_regs_wait();
        pack_tile_with_dt(dst0, cb::exp_avg_sq_i);
        pack_tile_with_dt(dst0, cb::exp_avg_sq_out);
        cb_push_back(cb::exp_avg_sq_i, onetile);
        cb_push_back(cb::exp_avg_sq_out, onetile);
        cb_pop_front(cb::grad_i, onetile);
        tile_regs_release();

        if constexpr (amsgrad) {


            tile_regs_acquire();
            cb_wait_front(cb::exp_avg_sq_i, onetile);
            cb_reserve_back(cb::max_exp_avg_sq_i, onetile);
            cb_reserve_back(cb::max_exp_avg_sq_out, onetile);
            copy_tile_init_with_dt(cb::max_exp_avg_sq_in);
            copy_tile(cb::max_exp_avg_sq_in, 0, dst0);
            copy_tile_init_with_dt(cb::exp_avg_sq_i);
            copy_tile(cb::exp_avg_sq_i, 0, dst1);
            max_tile_init();
            max_tile(dst0, dst1);
            tile_regs_commit();

            tile_regs_wait();
            pack_tile_with_dt(dst0, cb::max_exp_avg_sq_i);
            pack_tile_with_dt(dst0, cb::max_exp_avg_sq_out);
            cb_push_back(cb::max_exp_avg_sq_i, onetile);
            cb_push_back(cb::max_exp_avg_sq_out, onetile);
            cb_pop_front(cb::exp_avg_sq_i, onetile);
            tile_regs_release();
        }







        tile_regs_acquire();
        cb_wait_front(cb::exp_avg_i, onetile);
        if constexpr (amsgrad) {
            cb_wait_front(cb::max_exp_avg_sq_i, onetile);
        } else {
            cb_wait_front(cb::exp_avg_sq_i, onetile);
        }

        copy_tile_init_with_dt(cb::param_in);
        copy_tile(cb::param_in, 0, dst0);
        copy_tile_init_with_dt(cb::exp_avg_i);
        copy_tile(cb::exp_avg_i, 0, dst1);
        if constexpr (amsgrad) {
            copy_tile_init_with_dt(cb::max_exp_avg_sq_i);
            copy_tile(cb::max_exp_avg_sq_i, 0, dst2);
        } else {
            copy_tile_init_with_dt(cb::exp_avg_sq_i);
            copy_tile(cb::exp_avg_sq_i, 0, dst2);
        }
        binop_with_scalar_tile_init();
        unary_fp32<false, MUL>(dst1, to_bits(lr / bias_correction1));
        binop_with_scalar_tile_init();
        unary_fp32<false, MUL>(dst2, to_bits(1.f / bias_correction2));
        sqrt_tile_init();
        sqrt_tile(dst2);
        binop_with_scalar_tile_init();
        unary_fp32<false, ADD>(dst2, eps_bits);
        recip_tile_init();
        recip_tile(dst2);
        init_sfpu_default();
        binary_fp32<false, MUL>(dst1);
        init_sfpu_default();
        binary_fp32<false, SUB>(dst0);
        tile_regs_commit();

        cb_pop_front(cb::exp_avg_i, onetile);
        if constexpr (amsgrad) {
            cb_pop_front(cb::max_exp_avg_sq_i, onetile);
        } else {
            cb_pop_front(cb::exp_avg_sq_i, onetile);
        }
        pack_onetile_to_cb(cb::param_out, dst0);
        cb_pop_front(cb::param_in, onetile);
        cb_pop_front(cb::grad, onetile);
        cb_pop_front(cb::exp_avg_in, onetile);
        cb_pop_front(cb::exp_avg_sq_in, onetile);
        if constexpr (amsgrad) {
            cb_pop_front(cb::max_exp_avg_sq_in, onetile);
        }
    }
}
}
uint run_kernel() {

    zeroacc();
    chlkc_math::math_main();
    return 0;
}





       

       










       





       
static inline void mark_stack_usage() {}
static inline int measure_stack_usage() { return 0; }
static inline void record_stack_usage(uint32_t) {}


uint32_t unp_cfg_context = 0;
uint32_t pack_sync_tile_dst_ptr = 0;
uint32_t math_sync_tile_dst_index = 0;
uint32_t gl_alu_format_spec_reg = 0;
uint32_t op_info_offset = 0;

namespace ckernel
{
volatile __attribute__((rvtt_reg_ptr)) uint* regfile = reinterpret_cast<volatile uint*>(0xFFE00000);
volatile __attribute__((rvtt_reg_ptr)) uint * pc_buf_base = reinterpret_cast<volatile uint *>(0xFFE80000);
volatile __attribute__((rvtt_reg_ptr)) uint * mailbox_base[4] = {
    reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEC0000), reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEC1000),
    reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEC2000), reinterpret_cast<volatile uint __attribute__((rvtt_reg_ptr)) *>(0xFFEC3000)
};
}

extern "C" [[gnu::section(".start")]]
uint32_t _start() {

    asm("0: .reloc 0b, R_RISCV_NONE, __global_pointer$");
    mark_stack_usage();







    extern uint32_t __kernel_data_lma[];
    do_crt1((uint32_t __attribute__((rvtt_l1_ptr)) *)__kernel_data_lma);
    wait_for_go_message();
    ;
   
    ;
    run_kernel();
    ;
    ;

    return measure_stack_usage();
}
